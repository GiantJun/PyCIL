2022-05-25 10:07:45,196 [trainer.py] => config: options/bic.yaml
2022-05-25 10:07:45,196 [trainer.py] => prefix: reproduce
2022-05-25 10:07:45,196 [trainer.py] => device: [device(type='cuda', index=0)]
2022-05-25 10:07:45,196 [trainer.py] => seed: 1993
2022-05-25 10:07:45,196 [trainer.py] => num_workers: 8
2022-05-25 10:07:45,196 [trainer.py] => dataset: cifar100
2022-05-25 10:07:45,197 [trainer.py] => shuffle: False
2022-05-25 10:07:45,197 [trainer.py] => method: bic
2022-05-25 10:07:45,197 [trainer.py] => eval_metric: acc
2022-05-25 10:07:45,197 [trainer.py] => backbone: resnet32
2022-05-25 10:07:45,197 [trainer.py] => pretrained: True
2022-05-25 10:07:45,197 [trainer.py] => save_models: False
2022-05-25 10:07:45,197 [trainer.py] => memory_size: 2000
2022-05-25 10:07:45,197 [trainer.py] => fixed_memory: False
2022-05-25 10:07:45,197 [trainer.py] => sampling_method: icarl
2022-05-25 10:07:45,197 [trainer.py] => init_cls: 10
2022-05-25 10:07:45,197 [trainer.py] => increment: 10
2022-05-25 10:07:45,197 [trainer.py] => incre_type: cil
2022-05-25 10:07:45,197 [trainer.py] => T: 2
2022-05-25 10:07:45,197 [trainer.py] => split_ratio: 0.1
2022-05-25 10:07:45,197 [trainer.py] => epochs: 170
2022-05-25 10:07:45,197 [trainer.py] => lrate: 0.1
2022-05-25 10:07:45,197 [trainer.py] => milestones: [60, 100, 140]
2022-05-25 10:07:45,197 [trainer.py] => lrate_decay: 0.1
2022-05-25 10:07:45,197 [trainer.py] => batch_size: 128
2022-05-25 10:07:45,198 [trainer.py] => weight_decay: 0.0002
2022-05-25 10:07:46,944 [data_manager.py] => class order: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]
2022-05-25 10:07:47,291 [trainer.py] => All params: 464154
2022-05-25 10:07:47,291 [trainer.py] => Trainable params: 464154
2022-05-25 10:07:47,291 [bic.py] => Learning on 0-10
2022-05-25 10:07:47,303 [bic.py] => Parameters of bias layer:
2022-05-25 10:07:47,303 [bic.py] => 0 => 1.000, 0.000
2022-05-25 10:07:53,506 [bic.py] => training => Task 0, Epoch 1/170 => Loss 2.778, Train_accy 12.780, Test_accy 13.100
2022-05-25 10:07:56,502 [bic.py] => training => Task 0, Epoch 2/170 => Loss 2.231, Train_accy 20.280, Test_accy 23.300
2022-05-25 10:07:59,426 [bic.py] => training => Task 0, Epoch 3/170 => Loss 2.064, Train_accy 24.040, Test_accy 26.100
2022-05-25 10:08:02,275 [bic.py] => training => Task 0, Epoch 4/170 => Loss 1.959, Train_accy 30.720, Test_accy 33.700
2022-05-25 10:08:05,254 [bic.py] => training => Task 0, Epoch 5/170 => Loss 1.923, Train_accy 34.560, Test_accy 36.300
2022-05-25 10:08:08,225 [bic.py] => training => Task 0, Epoch 6/170 => Loss 1.864, Train_accy 33.020, Test_accy 34.800
2022-05-25 10:08:11,225 [bic.py] => training => Task 0, Epoch 7/170 => Loss 1.786, Train_accy 37.260, Test_accy 38.500
2022-05-25 10:08:14,180 [bic.py] => training => Task 0, Epoch 8/170 => Loss 1.712, Train_accy 34.700, Test_accy 38.100
2022-05-25 10:08:17,179 [bic.py] => training => Task 0, Epoch 9/170 => Loss 1.698, Train_accy 42.360, Test_accy 45.200
2022-05-25 10:08:20,105 [bic.py] => training => Task 0, Epoch 10/170 => Loss 1.616, Train_accy 43.140, Test_accy 48.900
2022-05-25 10:08:23,069 [bic.py] => training => Task 0, Epoch 11/170 => Loss 1.539, Train_accy 44.040, Test_accy 45.000
2022-05-25 10:08:25,963 [bic.py] => training => Task 0, Epoch 12/170 => Loss 1.465, Train_accy 49.480, Test_accy 50.100
2022-05-25 10:08:28,880 [bic.py] => training => Task 0, Epoch 13/170 => Loss 1.409, Train_accy 54.540, Test_accy 57.000
2022-05-25 10:08:31,831 [bic.py] => training => Task 0, Epoch 14/170 => Loss 1.324, Train_accy 50.420, Test_accy 52.800
2022-05-25 10:08:34,866 [bic.py] => training => Task 0, Epoch 15/170 => Loss 1.265, Train_accy 53.980, Test_accy 53.800
2022-05-25 10:08:37,871 [bic.py] => training => Task 0, Epoch 16/170 => Loss 1.257, Train_accy 49.660, Test_accy 51.000
2022-05-25 10:08:40,889 [bic.py] => training => Task 0, Epoch 17/170 => Loss 1.218, Train_accy 55.040, Test_accy 57.300
2022-05-25 10:08:43,916 [bic.py] => training => Task 0, Epoch 18/170 => Loss 1.114, Train_accy 58.020, Test_accy 57.500
2022-05-25 10:08:46,883 [bic.py] => training => Task 0, Epoch 19/170 => Loss 1.196, Train_accy 56.220, Test_accy 57.900
2022-05-25 10:08:49,885 [bic.py] => training => Task 0, Epoch 20/170 => Loss 1.090, Train_accy 55.420, Test_accy 55.200
2022-05-25 10:08:52,809 [bic.py] => training => Task 0, Epoch 21/170 => Loss 1.140, Train_accy 61.620, Test_accy 61.200
2022-05-25 10:08:55,775 [bic.py] => training => Task 0, Epoch 22/170 => Loss 1.003, Train_accy 66.580, Test_accy 65.400
2022-05-25 10:08:58,747 [bic.py] => training => Task 0, Epoch 23/170 => Loss 0.927, Train_accy 68.200, Test_accy 63.400
2022-05-25 10:09:01,764 [bic.py] => training => Task 0, Epoch 24/170 => Loss 0.927, Train_accy 62.760, Test_accy 61.600
2022-05-25 10:09:04,791 [bic.py] => training => Task 0, Epoch 25/170 => Loss 0.858, Train_accy 73.380, Test_accy 67.800
2022-05-25 10:09:07,802 [bic.py] => training => Task 0, Epoch 26/170 => Loss 0.835, Train_accy 72.320, Test_accy 69.500
2022-05-25 10:09:10,811 [bic.py] => training => Task 0, Epoch 27/170 => Loss 0.828, Train_accy 70.540, Test_accy 67.900
2022-05-25 10:09:13,820 [bic.py] => training => Task 0, Epoch 28/170 => Loss 0.766, Train_accy 70.960, Test_accy 67.900
2022-05-25 10:09:16,836 [bic.py] => training => Task 0, Epoch 29/170 => Loss 0.821, Train_accy 72.400, Test_accy 69.300
2022-05-25 10:09:19,919 [bic.py] => training => Task 0, Epoch 30/170 => Loss 0.779, Train_accy 72.700, Test_accy 71.200
2022-05-25 10:09:22,946 [bic.py] => training => Task 0, Epoch 31/170 => Loss 0.731, Train_accy 62.800, Test_accy 60.000
2022-05-25 10:09:25,985 [bic.py] => training => Task 0, Epoch 32/170 => Loss 0.737, Train_accy 65.320, Test_accy 61.800
2022-05-25 10:09:29,063 [bic.py] => training => Task 0, Epoch 33/170 => Loss 0.722, Train_accy 75.820, Test_accy 70.800
2022-05-25 10:09:32,088 [bic.py] => training => Task 0, Epoch 34/170 => Loss 0.617, Train_accy 72.460, Test_accy 67.400
2022-05-25 10:09:35,087 [bic.py] => training => Task 0, Epoch 35/170 => Loss 0.697, Train_accy 69.520, Test_accy 65.000
2022-05-25 10:09:38,155 [bic.py] => training => Task 0, Epoch 36/170 => Loss 0.751, Train_accy 70.560, Test_accy 65.500
2022-05-25 10:09:41,174 [bic.py] => training => Task 0, Epoch 37/170 => Loss 0.703, Train_accy 74.540, Test_accy 72.000
2022-05-25 10:09:44,237 [bic.py] => training => Task 0, Epoch 38/170 => Loss 0.688, Train_accy 78.580, Test_accy 74.500
2022-05-25 10:09:47,346 [bic.py] => training => Task 0, Epoch 39/170 => Loss 0.590, Train_accy 78.180, Test_accy 70.700
2022-05-25 10:09:50,410 [bic.py] => training => Task 0, Epoch 40/170 => Loss 0.592, Train_accy 73.620, Test_accy 73.100
2022-05-25 10:09:53,601 [bic.py] => training => Task 0, Epoch 41/170 => Loss 0.633, Train_accy 78.980, Test_accy 72.900
2022-05-25 10:09:56,677 [bic.py] => training => Task 0, Epoch 42/170 => Loss 0.564, Train_accy 79.960, Test_accy 70.800
2022-05-25 10:09:59,724 [bic.py] => training => Task 0, Epoch 43/170 => Loss 0.567, Train_accy 80.820, Test_accy 72.200
2022-05-25 10:10:02,862 [bic.py] => training => Task 0, Epoch 44/170 => Loss 0.618, Train_accy 76.020, Test_accy 68.400
2022-05-25 10:10:05,850 [bic.py] => training => Task 0, Epoch 45/170 => Loss 0.551, Train_accy 79.300, Test_accy 71.400
2022-05-25 10:10:08,870 [bic.py] => training => Task 0, Epoch 46/170 => Loss 0.526, Train_accy 80.960, Test_accy 71.600
2022-05-25 10:10:11,910 [bic.py] => training => Task 0, Epoch 47/170 => Loss 0.485, Train_accy 76.480, Test_accy 68.600
2022-05-25 10:10:14,880 [bic.py] => training => Task 0, Epoch 48/170 => Loss 0.473, Train_accy 77.780, Test_accy 71.400
2022-05-25 10:10:17,957 [bic.py] => training => Task 0, Epoch 49/170 => Loss 0.675, Train_accy 77.140, Test_accy 71.800
2022-05-25 10:10:20,995 [bic.py] => training => Task 0, Epoch 50/170 => Loss 0.535, Train_accy 79.380, Test_accy 73.400
2022-05-25 10:10:24,151 [bic.py] => training => Task 0, Epoch 51/170 => Loss 0.606, Train_accy 79.440, Test_accy 70.600
2022-05-25 10:10:27,175 [bic.py] => training => Task 0, Epoch 52/170 => Loss 0.529, Train_accy 82.200, Test_accy 75.000
2022-05-25 10:10:30,158 [bic.py] => training => Task 0, Epoch 53/170 => Loss 0.521, Train_accy 81.300, Test_accy 72.700
2022-05-25 10:10:33,087 [bic.py] => training => Task 0, Epoch 54/170 => Loss 0.485, Train_accy 83.380, Test_accy 75.400
2022-05-25 10:10:36,119 [bic.py] => training => Task 0, Epoch 55/170 => Loss 0.417, Train_accy 81.000, Test_accy 73.400
2022-05-25 10:10:39,162 [bic.py] => training => Task 0, Epoch 56/170 => Loss 0.387, Train_accy 87.540, Test_accy 77.600
2022-05-25 10:10:42,145 [bic.py] => training => Task 0, Epoch 57/170 => Loss 0.459, Train_accy 81.680, Test_accy 75.000
2022-05-25 10:10:45,185 [bic.py] => training => Task 0, Epoch 58/170 => Loss 0.454, Train_accy 81.520, Test_accy 72.200
2022-05-25 10:10:48,172 [bic.py] => training => Task 0, Epoch 59/170 => Loss 0.388, Train_accy 86.240, Test_accy 76.700
2022-05-25 10:10:51,192 [bic.py] => training => Task 0, Epoch 60/170 => Loss 0.407, Train_accy 81.820, Test_accy 72.500
2022-05-25 10:10:54,237 [bic.py] => training => Task 0, Epoch 61/170 => Loss 0.310, Train_accy 92.140, Test_accy 81.000
2022-05-25 10:10:57,244 [bic.py] => training => Task 0, Epoch 62/170 => Loss 0.243, Train_accy 93.900, Test_accy 82.400
2022-05-25 10:11:00,321 [bic.py] => training => Task 0, Epoch 63/170 => Loss 0.216, Train_accy 94.020, Test_accy 81.900
2022-05-25 10:11:03,443 [bic.py] => training => Task 0, Epoch 64/170 => Loss 0.200, Train_accy 94.380, Test_accy 82.600
2022-05-25 10:11:06,524 [bic.py] => training => Task 0, Epoch 65/170 => Loss 0.197, Train_accy 95.140, Test_accy 83.400
2022-05-25 10:11:09,554 [bic.py] => training => Task 0, Epoch 66/170 => Loss 0.189, Train_accy 94.860, Test_accy 82.400
2022-05-25 10:11:12,614 [bic.py] => training => Task 0, Epoch 67/170 => Loss 0.174, Train_accy 95.640, Test_accy 83.800
2022-05-25 10:11:15,716 [bic.py] => training => Task 0, Epoch 68/170 => Loss 0.174, Train_accy 95.680, Test_accy 83.400
2022-05-25 10:11:18,762 [bic.py] => training => Task 0, Epoch 69/170 => Loss 0.199, Train_accy 95.100, Test_accy 83.400
2022-05-25 10:11:21,783 [bic.py] => training => Task 0, Epoch 70/170 => Loss 0.185, Train_accy 95.660, Test_accy 83.300
2022-05-25 10:11:24,837 [bic.py] => training => Task 0, Epoch 71/170 => Loss 0.155, Train_accy 95.840, Test_accy 83.700
2022-05-25 10:11:27,918 [bic.py] => training => Task 0, Epoch 72/170 => Loss 0.164, Train_accy 96.220, Test_accy 82.300
2022-05-25 10:11:30,935 [bic.py] => training => Task 0, Epoch 73/170 => Loss 0.181, Train_accy 95.900, Test_accy 82.600
2022-05-25 10:11:33,876 [bic.py] => training => Task 0, Epoch 74/170 => Loss 0.161, Train_accy 95.980, Test_accy 83.400
2022-05-25 10:11:36,887 [bic.py] => training => Task 0, Epoch 75/170 => Loss 0.161, Train_accy 96.260, Test_accy 82.400
2022-05-25 10:11:39,910 [bic.py] => training => Task 0, Epoch 76/170 => Loss 0.147, Train_accy 95.480, Test_accy 82.500
2022-05-25 10:11:42,966 [bic.py] => training => Task 0, Epoch 77/170 => Loss 0.137, Train_accy 96.420, Test_accy 81.800
2022-05-25 10:11:46,021 [bic.py] => training => Task 0, Epoch 78/170 => Loss 0.155, Train_accy 96.380, Test_accy 82.100
2022-05-25 10:11:49,054 [bic.py] => training => Task 0, Epoch 79/170 => Loss 0.153, Train_accy 96.780, Test_accy 84.100
2022-05-25 10:11:52,124 [bic.py] => training => Task 0, Epoch 80/170 => Loss 0.135, Train_accy 96.840, Test_accy 83.800
2022-05-25 10:11:55,176 [bic.py] => training => Task 0, Epoch 81/170 => Loss 0.134, Train_accy 96.840, Test_accy 83.300
2022-05-25 10:11:58,252 [bic.py] => training => Task 0, Epoch 82/170 => Loss 0.125, Train_accy 96.540, Test_accy 82.800
2022-05-25 10:12:01,347 [bic.py] => training => Task 0, Epoch 83/170 => Loss 0.133, Train_accy 96.560, Test_accy 82.100
2022-05-25 10:12:04,383 [bic.py] => training => Task 0, Epoch 84/170 => Loss 0.134, Train_accy 96.520, Test_accy 83.700
2022-05-25 10:12:07,474 [bic.py] => training => Task 0, Epoch 85/170 => Loss 0.140, Train_accy 96.880, Test_accy 82.400
2022-05-25 10:12:10,511 [bic.py] => training => Task 0, Epoch 86/170 => Loss 0.113, Train_accy 97.860, Test_accy 82.000
2022-05-25 10:12:13,538 [bic.py] => training => Task 0, Epoch 87/170 => Loss 0.123, Train_accy 97.480, Test_accy 82.900
2022-05-25 10:12:16,474 [bic.py] => training => Task 0, Epoch 88/170 => Loss 0.109, Train_accy 97.720, Test_accy 83.100
2022-05-25 10:12:19,502 [bic.py] => training => Task 0, Epoch 89/170 => Loss 0.097, Train_accy 97.400, Test_accy 82.900
2022-05-25 10:12:22,553 [bic.py] => training => Task 0, Epoch 90/170 => Loss 0.114, Train_accy 97.640, Test_accy 83.000
2022-05-25 10:12:25,559 [bic.py] => training => Task 0, Epoch 91/170 => Loss 0.110, Train_accy 97.660, Test_accy 82.200
2022-05-25 10:12:28,559 [bic.py] => training => Task 0, Epoch 92/170 => Loss 0.109, Train_accy 97.780, Test_accy 82.600
2022-05-25 10:12:31,639 [bic.py] => training => Task 0, Epoch 93/170 => Loss 0.126, Train_accy 97.500, Test_accy 81.800
2022-05-25 10:12:34,606 [bic.py] => training => Task 0, Epoch 94/170 => Loss 0.130, Train_accy 97.680, Test_accy 82.600
2022-05-25 10:12:37,686 [bic.py] => training => Task 0, Epoch 95/170 => Loss 0.127, Train_accy 97.380, Test_accy 82.200
2022-05-25 10:12:40,723 [bic.py] => training => Task 0, Epoch 96/170 => Loss 0.114, Train_accy 97.560, Test_accy 82.200
2022-05-25 10:12:43,792 [bic.py] => training => Task 0, Epoch 97/170 => Loss 0.103, Train_accy 97.820, Test_accy 82.500
2022-05-25 10:12:46,871 [bic.py] => training => Task 0, Epoch 98/170 => Loss 0.109, Train_accy 98.060, Test_accy 82.200
2022-05-25 10:12:49,919 [bic.py] => training => Task 0, Epoch 99/170 => Loss 0.111, Train_accy 97.980, Test_accy 83.000
2022-05-25 10:12:52,954 [bic.py] => training => Task 0, Epoch 100/170 => Loss 0.123, Train_accy 97.300, Test_accy 82.300
2022-05-25 10:12:55,891 [bic.py] => training => Task 0, Epoch 101/170 => Loss 0.099, Train_accy 97.900, Test_accy 82.600
2022-05-25 10:12:58,946 [bic.py] => training => Task 0, Epoch 102/170 => Loss 0.092, Train_accy 97.580, Test_accy 82.400
2022-05-25 10:13:01,902 [bic.py] => training => Task 0, Epoch 103/170 => Loss 0.108, Train_accy 97.840, Test_accy 82.500
2022-05-25 10:13:04,899 [bic.py] => training => Task 0, Epoch 104/170 => Loss 0.085, Train_accy 98.080, Test_accy 82.800
2022-05-25 10:13:07,888 [bic.py] => training => Task 0, Epoch 105/170 => Loss 0.097, Train_accy 98.380, Test_accy 83.000
2022-05-25 10:13:10,914 [bic.py] => training => Task 0, Epoch 106/170 => Loss 0.084, Train_accy 98.460, Test_accy 83.000
2022-05-25 10:13:13,962 [bic.py] => training => Task 0, Epoch 107/170 => Loss 0.090, Train_accy 98.080, Test_accy 83.100
2022-05-25 10:13:16,992 [bic.py] => training => Task 0, Epoch 108/170 => Loss 0.080, Train_accy 98.360, Test_accy 82.700
2022-05-25 10:13:19,976 [bic.py] => training => Task 0, Epoch 109/170 => Loss 0.078, Train_accy 98.480, Test_accy 82.700
2022-05-25 10:13:22,961 [bic.py] => training => Task 0, Epoch 110/170 => Loss 0.115, Train_accy 98.200, Test_accy 81.900
2022-05-25 10:13:25,971 [bic.py] => training => Task 0, Epoch 111/170 => Loss 0.084, Train_accy 98.720, Test_accy 83.300
2022-05-25 10:13:28,999 [bic.py] => training => Task 0, Epoch 112/170 => Loss 0.091, Train_accy 98.200, Test_accy 82.900
2022-05-25 10:13:32,050 [bic.py] => training => Task 0, Epoch 113/170 => Loss 0.091, Train_accy 98.560, Test_accy 82.400
2022-05-25 10:13:35,114 [bic.py] => training => Task 0, Epoch 114/170 => Loss 0.101, Train_accy 98.040, Test_accy 83.100
2022-05-25 10:13:38,147 [bic.py] => training => Task 0, Epoch 115/170 => Loss 0.084, Train_accy 98.720, Test_accy 82.800
2022-05-25 10:13:41,207 [bic.py] => training => Task 0, Epoch 116/170 => Loss 0.092, Train_accy 98.460, Test_accy 82.900
2022-05-25 10:13:44,290 [bic.py] => training => Task 0, Epoch 117/170 => Loss 0.081, Train_accy 98.520, Test_accy 83.300
2022-05-25 10:13:47,277 [bic.py] => training => Task 0, Epoch 118/170 => Loss 0.079, Train_accy 98.280, Test_accy 82.000
2022-05-25 10:13:50,262 [bic.py] => training => Task 0, Epoch 119/170 => Loss 0.097, Train_accy 98.340, Test_accy 82.300
2022-05-25 10:13:53,248 [bic.py] => training => Task 0, Epoch 120/170 => Loss 0.074, Train_accy 98.660, Test_accy 82.500
2022-05-25 10:13:56,276 [bic.py] => training => Task 0, Epoch 121/170 => Loss 0.079, Train_accy 98.600, Test_accy 82.800
2022-05-25 10:13:59,294 [bic.py] => training => Task 0, Epoch 122/170 => Loss 0.078, Train_accy 98.160, Test_accy 83.300
2022-05-25 10:14:02,329 [bic.py] => training => Task 0, Epoch 123/170 => Loss 0.082, Train_accy 98.580, Test_accy 82.800
2022-05-25 10:14:05,359 [bic.py] => training => Task 0, Epoch 124/170 => Loss 0.072, Train_accy 98.260, Test_accy 82.400
2022-05-25 10:14:08,423 [bic.py] => training => Task 0, Epoch 125/170 => Loss 0.078, Train_accy 98.560, Test_accy 82.700
2022-05-25 10:14:11,386 [bic.py] => training => Task 0, Epoch 126/170 => Loss 0.086, Train_accy 98.380, Test_accy 82.500
2022-05-25 10:14:14,424 [bic.py] => training => Task 0, Epoch 127/170 => Loss 0.069, Train_accy 98.320, Test_accy 82.300
2022-05-25 10:14:17,358 [bic.py] => training => Task 0, Epoch 128/170 => Loss 0.076, Train_accy 98.360, Test_accy 82.200
2022-05-25 10:14:20,341 [bic.py] => training => Task 0, Epoch 129/170 => Loss 0.093, Train_accy 98.860, Test_accy 82.100
2022-05-25 10:14:23,370 [bic.py] => training => Task 0, Epoch 130/170 => Loss 0.081, Train_accy 98.700, Test_accy 82.200
2022-05-25 10:14:26,375 [bic.py] => training => Task 0, Epoch 131/170 => Loss 0.081, Train_accy 98.720, Test_accy 82.600
2022-05-25 10:14:29,426 [bic.py] => training => Task 0, Epoch 132/170 => Loss 0.072, Train_accy 98.820, Test_accy 82.200
2022-05-25 10:14:32,489 [bic.py] => training => Task 0, Epoch 133/170 => Loss 0.072, Train_accy 98.600, Test_accy 81.900
2022-05-25 10:14:35,546 [bic.py] => training => Task 0, Epoch 134/170 => Loss 0.072, Train_accy 98.760, Test_accy 82.700
2022-05-25 10:14:38,578 [bic.py] => training => Task 0, Epoch 135/170 => Loss 0.077, Train_accy 98.800, Test_accy 82.900
2022-05-25 10:14:41,611 [bic.py] => training => Task 0, Epoch 136/170 => Loss 0.078, Train_accy 98.680, Test_accy 83.200
2022-05-25 10:14:44,601 [bic.py] => training => Task 0, Epoch 137/170 => Loss 0.067, Train_accy 98.880, Test_accy 82.700
2022-05-25 10:14:47,672 [bic.py] => training => Task 0, Epoch 138/170 => Loss 0.070, Train_accy 98.940, Test_accy 83.000
2022-05-25 10:14:50,694 [bic.py] => training => Task 0, Epoch 139/170 => Loss 0.069, Train_accy 98.880, Test_accy 83.300
2022-05-25 10:14:53,785 [bic.py] => training => Task 0, Epoch 140/170 => Loss 0.103, Train_accy 99.040, Test_accy 82.700
2022-05-25 10:14:56,832 [bic.py] => training => Task 0, Epoch 141/170 => Loss 0.077, Train_accy 98.620, Test_accy 82.800
2022-05-25 10:14:59,821 [bic.py] => training => Task 0, Epoch 142/170 => Loss 0.069, Train_accy 98.840, Test_accy 82.800
2022-05-25 10:15:02,872 [bic.py] => training => Task 0, Epoch 143/170 => Loss 0.074, Train_accy 98.600, Test_accy 82.200
2022-05-25 10:15:05,934 [bic.py] => training => Task 0, Epoch 144/170 => Loss 0.082, Train_accy 98.400, Test_accy 83.000
2022-05-25 10:15:09,066 [bic.py] => training => Task 0, Epoch 145/170 => Loss 0.067, Train_accy 98.960, Test_accy 83.000
2022-05-25 10:15:12,172 [bic.py] => training => Task 0, Epoch 146/170 => Loss 0.076, Train_accy 98.840, Test_accy 83.100
2022-05-25 10:15:15,162 [bic.py] => training => Task 0, Epoch 147/170 => Loss 0.075, Train_accy 98.720, Test_accy 83.000
2022-05-25 10:15:18,143 [bic.py] => training => Task 0, Epoch 148/170 => Loss 0.067, Train_accy 98.400, Test_accy 82.900
2022-05-25 10:15:21,150 [bic.py] => training => Task 0, Epoch 149/170 => Loss 0.080, Train_accy 98.740, Test_accy 83.200
2022-05-25 10:15:24,215 [bic.py] => training => Task 0, Epoch 150/170 => Loss 0.090, Train_accy 98.760, Test_accy 82.700
2022-05-25 10:15:27,202 [bic.py] => training => Task 0, Epoch 151/170 => Loss 0.064, Train_accy 98.600, Test_accy 82.600
2022-05-25 10:15:30,320 [bic.py] => training => Task 0, Epoch 152/170 => Loss 0.075, Train_accy 98.680, Test_accy 83.100
2022-05-25 10:15:33,335 [bic.py] => training => Task 0, Epoch 153/170 => Loss 0.086, Train_accy 98.500, Test_accy 82.500
2022-05-25 10:15:36,420 [bic.py] => training => Task 0, Epoch 154/170 => Loss 0.067, Train_accy 98.640, Test_accy 82.800
2022-05-25 10:15:39,456 [bic.py] => training => Task 0, Epoch 155/170 => Loss 0.091, Train_accy 98.380, Test_accy 82.100
2022-05-25 10:15:42,454 [bic.py] => training => Task 0, Epoch 156/170 => Loss 0.087, Train_accy 98.720, Test_accy 83.200
2022-05-25 10:15:45,484 [bic.py] => training => Task 0, Epoch 157/170 => Loss 0.064, Train_accy 98.840, Test_accy 83.100
2022-05-25 10:15:48,481 [bic.py] => training => Task 0, Epoch 158/170 => Loss 0.064, Train_accy 98.760, Test_accy 82.600
2022-05-25 10:15:51,670 [bic.py] => training => Task 0, Epoch 159/170 => Loss 0.077, Train_accy 98.400, Test_accy 82.200
2022-05-25 10:15:54,660 [bic.py] => training => Task 0, Epoch 160/170 => Loss 0.071, Train_accy 98.760, Test_accy 82.700
2022-05-25 10:15:57,736 [bic.py] => training => Task 0, Epoch 161/170 => Loss 0.092, Train_accy 98.940, Test_accy 82.500
2022-05-25 10:16:00,759 [bic.py] => training => Task 0, Epoch 162/170 => Loss 0.064, Train_accy 98.540, Test_accy 82.800
2022-05-25 10:16:03,757 [bic.py] => training => Task 0, Epoch 163/170 => Loss 0.084, Train_accy 98.860, Test_accy 83.300
2022-05-25 10:16:06,805 [bic.py] => training => Task 0, Epoch 164/170 => Loss 0.074, Train_accy 98.580, Test_accy 82.400
2022-05-25 10:16:09,794 [bic.py] => training => Task 0, Epoch 165/170 => Loss 0.088, Train_accy 98.420, Test_accy 82.400
2022-05-25 10:16:12,834 [bic.py] => training => Task 0, Epoch 166/170 => Loss 0.075, Train_accy 98.680, Test_accy 83.300
2022-05-25 10:16:15,864 [bic.py] => training => Task 0, Epoch 167/170 => Loss 0.078, Train_accy 98.680, Test_accy 82.800
2022-05-25 10:16:19,004 [bic.py] => training => Task 0, Epoch 168/170 => Loss 0.086, Train_accy 98.500, Test_accy 83.000
2022-05-25 10:16:22,009 [bic.py] => training => Task 0, Epoch 169/170 => Loss 0.089, Train_accy 98.840, Test_accy 83.200
2022-05-25 10:16:25,088 [bic.py] => training => Task 0, Epoch 170/170 => Loss 0.067, Train_accy 98.660, Test_accy 83.000
2022-05-25 10:16:25,089 [base.py] => Reducing exemplars...(200 per classes)
2022-05-25 10:16:25,089 [base.py] => Constructing exemplars...(200 per classes)
2022-05-25 10:16:31,000 [bic.py] => Parameters of bias layer:
2022-05-25 10:16:31,001 [bic.py] => 0 => 1.000, 0.000
2022-05-25 10:16:31,957 [bic.py] => Exemplar size: 2000
2022-05-25 10:16:31,957 [trainer.py] => CNN: {'total': 83.0, '00-09': 83.0, 'old': 0, 'new': 83.0}
2022-05-25 10:16:31,957 [trainer.py] => NME: {'total': 82.8, '00-09': 82.8, 'old': 0, 'new': 82.8}
2022-05-25 10:16:31,957 [trainer.py] => CNN top1 curve: [83.0]
2022-05-25 10:16:31,957 [trainer.py] => CNN top5 curve: [99.1]
2022-05-25 10:16:31,957 [trainer.py] => NME top1 curve: [82.8]
2022-05-25 10:16:31,957 [trainer.py] => NME top5 curve: [99.0]

2022-05-25 10:16:31,958 [trainer.py] => All params: 464806
2022-05-25 10:16:31,958 [trainer.py] => Trainable params: 464806
2022-05-25 10:16:31,959 [bic.py] => Learning on 10-20
2022-05-25 10:16:32,025 [bic.py] => Stage1 dset: 6600, Stage2 dset: 400
2022-05-25 10:16:32,025 [bic.py] => Lambda: 0.500
2022-05-25 10:16:32,029 [bic.py] => Parameters of bias layer:
2022-05-25 10:16:32,029 [bic.py] => 0 => 1.000, 0.000
2022-05-25 10:16:32,029 [bic.py] => 1 => 1.000, 0.000
2022-05-25 10:16:36,077 [bic.py] => training => Task 1, Epoch 1/170 => Loss 1.756, Train_accy 48.790, Test_accy 46.700
2022-05-25 10:16:40,168 [bic.py] => training => Task 1, Epoch 2/170 => Loss 1.272, Train_accy 56.790, Test_accy 51.650
2022-05-25 10:16:44,112 [bic.py] => training => Task 1, Epoch 3/170 => Loss 1.175, Train_accy 59.550, Test_accy 53.650
2022-05-25 10:16:48,085 [bic.py] => training => Task 1, Epoch 4/170 => Loss 1.126, Train_accy 63.240, Test_accy 56.800
2022-05-25 10:16:51,922 [bic.py] => training => Task 1, Epoch 5/170 => Loss 1.086, Train_accy 66.480, Test_accy 58.600
2022-05-25 10:16:55,885 [bic.py] => training => Task 1, Epoch 6/170 => Loss 1.042, Train_accy 68.830, Test_accy 59.500
2022-05-25 10:16:59,804 [bic.py] => training => Task 1, Epoch 7/170 => Loss 1.025, Train_accy 69.320, Test_accy 60.100
2022-05-25 10:17:03,718 [bic.py] => training => Task 1, Epoch 8/170 => Loss 1.003, Train_accy 73.060, Test_accy 63.250
2022-05-25 10:17:07,613 [bic.py] => training => Task 1, Epoch 9/170 => Loss 0.984, Train_accy 74.060, Test_accy 62.100
2022-05-25 10:17:11,601 [bic.py] => training => Task 1, Epoch 10/170 => Loss 0.969, Train_accy 69.710, Test_accy 56.450
2022-05-25 10:17:15,735 [bic.py] => training => Task 1, Epoch 11/170 => Loss 0.953, Train_accy 77.670, Test_accy 63.250
2022-05-25 10:17:19,683 [bic.py] => training => Task 1, Epoch 12/170 => Loss 0.928, Train_accy 76.090, Test_accy 60.800
2022-05-25 10:17:23,519 [bic.py] => training => Task 1, Epoch 13/170 => Loss 0.938, Train_accy 75.790, Test_accy 63.050
2022-05-25 10:17:27,468 [bic.py] => training => Task 1, Epoch 14/170 => Loss 0.915, Train_accy 73.350, Test_accy 62.050
2022-05-25 10:17:31,397 [bic.py] => training => Task 1, Epoch 15/170 => Loss 0.893, Train_accy 79.480, Test_accy 64.450
2022-05-25 10:17:35,288 [bic.py] => training => Task 1, Epoch 16/170 => Loss 0.875, Train_accy 80.700, Test_accy 64.300
2022-05-25 10:17:39,240 [bic.py] => training => Task 1, Epoch 17/170 => Loss 0.863, Train_accy 80.820, Test_accy 64.400
2022-05-25 10:17:43,102 [bic.py] => training => Task 1, Epoch 18/170 => Loss 0.869, Train_accy 81.760, Test_accy 63.950
2022-05-25 10:17:47,044 [bic.py] => training => Task 1, Epoch 19/170 => Loss 0.870, Train_accy 80.830, Test_accy 62.450
2022-05-25 10:17:50,898 [bic.py] => training => Task 1, Epoch 20/170 => Loss 0.845, Train_accy 79.170, Test_accy 62.650
2022-05-25 10:17:54,987 [bic.py] => training => Task 1, Epoch 21/170 => Loss 0.834, Train_accy 84.330, Test_accy 64.500
2022-05-25 10:17:58,835 [bic.py] => training => Task 1, Epoch 22/170 => Loss 0.834, Train_accy 69.450, Test_accy 53.950
2022-05-25 10:18:02,813 [bic.py] => training => Task 1, Epoch 23/170 => Loss 0.833, Train_accy 83.080, Test_accy 64.050
2022-05-25 10:18:06,685 [bic.py] => training => Task 1, Epoch 24/170 => Loss 0.826, Train_accy 82.240, Test_accy 63.550
2022-05-25 10:18:10,588 [bic.py] => training => Task 1, Epoch 25/170 => Loss 0.824, Train_accy 82.940, Test_accy 64.000
2022-05-25 10:18:14,516 [bic.py] => training => Task 1, Epoch 26/170 => Loss 0.809, Train_accy 85.950, Test_accy 66.850
2022-05-25 10:18:18,477 [bic.py] => training => Task 1, Epoch 27/170 => Loss 0.812, Train_accy 83.820, Test_accy 64.400
2022-05-25 10:18:22,453 [bic.py] => training => Task 1, Epoch 28/170 => Loss 0.805, Train_accy 83.030, Test_accy 62.450
2022-05-25 10:18:26,400 [bic.py] => training => Task 1, Epoch 29/170 => Loss 0.795, Train_accy 85.610, Test_accy 63.350
2022-05-25 10:18:30,284 [bic.py] => training => Task 1, Epoch 30/170 => Loss 0.792, Train_accy 80.520, Test_accy 60.800
2022-05-25 10:18:34,194 [bic.py] => training => Task 1, Epoch 31/170 => Loss 0.788, Train_accy 87.700, Test_accy 65.900
2022-05-25 10:18:38,090 [bic.py] => training => Task 1, Epoch 32/170 => Loss 0.771, Train_accy 88.420, Test_accy 66.750
2022-05-25 10:18:41,982 [bic.py] => training => Task 1, Epoch 33/170 => Loss 0.752, Train_accy 85.610, Test_accy 62.300
2022-05-25 10:18:45,899 [bic.py] => training => Task 1, Epoch 34/170 => Loss 0.772, Train_accy 87.670, Test_accy 68.000
2022-05-25 10:18:49,786 [bic.py] => training => Task 1, Epoch 35/170 => Loss 0.763, Train_accy 84.140, Test_accy 62.850
2022-05-25 10:18:53,767 [bic.py] => training => Task 1, Epoch 36/170 => Loss 0.761, Train_accy 89.390, Test_accy 67.400
2022-05-25 10:18:57,715 [bic.py] => training => Task 1, Epoch 37/170 => Loss 0.750, Train_accy 88.390, Test_accy 67.200
2022-05-25 10:19:01,620 [bic.py] => training => Task 1, Epoch 38/170 => Loss 0.746, Train_accy 85.020, Test_accy 62.200
2022-05-25 10:19:05,539 [bic.py] => training => Task 1, Epoch 39/170 => Loss 0.739, Train_accy 88.390, Test_accy 64.300
2022-05-25 10:19:09,447 [bic.py] => training => Task 1, Epoch 40/170 => Loss 0.743, Train_accy 89.240, Test_accy 66.250
2022-05-25 10:19:13,336 [bic.py] => training => Task 1, Epoch 41/170 => Loss 0.741, Train_accy 87.560, Test_accy 63.800
2022-05-25 10:19:17,178 [bic.py] => training => Task 1, Epoch 42/170 => Loss 0.738, Train_accy 85.120, Test_accy 62.200
2022-05-25 10:19:21,200 [bic.py] => training => Task 1, Epoch 43/170 => Loss 0.742, Train_accy 86.020, Test_accy 63.500
2022-05-25 10:19:25,074 [bic.py] => training => Task 1, Epoch 44/170 => Loss 0.741, Train_accy 88.710, Test_accy 66.350
2022-05-25 10:19:29,021 [bic.py] => training => Task 1, Epoch 45/170 => Loss 0.737, Train_accy 90.440, Test_accy 67.800
2022-05-25 10:19:32,859 [bic.py] => training => Task 1, Epoch 46/170 => Loss 0.737, Train_accy 82.680, Test_accy 60.950
2022-05-25 10:19:36,778 [bic.py] => training => Task 1, Epoch 47/170 => Loss 0.740, Train_accy 87.650, Test_accy 64.200
2022-05-25 10:19:40,879 [bic.py] => training => Task 1, Epoch 48/170 => Loss 0.727, Train_accy 85.820, Test_accy 62.750
2022-05-25 10:19:44,821 [bic.py] => training => Task 1, Epoch 49/170 => Loss 0.716, Train_accy 86.670, Test_accy 63.050
2022-05-25 10:19:48,801 [bic.py] => training => Task 1, Epoch 50/170 => Loss 0.699, Train_accy 88.380, Test_accy 65.050
2022-05-25 10:19:52,724 [bic.py] => training => Task 1, Epoch 51/170 => Loss 0.710, Train_accy 87.910, Test_accy 65.550
2022-05-25 10:19:56,698 [bic.py] => training => Task 1, Epoch 52/170 => Loss 0.712, Train_accy 84.710, Test_accy 62.700
2022-05-25 10:20:00,705 [bic.py] => training => Task 1, Epoch 53/170 => Loss 0.713, Train_accy 88.060, Test_accy 64.500
2022-05-25 10:20:04,540 [bic.py] => training => Task 1, Epoch 54/170 => Loss 0.702, Train_accy 89.640, Test_accy 65.350
2022-05-25 10:20:08,351 [bic.py] => training => Task 1, Epoch 55/170 => Loss 0.712, Train_accy 89.830, Test_accy 62.900
2022-05-25 10:20:12,179 [bic.py] => training => Task 1, Epoch 56/170 => Loss 0.717, Train_accy 88.020, Test_accy 66.400
2022-05-25 10:20:16,098 [bic.py] => training => Task 1, Epoch 57/170 => Loss 0.691, Train_accy 92.580, Test_accy 67.750
2022-05-25 10:20:19,969 [bic.py] => training => Task 1, Epoch 58/170 => Loss 0.681, Train_accy 92.880, Test_accy 66.450
2022-05-25 10:20:23,934 [bic.py] => training => Task 1, Epoch 59/170 => Loss 0.686, Train_accy 90.020, Test_accy 65.650
2022-05-25 10:20:27,946 [bic.py] => training => Task 1, Epoch 60/170 => Loss 0.706, Train_accy 89.240, Test_accy 65.800
2022-05-25 10:20:31,922 [bic.py] => training => Task 1, Epoch 61/170 => Loss 0.656, Train_accy 97.800, Test_accy 72.000
2022-05-25 10:20:35,841 [bic.py] => training => Task 1, Epoch 62/170 => Loss 0.618, Train_accy 98.350, Test_accy 72.350
2022-05-25 10:20:39,698 [bic.py] => training => Task 1, Epoch 63/170 => Loss 0.614, Train_accy 98.950, Test_accy 71.900
2022-05-25 10:20:43,561 [bic.py] => training => Task 1, Epoch 64/170 => Loss 0.609, Train_accy 98.950, Test_accy 72.550
2022-05-25 10:20:47,482 [bic.py] => training => Task 1, Epoch 65/170 => Loss 0.597, Train_accy 99.030, Test_accy 72.400
2022-05-25 10:20:51,362 [bic.py] => training => Task 1, Epoch 66/170 => Loss 0.597, Train_accy 99.210, Test_accy 72.700
2022-05-25 10:20:55,203 [bic.py] => training => Task 1, Epoch 67/170 => Loss 0.596, Train_accy 99.260, Test_accy 72.200
2022-05-25 10:20:59,108 [bic.py] => training => Task 1, Epoch 68/170 => Loss 0.597, Train_accy 99.350, Test_accy 73.000
2022-05-25 10:21:02,973 [bic.py] => training => Task 1, Epoch 69/170 => Loss 0.592, Train_accy 99.260, Test_accy 72.650
2022-05-25 10:21:06,877 [bic.py] => training => Task 1, Epoch 70/170 => Loss 0.590, Train_accy 99.380, Test_accy 72.500
2022-05-25 10:21:10,808 [bic.py] => training => Task 1, Epoch 71/170 => Loss 0.589, Train_accy 99.260, Test_accy 72.750
2022-05-25 10:21:14,704 [bic.py] => training => Task 1, Epoch 72/170 => Loss 0.588, Train_accy 99.380, Test_accy 72.500
2022-05-25 10:21:18,545 [bic.py] => training => Task 1, Epoch 73/170 => Loss 0.588, Train_accy 99.380, Test_accy 73.100
2022-05-25 10:21:22,475 [bic.py] => training => Task 1, Epoch 74/170 => Loss 0.583, Train_accy 99.520, Test_accy 73.200
2022-05-25 10:21:26,408 [bic.py] => training => Task 1, Epoch 75/170 => Loss 0.587, Train_accy 99.420, Test_accy 72.750
2022-05-25 10:21:30,318 [bic.py] => training => Task 1, Epoch 76/170 => Loss 0.582, Train_accy 99.520, Test_accy 72.450
2022-05-25 10:21:34,278 [bic.py] => training => Task 1, Epoch 77/170 => Loss 0.580, Train_accy 99.350, Test_accy 72.550
2022-05-25 10:21:38,193 [bic.py] => training => Task 1, Epoch 78/170 => Loss 0.583, Train_accy 99.530, Test_accy 72.700
2022-05-25 10:21:42,124 [bic.py] => training => Task 1, Epoch 79/170 => Loss 0.584, Train_accy 99.410, Test_accy 72.250
2022-05-25 10:21:46,094 [bic.py] => training => Task 1, Epoch 80/170 => Loss 0.583, Train_accy 99.670, Test_accy 72.850
2022-05-25 10:21:50,013 [bic.py] => training => Task 1, Epoch 81/170 => Loss 0.584, Train_accy 99.530, Test_accy 73.150
2022-05-25 10:21:53,966 [bic.py] => training => Task 1, Epoch 82/170 => Loss 0.581, Train_accy 99.610, Test_accy 72.700
2022-05-25 10:21:57,970 [bic.py] => training => Task 1, Epoch 83/170 => Loss 0.576, Train_accy 99.640, Test_accy 72.500
2022-05-25 10:22:01,938 [bic.py] => training => Task 1, Epoch 84/170 => Loss 0.575, Train_accy 99.770, Test_accy 72.950
2022-05-25 10:22:05,945 [bic.py] => training => Task 1, Epoch 85/170 => Loss 0.578, Train_accy 99.790, Test_accy 72.800
2022-05-25 10:22:09,851 [bic.py] => training => Task 1, Epoch 86/170 => Loss 0.576, Train_accy 99.850, Test_accy 72.900
2022-05-25 10:22:13,817 [bic.py] => training => Task 1, Epoch 87/170 => Loss 0.579, Train_accy 99.550, Test_accy 73.350
2022-05-25 10:22:17,702 [bic.py] => training => Task 1, Epoch 88/170 => Loss 0.581, Train_accy 99.620, Test_accy 72.900
2022-05-25 10:22:21,667 [bic.py] => training => Task 1, Epoch 89/170 => Loss 0.579, Train_accy 99.790, Test_accy 72.700
2022-05-25 10:22:25,623 [bic.py] => training => Task 1, Epoch 90/170 => Loss 0.573, Train_accy 99.610, Test_accy 73.000
2022-05-25 10:22:29,602 [bic.py] => training => Task 1, Epoch 91/170 => Loss 0.580, Train_accy 99.680, Test_accy 73.400
2022-05-25 10:22:33,420 [bic.py] => training => Task 1, Epoch 92/170 => Loss 0.576, Train_accy 99.830, Test_accy 73.500
2022-05-25 10:22:37,332 [bic.py] => training => Task 1, Epoch 93/170 => Loss 0.579, Train_accy 99.760, Test_accy 72.800
2022-05-25 10:22:41,221 [bic.py] => training => Task 1, Epoch 94/170 => Loss 0.573, Train_accy 99.700, Test_accy 72.850
2022-05-25 10:22:45,015 [bic.py] => training => Task 1, Epoch 95/170 => Loss 0.575, Train_accy 99.790, Test_accy 72.600
2022-05-25 10:22:48,882 [bic.py] => training => Task 1, Epoch 96/170 => Loss 0.572, Train_accy 99.740, Test_accy 72.950
2022-05-25 10:22:52,812 [bic.py] => training => Task 1, Epoch 97/170 => Loss 0.574, Train_accy 99.730, Test_accy 73.100
2022-05-25 10:22:56,640 [bic.py] => training => Task 1, Epoch 98/170 => Loss 0.572, Train_accy 99.800, Test_accy 72.600
2022-05-25 10:23:00,706 [bic.py] => training => Task 1, Epoch 99/170 => Loss 0.574, Train_accy 99.850, Test_accy 72.750
2022-05-25 10:23:04,592 [bic.py] => training => Task 1, Epoch 100/170 => Loss 0.577, Train_accy 99.820, Test_accy 72.750
2022-05-25 10:23:08,424 [bic.py] => training => Task 1, Epoch 101/170 => Loss 0.569, Train_accy 99.880, Test_accy 72.700
2022-05-25 10:23:12,373 [bic.py] => training => Task 1, Epoch 102/170 => Loss 0.575, Train_accy 99.800, Test_accy 72.700
2022-05-25 10:23:16,228 [bic.py] => training => Task 1, Epoch 103/170 => Loss 0.570, Train_accy 99.830, Test_accy 73.050
2022-05-25 10:23:20,078 [bic.py] => training => Task 1, Epoch 104/170 => Loss 0.573, Train_accy 99.710, Test_accy 73.100
2022-05-25 10:23:24,117 [bic.py] => training => Task 1, Epoch 105/170 => Loss 0.569, Train_accy 99.770, Test_accy 73.100
2022-05-25 10:23:28,046 [bic.py] => training => Task 1, Epoch 106/170 => Loss 0.570, Train_accy 99.790, Test_accy 72.650
2022-05-25 10:23:31,974 [bic.py] => training => Task 1, Epoch 107/170 => Loss 0.570, Train_accy 99.730, Test_accy 73.450
2022-05-25 10:23:35,901 [bic.py] => training => Task 1, Epoch 108/170 => Loss 0.575, Train_accy 99.790, Test_accy 72.900
2022-05-25 10:23:39,877 [bic.py] => training => Task 1, Epoch 109/170 => Loss 0.568, Train_accy 99.800, Test_accy 72.700
2022-05-25 10:23:43,880 [bic.py] => training => Task 1, Epoch 110/170 => Loss 0.572, Train_accy 99.820, Test_accy 73.250
2022-05-25 10:23:47,774 [bic.py] => training => Task 1, Epoch 111/170 => Loss 0.570, Train_accy 99.850, Test_accy 73.200
2022-05-25 10:23:51,759 [bic.py] => training => Task 1, Epoch 112/170 => Loss 0.570, Train_accy 99.920, Test_accy 73.100
2022-05-25 10:23:55,791 [bic.py] => training => Task 1, Epoch 113/170 => Loss 0.567, Train_accy 99.770, Test_accy 73.050
2022-05-25 10:23:59,779 [bic.py] => training => Task 1, Epoch 114/170 => Loss 0.570, Train_accy 99.770, Test_accy 73.300
2022-05-25 10:24:03,831 [bic.py] => training => Task 1, Epoch 115/170 => Loss 0.567, Train_accy 99.820, Test_accy 72.950
2022-05-25 10:24:07,740 [bic.py] => training => Task 1, Epoch 116/170 => Loss 0.574, Train_accy 99.860, Test_accy 73.050
2022-05-25 10:24:11,830 [bic.py] => training => Task 1, Epoch 117/170 => Loss 0.565, Train_accy 99.820, Test_accy 73.050
2022-05-25 10:24:15,716 [bic.py] => training => Task 1, Epoch 118/170 => Loss 0.567, Train_accy 99.740, Test_accy 73.500
2022-05-25 10:24:19,647 [bic.py] => training => Task 1, Epoch 119/170 => Loss 0.573, Train_accy 99.800, Test_accy 72.750
2022-05-25 10:24:23,676 [bic.py] => training => Task 1, Epoch 120/170 => Loss 0.569, Train_accy 99.800, Test_accy 72.600
2022-05-25 10:24:27,678 [bic.py] => training => Task 1, Epoch 121/170 => Loss 0.570, Train_accy 99.890, Test_accy 73.100
2022-05-25 10:24:31,585 [bic.py] => training => Task 1, Epoch 122/170 => Loss 0.570, Train_accy 99.760, Test_accy 73.150
2022-05-25 10:24:35,500 [bic.py] => training => Task 1, Epoch 123/170 => Loss 0.573, Train_accy 99.800, Test_accy 73.350
2022-05-25 10:24:39,471 [bic.py] => training => Task 1, Epoch 124/170 => Loss 0.571, Train_accy 99.740, Test_accy 73.050
2022-05-25 10:24:43,411 [bic.py] => training => Task 1, Epoch 125/170 => Loss 0.570, Train_accy 99.770, Test_accy 73.000
2022-05-25 10:24:47,404 [bic.py] => training => Task 1, Epoch 126/170 => Loss 0.572, Train_accy 99.760, Test_accy 72.950
2022-05-25 10:24:51,328 [bic.py] => training => Task 1, Epoch 127/170 => Loss 0.570, Train_accy 99.800, Test_accy 73.150
2022-05-25 10:24:55,241 [bic.py] => training => Task 1, Epoch 128/170 => Loss 0.569, Train_accy 99.820, Test_accy 73.050
2022-05-25 10:24:59,221 [bic.py] => training => Task 1, Epoch 129/170 => Loss 0.567, Train_accy 99.830, Test_accy 72.900
2022-05-25 10:25:03,120 [bic.py] => training => Task 1, Epoch 130/170 => Loss 0.572, Train_accy 99.700, Test_accy 73.200
2022-05-25 10:25:07,000 [bic.py] => training => Task 1, Epoch 131/170 => Loss 0.566, Train_accy 99.740, Test_accy 73.150
2022-05-25 10:25:10,908 [bic.py] => training => Task 1, Epoch 132/170 => Loss 0.569, Train_accy 99.760, Test_accy 72.850
2022-05-25 10:25:14,876 [bic.py] => training => Task 1, Epoch 133/170 => Loss 0.568, Train_accy 99.850, Test_accy 72.800
2022-05-25 10:25:18,852 [bic.py] => training => Task 1, Epoch 134/170 => Loss 0.570, Train_accy 99.880, Test_accy 72.950
2022-05-25 10:25:22,708 [bic.py] => training => Task 1, Epoch 135/170 => Loss 0.570, Train_accy 99.730, Test_accy 73.000
2022-05-25 10:25:26,708 [bic.py] => training => Task 1, Epoch 136/170 => Loss 0.568, Train_accy 99.790, Test_accy 72.750
2022-05-25 10:25:30,818 [bic.py] => training => Task 1, Epoch 137/170 => Loss 0.571, Train_accy 99.860, Test_accy 72.850
2022-05-25 10:25:34,750 [bic.py] => training => Task 1, Epoch 138/170 => Loss 0.567, Train_accy 99.830, Test_accy 72.700
2022-05-25 10:25:38,661 [bic.py] => training => Task 1, Epoch 139/170 => Loss 0.569, Train_accy 99.910, Test_accy 72.950
2022-05-25 10:25:42,531 [bic.py] => training => Task 1, Epoch 140/170 => Loss 0.566, Train_accy 99.920, Test_accy 72.900
2022-05-25 10:25:46,420 [bic.py] => training => Task 1, Epoch 141/170 => Loss 0.570, Train_accy 99.770, Test_accy 72.950
2022-05-25 10:25:50,369 [bic.py] => training => Task 1, Epoch 142/170 => Loss 0.569, Train_accy 99.830, Test_accy 73.150
2022-05-25 10:25:54,350 [bic.py] => training => Task 1, Epoch 143/170 => Loss 0.570, Train_accy 99.830, Test_accy 72.950
2022-05-25 10:25:58,412 [bic.py] => training => Task 1, Epoch 144/170 => Loss 0.570, Train_accy 99.760, Test_accy 72.950
2022-05-25 10:26:02,361 [bic.py] => training => Task 1, Epoch 145/170 => Loss 0.569, Train_accy 99.800, Test_accy 72.650
2022-05-25 10:26:06,330 [bic.py] => training => Task 1, Epoch 146/170 => Loss 0.568, Train_accy 99.850, Test_accy 73.400
2022-05-25 10:26:10,360 [bic.py] => training => Task 1, Epoch 147/170 => Loss 0.567, Train_accy 99.830, Test_accy 73.050
2022-05-25 10:26:14,317 [bic.py] => training => Task 1, Epoch 148/170 => Loss 0.569, Train_accy 99.800, Test_accy 72.950
2022-05-25 10:26:18,365 [bic.py] => training => Task 1, Epoch 149/170 => Loss 0.572, Train_accy 99.790, Test_accy 73.200
2022-05-25 10:26:22,454 [bic.py] => training => Task 1, Epoch 150/170 => Loss 0.566, Train_accy 99.790, Test_accy 72.700
2022-05-25 10:26:26,351 [bic.py] => training => Task 1, Epoch 151/170 => Loss 0.569, Train_accy 99.880, Test_accy 72.800
2022-05-25 10:26:30,167 [bic.py] => training => Task 1, Epoch 152/170 => Loss 0.566, Train_accy 99.830, Test_accy 72.800
2022-05-25 10:26:34,044 [bic.py] => training => Task 1, Epoch 153/170 => Loss 0.566, Train_accy 99.830, Test_accy 73.350
2022-05-25 10:26:37,873 [bic.py] => training => Task 1, Epoch 154/170 => Loss 0.567, Train_accy 99.770, Test_accy 73.000
2022-05-25 10:26:41,767 [bic.py] => training => Task 1, Epoch 155/170 => Loss 0.570, Train_accy 99.820, Test_accy 72.900
2022-05-25 10:26:45,633 [bic.py] => training => Task 1, Epoch 156/170 => Loss 0.567, Train_accy 99.850, Test_accy 73.100
2022-05-25 10:26:49,526 [bic.py] => training => Task 1, Epoch 157/170 => Loss 0.567, Train_accy 99.860, Test_accy 72.850
2022-05-25 10:26:53,460 [bic.py] => training => Task 1, Epoch 158/170 => Loss 0.570, Train_accy 99.790, Test_accy 73.000
2022-05-25 10:26:57,331 [bic.py] => training => Task 1, Epoch 159/170 => Loss 0.568, Train_accy 99.700, Test_accy 73.200
2022-05-25 10:27:01,282 [bic.py] => training => Task 1, Epoch 160/170 => Loss 0.571, Train_accy 99.790, Test_accy 73.250
2022-05-25 10:27:05,308 [bic.py] => training => Task 1, Epoch 161/170 => Loss 0.569, Train_accy 99.800, Test_accy 73.050
2022-05-25 10:27:09,178 [bic.py] => training => Task 1, Epoch 162/170 => Loss 0.568, Train_accy 99.740, Test_accy 73.000
2022-05-25 10:27:13,134 [bic.py] => training => Task 1, Epoch 163/170 => Loss 0.569, Train_accy 99.850, Test_accy 72.950
2022-05-25 10:27:17,093 [bic.py] => training => Task 1, Epoch 164/170 => Loss 0.571, Train_accy 99.830, Test_accy 73.150
2022-05-25 10:27:20,965 [bic.py] => training => Task 1, Epoch 165/170 => Loss 0.572, Train_accy 99.830, Test_accy 73.250
2022-05-25 10:27:24,935 [bic.py] => training => Task 1, Epoch 166/170 => Loss 0.570, Train_accy 99.860, Test_accy 73.300
2022-05-25 10:27:28,864 [bic.py] => training => Task 1, Epoch 167/170 => Loss 0.569, Train_accy 99.880, Test_accy 73.050
2022-05-25 10:27:32,788 [bic.py] => training => Task 1, Epoch 168/170 => Loss 0.567, Train_accy 99.850, Test_accy 72.750
2022-05-25 10:27:36,725 [bic.py] => training => Task 1, Epoch 169/170 => Loss 0.572, Train_accy 99.800, Test_accy 72.800
2022-05-25 10:27:40,712 [bic.py] => training => Task 1, Epoch 170/170 => Loss 0.568, Train_accy 99.760, Test_accy 73.100
2022-05-25 10:27:42,219 [bic.py] => bias_correction => Task 1, Epoch 1/170 => Loss 2.334, Train_accy 78.750, Test_accy 74.200
2022-05-25 10:27:43,725 [bic.py] => bias_correction => Task 1, Epoch 2/170 => Loss 2.355, Train_accy 76.250, Test_accy 74.200
2022-05-25 10:27:45,248 [bic.py] => bias_correction => Task 1, Epoch 3/170 => Loss 2.330, Train_accy 75.750, Test_accy 73.900
2022-05-25 10:27:46,761 [bic.py] => bias_correction => Task 1, Epoch 4/170 => Loss 2.340, Train_accy 78.000, Test_accy 74.400
2022-05-25 10:27:48,304 [bic.py] => bias_correction => Task 1, Epoch 5/170 => Loss 2.373, Train_accy 75.750, Test_accy 73.700
2022-05-25 10:27:49,823 [bic.py] => bias_correction => Task 1, Epoch 6/170 => Loss 2.389, Train_accy 77.750, Test_accy 73.450
2022-05-25 10:27:51,362 [bic.py] => bias_correction => Task 1, Epoch 7/170 => Loss 2.330, Train_accy 80.750, Test_accy 73.950
2022-05-25 10:27:52,859 [bic.py] => bias_correction => Task 1, Epoch 8/170 => Loss 2.335, Train_accy 79.000, Test_accy 73.800
2022-05-25 10:27:54,329 [bic.py] => bias_correction => Task 1, Epoch 9/170 => Loss 2.390, Train_accy 80.500, Test_accy 74.300
2022-05-25 10:27:55,798 [bic.py] => bias_correction => Task 1, Epoch 10/170 => Loss 2.365, Train_accy 77.500, Test_accy 74.050
2022-05-25 10:27:57,325 [bic.py] => bias_correction => Task 1, Epoch 11/170 => Loss 2.332, Train_accy 80.750, Test_accy 73.950
2022-05-25 10:27:58,841 [bic.py] => bias_correction => Task 1, Epoch 12/170 => Loss 2.356, Train_accy 78.500, Test_accy 73.700
2022-05-25 10:28:00,350 [bic.py] => bias_correction => Task 1, Epoch 13/170 => Loss 2.380, Train_accy 79.250, Test_accy 74.100
2022-05-25 10:28:01,905 [bic.py] => bias_correction => Task 1, Epoch 14/170 => Loss 2.366, Train_accy 77.250, Test_accy 74.250
2022-05-25 10:28:03,422 [bic.py] => bias_correction => Task 1, Epoch 15/170 => Loss 2.353, Train_accy 80.500, Test_accy 73.750
2022-05-25 10:28:04,900 [bic.py] => bias_correction => Task 1, Epoch 16/170 => Loss 2.340, Train_accy 77.750, Test_accy 74.350
2022-05-25 10:28:06,420 [bic.py] => bias_correction => Task 1, Epoch 17/170 => Loss 2.372, Train_accy 77.500, Test_accy 73.700
2022-05-25 10:28:07,885 [bic.py] => bias_correction => Task 1, Epoch 18/170 => Loss 2.371, Train_accy 75.500, Test_accy 72.900
2022-05-25 10:28:09,434 [bic.py] => bias_correction => Task 1, Epoch 19/170 => Loss 2.336, Train_accy 80.750, Test_accy 73.850
2022-05-25 10:28:10,929 [bic.py] => bias_correction => Task 1, Epoch 20/170 => Loss 2.355, Train_accy 78.000, Test_accy 73.450
2022-05-25 10:28:12,369 [bic.py] => bias_correction => Task 1, Epoch 21/170 => Loss 2.358, Train_accy 77.750, Test_accy 73.950
2022-05-25 10:28:13,841 [bic.py] => bias_correction => Task 1, Epoch 22/170 => Loss 2.396, Train_accy 79.000, Test_accy 74.250
2022-05-25 10:28:15,244 [bic.py] => bias_correction => Task 1, Epoch 23/170 => Loss 2.340, Train_accy 78.000, Test_accy 74.200
2022-05-25 10:28:16,726 [bic.py] => bias_correction => Task 1, Epoch 24/170 => Loss 2.339, Train_accy 80.000, Test_accy 73.950
2022-05-25 10:28:18,231 [bic.py] => bias_correction => Task 1, Epoch 25/170 => Loss 2.334, Train_accy 77.250, Test_accy 73.200
2022-05-25 10:28:19,742 [bic.py] => bias_correction => Task 1, Epoch 26/170 => Loss 2.365, Train_accy 75.250, Test_accy 73.200
2022-05-25 10:28:21,157 [bic.py] => bias_correction => Task 1, Epoch 27/170 => Loss 2.407, Train_accy 77.750, Test_accy 73.500
2022-05-25 10:28:22,606 [bic.py] => bias_correction => Task 1, Epoch 28/170 => Loss 2.392, Train_accy 79.500, Test_accy 73.900
2022-05-25 10:28:24,069 [bic.py] => bias_correction => Task 1, Epoch 29/170 => Loss 2.358, Train_accy 77.750, Test_accy 73.350
2022-05-25 10:28:25,581 [bic.py] => bias_correction => Task 1, Epoch 30/170 => Loss 2.362, Train_accy 77.750, Test_accy 73.850
2022-05-25 10:28:27,113 [bic.py] => bias_correction => Task 1, Epoch 31/170 => Loss 2.370, Train_accy 76.500, Test_accy 73.400
2022-05-25 10:28:28,643 [bic.py] => bias_correction => Task 1, Epoch 32/170 => Loss 2.371, Train_accy 77.000, Test_accy 73.900
2022-05-25 10:28:30,177 [bic.py] => bias_correction => Task 1, Epoch 33/170 => Loss 2.319, Train_accy 76.750, Test_accy 74.250
2022-05-25 10:28:31,693 [bic.py] => bias_correction => Task 1, Epoch 34/170 => Loss 2.334, Train_accy 77.750, Test_accy 73.900
2022-05-25 10:28:33,227 [bic.py] => bias_correction => Task 1, Epoch 35/170 => Loss 2.360, Train_accy 77.500, Test_accy 74.150
2022-05-25 10:28:34,752 [bic.py] => bias_correction => Task 1, Epoch 36/170 => Loss 2.368, Train_accy 78.500, Test_accy 73.750
2022-05-25 10:28:36,274 [bic.py] => bias_correction => Task 1, Epoch 37/170 => Loss 2.366, Train_accy 76.500, Test_accy 73.950
2022-05-25 10:28:37,806 [bic.py] => bias_correction => Task 1, Epoch 38/170 => Loss 2.323, Train_accy 76.250, Test_accy 73.600
2022-05-25 10:28:39,302 [bic.py] => bias_correction => Task 1, Epoch 39/170 => Loss 2.369, Train_accy 79.750, Test_accy 74.150
2022-05-25 10:28:40,792 [bic.py] => bias_correction => Task 1, Epoch 40/170 => Loss 2.349, Train_accy 81.250, Test_accy 74.250
2022-05-25 10:28:42,342 [bic.py] => bias_correction => Task 1, Epoch 41/170 => Loss 2.379, Train_accy 77.000, Test_accy 73.600
2022-05-25 10:28:43,864 [bic.py] => bias_correction => Task 1, Epoch 42/170 => Loss 2.345, Train_accy 78.500, Test_accy 73.350
2022-05-25 10:28:45,436 [bic.py] => bias_correction => Task 1, Epoch 43/170 => Loss 2.394, Train_accy 78.500, Test_accy 74.300
2022-05-25 10:28:46,855 [bic.py] => bias_correction => Task 1, Epoch 44/170 => Loss 2.343, Train_accy 76.750, Test_accy 73.700
2022-05-25 10:28:48,348 [bic.py] => bias_correction => Task 1, Epoch 45/170 => Loss 2.388, Train_accy 78.250, Test_accy 73.550
2022-05-25 10:28:49,820 [bic.py] => bias_correction => Task 1, Epoch 46/170 => Loss 2.322, Train_accy 77.250, Test_accy 74.650
2022-05-25 10:28:51,347 [bic.py] => bias_correction => Task 1, Epoch 47/170 => Loss 2.341, Train_accy 78.000, Test_accy 73.900
2022-05-25 10:28:52,849 [bic.py] => bias_correction => Task 1, Epoch 48/170 => Loss 2.326, Train_accy 75.000, Test_accy 74.350
2022-05-25 10:28:54,363 [bic.py] => bias_correction => Task 1, Epoch 49/170 => Loss 2.306, Train_accy 76.750, Test_accy 73.350
2022-05-25 10:28:55,911 [bic.py] => bias_correction => Task 1, Epoch 50/170 => Loss 2.344, Train_accy 77.250, Test_accy 73.050
2022-05-25 10:28:57,459 [bic.py] => bias_correction => Task 1, Epoch 51/170 => Loss 2.367, Train_accy 75.500, Test_accy 73.500
2022-05-25 10:28:58,951 [bic.py] => bias_correction => Task 1, Epoch 52/170 => Loss 2.331, Train_accy 76.500, Test_accy 74.150
2022-05-25 10:29:00,510 [bic.py] => bias_correction => Task 1, Epoch 53/170 => Loss 2.333, Train_accy 77.000, Test_accy 73.600
2022-05-25 10:29:02,043 [bic.py] => bias_correction => Task 1, Epoch 54/170 => Loss 2.354, Train_accy 77.250, Test_accy 74.000
2022-05-25 10:29:03,570 [bic.py] => bias_correction => Task 1, Epoch 55/170 => Loss 2.324, Train_accy 78.500, Test_accy 74.050
2022-05-25 10:29:05,068 [bic.py] => bias_correction => Task 1, Epoch 56/170 => Loss 2.330, Train_accy 78.000, Test_accy 73.350
2022-05-25 10:29:06,575 [bic.py] => bias_correction => Task 1, Epoch 57/170 => Loss 2.395, Train_accy 79.000, Test_accy 74.100
2022-05-25 10:29:08,078 [bic.py] => bias_correction => Task 1, Epoch 58/170 => Loss 2.362, Train_accy 77.500, Test_accy 74.300
2022-05-25 10:29:09,566 [bic.py] => bias_correction => Task 1, Epoch 59/170 => Loss 2.374, Train_accy 77.000, Test_accy 73.650
2022-05-25 10:29:11,109 [bic.py] => bias_correction => Task 1, Epoch 60/170 => Loss 2.378, Train_accy 77.500, Test_accy 73.750
2022-05-25 10:29:12,625 [bic.py] => bias_correction => Task 1, Epoch 61/170 => Loss 2.380, Train_accy 78.000, Test_accy 73.750
2022-05-25 10:29:14,140 [bic.py] => bias_correction => Task 1, Epoch 62/170 => Loss 2.337, Train_accy 79.500, Test_accy 73.850
2022-05-25 10:29:15,632 [bic.py] => bias_correction => Task 1, Epoch 63/170 => Loss 2.386, Train_accy 78.000, Test_accy 74.200
2022-05-25 10:29:17,109 [bic.py] => bias_correction => Task 1, Epoch 64/170 => Loss 2.345, Train_accy 78.750, Test_accy 73.800
2022-05-25 10:29:18,667 [bic.py] => bias_correction => Task 1, Epoch 65/170 => Loss 2.332, Train_accy 78.750, Test_accy 73.850
2022-05-25 10:29:20,147 [bic.py] => bias_correction => Task 1, Epoch 66/170 => Loss 2.343, Train_accy 78.000, Test_accy 73.650
2022-05-25 10:29:21,686 [bic.py] => bias_correction => Task 1, Epoch 67/170 => Loss 2.369, Train_accy 79.000, Test_accy 73.950
2022-05-25 10:29:23,241 [bic.py] => bias_correction => Task 1, Epoch 68/170 => Loss 2.341, Train_accy 78.500, Test_accy 73.550
2022-05-25 10:29:24,767 [bic.py] => bias_correction => Task 1, Epoch 69/170 => Loss 2.377, Train_accy 77.500, Test_accy 74.100
2022-05-25 10:29:26,279 [bic.py] => bias_correction => Task 1, Epoch 70/170 => Loss 2.365, Train_accy 77.500, Test_accy 74.050
2022-05-25 10:29:27,776 [bic.py] => bias_correction => Task 1, Epoch 71/170 => Loss 2.316, Train_accy 76.000, Test_accy 73.900
2022-05-25 10:29:29,260 [bic.py] => bias_correction => Task 1, Epoch 72/170 => Loss 2.348, Train_accy 77.500, Test_accy 73.900
2022-05-25 10:29:30,793 [bic.py] => bias_correction => Task 1, Epoch 73/170 => Loss 2.369, Train_accy 77.750, Test_accy 73.650
2022-05-25 10:29:32,300 [bic.py] => bias_correction => Task 1, Epoch 74/170 => Loss 2.351, Train_accy 77.500, Test_accy 73.900
2022-05-25 10:29:33,813 [bic.py] => bias_correction => Task 1, Epoch 75/170 => Loss 2.346, Train_accy 77.750, Test_accy 73.800
2022-05-25 10:29:35,333 [bic.py] => bias_correction => Task 1, Epoch 76/170 => Loss 2.364, Train_accy 76.750, Test_accy 74.300
2022-05-25 10:29:36,854 [bic.py] => bias_correction => Task 1, Epoch 77/170 => Loss 2.336, Train_accy 76.000, Test_accy 74.000
2022-05-25 10:29:38,388 [bic.py] => bias_correction => Task 1, Epoch 78/170 => Loss 2.321, Train_accy 75.750, Test_accy 73.550
2022-05-25 10:29:39,870 [bic.py] => bias_correction => Task 1, Epoch 79/170 => Loss 2.328, Train_accy 78.750, Test_accy 74.100
2022-05-25 10:29:41,443 [bic.py] => bias_correction => Task 1, Epoch 80/170 => Loss 2.373, Train_accy 75.500, Test_accy 74.300
2022-05-25 10:29:43,019 [bic.py] => bias_correction => Task 1, Epoch 81/170 => Loss 2.358, Train_accy 77.750, Test_accy 73.850
2022-05-25 10:29:44,528 [bic.py] => bias_correction => Task 1, Epoch 82/170 => Loss 2.348, Train_accy 77.000, Test_accy 74.100
2022-05-25 10:29:46,047 [bic.py] => bias_correction => Task 1, Epoch 83/170 => Loss 2.314, Train_accy 77.000, Test_accy 74.100
2022-05-25 10:29:47,550 [bic.py] => bias_correction => Task 1, Epoch 84/170 => Loss 2.340, Train_accy 78.750, Test_accy 74.000
2022-05-25 10:29:49,079 [bic.py] => bias_correction => Task 1, Epoch 85/170 => Loss 2.327, Train_accy 75.750, Test_accy 73.600
2022-05-25 10:29:50,639 [bic.py] => bias_correction => Task 1, Epoch 86/170 => Loss 2.367, Train_accy 78.500, Test_accy 74.050
2022-05-25 10:29:52,121 [bic.py] => bias_correction => Task 1, Epoch 87/170 => Loss 2.369, Train_accy 76.500, Test_accy 73.700
2022-05-25 10:29:53,656 [bic.py] => bias_correction => Task 1, Epoch 88/170 => Loss 2.331, Train_accy 79.500, Test_accy 74.200
2022-05-25 10:29:55,142 [bic.py] => bias_correction => Task 1, Epoch 89/170 => Loss 2.343, Train_accy 77.250, Test_accy 73.950
2022-05-25 10:29:56,668 [bic.py] => bias_correction => Task 1, Epoch 90/170 => Loss 2.345, Train_accy 78.500, Test_accy 74.050
2022-05-25 10:29:58,200 [bic.py] => bias_correction => Task 1, Epoch 91/170 => Loss 2.319, Train_accy 80.500, Test_accy 73.900
2022-05-25 10:29:59,673 [bic.py] => bias_correction => Task 1, Epoch 92/170 => Loss 2.356, Train_accy 78.250, Test_accy 74.000
2022-05-25 10:30:01,182 [bic.py] => bias_correction => Task 1, Epoch 93/170 => Loss 2.350, Train_accy 79.000, Test_accy 74.350
2022-05-25 10:30:02,663 [bic.py] => bias_correction => Task 1, Epoch 94/170 => Loss 2.337, Train_accy 78.250, Test_accy 74.000
2022-05-25 10:30:04,164 [bic.py] => bias_correction => Task 1, Epoch 95/170 => Loss 2.358, Train_accy 79.500, Test_accy 73.750
2022-05-25 10:30:05,691 [bic.py] => bias_correction => Task 1, Epoch 96/170 => Loss 2.386, Train_accy 78.500, Test_accy 74.000
2022-05-25 10:30:07,262 [bic.py] => bias_correction => Task 1, Epoch 97/170 => Loss 2.407, Train_accy 77.750, Test_accy 74.100
2022-05-25 10:30:08,728 [bic.py] => bias_correction => Task 1, Epoch 98/170 => Loss 2.340, Train_accy 79.250, Test_accy 73.850
2022-05-25 10:30:10,225 [bic.py] => bias_correction => Task 1, Epoch 99/170 => Loss 2.348, Train_accy 77.250, Test_accy 73.700
2022-05-25 10:30:11,756 [bic.py] => bias_correction => Task 1, Epoch 100/170 => Loss 2.331, Train_accy 78.250, Test_accy 74.000
2022-05-25 10:30:13,193 [bic.py] => bias_correction => Task 1, Epoch 101/170 => Loss 2.370, Train_accy 77.500, Test_accy 73.700
2022-05-25 10:30:14,672 [bic.py] => bias_correction => Task 1, Epoch 102/170 => Loss 2.345, Train_accy 79.750, Test_accy 73.850
2022-05-25 10:30:16,198 [bic.py] => bias_correction => Task 1, Epoch 103/170 => Loss 2.346, Train_accy 76.750, Test_accy 73.550
2022-05-25 10:30:17,711 [bic.py] => bias_correction => Task 1, Epoch 104/170 => Loss 2.390, Train_accy 78.000, Test_accy 73.650
2022-05-25 10:30:19,375 [bic.py] => bias_correction => Task 1, Epoch 105/170 => Loss 2.370, Train_accy 76.750, Test_accy 73.550
2022-05-25 10:30:20,839 [bic.py] => bias_correction => Task 1, Epoch 106/170 => Loss 2.324, Train_accy 79.000, Test_accy 74.000
2022-05-25 10:30:22,318 [bic.py] => bias_correction => Task 1, Epoch 107/170 => Loss 2.414, Train_accy 77.000, Test_accy 73.850
2022-05-25 10:30:23,829 [bic.py] => bias_correction => Task 1, Epoch 108/170 => Loss 2.373, Train_accy 78.750, Test_accy 73.950
2022-05-25 10:30:25,393 [bic.py] => bias_correction => Task 1, Epoch 109/170 => Loss 2.347, Train_accy 78.750, Test_accy 74.000
2022-05-25 10:30:26,950 [bic.py] => bias_correction => Task 1, Epoch 110/170 => Loss 2.350, Train_accy 77.250, Test_accy 74.000
2022-05-25 10:30:28,561 [bic.py] => bias_correction => Task 1, Epoch 111/170 => Loss 2.335, Train_accy 78.500, Test_accy 74.200
2022-05-25 10:30:30,103 [bic.py] => bias_correction => Task 1, Epoch 112/170 => Loss 2.341, Train_accy 78.750, Test_accy 74.000
2022-05-25 10:30:31,575 [bic.py] => bias_correction => Task 1, Epoch 113/170 => Loss 2.359, Train_accy 77.750, Test_accy 74.250
2022-05-25 10:30:32,998 [bic.py] => bias_correction => Task 1, Epoch 114/170 => Loss 2.374, Train_accy 76.750, Test_accy 74.450
2022-05-25 10:30:34,427 [bic.py] => bias_correction => Task 1, Epoch 115/170 => Loss 2.357, Train_accy 77.000, Test_accy 74.250
2022-05-25 10:30:35,861 [bic.py] => bias_correction => Task 1, Epoch 116/170 => Loss 2.331, Train_accy 78.500, Test_accy 74.350
2022-05-25 10:30:37,355 [bic.py] => bias_correction => Task 1, Epoch 117/170 => Loss 2.352, Train_accy 78.750, Test_accy 74.400
2022-05-25 10:30:38,847 [bic.py] => bias_correction => Task 1, Epoch 118/170 => Loss 2.350, Train_accy 77.250, Test_accy 73.750
2022-05-25 10:30:40,320 [bic.py] => bias_correction => Task 1, Epoch 119/170 => Loss 2.333, Train_accy 76.250, Test_accy 73.900
2022-05-25 10:30:41,769 [bic.py] => bias_correction => Task 1, Epoch 120/170 => Loss 2.330, Train_accy 79.250, Test_accy 74.150
2022-05-25 10:30:43,277 [bic.py] => bias_correction => Task 1, Epoch 121/170 => Loss 2.322, Train_accy 77.750, Test_accy 73.800
2022-05-25 10:30:44,833 [bic.py] => bias_correction => Task 1, Epoch 122/170 => Loss 2.380, Train_accy 78.000, Test_accy 74.050
2022-05-25 10:30:46,373 [bic.py] => bias_correction => Task 1, Epoch 123/170 => Loss 2.359, Train_accy 76.250, Test_accy 74.100
2022-05-25 10:30:47,898 [bic.py] => bias_correction => Task 1, Epoch 124/170 => Loss 2.352, Train_accy 78.250, Test_accy 73.950
2022-05-25 10:30:49,461 [bic.py] => bias_correction => Task 1, Epoch 125/170 => Loss 2.336, Train_accy 79.750, Test_accy 73.950
2022-05-25 10:30:51,027 [bic.py] => bias_correction => Task 1, Epoch 126/170 => Loss 2.345, Train_accy 78.250, Test_accy 73.650
2022-05-25 10:30:52,590 [bic.py] => bias_correction => Task 1, Epoch 127/170 => Loss 2.398, Train_accy 76.250, Test_accy 74.050
2022-05-25 10:30:54,151 [bic.py] => bias_correction => Task 1, Epoch 128/170 => Loss 2.327, Train_accy 78.000, Test_accy 74.200
2022-05-25 10:30:55,707 [bic.py] => bias_correction => Task 1, Epoch 129/170 => Loss 2.351, Train_accy 77.750, Test_accy 74.500
2022-05-25 10:30:57,201 [bic.py] => bias_correction => Task 1, Epoch 130/170 => Loss 2.320, Train_accy 78.500, Test_accy 74.050
2022-05-25 10:30:58,696 [bic.py] => bias_correction => Task 1, Epoch 131/170 => Loss 2.359, Train_accy 77.250, Test_accy 74.200
2022-05-25 10:31:00,249 [bic.py] => bias_correction => Task 1, Epoch 132/170 => Loss 2.372, Train_accy 78.750, Test_accy 73.850
2022-05-25 10:31:01,800 [bic.py] => bias_correction => Task 1, Epoch 133/170 => Loss 2.355, Train_accy 79.000, Test_accy 73.800
2022-05-25 10:31:03,317 [bic.py] => bias_correction => Task 1, Epoch 134/170 => Loss 2.357, Train_accy 78.750, Test_accy 74.200
2022-05-25 10:31:04,951 [bic.py] => bias_correction => Task 1, Epoch 135/170 => Loss 2.328, Train_accy 78.750, Test_accy 73.750
2022-05-25 10:31:06,602 [bic.py] => bias_correction => Task 1, Epoch 136/170 => Loss 2.329, Train_accy 78.000, Test_accy 73.800
2022-05-25 10:31:08,030 [bic.py] => bias_correction => Task 1, Epoch 137/170 => Loss 2.335, Train_accy 76.250, Test_accy 74.050
2022-05-25 10:31:09,510 [bic.py] => bias_correction => Task 1, Epoch 138/170 => Loss 2.352, Train_accy 78.250, Test_accy 73.950
2022-05-25 10:31:11,036 [bic.py] => bias_correction => Task 1, Epoch 139/170 => Loss 2.298, Train_accy 77.000, Test_accy 73.700
2022-05-25 10:31:12,532 [bic.py] => bias_correction => Task 1, Epoch 140/170 => Loss 2.362, Train_accy 78.250, Test_accy 74.000
2022-05-25 10:31:14,002 [bic.py] => bias_correction => Task 1, Epoch 141/170 => Loss 2.341, Train_accy 77.000, Test_accy 73.650
2022-05-25 10:31:15,555 [bic.py] => bias_correction => Task 1, Epoch 142/170 => Loss 2.341, Train_accy 78.750, Test_accy 73.700
2022-05-25 10:31:17,159 [bic.py] => bias_correction => Task 1, Epoch 143/170 => Loss 2.370, Train_accy 78.250, Test_accy 73.750
2022-05-25 10:31:18,695 [bic.py] => bias_correction => Task 1, Epoch 144/170 => Loss 2.355, Train_accy 79.000, Test_accy 73.750
2022-05-25 10:31:20,207 [bic.py] => bias_correction => Task 1, Epoch 145/170 => Loss 2.325, Train_accy 76.750, Test_accy 73.350
2022-05-25 10:31:21,769 [bic.py] => bias_correction => Task 1, Epoch 146/170 => Loss 2.374, Train_accy 79.000, Test_accy 73.700
2022-05-25 10:31:23,345 [bic.py] => bias_correction => Task 1, Epoch 147/170 => Loss 2.387, Train_accy 77.500, Test_accy 73.800
2022-05-25 10:31:24,941 [bic.py] => bias_correction => Task 1, Epoch 148/170 => Loss 2.381, Train_accy 77.250, Test_accy 73.900
2022-05-25 10:31:26,542 [bic.py] => bias_correction => Task 1, Epoch 149/170 => Loss 2.355, Train_accy 79.750, Test_accy 73.650
2022-05-25 10:31:28,086 [bic.py] => bias_correction => Task 1, Epoch 150/170 => Loss 2.391, Train_accy 77.250, Test_accy 74.050
2022-05-25 10:31:29,741 [bic.py] => bias_correction => Task 1, Epoch 151/170 => Loss 2.342, Train_accy 81.250, Test_accy 74.050
2022-05-25 10:31:31,329 [bic.py] => bias_correction => Task 1, Epoch 152/170 => Loss 2.343, Train_accy 78.500, Test_accy 74.300
2022-05-25 10:31:32,886 [bic.py] => bias_correction => Task 1, Epoch 153/170 => Loss 2.335, Train_accy 79.750, Test_accy 74.250
2022-05-25 10:31:34,407 [bic.py] => bias_correction => Task 1, Epoch 154/170 => Loss 2.326, Train_accy 79.500, Test_accy 74.400
2022-05-25 10:31:36,000 [bic.py] => bias_correction => Task 1, Epoch 155/170 => Loss 2.345, Train_accy 77.250, Test_accy 74.400
2022-05-25 10:31:37,615 [bic.py] => bias_correction => Task 1, Epoch 156/170 => Loss 2.362, Train_accy 76.750, Test_accy 74.550
2022-05-25 10:31:39,156 [bic.py] => bias_correction => Task 1, Epoch 157/170 => Loss 2.339, Train_accy 77.000, Test_accy 74.350
2022-05-25 10:31:40,704 [bic.py] => bias_correction => Task 1, Epoch 158/170 => Loss 2.353, Train_accy 79.000, Test_accy 74.000
2022-05-25 10:31:42,189 [bic.py] => bias_correction => Task 1, Epoch 159/170 => Loss 2.347, Train_accy 79.500, Test_accy 74.200
2022-05-25 10:31:43,665 [bic.py] => bias_correction => Task 1, Epoch 160/170 => Loss 2.347, Train_accy 77.500, Test_accy 74.050
2022-05-25 10:31:45,201 [bic.py] => bias_correction => Task 1, Epoch 161/170 => Loss 2.332, Train_accy 78.750, Test_accy 74.100
2022-05-25 10:31:46,697 [bic.py] => bias_correction => Task 1, Epoch 162/170 => Loss 2.359, Train_accy 77.000, Test_accy 73.950
2022-05-25 10:31:48,236 [bic.py] => bias_correction => Task 1, Epoch 163/170 => Loss 2.343, Train_accy 79.500, Test_accy 73.800
2022-05-25 10:31:49,869 [bic.py] => bias_correction => Task 1, Epoch 164/170 => Loss 2.319, Train_accy 78.250, Test_accy 73.300
2022-05-25 10:31:51,485 [bic.py] => bias_correction => Task 1, Epoch 165/170 => Loss 2.332, Train_accy 79.000, Test_accy 73.850
2022-05-25 10:31:53,070 [bic.py] => bias_correction => Task 1, Epoch 166/170 => Loss 2.340, Train_accy 78.750, Test_accy 73.600
2022-05-25 10:31:54,688 [bic.py] => bias_correction => Task 1, Epoch 167/170 => Loss 2.354, Train_accy 77.250, Test_accy 73.700
2022-05-25 10:31:56,237 [bic.py] => bias_correction => Task 1, Epoch 168/170 => Loss 2.350, Train_accy 80.250, Test_accy 73.800
2022-05-25 10:31:57,779 [bic.py] => bias_correction => Task 1, Epoch 169/170 => Loss 2.347, Train_accy 78.750, Test_accy 74.150
2022-05-25 10:31:59,323 [bic.py] => bias_correction => Task 1, Epoch 170/170 => Loss 2.320, Train_accy 77.500, Test_accy 73.700
2022-05-25 10:31:59,324 [base.py] => Reducing exemplars...(100 per classes)
2022-05-25 10:32:01,680 [base.py] => Constructing exemplars...(100 per classes)
2022-05-25 10:32:07,366 [bic.py] => Parameters of bias layer:
2022-05-25 10:32:07,367 [bic.py] => 0 => 1.000, 0.000
2022-05-25 10:32:07,367 [bic.py] => 1 => 0.904, -1.125
2022-05-25 10:32:08,499 [bic.py] => Exemplar size: 2000
2022-05-25 10:32:08,500 [trainer.py] => CNN: {'total': 73.7, '00-09': 74.5, '10-19': 72.9, 'old': 74.5, 'new': 72.9}
2022-05-25 10:32:08,500 [trainer.py] => NME: {'total': 74.15, '00-09': 74.7, '10-19': 73.6, 'old': 74.7, 'new': 73.6}
2022-05-25 10:32:08,500 [trainer.py] => CNN top1 curve: [83.0, 73.7]
2022-05-25 10:32:08,500 [trainer.py] => CNN top5 curve: [99.1, 95.65]
2022-05-25 10:32:08,500 [trainer.py] => NME top1 curve: [82.8, 74.15]
2022-05-25 10:32:08,500 [trainer.py] => NME top5 curve: [99.0, 95.75]

2022-05-25 10:32:08,501 [trainer.py] => All params: 465458
2022-05-25 10:32:08,501 [trainer.py] => Trainable params: 465458
2022-05-25 10:32:08,502 [bic.py] => Learning on 20-30
2022-05-25 10:32:08,565 [bic.py] => Stage1 dset: 6700, Stage2 dset: 300
2022-05-25 10:32:08,565 [bic.py] => Lambda: 0.667
2022-05-25 10:32:08,572 [bic.py] => Parameters of bias layer:
2022-05-25 10:32:08,572 [bic.py] => 0 => 1.000, 0.000
2022-05-25 10:32:08,572 [bic.py] => 1 => 0.904, -1.125
2022-05-25 10:32:08,572 [bic.py] => 2 => 1.000, 0.000
2022-05-25 10:32:12,987 [bic.py] => training => Task 2, Epoch 1/170 => Loss 1.789, Train_accy 60.600, Test_accy 49.070
2022-05-25 10:32:17,251 [bic.py] => training => Task 2, Epoch 2/170 => Loss 1.480, Train_accy 66.150, Test_accy 48.800
2022-05-25 10:32:21,465 [bic.py] => training => Task 2, Epoch 3/170 => Loss 1.423, Train_accy 71.220, Test_accy 54.130
2022-05-25 10:32:25,710 [bic.py] => training => Task 2, Epoch 4/170 => Loss 1.391, Train_accy 73.060, Test_accy 55.000
2022-05-25 10:32:29,805 [bic.py] => training => Task 2, Epoch 5/170 => Loss 1.363, Train_accy 77.010, Test_accy 57.230
2022-05-25 10:32:33,947 [bic.py] => training => Task 2, Epoch 6/170 => Loss 1.353, Train_accy 75.340, Test_accy 57.100
2022-05-25 10:32:38,095 [bic.py] => training => Task 2, Epoch 7/170 => Loss 1.347, Train_accy 78.840, Test_accy 57.600
2022-05-25 10:32:42,284 [bic.py] => training => Task 2, Epoch 8/170 => Loss 1.330, Train_accy 77.220, Test_accy 56.900
2022-05-25 10:32:46,510 [bic.py] => training => Task 2, Epoch 9/170 => Loss 1.316, Train_accy 82.780, Test_accy 59.700
2022-05-25 10:32:50,692 [bic.py] => training => Task 2, Epoch 10/170 => Loss 1.299, Train_accy 81.300, Test_accy 56.830
2022-05-25 10:32:54,840 [bic.py] => training => Task 2, Epoch 11/170 => Loss 1.298, Train_accy 80.810, Test_accy 57.330
2022-05-25 10:32:59,039 [bic.py] => training => Task 2, Epoch 12/170 => Loss 1.292, Train_accy 82.630, Test_accy 58.300
2022-05-25 10:33:03,180 [bic.py] => training => Task 2, Epoch 13/170 => Loss 1.269, Train_accy 83.870, Test_accy 55.870
2022-05-25 10:33:07,377 [bic.py] => training => Task 2, Epoch 14/170 => Loss 1.275, Train_accy 82.190, Test_accy 56.700
2022-05-25 10:33:11,568 [bic.py] => training => Task 2, Epoch 15/170 => Loss 1.264, Train_accy 85.400, Test_accy 58.970
2022-05-25 10:33:15,746 [bic.py] => training => Task 2, Epoch 16/170 => Loss 1.263, Train_accy 83.670, Test_accy 57.070
2022-05-25 10:33:20,090 [bic.py] => training => Task 2, Epoch 17/170 => Loss 1.260, Train_accy 84.480, Test_accy 57.100
2022-05-25 10:33:24,199 [bic.py] => training => Task 2, Epoch 18/170 => Loss 1.251, Train_accy 86.070, Test_accy 59.670
2022-05-25 10:33:28,361 [bic.py] => training => Task 2, Epoch 19/170 => Loss 1.246, Train_accy 86.820, Test_accy 57.300
2022-05-25 10:33:32,535 [bic.py] => training => Task 2, Epoch 20/170 => Loss 1.250, Train_accy 84.280, Test_accy 54.530
2022-05-25 10:33:36,718 [bic.py] => training => Task 2, Epoch 21/170 => Loss 1.248, Train_accy 88.160, Test_accy 58.500
2022-05-25 10:33:41,039 [bic.py] => training => Task 2, Epoch 22/170 => Loss 1.240, Train_accy 89.310, Test_accy 60.300
2022-05-25 10:33:45,238 [bic.py] => training => Task 2, Epoch 23/170 => Loss 1.235, Train_accy 88.520, Test_accy 59.270
2022-05-25 10:33:49,339 [bic.py] => training => Task 2, Epoch 24/170 => Loss 1.236, Train_accy 87.000, Test_accy 58.900
2022-05-25 10:33:53,589 [bic.py] => training => Task 2, Epoch 25/170 => Loss 1.242, Train_accy 86.750, Test_accy 56.670
2022-05-25 10:33:57,741 [bic.py] => training => Task 2, Epoch 26/170 => Loss 1.248, Train_accy 87.900, Test_accy 59.030
2022-05-25 10:34:01,807 [bic.py] => training => Task 2, Epoch 27/170 => Loss 1.233, Train_accy 87.880, Test_accy 60.530
2022-05-25 10:34:06,015 [bic.py] => training => Task 2, Epoch 28/170 => Loss 1.232, Train_accy 88.130, Test_accy 58.530
2022-05-25 10:34:10,204 [bic.py] => training => Task 2, Epoch 29/170 => Loss 1.217, Train_accy 87.210, Test_accy 55.630
2022-05-25 10:34:14,560 [bic.py] => training => Task 2, Epoch 30/170 => Loss 1.216, Train_accy 88.840, Test_accy 57.770
2022-05-25 10:34:18,588 [bic.py] => training => Task 2, Epoch 31/170 => Loss 1.209, Train_accy 89.420, Test_accy 58.500
2022-05-25 10:34:22,690 [bic.py] => training => Task 2, Epoch 32/170 => Loss 1.209, Train_accy 87.820, Test_accy 54.630
2022-05-25 10:34:26,792 [bic.py] => training => Task 2, Epoch 33/170 => Loss 1.225, Train_accy 91.970, Test_accy 57.570
2022-05-25 10:34:30,997 [bic.py] => training => Task 2, Epoch 34/170 => Loss 1.209, Train_accy 89.520, Test_accy 59.970
2022-05-25 10:34:35,075 [bic.py] => training => Task 2, Epoch 35/170 => Loss 1.207, Train_accy 90.540, Test_accy 58.730
2022-05-25 10:34:39,137 [bic.py] => training => Task 2, Epoch 36/170 => Loss 1.217, Train_accy 89.850, Test_accy 58.830
2022-05-25 10:34:43,283 [bic.py] => training => Task 2, Epoch 37/170 => Loss 1.199, Train_accy 90.210, Test_accy 58.800
2022-05-25 10:34:47,379 [bic.py] => training => Task 2, Epoch 38/170 => Loss 1.210, Train_accy 88.700, Test_accy 58.270
2022-05-25 10:34:51,507 [bic.py] => training => Task 2, Epoch 39/170 => Loss 1.210, Train_accy 91.310, Test_accy 57.900
2022-05-25 10:34:55,637 [bic.py] => training => Task 2, Epoch 40/170 => Loss 1.207, Train_accy 90.610, Test_accy 59.170
2022-05-25 10:34:59,658 [bic.py] => training => Task 2, Epoch 41/170 => Loss 1.194, Train_accy 88.940, Test_accy 59.800
2022-05-25 10:35:03,730 [bic.py] => training => Task 2, Epoch 42/170 => Loss 1.186, Train_accy 90.960, Test_accy 56.070
2022-05-25 10:35:07,806 [bic.py] => training => Task 2, Epoch 43/170 => Loss 1.197, Train_accy 90.880, Test_accy 57.400
2022-05-25 10:35:11,932 [bic.py] => training => Task 2, Epoch 44/170 => Loss 1.197, Train_accy 90.570, Test_accy 55.770
2022-05-25 10:35:16,158 [bic.py] => training => Task 2, Epoch 45/170 => Loss 1.197, Train_accy 87.490, Test_accy 53.600
2022-05-25 10:35:20,229 [bic.py] => training => Task 2, Epoch 46/170 => Loss 1.196, Train_accy 88.870, Test_accy 56.100
2022-05-25 10:35:24,363 [bic.py] => training => Task 2, Epoch 47/170 => Loss 1.196, Train_accy 91.810, Test_accy 58.870
2022-05-25 10:35:28,397 [bic.py] => training => Task 2, Epoch 48/170 => Loss 1.196, Train_accy 91.180, Test_accy 59.670
2022-05-25 10:35:32,405 [bic.py] => training => Task 2, Epoch 49/170 => Loss 1.190, Train_accy 90.510, Test_accy 58.730
2022-05-25 10:35:36,637 [bic.py] => training => Task 2, Epoch 50/170 => Loss 1.180, Train_accy 90.670, Test_accy 57.500
2022-05-25 10:35:40,667 [bic.py] => training => Task 2, Epoch 51/170 => Loss 1.189, Train_accy 92.130, Test_accy 57.800
2022-05-25 10:35:44,868 [bic.py] => training => Task 2, Epoch 52/170 => Loss 1.184, Train_accy 92.550, Test_accy 56.900
2022-05-25 10:35:49,127 [bic.py] => training => Task 2, Epoch 53/170 => Loss 1.183, Train_accy 92.390, Test_accy 60.500
2022-05-25 10:35:53,251 [bic.py] => training => Task 2, Epoch 54/170 => Loss 1.185, Train_accy 88.550, Test_accy 57.030
2022-05-25 10:35:57,400 [bic.py] => training => Task 2, Epoch 55/170 => Loss 1.190, Train_accy 92.580, Test_accy 58.700
2022-05-25 10:36:01,587 [bic.py] => training => Task 2, Epoch 56/170 => Loss 1.192, Train_accy 93.780, Test_accy 59.400
2022-05-25 10:36:05,613 [bic.py] => training => Task 2, Epoch 57/170 => Loss 1.199, Train_accy 94.510, Test_accy 61.500
2022-05-25 10:36:09,741 [bic.py] => training => Task 2, Epoch 58/170 => Loss 1.192, Train_accy 91.180, Test_accy 57.730
2022-05-25 10:36:13,894 [bic.py] => training => Task 2, Epoch 59/170 => Loss 1.182, Train_accy 90.240, Test_accy 56.000
2022-05-25 10:36:18,053 [bic.py] => training => Task 2, Epoch 60/170 => Loss 1.196, Train_accy 90.910, Test_accy 58.470
2022-05-25 10:36:22,298 [bic.py] => training => Task 2, Epoch 61/170 => Loss 1.144, Train_accy 98.420, Test_accy 64.970
2022-05-25 10:36:26,445 [bic.py] => training => Task 2, Epoch 62/170 => Loss 1.115, Train_accy 99.120, Test_accy 64.600
2022-05-25 10:36:30,588 [bic.py] => training => Task 2, Epoch 63/170 => Loss 1.109, Train_accy 99.010, Test_accy 64.370
2022-05-25 10:36:34,761 [bic.py] => training => Task 2, Epoch 64/170 => Loss 1.103, Train_accy 99.190, Test_accy 64.300
2022-05-25 10:36:38,808 [bic.py] => training => Task 2, Epoch 65/170 => Loss 1.104, Train_accy 99.270, Test_accy 64.500
2022-05-25 10:36:42,775 [bic.py] => training => Task 2, Epoch 66/170 => Loss 1.103, Train_accy 99.240, Test_accy 64.570
2022-05-25 10:36:46,969 [bic.py] => training => Task 2, Epoch 67/170 => Loss 1.097, Train_accy 99.360, Test_accy 64.530
2022-05-25 10:36:50,990 [bic.py] => training => Task 2, Epoch 68/170 => Loss 1.101, Train_accy 99.430, Test_accy 64.400
2022-05-25 10:36:55,172 [bic.py] => training => Task 2, Epoch 69/170 => Loss 1.103, Train_accy 99.550, Test_accy 64.400
2022-05-25 10:36:59,321 [bic.py] => training => Task 2, Epoch 70/170 => Loss 1.094, Train_accy 99.510, Test_accy 64.200
2022-05-25 10:37:03,399 [bic.py] => training => Task 2, Epoch 71/170 => Loss 1.098, Train_accy 99.580, Test_accy 64.030
2022-05-25 10:37:07,473 [bic.py] => training => Task 2, Epoch 72/170 => Loss 1.092, Train_accy 99.430, Test_accy 64.470
2022-05-25 10:37:11,572 [bic.py] => training => Task 2, Epoch 73/170 => Loss 1.090, Train_accy 99.610, Test_accy 64.800
2022-05-25 10:37:15,786 [bic.py] => training => Task 2, Epoch 74/170 => Loss 1.085, Train_accy 99.420, Test_accy 64.370
2022-05-25 10:37:20,027 [bic.py] => training => Task 2, Epoch 75/170 => Loss 1.093, Train_accy 99.610, Test_accy 64.700
2022-05-25 10:37:24,104 [bic.py] => training => Task 2, Epoch 76/170 => Loss 1.094, Train_accy 99.660, Test_accy 64.400
2022-05-25 10:37:28,224 [bic.py] => training => Task 2, Epoch 77/170 => Loss 1.093, Train_accy 99.520, Test_accy 64.330
2022-05-25 10:37:32,410 [bic.py] => training => Task 2, Epoch 78/170 => Loss 1.090, Train_accy 99.330, Test_accy 64.670
2022-05-25 10:37:36,635 [bic.py] => training => Task 2, Epoch 79/170 => Loss 1.093, Train_accy 99.520, Test_accy 64.700
2022-05-25 10:37:40,746 [bic.py] => training => Task 2, Epoch 80/170 => Loss 1.085, Train_accy 99.640, Test_accy 64.430
2022-05-25 10:37:44,859 [bic.py] => training => Task 2, Epoch 81/170 => Loss 1.089, Train_accy 99.730, Test_accy 64.730
2022-05-25 10:37:49,047 [bic.py] => training => Task 2, Epoch 82/170 => Loss 1.083, Train_accy 99.660, Test_accy 64.400
2022-05-25 10:37:53,187 [bic.py] => training => Task 2, Epoch 83/170 => Loss 1.089, Train_accy 99.600, Test_accy 64.470
2022-05-25 10:37:57,357 [bic.py] => training => Task 2, Epoch 84/170 => Loss 1.086, Train_accy 99.640, Test_accy 64.500
2022-05-25 10:38:01,497 [bic.py] => training => Task 2, Epoch 85/170 => Loss 1.084, Train_accy 99.720, Test_accy 64.100
2022-05-25 10:38:05,658 [bic.py] => training => Task 2, Epoch 86/170 => Loss 1.085, Train_accy 99.810, Test_accy 64.400
2022-05-25 10:38:09,855 [bic.py] => training => Task 2, Epoch 87/170 => Loss 1.086, Train_accy 99.660, Test_accy 64.500
2022-05-25 10:38:14,050 [bic.py] => training => Task 2, Epoch 88/170 => Loss 1.086, Train_accy 99.790, Test_accy 64.070
2022-05-25 10:38:18,215 [bic.py] => training => Task 2, Epoch 89/170 => Loss 1.092, Train_accy 99.660, Test_accy 64.830
2022-05-25 10:38:22,480 [bic.py] => training => Task 2, Epoch 90/170 => Loss 1.084, Train_accy 99.700, Test_accy 64.300
2022-05-25 10:38:26,636 [bic.py] => training => Task 2, Epoch 91/170 => Loss 1.087, Train_accy 99.750, Test_accy 64.970
2022-05-25 10:38:30,815 [bic.py] => training => Task 2, Epoch 92/170 => Loss 1.080, Train_accy 99.570, Test_accy 64.330
2022-05-25 10:38:34,987 [bic.py] => training => Task 2, Epoch 93/170 => Loss 1.088, Train_accy 99.630, Test_accy 64.300
2022-05-25 10:38:39,086 [bic.py] => training => Task 2, Epoch 94/170 => Loss 1.085, Train_accy 99.760, Test_accy 64.770
2022-05-25 10:38:43,267 [bic.py] => training => Task 2, Epoch 95/170 => Loss 1.086, Train_accy 99.720, Test_accy 64.200
2022-05-25 10:38:47,491 [bic.py] => training => Task 2, Epoch 96/170 => Loss 1.079, Train_accy 99.730, Test_accy 64.570
2022-05-25 10:38:51,620 [bic.py] => training => Task 2, Epoch 97/170 => Loss 1.078, Train_accy 99.610, Test_accy 63.930
2022-05-25 10:38:55,757 [bic.py] => training => Task 2, Epoch 98/170 => Loss 1.081, Train_accy 99.640, Test_accy 64.470
2022-05-25 10:38:59,955 [bic.py] => training => Task 2, Epoch 99/170 => Loss 1.079, Train_accy 99.820, Test_accy 64.400
2022-05-25 10:39:04,066 [bic.py] => training => Task 2, Epoch 100/170 => Loss 1.081, Train_accy 99.600, Test_accy 64.230
2022-05-25 10:39:08,182 [bic.py] => training => Task 2, Epoch 101/170 => Loss 1.085, Train_accy 99.670, Test_accy 64.270
2022-05-25 10:39:12,372 [bic.py] => training => Task 2, Epoch 102/170 => Loss 1.083, Train_accy 99.690, Test_accy 64.300
2022-05-25 10:39:16,388 [bic.py] => training => Task 2, Epoch 103/170 => Loss 1.082, Train_accy 99.720, Test_accy 64.600
2022-05-25 10:39:20,603 [bic.py] => training => Task 2, Epoch 104/170 => Loss 1.079, Train_accy 99.750, Test_accy 64.700
2022-05-25 10:39:24,737 [bic.py] => training => Task 2, Epoch 105/170 => Loss 1.075, Train_accy 99.670, Test_accy 64.470
2022-05-25 10:39:28,940 [bic.py] => training => Task 2, Epoch 106/170 => Loss 1.077, Train_accy 99.790, Test_accy 64.470
2022-05-25 10:39:33,135 [bic.py] => training => Task 2, Epoch 107/170 => Loss 1.079, Train_accy 99.880, Test_accy 64.800
2022-05-25 10:39:37,270 [bic.py] => training => Task 2, Epoch 108/170 => Loss 1.077, Train_accy 99.820, Test_accy 64.670
2022-05-25 10:39:41,408 [bic.py] => training => Task 2, Epoch 109/170 => Loss 1.077, Train_accy 99.750, Test_accy 64.400
2022-05-25 10:39:45,507 [bic.py] => training => Task 2, Epoch 110/170 => Loss 1.076, Train_accy 99.750, Test_accy 64.670
2022-05-25 10:39:49,677 [bic.py] => training => Task 2, Epoch 111/170 => Loss 1.074, Train_accy 99.660, Test_accy 64.970
2022-05-25 10:39:53,861 [bic.py] => training => Task 2, Epoch 112/170 => Loss 1.081, Train_accy 99.780, Test_accy 64.570
2022-05-25 10:39:58,156 [bic.py] => training => Task 2, Epoch 113/170 => Loss 1.080, Train_accy 99.810, Test_accy 64.730
2022-05-25 10:40:02,303 [bic.py] => training => Task 2, Epoch 114/170 => Loss 1.083, Train_accy 99.790, Test_accy 65.000
2022-05-25 10:40:06,484 [bic.py] => training => Task 2, Epoch 115/170 => Loss 1.080, Train_accy 99.760, Test_accy 64.670
2022-05-25 10:40:10,718 [bic.py] => training => Task 2, Epoch 116/170 => Loss 1.077, Train_accy 99.820, Test_accy 64.470
2022-05-25 10:40:15,008 [bic.py] => training => Task 2, Epoch 117/170 => Loss 1.080, Train_accy 99.780, Test_accy 64.530
2022-05-25 10:40:19,299 [bic.py] => training => Task 2, Epoch 118/170 => Loss 1.078, Train_accy 99.690, Test_accy 64.730
2022-05-25 10:40:23,399 [bic.py] => training => Task 2, Epoch 119/170 => Loss 1.080, Train_accy 99.850, Test_accy 64.300
2022-05-25 10:40:27,514 [bic.py] => training => Task 2, Epoch 120/170 => Loss 1.071, Train_accy 99.870, Test_accy 64.330
2022-05-25 10:40:31,766 [bic.py] => training => Task 2, Epoch 121/170 => Loss 1.075, Train_accy 99.750, Test_accy 64.400
2022-05-25 10:40:36,039 [bic.py] => training => Task 2, Epoch 122/170 => Loss 1.077, Train_accy 99.810, Test_accy 64.530
2022-05-25 10:40:40,283 [bic.py] => training => Task 2, Epoch 123/170 => Loss 1.080, Train_accy 99.810, Test_accy 64.370
2022-05-25 10:40:44,685 [bic.py] => training => Task 2, Epoch 124/170 => Loss 1.073, Train_accy 99.780, Test_accy 64.700
2022-05-25 10:40:49,054 [bic.py] => training => Task 2, Epoch 125/170 => Loss 1.077, Train_accy 99.780, Test_accy 64.530
2022-05-25 10:40:53,251 [bic.py] => training => Task 2, Epoch 126/170 => Loss 1.078, Train_accy 99.760, Test_accy 64.530
2022-05-25 10:40:57,507 [bic.py] => training => Task 2, Epoch 127/170 => Loss 1.078, Train_accy 99.760, Test_accy 64.500
2022-05-25 10:41:01,851 [bic.py] => training => Task 2, Epoch 128/170 => Loss 1.081, Train_accy 99.730, Test_accy 64.230
2022-05-25 10:41:06,158 [bic.py] => training => Task 2, Epoch 129/170 => Loss 1.074, Train_accy 99.640, Test_accy 64.430
2022-05-25 10:41:10,390 [bic.py] => training => Task 2, Epoch 130/170 => Loss 1.074, Train_accy 99.660, Test_accy 64.430
2022-05-25 10:41:14,764 [bic.py] => training => Task 2, Epoch 131/170 => Loss 1.076, Train_accy 99.700, Test_accy 64.570
2022-05-25 10:41:18,956 [bic.py] => training => Task 2, Epoch 132/170 => Loss 1.079, Train_accy 99.780, Test_accy 64.430
2022-05-25 10:41:23,251 [bic.py] => training => Task 2, Epoch 133/170 => Loss 1.079, Train_accy 99.730, Test_accy 64.570
2022-05-25 10:41:27,473 [bic.py] => training => Task 2, Epoch 134/170 => Loss 1.076, Train_accy 99.820, Test_accy 64.300
2022-05-25 10:41:31,687 [bic.py] => training => Task 2, Epoch 135/170 => Loss 1.077, Train_accy 99.750, Test_accy 64.470
2022-05-25 10:41:36,071 [bic.py] => training => Task 2, Epoch 136/170 => Loss 1.076, Train_accy 99.900, Test_accy 64.200
2022-05-25 10:41:40,616 [bic.py] => training => Task 2, Epoch 137/170 => Loss 1.079, Train_accy 99.810, Test_accy 64.500
2022-05-25 10:41:45,000 [bic.py] => training => Task 2, Epoch 138/170 => Loss 1.078, Train_accy 99.780, Test_accy 64.730
2022-05-25 10:41:49,298 [bic.py] => training => Task 2, Epoch 139/170 => Loss 1.079, Train_accy 99.840, Test_accy 64.100
2022-05-25 10:41:53,707 [bic.py] => training => Task 2, Epoch 140/170 => Loss 1.075, Train_accy 99.750, Test_accy 64.330
2022-05-25 10:41:57,951 [bic.py] => training => Task 2, Epoch 141/170 => Loss 1.074, Train_accy 99.850, Test_accy 64.470
2022-05-25 10:42:02,374 [bic.py] => training => Task 2, Epoch 142/170 => Loss 1.079, Train_accy 99.810, Test_accy 64.730
2022-05-25 10:42:06,674 [bic.py] => training => Task 2, Epoch 143/170 => Loss 1.074, Train_accy 99.790, Test_accy 64.630
2022-05-25 10:42:11,093 [bic.py] => training => Task 2, Epoch 144/170 => Loss 1.075, Train_accy 99.750, Test_accy 64.400
2022-05-25 10:42:15,306 [bic.py] => training => Task 2, Epoch 145/170 => Loss 1.074, Train_accy 99.810, Test_accy 64.270
2022-05-25 10:42:19,458 [bic.py] => training => Task 2, Epoch 146/170 => Loss 1.079, Train_accy 99.730, Test_accy 64.270
2022-05-25 10:42:23,736 [bic.py] => training => Task 2, Epoch 147/170 => Loss 1.078, Train_accy 99.790, Test_accy 64.800
2022-05-25 10:42:28,089 [bic.py] => training => Task 2, Epoch 148/170 => Loss 1.080, Train_accy 99.760, Test_accy 64.430
2022-05-25 10:42:32,442 [bic.py] => training => Task 2, Epoch 149/170 => Loss 1.074, Train_accy 99.870, Test_accy 64.770
2022-05-25 10:42:36,692 [bic.py] => training => Task 2, Epoch 150/170 => Loss 1.075, Train_accy 99.790, Test_accy 64.200
2022-05-25 10:42:40,925 [bic.py] => training => Task 2, Epoch 151/170 => Loss 1.077, Train_accy 99.810, Test_accy 64.600
2022-05-25 10:42:45,293 [bic.py] => training => Task 2, Epoch 152/170 => Loss 1.078, Train_accy 99.670, Test_accy 64.470
2022-05-25 10:42:49,547 [bic.py] => training => Task 2, Epoch 153/170 => Loss 1.074, Train_accy 99.810, Test_accy 64.430
2022-05-25 10:42:53,950 [bic.py] => training => Task 2, Epoch 154/170 => Loss 1.076, Train_accy 99.790, Test_accy 64.270
2022-05-25 10:42:58,347 [bic.py] => training => Task 2, Epoch 155/170 => Loss 1.077, Train_accy 99.820, Test_accy 64.070
2022-05-25 10:43:02,513 [bic.py] => training => Task 2, Epoch 156/170 => Loss 1.078, Train_accy 99.810, Test_accy 64.370
2022-05-25 10:43:06,762 [bic.py] => training => Task 2, Epoch 157/170 => Loss 1.078, Train_accy 99.820, Test_accy 64.570
2022-05-25 10:43:10,936 [bic.py] => training => Task 2, Epoch 158/170 => Loss 1.077, Train_accy 99.670, Test_accy 64.470
2022-05-25 10:43:15,137 [bic.py] => training => Task 2, Epoch 159/170 => Loss 1.076, Train_accy 99.730, Test_accy 64.370
2022-05-25 10:43:19,506 [bic.py] => training => Task 2, Epoch 160/170 => Loss 1.079, Train_accy 99.700, Test_accy 64.570
2022-05-25 10:43:23,816 [bic.py] => training => Task 2, Epoch 161/170 => Loss 1.072, Train_accy 99.670, Test_accy 64.400
2022-05-25 10:43:28,201 [bic.py] => training => Task 2, Epoch 162/170 => Loss 1.072, Train_accy 99.750, Test_accy 64.730
2022-05-25 10:43:32,671 [bic.py] => training => Task 2, Epoch 163/170 => Loss 1.078, Train_accy 99.810, Test_accy 64.300
2022-05-25 10:43:36,917 [bic.py] => training => Task 2, Epoch 164/170 => Loss 1.074, Train_accy 99.850, Test_accy 64.770
2022-05-25 10:43:41,220 [bic.py] => training => Task 2, Epoch 165/170 => Loss 1.078, Train_accy 99.810, Test_accy 64.600
2022-05-25 10:43:45,390 [bic.py] => training => Task 2, Epoch 166/170 => Loss 1.075, Train_accy 99.810, Test_accy 64.370
2022-05-25 10:43:49,576 [bic.py] => training => Task 2, Epoch 167/170 => Loss 1.083, Train_accy 99.780, Test_accy 64.500
2022-05-25 10:43:53,857 [bic.py] => training => Task 2, Epoch 168/170 => Loss 1.081, Train_accy 99.790, Test_accy 64.330
2022-05-25 10:43:58,056 [bic.py] => training => Task 2, Epoch 169/170 => Loss 1.073, Train_accy 99.820, Test_accy 64.400
2022-05-25 10:44:02,299 [bic.py] => training => Task 2, Epoch 170/170 => Loss 1.076, Train_accy 99.810, Test_accy 64.300
2022-05-25 10:44:03,854 [bic.py] => bias_correction => Task 2, Epoch 1/170 => Loss 2.822, Train_accy 75.000, Test_accy 66.870
2022-05-25 10:44:05,505 [bic.py] => bias_correction => Task 2, Epoch 2/170 => Loss 2.767, Train_accy 78.000, Test_accy 67.400
2022-05-25 10:44:07,131 [bic.py] => bias_correction => Task 2, Epoch 3/170 => Loss 2.809, Train_accy 75.670, Test_accy 65.000
2022-05-25 10:44:08,760 [bic.py] => bias_correction => Task 2, Epoch 4/170 => Loss 2.781, Train_accy 78.330, Test_accy 68.300
2022-05-25 10:44:10,419 [bic.py] => bias_correction => Task 2, Epoch 5/170 => Loss 2.772, Train_accy 78.670, Test_accy 66.830
2022-05-25 10:44:12,081 [bic.py] => bias_correction => Task 2, Epoch 6/170 => Loss 2.774, Train_accy 77.000, Test_accy 66.530
2022-05-25 10:44:13,700 [bic.py] => bias_correction => Task 2, Epoch 7/170 => Loss 2.802, Train_accy 77.000, Test_accy 67.830
2022-05-25 10:44:15,255 [bic.py] => bias_correction => Task 2, Epoch 8/170 => Loss 2.770, Train_accy 79.330, Test_accy 67.000
2022-05-25 10:44:16,943 [bic.py] => bias_correction => Task 2, Epoch 9/170 => Loss 2.777, Train_accy 77.000, Test_accy 67.600
2022-05-25 10:44:18,577 [bic.py] => bias_correction => Task 2, Epoch 10/170 => Loss 2.769, Train_accy 79.670, Test_accy 67.570
2022-05-25 10:44:20,298 [bic.py] => bias_correction => Task 2, Epoch 11/170 => Loss 2.761, Train_accy 78.670, Test_accy 67.200
2022-05-25 10:44:21,894 [bic.py] => bias_correction => Task 2, Epoch 12/170 => Loss 2.760, Train_accy 76.330, Test_accy 67.730
2022-05-25 10:44:23,685 [bic.py] => bias_correction => Task 2, Epoch 13/170 => Loss 2.760, Train_accy 78.670, Test_accy 68.030
2022-05-25 10:44:25,318 [bic.py] => bias_correction => Task 2, Epoch 14/170 => Loss 2.758, Train_accy 76.330, Test_accy 67.400
2022-05-25 10:44:26,945 [bic.py] => bias_correction => Task 2, Epoch 15/170 => Loss 2.776, Train_accy 77.330, Test_accy 68.000
2022-05-25 10:44:28,545 [bic.py] => bias_correction => Task 2, Epoch 16/170 => Loss 2.761, Train_accy 77.330, Test_accy 68.030
2022-05-25 10:44:30,113 [bic.py] => bias_correction => Task 2, Epoch 17/170 => Loss 2.792, Train_accy 78.000, Test_accy 67.970
2022-05-25 10:44:31,689 [bic.py] => bias_correction => Task 2, Epoch 18/170 => Loss 2.775, Train_accy 77.670, Test_accy 68.100
2022-05-25 10:44:33,265 [bic.py] => bias_correction => Task 2, Epoch 19/170 => Loss 2.766, Train_accy 79.330, Test_accy 68.330
2022-05-25 10:44:34,891 [bic.py] => bias_correction => Task 2, Epoch 20/170 => Loss 2.750, Train_accy 76.670, Test_accy 68.030
2022-05-25 10:44:36,473 [bic.py] => bias_correction => Task 2, Epoch 21/170 => Loss 2.771, Train_accy 76.000, Test_accy 67.970
2022-05-25 10:44:38,017 [bic.py] => bias_correction => Task 2, Epoch 22/170 => Loss 2.762, Train_accy 75.670, Test_accy 67.930
2022-05-25 10:44:39,662 [bic.py] => bias_correction => Task 2, Epoch 23/170 => Loss 2.777, Train_accy 78.000, Test_accy 67.600
2022-05-25 10:44:41,327 [bic.py] => bias_correction => Task 2, Epoch 24/170 => Loss 2.764, Train_accy 79.000, Test_accy 67.830
2022-05-25 10:44:42,969 [bic.py] => bias_correction => Task 2, Epoch 25/170 => Loss 2.757, Train_accy 74.670, Test_accy 68.230
2022-05-25 10:44:44,603 [bic.py] => bias_correction => Task 2, Epoch 26/170 => Loss 2.759, Train_accy 76.000, Test_accy 68.100
2022-05-25 10:44:46,265 [bic.py] => bias_correction => Task 2, Epoch 27/170 => Loss 2.767, Train_accy 76.330, Test_accy 68.170
2022-05-25 10:44:47,865 [bic.py] => bias_correction => Task 2, Epoch 28/170 => Loss 2.782, Train_accy 74.670, Test_accy 67.970
2022-05-25 10:44:49,499 [bic.py] => bias_correction => Task 2, Epoch 29/170 => Loss 2.742, Train_accy 79.670, Test_accy 68.030
2022-05-25 10:44:51,293 [bic.py] => bias_correction => Task 2, Epoch 30/170 => Loss 2.748, Train_accy 76.670, Test_accy 68.300
2022-05-25 10:44:52,968 [bic.py] => bias_correction => Task 2, Epoch 31/170 => Loss 2.770, Train_accy 74.330, Test_accy 68.130
2022-05-25 10:44:54,541 [bic.py] => bias_correction => Task 2, Epoch 32/170 => Loss 2.754, Train_accy 76.000, Test_accy 67.800
2022-05-25 10:44:56,156 [bic.py] => bias_correction => Task 2, Epoch 33/170 => Loss 2.756, Train_accy 76.000, Test_accy 67.700
2022-05-25 10:44:57,878 [bic.py] => bias_correction => Task 2, Epoch 34/170 => Loss 2.760, Train_accy 78.330, Test_accy 68.030
2022-05-25 10:44:59,562 [bic.py] => bias_correction => Task 2, Epoch 35/170 => Loss 2.753, Train_accy 78.000, Test_accy 68.070
2022-05-25 10:45:01,218 [bic.py] => bias_correction => Task 2, Epoch 36/170 => Loss 2.744, Train_accy 77.330, Test_accy 68.330
2022-05-25 10:45:02,945 [bic.py] => bias_correction => Task 2, Epoch 37/170 => Loss 2.773, Train_accy 79.670, Test_accy 68.230
2022-05-25 10:45:04,598 [bic.py] => bias_correction => Task 2, Epoch 38/170 => Loss 2.787, Train_accy 76.670, Test_accy 68.100
2022-05-25 10:45:06,367 [bic.py] => bias_correction => Task 2, Epoch 39/170 => Loss 2.778, Train_accy 77.330, Test_accy 67.770
2022-05-25 10:45:08,040 [bic.py] => bias_correction => Task 2, Epoch 40/170 => Loss 2.772, Train_accy 77.330, Test_accy 67.870
2022-05-25 10:45:09,749 [bic.py] => bias_correction => Task 2, Epoch 41/170 => Loss 2.785, Train_accy 77.000, Test_accy 68.070
2022-05-25 10:45:11,316 [bic.py] => bias_correction => Task 2, Epoch 42/170 => Loss 2.745, Train_accy 78.330, Test_accy 68.200
2022-05-25 10:45:12,888 [bic.py] => bias_correction => Task 2, Epoch 43/170 => Loss 2.784, Train_accy 79.330, Test_accy 68.270
2022-05-25 10:45:14,535 [bic.py] => bias_correction => Task 2, Epoch 44/170 => Loss 2.769, Train_accy 77.670, Test_accy 68.030
2022-05-25 10:45:16,207 [bic.py] => bias_correction => Task 2, Epoch 45/170 => Loss 2.772, Train_accy 78.670, Test_accy 68.230
2022-05-25 10:45:17,864 [bic.py] => bias_correction => Task 2, Epoch 46/170 => Loss 2.750, Train_accy 77.670, Test_accy 67.770
2022-05-25 10:45:19,411 [bic.py] => bias_correction => Task 2, Epoch 47/170 => Loss 2.748, Train_accy 77.670, Test_accy 68.030
2022-05-25 10:45:20,982 [bic.py] => bias_correction => Task 2, Epoch 48/170 => Loss 2.740, Train_accy 79.670, Test_accy 68.270
2022-05-25 10:45:22,597 [bic.py] => bias_correction => Task 2, Epoch 49/170 => Loss 2.744, Train_accy 78.000, Test_accy 68.070
2022-05-25 10:45:24,279 [bic.py] => bias_correction => Task 2, Epoch 50/170 => Loss 2.765, Train_accy 79.330, Test_accy 68.330
2022-05-25 10:45:25,984 [bic.py] => bias_correction => Task 2, Epoch 51/170 => Loss 2.769, Train_accy 78.000, Test_accy 67.770
2022-05-25 10:45:27,603 [bic.py] => bias_correction => Task 2, Epoch 52/170 => Loss 2.755, Train_accy 79.000, Test_accy 67.570
2022-05-25 10:45:29,283 [bic.py] => bias_correction => Task 2, Epoch 53/170 => Loss 2.729, Train_accy 78.000, Test_accy 68.000
2022-05-25 10:45:30,890 [bic.py] => bias_correction => Task 2, Epoch 54/170 => Loss 2.738, Train_accy 76.670, Test_accy 68.030
2022-05-25 10:45:32,604 [bic.py] => bias_correction => Task 2, Epoch 55/170 => Loss 2.753, Train_accy 78.670, Test_accy 68.330
2022-05-25 10:45:34,386 [bic.py] => bias_correction => Task 2, Epoch 56/170 => Loss 2.753, Train_accy 80.670, Test_accy 68.330
2022-05-25 10:45:36,167 [bic.py] => bias_correction => Task 2, Epoch 57/170 => Loss 2.751, Train_accy 77.330, Test_accy 68.300
2022-05-25 10:45:37,818 [bic.py] => bias_correction => Task 2, Epoch 58/170 => Loss 2.743, Train_accy 77.000, Test_accy 67.800
2022-05-25 10:45:39,442 [bic.py] => bias_correction => Task 2, Epoch 59/170 => Loss 2.765, Train_accy 79.330, Test_accy 67.730
2022-05-25 10:45:40,997 [bic.py] => bias_correction => Task 2, Epoch 60/170 => Loss 2.756, Train_accy 78.670, Test_accy 68.100
2022-05-25 10:45:42,654 [bic.py] => bias_correction => Task 2, Epoch 61/170 => Loss 2.770, Train_accy 75.330, Test_accy 68.030
2022-05-25 10:45:44,395 [bic.py] => bias_correction => Task 2, Epoch 62/170 => Loss 2.734, Train_accy 80.000, Test_accy 68.070
2022-05-25 10:45:46,133 [bic.py] => bias_correction => Task 2, Epoch 63/170 => Loss 2.746, Train_accy 74.330, Test_accy 67.830
2022-05-25 10:45:47,791 [bic.py] => bias_correction => Task 2, Epoch 64/170 => Loss 2.772, Train_accy 77.000, Test_accy 68.000
2022-05-25 10:45:49,481 [bic.py] => bias_correction => Task 2, Epoch 65/170 => Loss 2.748, Train_accy 76.670, Test_accy 68.030
2022-05-25 10:45:51,172 [bic.py] => bias_correction => Task 2, Epoch 66/170 => Loss 2.747, Train_accy 80.330, Test_accy 68.000
2022-05-25 10:45:52,816 [bic.py] => bias_correction => Task 2, Epoch 67/170 => Loss 2.765, Train_accy 79.000, Test_accy 67.830
2022-05-25 10:45:54,485 [bic.py] => bias_correction => Task 2, Epoch 68/170 => Loss 2.765, Train_accy 78.330, Test_accy 67.900
2022-05-25 10:45:56,104 [bic.py] => bias_correction => Task 2, Epoch 69/170 => Loss 2.746, Train_accy 76.000, Test_accy 67.970
2022-05-25 10:45:57,872 [bic.py] => bias_correction => Task 2, Epoch 70/170 => Loss 2.746, Train_accy 78.670, Test_accy 68.070
2022-05-25 10:45:59,493 [bic.py] => bias_correction => Task 2, Epoch 71/170 => Loss 2.737, Train_accy 75.670, Test_accy 68.130
2022-05-25 10:46:01,215 [bic.py] => bias_correction => Task 2, Epoch 72/170 => Loss 2.749, Train_accy 79.000, Test_accy 68.230
2022-05-25 10:46:02,906 [bic.py] => bias_correction => Task 2, Epoch 73/170 => Loss 2.760, Train_accy 78.330, Test_accy 68.230
2022-05-25 10:46:04,594 [bic.py] => bias_correction => Task 2, Epoch 74/170 => Loss 2.736, Train_accy 79.330, Test_accy 68.170
2022-05-25 10:46:06,243 [bic.py] => bias_correction => Task 2, Epoch 75/170 => Loss 2.763, Train_accy 77.330, Test_accy 68.330
2022-05-25 10:46:07,974 [bic.py] => bias_correction => Task 2, Epoch 76/170 => Loss 2.772, Train_accy 77.670, Test_accy 68.230
2022-05-25 10:46:09,633 [bic.py] => bias_correction => Task 2, Epoch 77/170 => Loss 2.752, Train_accy 75.670, Test_accy 68.230
2022-05-25 10:46:11,277 [bic.py] => bias_correction => Task 2, Epoch 78/170 => Loss 2.740, Train_accy 76.330, Test_accy 68.270
2022-05-25 10:46:12,949 [bic.py] => bias_correction => Task 2, Epoch 79/170 => Loss 2.772, Train_accy 77.330, Test_accy 68.000
2022-05-25 10:46:14,623 [bic.py] => bias_correction => Task 2, Epoch 80/170 => Loss 2.755, Train_accy 78.000, Test_accy 68.030
2022-05-25 10:46:16,197 [bic.py] => bias_correction => Task 2, Epoch 81/170 => Loss 2.741, Train_accy 78.330, Test_accy 68.070
2022-05-25 10:46:17,803 [bic.py] => bias_correction => Task 2, Epoch 82/170 => Loss 2.755, Train_accy 79.330, Test_accy 68.070
2022-05-25 10:46:19,412 [bic.py] => bias_correction => Task 2, Epoch 83/170 => Loss 2.755, Train_accy 80.000, Test_accy 67.970
2022-05-25 10:46:20,991 [bic.py] => bias_correction => Task 2, Epoch 84/170 => Loss 2.727, Train_accy 78.670, Test_accy 67.800
2022-05-25 10:46:22,834 [bic.py] => bias_correction => Task 2, Epoch 85/170 => Loss 2.738, Train_accy 78.330, Test_accy 67.900
2022-05-25 10:46:24,478 [bic.py] => bias_correction => Task 2, Epoch 86/170 => Loss 2.741, Train_accy 78.330, Test_accy 68.030
2022-05-25 10:46:26,135 [bic.py] => bias_correction => Task 2, Epoch 87/170 => Loss 2.748, Train_accy 74.670, Test_accy 67.900
2022-05-25 10:46:27,823 [bic.py] => bias_correction => Task 2, Epoch 88/170 => Loss 2.754, Train_accy 78.000, Test_accy 67.930
2022-05-25 10:46:29,488 [bic.py] => bias_correction => Task 2, Epoch 89/170 => Loss 2.754, Train_accy 80.670, Test_accy 68.330
2022-05-25 10:46:31,157 [bic.py] => bias_correction => Task 2, Epoch 90/170 => Loss 2.727, Train_accy 79.000, Test_accy 68.170
2022-05-25 10:46:32,869 [bic.py] => bias_correction => Task 2, Epoch 91/170 => Loss 2.750, Train_accy 78.330, Test_accy 68.000
2022-05-25 10:46:34,489 [bic.py] => bias_correction => Task 2, Epoch 92/170 => Loss 2.734, Train_accy 75.670, Test_accy 68.270
2022-05-25 10:46:36,135 [bic.py] => bias_correction => Task 2, Epoch 93/170 => Loss 2.739, Train_accy 77.670, Test_accy 68.200
2022-05-25 10:46:37,807 [bic.py] => bias_correction => Task 2, Epoch 94/170 => Loss 2.774, Train_accy 79.000, Test_accy 67.870
2022-05-25 10:46:39,468 [bic.py] => bias_correction => Task 2, Epoch 95/170 => Loss 2.759, Train_accy 77.330, Test_accy 68.070
2022-05-25 10:46:41,134 [bic.py] => bias_correction => Task 2, Epoch 96/170 => Loss 2.762, Train_accy 77.000, Test_accy 67.930
2022-05-25 10:46:42,772 [bic.py] => bias_correction => Task 2, Epoch 97/170 => Loss 2.757, Train_accy 77.670, Test_accy 68.230
2022-05-25 10:46:44,464 [bic.py] => bias_correction => Task 2, Epoch 98/170 => Loss 2.751, Train_accy 76.670, Test_accy 68.100
2022-05-25 10:46:46,155 [bic.py] => bias_correction => Task 2, Epoch 99/170 => Loss 2.766, Train_accy 76.000, Test_accy 68.170
2022-05-25 10:46:47,734 [bic.py] => bias_correction => Task 2, Epoch 100/170 => Loss 2.772, Train_accy 77.330, Test_accy 68.170
2022-05-25 10:46:49,292 [bic.py] => bias_correction => Task 2, Epoch 101/170 => Loss 2.757, Train_accy 74.330, Test_accy 68.070
2022-05-25 10:46:50,849 [bic.py] => bias_correction => Task 2, Epoch 102/170 => Loss 2.748, Train_accy 77.670, Test_accy 68.170
2022-05-25 10:46:52,484 [bic.py] => bias_correction => Task 2, Epoch 103/170 => Loss 2.758, Train_accy 79.330, Test_accy 68.070
2022-05-25 10:46:54,110 [bic.py] => bias_correction => Task 2, Epoch 104/170 => Loss 2.773, Train_accy 80.330, Test_accy 68.000
2022-05-25 10:46:55,747 [bic.py] => bias_correction => Task 2, Epoch 105/170 => Loss 2.749, Train_accy 76.000, Test_accy 68.030
2022-05-25 10:46:57,458 [bic.py] => bias_correction => Task 2, Epoch 106/170 => Loss 2.740, Train_accy 75.670, Test_accy 68.070
2022-05-25 10:46:59,184 [bic.py] => bias_correction => Task 2, Epoch 107/170 => Loss 2.765, Train_accy 75.330, Test_accy 68.100
2022-05-25 10:47:00,832 [bic.py] => bias_correction => Task 2, Epoch 108/170 => Loss 2.758, Train_accy 78.330, Test_accy 67.900
2022-05-25 10:47:02,435 [bic.py] => bias_correction => Task 2, Epoch 109/170 => Loss 2.742, Train_accy 75.670, Test_accy 67.870
2022-05-25 10:47:04,094 [bic.py] => bias_correction => Task 2, Epoch 110/170 => Loss 2.768, Train_accy 77.670, Test_accy 67.830
2022-05-25 10:47:05,827 [bic.py] => bias_correction => Task 2, Epoch 111/170 => Loss 2.759, Train_accy 78.000, Test_accy 67.900
2022-05-25 10:47:07,459 [bic.py] => bias_correction => Task 2, Epoch 112/170 => Loss 2.745, Train_accy 81.670, Test_accy 67.830
2022-05-25 10:47:09,143 [bic.py] => bias_correction => Task 2, Epoch 113/170 => Loss 2.748, Train_accy 78.000, Test_accy 67.970
2022-05-25 10:47:10,762 [bic.py] => bias_correction => Task 2, Epoch 114/170 => Loss 2.765, Train_accy 78.000, Test_accy 67.800
2022-05-25 10:47:12,379 [bic.py] => bias_correction => Task 2, Epoch 115/170 => Loss 2.752, Train_accy 77.670, Test_accy 67.630
2022-05-25 10:47:13,962 [bic.py] => bias_correction => Task 2, Epoch 116/170 => Loss 2.766, Train_accy 80.000, Test_accy 67.930
2022-05-25 10:47:15,487 [bic.py] => bias_correction => Task 2, Epoch 117/170 => Loss 2.753, Train_accy 76.000, Test_accy 68.000
2022-05-25 10:47:17,141 [bic.py] => bias_correction => Task 2, Epoch 118/170 => Loss 2.716, Train_accy 79.000, Test_accy 68.200
2022-05-25 10:47:18,767 [bic.py] => bias_correction => Task 2, Epoch 119/170 => Loss 2.766, Train_accy 79.670, Test_accy 68.030
2022-05-25 10:47:20,398 [bic.py] => bias_correction => Task 2, Epoch 120/170 => Loss 2.760, Train_accy 77.670, Test_accy 68.100
2022-05-25 10:47:22,015 [bic.py] => bias_correction => Task 2, Epoch 121/170 => Loss 2.744, Train_accy 80.330, Test_accy 68.070
2022-05-25 10:47:23,773 [bic.py] => bias_correction => Task 2, Epoch 122/170 => Loss 2.744, Train_accy 79.330, Test_accy 67.930
2022-05-25 10:47:25,474 [bic.py] => bias_correction => Task 2, Epoch 123/170 => Loss 2.743, Train_accy 76.670, Test_accy 67.930
2022-05-25 10:47:27,140 [bic.py] => bias_correction => Task 2, Epoch 124/170 => Loss 2.763, Train_accy 77.670, Test_accy 68.100
2022-05-25 10:47:28,763 [bic.py] => bias_correction => Task 2, Epoch 125/170 => Loss 2.775, Train_accy 80.330, Test_accy 68.130
2022-05-25 10:47:30,433 [bic.py] => bias_correction => Task 2, Epoch 126/170 => Loss 2.774, Train_accy 76.670, Test_accy 67.970
2022-05-25 10:47:32,099 [bic.py] => bias_correction => Task 2, Epoch 127/170 => Loss 2.758, Train_accy 79.330, Test_accy 67.930
2022-05-25 10:47:33,735 [bic.py] => bias_correction => Task 2, Epoch 128/170 => Loss 2.748, Train_accy 78.670, Test_accy 68.100
2022-05-25 10:47:35,408 [bic.py] => bias_correction => Task 2, Epoch 129/170 => Loss 2.755, Train_accy 75.670, Test_accy 68.030
2022-05-25 10:47:37,037 [bic.py] => bias_correction => Task 2, Epoch 130/170 => Loss 2.741, Train_accy 75.330, Test_accy 68.070
2022-05-25 10:47:38,747 [bic.py] => bias_correction => Task 2, Epoch 131/170 => Loss 2.751, Train_accy 74.330, Test_accy 67.970
2022-05-25 10:47:40,433 [bic.py] => bias_correction => Task 2, Epoch 132/170 => Loss 2.736, Train_accy 77.000, Test_accy 68.070
2022-05-25 10:47:42,126 [bic.py] => bias_correction => Task 2, Epoch 133/170 => Loss 2.762, Train_accy 73.670, Test_accy 68.030
2022-05-25 10:47:43,690 [bic.py] => bias_correction => Task 2, Epoch 134/170 => Loss 2.748, Train_accy 78.670, Test_accy 67.930
2022-05-25 10:47:45,458 [bic.py] => bias_correction => Task 2, Epoch 135/170 => Loss 2.746, Train_accy 79.330, Test_accy 68.030
2022-05-25 10:47:47,113 [bic.py] => bias_correction => Task 2, Epoch 136/170 => Loss 2.747, Train_accy 76.330, Test_accy 67.900
2022-05-25 10:47:48,817 [bic.py] => bias_correction => Task 2, Epoch 137/170 => Loss 2.750, Train_accy 78.330, Test_accy 68.100
2022-05-25 10:47:50,426 [bic.py] => bias_correction => Task 2, Epoch 138/170 => Loss 2.770, Train_accy 79.670, Test_accy 68.070
2022-05-25 10:47:52,092 [bic.py] => bias_correction => Task 2, Epoch 139/170 => Loss 2.750, Train_accy 80.000, Test_accy 68.200
2022-05-25 10:47:53,705 [bic.py] => bias_correction => Task 2, Epoch 140/170 => Loss 2.761, Train_accy 78.330, Test_accy 68.070
2022-05-25 10:47:55,389 [bic.py] => bias_correction => Task 2, Epoch 141/170 => Loss 2.759, Train_accy 78.670, Test_accy 67.900
2022-05-25 10:47:57,031 [bic.py] => bias_correction => Task 2, Epoch 142/170 => Loss 2.768, Train_accy 77.000, Test_accy 67.900
2022-05-25 10:47:58,670 [bic.py] => bias_correction => Task 2, Epoch 143/170 => Loss 2.775, Train_accy 77.000, Test_accy 67.970
2022-05-25 10:48:00,337 [bic.py] => bias_correction => Task 2, Epoch 144/170 => Loss 2.755, Train_accy 76.670, Test_accy 67.970
2022-05-25 10:48:01,880 [bic.py] => bias_correction => Task 2, Epoch 145/170 => Loss 2.758, Train_accy 77.670, Test_accy 67.830
2022-05-25 10:48:03,430 [bic.py] => bias_correction => Task 2, Epoch 146/170 => Loss 2.758, Train_accy 78.670, Test_accy 68.000
2022-05-25 10:48:04,946 [bic.py] => bias_correction => Task 2, Epoch 147/170 => Loss 2.737, Train_accy 76.670, Test_accy 68.030
2022-05-25 10:48:06,542 [bic.py] => bias_correction => Task 2, Epoch 148/170 => Loss 2.761, Train_accy 77.330, Test_accy 68.070
2022-05-25 10:48:08,170 [bic.py] => bias_correction => Task 2, Epoch 149/170 => Loss 2.755, Train_accy 78.670, Test_accy 68.030
2022-05-25 10:48:09,905 [bic.py] => bias_correction => Task 2, Epoch 150/170 => Loss 2.751, Train_accy 77.330, Test_accy 68.200
2022-05-25 10:48:11,475 [bic.py] => bias_correction => Task 2, Epoch 151/170 => Loss 2.759, Train_accy 77.000, Test_accy 68.270
2022-05-25 10:48:13,104 [bic.py] => bias_correction => Task 2, Epoch 152/170 => Loss 2.752, Train_accy 77.330, Test_accy 68.170
2022-05-25 10:48:14,686 [bic.py] => bias_correction => Task 2, Epoch 153/170 => Loss 2.735, Train_accy 77.330, Test_accy 68.070
2022-05-25 10:48:16,376 [bic.py] => bias_correction => Task 2, Epoch 154/170 => Loss 2.763, Train_accy 77.330, Test_accy 68.130
2022-05-25 10:48:18,033 [bic.py] => bias_correction => Task 2, Epoch 155/170 => Loss 2.757, Train_accy 77.000, Test_accy 68.100
2022-05-25 10:48:19,671 [bic.py] => bias_correction => Task 2, Epoch 156/170 => Loss 2.755, Train_accy 79.000, Test_accy 68.270
2022-05-25 10:48:21,304 [bic.py] => bias_correction => Task 2, Epoch 157/170 => Loss 2.741, Train_accy 75.330, Test_accy 68.130
2022-05-25 10:48:22,882 [bic.py] => bias_correction => Task 2, Epoch 158/170 => Loss 2.746, Train_accy 79.000, Test_accy 68.100
2022-05-25 10:48:24,577 [bic.py] => bias_correction => Task 2, Epoch 159/170 => Loss 2.762, Train_accy 78.000, Test_accy 68.130
2022-05-25 10:48:26,174 [bic.py] => bias_correction => Task 2, Epoch 160/170 => Loss 2.773, Train_accy 76.330, Test_accy 68.170
2022-05-25 10:48:27,933 [bic.py] => bias_correction => Task 2, Epoch 161/170 => Loss 2.761, Train_accy 79.670, Test_accy 68.100
2022-05-25 10:48:29,638 [bic.py] => bias_correction => Task 2, Epoch 162/170 => Loss 2.739, Train_accy 79.000, Test_accy 68.000
2022-05-25 10:48:31,376 [bic.py] => bias_correction => Task 2, Epoch 163/170 => Loss 2.756, Train_accy 78.000, Test_accy 68.070
2022-05-25 10:48:32,903 [bic.py] => bias_correction => Task 2, Epoch 164/170 => Loss 2.750, Train_accy 77.330, Test_accy 68.000
2022-05-25 10:48:34,546 [bic.py] => bias_correction => Task 2, Epoch 165/170 => Loss 2.739, Train_accy 77.000, Test_accy 68.100
2022-05-25 10:48:36,219 [bic.py] => bias_correction => Task 2, Epoch 166/170 => Loss 2.760, Train_accy 77.670, Test_accy 68.100
2022-05-25 10:48:37,864 [bic.py] => bias_correction => Task 2, Epoch 167/170 => Loss 2.740, Train_accy 79.330, Test_accy 67.970
2022-05-25 10:48:39,493 [bic.py] => bias_correction => Task 2, Epoch 168/170 => Loss 2.756, Train_accy 75.670, Test_accy 68.030
2022-05-25 10:48:40,990 [bic.py] => bias_correction => Task 2, Epoch 169/170 => Loss 2.745, Train_accy 78.000, Test_accy 68.030
2022-05-25 10:48:42,693 [bic.py] => bias_correction => Task 2, Epoch 170/170 => Loss 2.770, Train_accy 78.000, Test_accy 68.100
2022-05-25 10:48:42,694 [base.py] => Reducing exemplars...(66 per classes)
2022-05-25 10:48:47,333 [base.py] => Constructing exemplars...(66 per classes)
2022-05-25 10:48:53,149 [bic.py] => Parameters of bias layer:
2022-05-25 10:48:53,150 [bic.py] => 0 => 1.000, 0.000
2022-05-25 10:48:53,150 [bic.py] => 1 => 0.904, -1.125
2022-05-25 10:48:53,150 [bic.py] => 2 => 0.889, -1.948
2022-05-25 10:48:54,610 [bic.py] => Exemplar size: 1980
2022-05-25 10:48:54,611 [trainer.py] => CNN: {'total': 68.1, '00-09': 68.7, '10-19': 64.5, '20-29': 71.1, 'old': 66.6, 'new': 71.1}
2022-05-25 10:48:54,611 [trainer.py] => NME: {'total': 67.37, '00-09': 67.0, '10-19': 64.4, '20-29': 70.7, 'old': 65.7, 'new': 70.7}
2022-05-25 10:48:54,611 [trainer.py] => CNN top1 curve: [83.0, 73.7, 68.1]
2022-05-25 10:48:54,611 [trainer.py] => CNN top5 curve: [99.1, 95.65, 92.07]
2022-05-25 10:48:54,611 [trainer.py] => NME top1 curve: [82.8, 74.15, 67.37]
2022-05-25 10:48:54,611 [trainer.py] => NME top5 curve: [99.0, 95.75, 92.47]

2022-05-25 10:48:54,612 [trainer.py] => All params: 466110
2022-05-25 10:48:54,612 [trainer.py] => Trainable params: 466110
2022-05-25 10:48:54,613 [bic.py] => Learning on 30-40
2022-05-25 10:48:54,673 [bic.py] => Stage1 dset: 6740, Stage2 dset: 240
2022-05-25 10:48:54,673 [bic.py] => Lambda: 0.750
2022-05-25 10:48:54,684 [bic.py] => Parameters of bias layer:
2022-05-25 10:48:54,684 [bic.py] => 0 => 1.000, 0.000
2022-05-25 10:48:54,685 [bic.py] => 1 => 0.904, -1.125
2022-05-25 10:48:54,685 [bic.py] => 2 => 0.889, -1.948
2022-05-25 10:48:54,685 [bic.py] => 3 => 1.000, 0.000
2022-05-25 10:48:58,959 [bic.py] => training => Task 3, Epoch 1/170 => Loss 2.010, Train_accy 59.050, Test_accy 42.880
2022-05-25 10:49:03,324 [bic.py] => training => Task 3, Epoch 2/170 => Loss 1.788, Train_accy 68.030, Test_accy 47.780
2022-05-25 10:49:07,694 [bic.py] => training => Task 3, Epoch 3/170 => Loss 1.750, Train_accy 73.060, Test_accy 49.050
2022-05-25 10:49:12,152 [bic.py] => training => Task 3, Epoch 4/170 => Loss 1.716, Train_accy 69.470, Test_accy 48.650
2022-05-25 10:49:16,486 [bic.py] => training => Task 3, Epoch 5/170 => Loss 1.711, Train_accy 76.440, Test_accy 52.000
2022-05-25 10:49:20,748 [bic.py] => training => Task 3, Epoch 6/170 => Loss 1.703, Train_accy 77.210, Test_accy 50.650
2022-05-25 10:49:25,124 [bic.py] => training => Task 3, Epoch 7/170 => Loss 1.683, Train_accy 70.850, Test_accy 47.020
2022-05-25 10:49:29,353 [bic.py] => training => Task 3, Epoch 8/170 => Loss 1.678, Train_accy 77.080, Test_accy 51.080
2022-05-25 10:49:33,589 [bic.py] => training => Task 3, Epoch 9/170 => Loss 1.672, Train_accy 77.210, Test_accy 50.100
2022-05-25 10:49:37,847 [bic.py] => training => Task 3, Epoch 10/170 => Loss 1.668, Train_accy 83.620, Test_accy 52.300
2022-05-25 10:49:42,197 [bic.py] => training => Task 3, Epoch 11/170 => Loss 1.652, Train_accy 80.270, Test_accy 49.920
2022-05-25 10:49:46,447 [bic.py] => training => Task 3, Epoch 12/170 => Loss 1.648, Train_accy 82.850, Test_accy 50.080
2022-05-25 10:49:50,713 [bic.py] => training => Task 3, Epoch 13/170 => Loss 1.650, Train_accy 82.460, Test_accy 50.950
2022-05-25 10:49:54,934 [bic.py] => training => Task 3, Epoch 14/170 => Loss 1.642, Train_accy 82.240, Test_accy 51.100
2022-05-25 10:49:59,252 [bic.py] => training => Task 3, Epoch 15/170 => Loss 1.642, Train_accy 84.900, Test_accy 52.450
2022-05-25 10:50:03,599 [bic.py] => training => Task 3, Epoch 16/170 => Loss 1.632, Train_accy 80.880, Test_accy 48.750
2022-05-25 10:50:07,874 [bic.py] => training => Task 3, Epoch 17/170 => Loss 1.637, Train_accy 83.550, Test_accy 49.820
2022-05-25 10:50:12,099 [bic.py] => training => Task 3, Epoch 18/170 => Loss 1.626, Train_accy 83.340, Test_accy 49.880
2022-05-25 10:50:16,636 [bic.py] => training => Task 3, Epoch 19/170 => Loss 1.630, Train_accy 86.970, Test_accy 52.450
2022-05-25 10:50:21,018 [bic.py] => training => Task 3, Epoch 20/170 => Loss 1.621, Train_accy 83.830, Test_accy 49.580
2022-05-25 10:50:25,329 [bic.py] => training => Task 3, Epoch 21/170 => Loss 1.623, Train_accy 85.280, Test_accy 49.400
2022-05-25 10:50:29,801 [bic.py] => training => Task 3, Epoch 22/170 => Loss 1.614, Train_accy 86.350, Test_accy 52.080
2022-05-25 10:50:34,143 [bic.py] => training => Task 3, Epoch 23/170 => Loss 1.617, Train_accy 86.080, Test_accy 50.420
2022-05-25 10:50:38,594 [bic.py] => training => Task 3, Epoch 24/170 => Loss 1.602, Train_accy 86.390, Test_accy 52.420
2022-05-25 10:50:42,924 [bic.py] => training => Task 3, Epoch 25/170 => Loss 1.604, Train_accy 89.440, Test_accy 52.120
2022-05-25 10:50:47,224 [bic.py] => training => Task 3, Epoch 26/170 => Loss 1.597, Train_accy 85.950, Test_accy 51.300
2022-05-25 10:50:51,539 [bic.py] => training => Task 3, Epoch 27/170 => Loss 1.610, Train_accy 88.520, Test_accy 51.200
2022-05-25 10:50:55,903 [bic.py] => training => Task 3, Epoch 28/170 => Loss 1.608, Train_accy 83.350, Test_accy 49.680
2022-05-25 10:51:00,215 [bic.py] => training => Task 3, Epoch 29/170 => Loss 1.608, Train_accy 86.870, Test_accy 53.050
2022-05-25 10:51:04,665 [bic.py] => training => Task 3, Epoch 30/170 => Loss 1.601, Train_accy 85.490, Test_accy 51.400
2022-05-25 10:51:08,966 [bic.py] => training => Task 3, Epoch 31/170 => Loss 1.596, Train_accy 87.200, Test_accy 51.050
2022-05-25 10:51:13,165 [bic.py] => training => Task 3, Epoch 32/170 => Loss 1.602, Train_accy 91.320, Test_accy 53.020
2022-05-25 10:51:17,441 [bic.py] => training => Task 3, Epoch 33/170 => Loss 1.590, Train_accy 88.740, Test_accy 52.000
2022-05-25 10:51:21,724 [bic.py] => training => Task 3, Epoch 34/170 => Loss 1.601, Train_accy 87.480, Test_accy 51.600
2022-05-25 10:51:25,968 [bic.py] => training => Task 3, Epoch 35/170 => Loss 1.589, Train_accy 89.540, Test_accy 53.050
2022-05-25 10:51:30,333 [bic.py] => training => Task 3, Epoch 36/170 => Loss 1.603, Train_accy 84.090, Test_accy 49.920
2022-05-25 10:51:34,628 [bic.py] => training => Task 3, Epoch 37/170 => Loss 1.597, Train_accy 87.310, Test_accy 49.480
2022-05-25 10:51:38,983 [bic.py] => training => Task 3, Epoch 38/170 => Loss 1.592, Train_accy 87.110, Test_accy 51.200
2022-05-25 10:51:43,435 [bic.py] => training => Task 3, Epoch 39/170 => Loss 1.591, Train_accy 90.520, Test_accy 51.620
2022-05-25 10:51:47,755 [bic.py] => training => Task 3, Epoch 40/170 => Loss 1.587, Train_accy 88.800, Test_accy 50.180
2022-05-25 10:51:52,150 [bic.py] => training => Task 3, Epoch 41/170 => Loss 1.583, Train_accy 90.930, Test_accy 52.300
2022-05-25 10:51:56,463 [bic.py] => training => Task 3, Epoch 42/170 => Loss 1.585, Train_accy 90.580, Test_accy 52.220
2022-05-25 10:52:00,856 [bic.py] => training => Task 3, Epoch 43/170 => Loss 1.583, Train_accy 88.520, Test_accy 49.320
2022-05-25 10:52:05,403 [bic.py] => training => Task 3, Epoch 44/170 => Loss 1.576, Train_accy 91.590, Test_accy 53.550
2022-05-25 10:52:09,955 [bic.py] => training => Task 3, Epoch 45/170 => Loss 1.583, Train_accy 88.610, Test_accy 50.900
2022-05-25 10:52:14,331 [bic.py] => training => Task 3, Epoch 46/170 => Loss 1.581, Train_accy 88.620, Test_accy 51.720
2022-05-25 10:52:18,743 [bic.py] => training => Task 3, Epoch 47/170 => Loss 1.586, Train_accy 90.710, Test_accy 49.920
2022-05-25 10:52:22,946 [bic.py] => training => Task 3, Epoch 48/170 => Loss 1.580, Train_accy 91.440, Test_accy 54.500
2022-05-25 10:52:27,319 [bic.py] => training => Task 3, Epoch 49/170 => Loss 1.586, Train_accy 89.540, Test_accy 50.320
2022-05-25 10:52:31,733 [bic.py] => training => Task 3, Epoch 50/170 => Loss 1.588, Train_accy 89.450, Test_accy 51.700
2022-05-25 10:52:36,170 [bic.py] => training => Task 3, Epoch 51/170 => Loss 1.582, Train_accy 90.300, Test_accy 51.300
2022-05-25 10:52:40,466 [bic.py] => training => Task 3, Epoch 52/170 => Loss 1.578, Train_accy 91.570, Test_accy 54.820
2022-05-25 10:52:44,988 [bic.py] => training => Task 3, Epoch 53/170 => Loss 1.580, Train_accy 90.770, Test_accy 48.550
2022-05-25 10:52:49,509 [bic.py] => training => Task 3, Epoch 54/170 => Loss 1.583, Train_accy 85.180, Test_accy 50.080
2022-05-25 10:52:53,978 [bic.py] => training => Task 3, Epoch 55/170 => Loss 1.584, Train_accy 91.800, Test_accy 51.400
2022-05-25 10:52:58,418 [bic.py] => training => Task 3, Epoch 56/170 => Loss 1.579, Train_accy 91.800, Test_accy 52.420
2022-05-25 10:53:02,952 [bic.py] => training => Task 3, Epoch 57/170 => Loss 1.573, Train_accy 87.330, Test_accy 50.420
2022-05-25 10:53:07,452 [bic.py] => training => Task 3, Epoch 58/170 => Loss 1.568, Train_accy 88.130, Test_accy 48.720
2022-05-25 10:53:12,076 [bic.py] => training => Task 3, Epoch 59/170 => Loss 1.574, Train_accy 91.510, Test_accy 51.220
2022-05-25 10:53:16,670 [bic.py] => training => Task 3, Epoch 60/170 => Loss 1.580, Train_accy 87.670, Test_accy 51.520
2022-05-25 10:53:21,259 [bic.py] => training => Task 3, Epoch 61/170 => Loss 1.541, Train_accy 98.120, Test_accy 56.650
2022-05-25 10:53:25,798 [bic.py] => training => Task 3, Epoch 62/170 => Loss 1.517, Train_accy 98.610, Test_accy 56.150
2022-05-25 10:53:30,283 [bic.py] => training => Task 3, Epoch 63/170 => Loss 1.512, Train_accy 98.590, Test_accy 56.550
2022-05-25 10:53:34,774 [bic.py] => training => Task 3, Epoch 64/170 => Loss 1.505, Train_accy 98.870, Test_accy 56.800
2022-05-25 10:53:39,231 [bic.py] => training => Task 3, Epoch 65/170 => Loss 1.504, Train_accy 98.890, Test_accy 56.700
2022-05-25 10:53:43,730 [bic.py] => training => Task 3, Epoch 66/170 => Loss 1.502, Train_accy 99.050, Test_accy 56.780
2022-05-25 10:53:48,206 [bic.py] => training => Task 3, Epoch 67/170 => Loss 1.497, Train_accy 99.140, Test_accy 56.880
2022-05-25 10:53:52,774 [bic.py] => training => Task 3, Epoch 68/170 => Loss 1.499, Train_accy 99.170, Test_accy 56.820
2022-05-25 10:53:57,266 [bic.py] => training => Task 3, Epoch 69/170 => Loss 1.496, Train_accy 99.050, Test_accy 57.200
2022-05-25 10:54:01,729 [bic.py] => training => Task 3, Epoch 70/170 => Loss 1.497, Train_accy 99.080, Test_accy 56.500
2022-05-25 10:54:06,312 [bic.py] => training => Task 3, Epoch 71/170 => Loss 1.490, Train_accy 99.120, Test_accy 57.220
2022-05-25 10:54:10,751 [bic.py] => training => Task 3, Epoch 72/170 => Loss 1.489, Train_accy 99.170, Test_accy 56.820
2022-05-25 10:54:15,177 [bic.py] => training => Task 3, Epoch 73/170 => Loss 1.491, Train_accy 99.320, Test_accy 56.680
2022-05-25 10:54:19,687 [bic.py] => training => Task 3, Epoch 74/170 => Loss 1.490, Train_accy 99.410, Test_accy 57.020
2022-05-25 10:54:24,101 [bic.py] => training => Task 3, Epoch 75/170 => Loss 1.494, Train_accy 99.270, Test_accy 57.100
2022-05-25 10:54:28,510 [bic.py] => training => Task 3, Epoch 76/170 => Loss 1.490, Train_accy 99.260, Test_accy 57.150
2022-05-25 10:54:32,950 [bic.py] => training => Task 3, Epoch 77/170 => Loss 1.493, Train_accy 99.170, Test_accy 56.950
2022-05-25 10:54:37,376 [bic.py] => training => Task 3, Epoch 78/170 => Loss 1.486, Train_accy 99.360, Test_accy 56.650
2022-05-25 10:54:41,777 [bic.py] => training => Task 3, Epoch 79/170 => Loss 1.493, Train_accy 99.330, Test_accy 56.520
2022-05-25 10:54:46,220 [bic.py] => training => Task 3, Epoch 80/170 => Loss 1.487, Train_accy 99.480, Test_accy 57.100
2022-05-25 10:54:50,703 [bic.py] => training => Task 3, Epoch 81/170 => Loss 1.487, Train_accy 99.380, Test_accy 57.180
2022-05-25 10:54:55,170 [bic.py] => training => Task 3, Epoch 82/170 => Loss 1.489, Train_accy 99.330, Test_accy 57.220
2022-05-25 10:54:59,596 [bic.py] => training => Task 3, Epoch 83/170 => Loss 1.484, Train_accy 99.470, Test_accy 56.800
2022-05-25 10:55:04,019 [bic.py] => training => Task 3, Epoch 84/170 => Loss 1.490, Train_accy 99.420, Test_accy 57.020
2022-05-25 10:55:08,313 [bic.py] => training => Task 3, Epoch 85/170 => Loss 1.491, Train_accy 99.390, Test_accy 56.980
2022-05-25 10:55:12,773 [bic.py] => training => Task 3, Epoch 86/170 => Loss 1.487, Train_accy 99.500, Test_accy 56.900
2022-05-25 10:55:17,131 [bic.py] => training => Task 3, Epoch 87/170 => Loss 1.487, Train_accy 99.360, Test_accy 56.950
2022-05-25 10:55:21,548 [bic.py] => training => Task 3, Epoch 88/170 => Loss 1.484, Train_accy 99.530, Test_accy 56.680
2022-05-25 10:55:26,094 [bic.py] => training => Task 3, Epoch 89/170 => Loss 1.485, Train_accy 99.580, Test_accy 56.820
2022-05-25 10:55:30,593 [bic.py] => training => Task 3, Epoch 90/170 => Loss 1.484, Train_accy 99.570, Test_accy 57.050
2022-05-25 10:55:35,309 [bic.py] => training => Task 3, Epoch 91/170 => Loss 1.482, Train_accy 99.530, Test_accy 56.850
2022-05-25 10:55:39,827 [bic.py] => training => Task 3, Epoch 92/170 => Loss 1.487, Train_accy 99.500, Test_accy 56.680
2022-05-25 10:55:44,222 [bic.py] => training => Task 3, Epoch 93/170 => Loss 1.489, Train_accy 99.550, Test_accy 56.500
2022-05-25 10:55:48,653 [bic.py] => training => Task 3, Epoch 94/170 => Loss 1.479, Train_accy 99.720, Test_accy 57.180
2022-05-25 10:55:53,088 [bic.py] => training => Task 3, Epoch 95/170 => Loss 1.486, Train_accy 99.610, Test_accy 57.000
2022-05-25 10:55:57,530 [bic.py] => training => Task 3, Epoch 96/170 => Loss 1.482, Train_accy 99.600, Test_accy 57.300
2022-05-25 10:56:01,879 [bic.py] => training => Task 3, Epoch 97/170 => Loss 1.484, Train_accy 99.530, Test_accy 56.800
2022-05-25 10:56:06,306 [bic.py] => training => Task 3, Epoch 98/170 => Loss 1.490, Train_accy 99.380, Test_accy 57.120
2022-05-25 10:56:10,885 [bic.py] => training => Task 3, Epoch 99/170 => Loss 1.482, Train_accy 99.550, Test_accy 56.420
2022-05-25 10:56:15,350 [bic.py] => training => Task 3, Epoch 100/170 => Loss 1.479, Train_accy 99.390, Test_accy 57.050
2022-05-25 10:56:19,835 [bic.py] => training => Task 3, Epoch 101/170 => Loss 1.483, Train_accy 99.550, Test_accy 57.200
2022-05-25 10:56:24,374 [bic.py] => training => Task 3, Epoch 102/170 => Loss 1.482, Train_accy 99.600, Test_accy 56.900
2022-05-25 10:56:28,736 [bic.py] => training => Task 3, Epoch 103/170 => Loss 1.478, Train_accy 99.570, Test_accy 57.050
2022-05-25 10:56:33,208 [bic.py] => training => Task 3, Epoch 104/170 => Loss 1.486, Train_accy 99.670, Test_accy 57.180
2022-05-25 10:56:37,590 [bic.py] => training => Task 3, Epoch 105/170 => Loss 1.482, Train_accy 99.690, Test_accy 57.180
2022-05-25 10:56:41,985 [bic.py] => training => Task 3, Epoch 106/170 => Loss 1.480, Train_accy 99.570, Test_accy 57.150
2022-05-25 10:56:46,485 [bic.py] => training => Task 3, Epoch 107/170 => Loss 1.485, Train_accy 99.600, Test_accy 57.320
2022-05-25 10:56:50,921 [bic.py] => training => Task 3, Epoch 108/170 => Loss 1.483, Train_accy 99.730, Test_accy 56.980
2022-05-25 10:56:55,338 [bic.py] => training => Task 3, Epoch 109/170 => Loss 1.478, Train_accy 99.640, Test_accy 56.920
2022-05-25 10:56:59,858 [bic.py] => training => Task 3, Epoch 110/170 => Loss 1.477, Train_accy 99.640, Test_accy 57.000
2022-05-25 10:57:04,296 [bic.py] => training => Task 3, Epoch 111/170 => Loss 1.475, Train_accy 99.640, Test_accy 57.020
2022-05-25 10:57:08,683 [bic.py] => training => Task 3, Epoch 112/170 => Loss 1.482, Train_accy 99.530, Test_accy 57.350
2022-05-25 10:57:13,264 [bic.py] => training => Task 3, Epoch 113/170 => Loss 1.478, Train_accy 99.610, Test_accy 57.080
2022-05-25 10:57:17,716 [bic.py] => training => Task 3, Epoch 114/170 => Loss 1.483, Train_accy 99.660, Test_accy 56.650
2022-05-25 10:57:22,080 [bic.py] => training => Task 3, Epoch 115/170 => Loss 1.480, Train_accy 99.600, Test_accy 56.950
2022-05-25 10:57:26,542 [bic.py] => training => Task 3, Epoch 116/170 => Loss 1.477, Train_accy 99.570, Test_accy 57.000
2022-05-25 10:57:31,074 [bic.py] => training => Task 3, Epoch 117/170 => Loss 1.483, Train_accy 99.750, Test_accy 56.750
2022-05-25 10:57:35,505 [bic.py] => training => Task 3, Epoch 118/170 => Loss 1.479, Train_accy 99.700, Test_accy 56.920
2022-05-25 10:57:39,873 [bic.py] => training => Task 3, Epoch 119/170 => Loss 1.476, Train_accy 99.600, Test_accy 57.100
2022-05-25 10:57:44,297 [bic.py] => training => Task 3, Epoch 120/170 => Loss 1.484, Train_accy 99.700, Test_accy 57.100
2022-05-25 10:57:48,725 [bic.py] => training => Task 3, Epoch 121/170 => Loss 1.478, Train_accy 99.600, Test_accy 56.900
2022-05-25 10:57:53,139 [bic.py] => training => Task 3, Epoch 122/170 => Loss 1.479, Train_accy 99.540, Test_accy 56.920
2022-05-25 10:57:57,567 [bic.py] => training => Task 3, Epoch 123/170 => Loss 1.476, Train_accy 99.550, Test_accy 56.900
2022-05-25 10:58:01,966 [bic.py] => training => Task 3, Epoch 124/170 => Loss 1.484, Train_accy 99.670, Test_accy 57.150
2022-05-25 10:58:06,474 [bic.py] => training => Task 3, Epoch 125/170 => Loss 1.484, Train_accy 99.690, Test_accy 57.150
2022-05-25 10:58:10,916 [bic.py] => training => Task 3, Epoch 126/170 => Loss 1.481, Train_accy 99.570, Test_accy 57.200
2022-05-25 10:58:15,436 [bic.py] => training => Task 3, Epoch 127/170 => Loss 1.481, Train_accy 99.640, Test_accy 57.120
2022-05-25 10:58:19,744 [bic.py] => training => Task 3, Epoch 128/170 => Loss 1.480, Train_accy 99.410, Test_accy 57.150
2022-05-25 10:58:24,144 [bic.py] => training => Task 3, Epoch 129/170 => Loss 1.479, Train_accy 99.690, Test_accy 57.080
2022-05-25 10:58:28,601 [bic.py] => training => Task 3, Epoch 130/170 => Loss 1.478, Train_accy 99.580, Test_accy 57.120
2022-05-25 10:58:33,203 [bic.py] => training => Task 3, Epoch 131/170 => Loss 1.482, Train_accy 99.690, Test_accy 57.180
2022-05-25 10:58:37,751 [bic.py] => training => Task 3, Epoch 132/170 => Loss 1.475, Train_accy 99.730, Test_accy 57.400
2022-05-25 10:58:42,389 [bic.py] => training => Task 3, Epoch 133/170 => Loss 1.479, Train_accy 99.570, Test_accy 57.080
2022-05-25 10:58:46,910 [bic.py] => training => Task 3, Epoch 134/170 => Loss 1.477, Train_accy 99.670, Test_accy 57.200
2022-05-25 10:58:51,446 [bic.py] => training => Task 3, Epoch 135/170 => Loss 1.480, Train_accy 99.610, Test_accy 57.300
2022-05-25 10:58:56,248 [bic.py] => training => Task 3, Epoch 136/170 => Loss 1.480, Train_accy 99.730, Test_accy 57.180
2022-05-25 10:59:01,006 [bic.py] => training => Task 3, Epoch 137/170 => Loss 1.480, Train_accy 99.580, Test_accy 56.900
2022-05-25 10:59:05,718 [bic.py] => training => Task 3, Epoch 138/170 => Loss 1.479, Train_accy 99.580, Test_accy 56.920
2022-05-25 10:59:10,316 [bic.py] => training => Task 3, Epoch 139/170 => Loss 1.475, Train_accy 99.610, Test_accy 56.800
2022-05-25 10:59:14,698 [bic.py] => training => Task 3, Epoch 140/170 => Loss 1.482, Train_accy 99.610, Test_accy 57.250
2022-05-25 10:59:19,044 [bic.py] => training => Task 3, Epoch 141/170 => Loss 1.480, Train_accy 99.580, Test_accy 57.100
2022-05-25 10:59:23,394 [bic.py] => training => Task 3, Epoch 142/170 => Loss 1.482, Train_accy 99.670, Test_accy 57.050
2022-05-25 10:59:27,650 [bic.py] => training => Task 3, Epoch 143/170 => Loss 1.480, Train_accy 99.630, Test_accy 56.920
2022-05-25 10:59:32,079 [bic.py] => training => Task 3, Epoch 144/170 => Loss 1.482, Train_accy 99.730, Test_accy 57.050
2022-05-25 10:59:36,661 [bic.py] => training => Task 3, Epoch 145/170 => Loss 1.479, Train_accy 99.690, Test_accy 57.200
2022-05-25 10:59:41,104 [bic.py] => training => Task 3, Epoch 146/170 => Loss 1.482, Train_accy 99.410, Test_accy 57.120
2022-05-25 10:59:45,678 [bic.py] => training => Task 3, Epoch 147/170 => Loss 1.476, Train_accy 99.570, Test_accy 57.080
2022-05-25 10:59:49,921 [bic.py] => training => Task 3, Epoch 148/170 => Loss 1.482, Train_accy 99.580, Test_accy 57.050
2022-05-25 10:59:54,389 [bic.py] => training => Task 3, Epoch 149/170 => Loss 1.481, Train_accy 99.580, Test_accy 57.150
2022-05-25 10:59:59,004 [bic.py] => training => Task 3, Epoch 150/170 => Loss 1.476, Train_accy 99.610, Test_accy 57.100
2022-05-25 11:00:03,396 [bic.py] => training => Task 3, Epoch 151/170 => Loss 1.478, Train_accy 99.530, Test_accy 56.900
2022-05-25 11:00:07,778 [bic.py] => training => Task 3, Epoch 152/170 => Loss 1.480, Train_accy 99.610, Test_accy 57.080
2022-05-25 11:00:12,298 [bic.py] => training => Task 3, Epoch 153/170 => Loss 1.477, Train_accy 99.500, Test_accy 56.950
2022-05-25 11:00:16,810 [bic.py] => training => Task 3, Epoch 154/170 => Loss 1.476, Train_accy 99.640, Test_accy 57.380
2022-05-25 11:00:21,266 [bic.py] => training => Task 3, Epoch 155/170 => Loss 1.474, Train_accy 99.700, Test_accy 57.080
2022-05-25 11:00:25,775 [bic.py] => training => Task 3, Epoch 156/170 => Loss 1.478, Train_accy 99.550, Test_accy 57.250
2022-05-25 11:00:30,373 [bic.py] => training => Task 3, Epoch 157/170 => Loss 1.479, Train_accy 99.500, Test_accy 56.780
2022-05-25 11:00:34,905 [bic.py] => training => Task 3, Epoch 158/170 => Loss 1.478, Train_accy 99.640, Test_accy 57.150
2022-05-25 11:00:39,309 [bic.py] => training => Task 3, Epoch 159/170 => Loss 1.476, Train_accy 99.600, Test_accy 57.080
2022-05-25 11:00:43,740 [bic.py] => training => Task 3, Epoch 160/170 => Loss 1.477, Train_accy 99.690, Test_accy 57.100
2022-05-25 11:00:48,224 [bic.py] => training => Task 3, Epoch 161/170 => Loss 1.480, Train_accy 99.660, Test_accy 57.050
2022-05-25 11:00:52,693 [bic.py] => training => Task 3, Epoch 162/170 => Loss 1.478, Train_accy 99.570, Test_accy 56.980
2022-05-25 11:00:57,092 [bic.py] => training => Task 3, Epoch 163/170 => Loss 1.475, Train_accy 99.600, Test_accy 57.120
2022-05-25 11:01:01,555 [bic.py] => training => Task 3, Epoch 164/170 => Loss 1.479, Train_accy 99.600, Test_accy 57.080
2022-05-25 11:01:05,978 [bic.py] => training => Task 3, Epoch 165/170 => Loss 1.477, Train_accy 99.790, Test_accy 57.200
2022-05-25 11:01:10,420 [bic.py] => training => Task 3, Epoch 166/170 => Loss 1.482, Train_accy 99.640, Test_accy 56.750
2022-05-25 11:01:14,998 [bic.py] => training => Task 3, Epoch 167/170 => Loss 1.484, Train_accy 99.610, Test_accy 56.950
2022-05-25 11:01:19,503 [bic.py] => training => Task 3, Epoch 168/170 => Loss 1.475, Train_accy 99.690, Test_accy 57.150
2022-05-25 11:01:24,045 [bic.py] => training => Task 3, Epoch 169/170 => Loss 1.481, Train_accy 99.640, Test_accy 57.150
2022-05-25 11:01:28,630 [bic.py] => training => Task 3, Epoch 170/170 => Loss 1.475, Train_accy 99.670, Test_accy 57.080
2022-05-25 11:01:30,390 [bic.py] => bias_correction => Task 3, Epoch 1/170 => Loss 3.171, Train_accy 64.580, Test_accy 59.550
2022-05-25 11:01:32,253 [bic.py] => bias_correction => Task 3, Epoch 2/170 => Loss 3.117, Train_accy 77.500, Test_accy 62.850
2022-05-25 11:01:34,048 [bic.py] => bias_correction => Task 3, Epoch 3/170 => Loss 3.075, Train_accy 74.580, Test_accy 58.900
2022-05-25 11:01:35,826 [bic.py] => bias_correction => Task 3, Epoch 4/170 => Loss 3.102, Train_accy 73.750, Test_accy 54.680
2022-05-25 11:01:37,658 [bic.py] => bias_correction => Task 3, Epoch 5/170 => Loss 3.116, Train_accy 73.330, Test_accy 55.080
2022-05-25 11:01:39,461 [bic.py] => bias_correction => Task 3, Epoch 6/170 => Loss 3.100, Train_accy 73.330, Test_accy 59.000
2022-05-25 11:01:41,320 [bic.py] => bias_correction => Task 3, Epoch 7/170 => Loss 3.075, Train_accy 78.750, Test_accy 62.280
2022-05-25 11:01:43,109 [bic.py] => bias_correction => Task 3, Epoch 8/170 => Loss 3.080, Train_accy 73.750, Test_accy 61.080
2022-05-25 11:01:44,868 [bic.py] => bias_correction => Task 3, Epoch 9/170 => Loss 3.099, Train_accy 74.170, Test_accy 61.050
2022-05-25 11:01:46,634 [bic.py] => bias_correction => Task 3, Epoch 10/170 => Loss 3.102, Train_accy 75.000, Test_accy 62.200
2022-05-25 11:01:48,472 [bic.py] => bias_correction => Task 3, Epoch 11/170 => Loss 3.062, Train_accy 75.830, Test_accy 61.580
2022-05-25 11:01:50,348 [bic.py] => bias_correction => Task 3, Epoch 12/170 => Loss 3.058, Train_accy 75.000, Test_accy 60.100
2022-05-25 11:01:52,222 [bic.py] => bias_correction => Task 3, Epoch 13/170 => Loss 3.100, Train_accy 75.830, Test_accy 60.220
2022-05-25 11:01:54,114 [bic.py] => bias_correction => Task 3, Epoch 14/170 => Loss 3.080, Train_accy 75.000, Test_accy 61.900
2022-05-25 11:01:55,880 [bic.py] => bias_correction => Task 3, Epoch 15/170 => Loss 3.087, Train_accy 75.830, Test_accy 62.020
2022-05-25 11:01:57,728 [bic.py] => bias_correction => Task 3, Epoch 16/170 => Loss 3.062, Train_accy 74.170, Test_accy 61.780
2022-05-25 11:01:59,572 [bic.py] => bias_correction => Task 3, Epoch 17/170 => Loss 3.078, Train_accy 72.920, Test_accy 61.980
2022-05-25 11:02:01,387 [bic.py] => bias_correction => Task 3, Epoch 18/170 => Loss 3.078, Train_accy 77.500, Test_accy 62.020
2022-05-25 11:02:03,241 [bic.py] => bias_correction => Task 3, Epoch 19/170 => Loss 3.058, Train_accy 75.420, Test_accy 61.800
2022-05-25 11:02:05,013 [bic.py] => bias_correction => Task 3, Epoch 20/170 => Loss 3.092, Train_accy 77.500, Test_accy 60.820
2022-05-25 11:02:06,963 [bic.py] => bias_correction => Task 3, Epoch 21/170 => Loss 3.080, Train_accy 75.830, Test_accy 60.880
2022-05-25 11:02:08,819 [bic.py] => bias_correction => Task 3, Epoch 22/170 => Loss 3.092, Train_accy 76.250, Test_accy 61.920
2022-05-25 11:02:10,575 [bic.py] => bias_correction => Task 3, Epoch 23/170 => Loss 3.070, Train_accy 75.420, Test_accy 62.120
2022-05-25 11:02:12,345 [bic.py] => bias_correction => Task 3, Epoch 24/170 => Loss 3.065, Train_accy 77.920, Test_accy 61.880
2022-05-25 11:02:14,135 [bic.py] => bias_correction => Task 3, Epoch 25/170 => Loss 3.076, Train_accy 76.250, Test_accy 61.950
2022-05-25 11:02:15,861 [bic.py] => bias_correction => Task 3, Epoch 26/170 => Loss 3.064, Train_accy 73.750, Test_accy 62.150
2022-05-25 11:02:17,720 [bic.py] => bias_correction => Task 3, Epoch 27/170 => Loss 3.062, Train_accy 74.170, Test_accy 62.080
2022-05-25 11:02:19,550 [bic.py] => bias_correction => Task 3, Epoch 28/170 => Loss 3.054, Train_accy 77.080, Test_accy 61.880
2022-05-25 11:02:21,319 [bic.py] => bias_correction => Task 3, Epoch 29/170 => Loss 3.081, Train_accy 73.750, Test_accy 62.020
2022-05-25 11:02:23,182 [bic.py] => bias_correction => Task 3, Epoch 30/170 => Loss 3.054, Train_accy 77.920, Test_accy 62.080
2022-05-25 11:02:24,873 [bic.py] => bias_correction => Task 3, Epoch 31/170 => Loss 3.068, Train_accy 73.330, Test_accy 62.150
2022-05-25 11:02:26,573 [bic.py] => bias_correction => Task 3, Epoch 32/170 => Loss 3.074, Train_accy 77.500, Test_accy 62.120
2022-05-25 11:02:28,276 [bic.py] => bias_correction => Task 3, Epoch 33/170 => Loss 3.073, Train_accy 77.500, Test_accy 62.080
2022-05-25 11:02:29,997 [bic.py] => bias_correction => Task 3, Epoch 34/170 => Loss 3.062, Train_accy 71.670, Test_accy 62.080
2022-05-25 11:02:31,698 [bic.py] => bias_correction => Task 3, Epoch 35/170 => Loss 3.075, Train_accy 76.670, Test_accy 61.850
2022-05-25 11:02:33,408 [bic.py] => bias_correction => Task 3, Epoch 36/170 => Loss 3.052, Train_accy 75.000, Test_accy 61.950
2022-05-25 11:02:35,204 [bic.py] => bias_correction => Task 3, Epoch 37/170 => Loss 3.074, Train_accy 76.250, Test_accy 61.880
2022-05-25 11:02:36,968 [bic.py] => bias_correction => Task 3, Epoch 38/170 => Loss 3.053, Train_accy 73.330, Test_accy 62.050
2022-05-25 11:02:38,748 [bic.py] => bias_correction => Task 3, Epoch 39/170 => Loss 3.065, Train_accy 77.920, Test_accy 62.080
2022-05-25 11:02:40,509 [bic.py] => bias_correction => Task 3, Epoch 40/170 => Loss 3.055, Train_accy 78.330, Test_accy 62.100
2022-05-25 11:02:42,293 [bic.py] => bias_correction => Task 3, Epoch 41/170 => Loss 3.067, Train_accy 77.500, Test_accy 62.120
2022-05-25 11:02:44,049 [bic.py] => bias_correction => Task 3, Epoch 42/170 => Loss 3.073, Train_accy 77.080, Test_accy 62.180
2022-05-25 11:02:45,946 [bic.py] => bias_correction => Task 3, Epoch 43/170 => Loss 3.075, Train_accy 74.170, Test_accy 62.150
2022-05-25 11:02:47,766 [bic.py] => bias_correction => Task 3, Epoch 44/170 => Loss 3.072, Train_accy 77.500, Test_accy 62.200
2022-05-25 11:02:49,637 [bic.py] => bias_correction => Task 3, Epoch 45/170 => Loss 3.055, Train_accy 76.250, Test_accy 62.100
2022-05-25 11:02:51,485 [bic.py] => bias_correction => Task 3, Epoch 46/170 => Loss 3.068, Train_accy 75.000, Test_accy 62.120
2022-05-25 11:02:53,202 [bic.py] => bias_correction => Task 3, Epoch 47/170 => Loss 3.066, Train_accy 76.250, Test_accy 62.100
2022-05-25 11:02:54,916 [bic.py] => bias_correction => Task 3, Epoch 48/170 => Loss 3.059, Train_accy 77.500, Test_accy 62.180
2022-05-25 11:02:56,654 [bic.py] => bias_correction => Task 3, Epoch 49/170 => Loss 3.047, Train_accy 78.330, Test_accy 62.250
2022-05-25 11:02:58,366 [bic.py] => bias_correction => Task 3, Epoch 50/170 => Loss 3.078, Train_accy 75.420, Test_accy 62.250
2022-05-25 11:03:00,238 [bic.py] => bias_correction => Task 3, Epoch 51/170 => Loss 3.060, Train_accy 76.670, Test_accy 62.180
2022-05-25 11:03:02,022 [bic.py] => bias_correction => Task 3, Epoch 52/170 => Loss 3.053, Train_accy 75.420, Test_accy 62.050
2022-05-25 11:03:03,786 [bic.py] => bias_correction => Task 3, Epoch 53/170 => Loss 3.061, Train_accy 75.830, Test_accy 62.080
2022-05-25 11:03:05,613 [bic.py] => bias_correction => Task 3, Epoch 54/170 => Loss 3.050, Train_accy 74.580, Test_accy 62.150
2022-05-25 11:03:07,428 [bic.py] => bias_correction => Task 3, Epoch 55/170 => Loss 3.065, Train_accy 75.420, Test_accy 62.000
2022-05-25 11:03:09,281 [bic.py] => bias_correction => Task 3, Epoch 56/170 => Loss 3.056, Train_accy 75.830, Test_accy 62.020
2022-05-25 11:03:11,119 [bic.py] => bias_correction => Task 3, Epoch 57/170 => Loss 3.055, Train_accy 72.500, Test_accy 62.080
2022-05-25 11:03:12,909 [bic.py] => bias_correction => Task 3, Epoch 58/170 => Loss 3.068, Train_accy 75.420, Test_accy 61.980
2022-05-25 11:03:14,647 [bic.py] => bias_correction => Task 3, Epoch 59/170 => Loss 3.040, Train_accy 75.000, Test_accy 62.180
2022-05-25 11:03:16,442 [bic.py] => bias_correction => Task 3, Epoch 60/170 => Loss 3.066, Train_accy 75.000, Test_accy 61.920
2022-05-25 11:03:18,236 [bic.py] => bias_correction => Task 3, Epoch 61/170 => Loss 3.050, Train_accy 75.000, Test_accy 61.980
2022-05-25 11:03:19,951 [bic.py] => bias_correction => Task 3, Epoch 62/170 => Loss 3.063, Train_accy 77.920, Test_accy 62.050
2022-05-25 11:03:21,716 [bic.py] => bias_correction => Task 3, Epoch 63/170 => Loss 3.051, Train_accy 78.330, Test_accy 62.120
2022-05-25 11:03:23,484 [bic.py] => bias_correction => Task 3, Epoch 64/170 => Loss 3.064, Train_accy 77.500, Test_accy 62.050
2022-05-25 11:03:25,257 [bic.py] => bias_correction => Task 3, Epoch 65/170 => Loss 3.059, Train_accy 78.750, Test_accy 62.000
2022-05-25 11:03:26,972 [bic.py] => bias_correction => Task 3, Epoch 66/170 => Loss 3.070, Train_accy 77.080, Test_accy 62.080
2022-05-25 11:03:28,650 [bic.py] => bias_correction => Task 3, Epoch 67/170 => Loss 3.043, Train_accy 72.500, Test_accy 62.020
2022-05-25 11:03:30,531 [bic.py] => bias_correction => Task 3, Epoch 68/170 => Loss 3.056, Train_accy 77.080, Test_accy 62.120
2022-05-25 11:03:32,266 [bic.py] => bias_correction => Task 3, Epoch 69/170 => Loss 3.048, Train_accy 76.250, Test_accy 62.120
2022-05-25 11:03:34,038 [bic.py] => bias_correction => Task 3, Epoch 70/170 => Loss 3.056, Train_accy 76.670, Test_accy 62.220
2022-05-25 11:03:35,906 [bic.py] => bias_correction => Task 3, Epoch 71/170 => Loss 3.053, Train_accy 77.080, Test_accy 62.180
2022-05-25 11:03:37,756 [bic.py] => bias_correction => Task 3, Epoch 72/170 => Loss 3.057, Train_accy 73.330, Test_accy 62.150
2022-05-25 11:03:39,491 [bic.py] => bias_correction => Task 3, Epoch 73/170 => Loss 3.042, Train_accy 75.830, Test_accy 62.150
2022-05-25 11:03:41,265 [bic.py] => bias_correction => Task 3, Epoch 74/170 => Loss 3.064, Train_accy 74.580, Test_accy 62.150
2022-05-25 11:03:43,166 [bic.py] => bias_correction => Task 3, Epoch 75/170 => Loss 3.065, Train_accy 72.080, Test_accy 62.180
2022-05-25 11:03:44,962 [bic.py] => bias_correction => Task 3, Epoch 76/170 => Loss 3.049, Train_accy 77.500, Test_accy 62.100
2022-05-25 11:03:46,580 [bic.py] => bias_correction => Task 3, Epoch 77/170 => Loss 3.070, Train_accy 77.500, Test_accy 62.020
2022-05-25 11:03:48,288 [bic.py] => bias_correction => Task 3, Epoch 78/170 => Loss 3.063, Train_accy 77.920, Test_accy 62.020
2022-05-25 11:03:50,077 [bic.py] => bias_correction => Task 3, Epoch 79/170 => Loss 3.051, Train_accy 77.920, Test_accy 61.980
2022-05-25 11:03:51,746 [bic.py] => bias_correction => Task 3, Epoch 80/170 => Loss 3.082, Train_accy 76.670, Test_accy 62.000
2022-05-25 11:03:53,433 [bic.py] => bias_correction => Task 3, Epoch 81/170 => Loss 3.063, Train_accy 75.420, Test_accy 62.120
2022-05-25 11:03:55,217 [bic.py] => bias_correction => Task 3, Epoch 82/170 => Loss 3.065, Train_accy 74.580, Test_accy 62.080
2022-05-25 11:03:56,910 [bic.py] => bias_correction => Task 3, Epoch 83/170 => Loss 3.065, Train_accy 74.580, Test_accy 62.150
2022-05-25 11:03:58,789 [bic.py] => bias_correction => Task 3, Epoch 84/170 => Loss 3.060, Train_accy 72.920, Test_accy 62.150
2022-05-25 11:04:00,486 [bic.py] => bias_correction => Task 3, Epoch 85/170 => Loss 3.052, Train_accy 77.080, Test_accy 62.120
2022-05-25 11:04:02,311 [bic.py] => bias_correction => Task 3, Epoch 86/170 => Loss 3.056, Train_accy 75.830, Test_accy 62.150
2022-05-25 11:04:04,147 [bic.py] => bias_correction => Task 3, Epoch 87/170 => Loss 3.064, Train_accy 74.580, Test_accy 62.150
2022-05-25 11:04:05,937 [bic.py] => bias_correction => Task 3, Epoch 88/170 => Loss 3.072, Train_accy 75.420, Test_accy 62.020
2022-05-25 11:04:07,773 [bic.py] => bias_correction => Task 3, Epoch 89/170 => Loss 3.044, Train_accy 78.750, Test_accy 62.050
2022-05-25 11:04:09,546 [bic.py] => bias_correction => Task 3, Epoch 90/170 => Loss 3.054, Train_accy 79.170, Test_accy 62.050
2022-05-25 11:04:11,315 [bic.py] => bias_correction => Task 3, Epoch 91/170 => Loss 3.057, Train_accy 74.580, Test_accy 62.150
2022-05-25 11:04:13,140 [bic.py] => bias_correction => Task 3, Epoch 92/170 => Loss 3.052, Train_accy 76.250, Test_accy 62.120
2022-05-25 11:04:14,930 [bic.py] => bias_correction => Task 3, Epoch 93/170 => Loss 3.052, Train_accy 80.000, Test_accy 62.120
2022-05-25 11:04:16,806 [bic.py] => bias_correction => Task 3, Epoch 94/170 => Loss 3.065, Train_accy 75.420, Test_accy 62.100
2022-05-25 11:04:18,643 [bic.py] => bias_correction => Task 3, Epoch 95/170 => Loss 3.046, Train_accy 72.920, Test_accy 62.300
2022-05-25 11:04:20,355 [bic.py] => bias_correction => Task 3, Epoch 96/170 => Loss 3.063, Train_accy 76.670, Test_accy 62.250
2022-05-25 11:04:22,150 [bic.py] => bias_correction => Task 3, Epoch 97/170 => Loss 3.053, Train_accy 73.330, Test_accy 62.080
2022-05-25 11:04:24,021 [bic.py] => bias_correction => Task 3, Epoch 98/170 => Loss 3.067, Train_accy 75.000, Test_accy 62.020
2022-05-25 11:04:25,759 [bic.py] => bias_correction => Task 3, Epoch 99/170 => Loss 3.070, Train_accy 77.500, Test_accy 62.080
2022-05-25 11:04:27,569 [bic.py] => bias_correction => Task 3, Epoch 100/170 => Loss 3.062, Train_accy 75.000, Test_accy 62.100
2022-05-25 11:04:29,314 [bic.py] => bias_correction => Task 3, Epoch 101/170 => Loss 3.065, Train_accy 76.250, Test_accy 62.080
2022-05-25 11:04:31,091 [bic.py] => bias_correction => Task 3, Epoch 102/170 => Loss 3.049, Train_accy 75.420, Test_accy 62.020
2022-05-25 11:04:32,855 [bic.py] => bias_correction => Task 3, Epoch 103/170 => Loss 3.054, Train_accy 75.420, Test_accy 62.050
2022-05-25 11:04:34,571 [bic.py] => bias_correction => Task 3, Epoch 104/170 => Loss 3.073, Train_accy 74.580, Test_accy 62.120
2022-05-25 11:04:36,248 [bic.py] => bias_correction => Task 3, Epoch 105/170 => Loss 3.050, Train_accy 76.250, Test_accy 62.150
2022-05-25 11:04:37,980 [bic.py] => bias_correction => Task 3, Epoch 106/170 => Loss 3.064, Train_accy 74.580, Test_accy 62.020
2022-05-25 11:04:39,732 [bic.py] => bias_correction => Task 3, Epoch 107/170 => Loss 3.052, Train_accy 74.170, Test_accy 62.080
2022-05-25 11:04:41,544 [bic.py] => bias_correction => Task 3, Epoch 108/170 => Loss 3.058, Train_accy 75.000, Test_accy 61.980
2022-05-25 11:04:43,265 [bic.py] => bias_correction => Task 3, Epoch 109/170 => Loss 3.068, Train_accy 75.420, Test_accy 62.000
2022-05-25 11:04:45,021 [bic.py] => bias_correction => Task 3, Epoch 110/170 => Loss 3.057, Train_accy 77.080, Test_accy 62.120
2022-05-25 11:04:46,800 [bic.py] => bias_correction => Task 3, Epoch 111/170 => Loss 3.060, Train_accy 77.500, Test_accy 62.050
2022-05-25 11:04:48,570 [bic.py] => bias_correction => Task 3, Epoch 112/170 => Loss 3.047, Train_accy 75.830, Test_accy 62.000
2022-05-25 11:04:50,381 [bic.py] => bias_correction => Task 3, Epoch 113/170 => Loss 3.055, Train_accy 72.920, Test_accy 62.080
2022-05-25 11:04:52,088 [bic.py] => bias_correction => Task 3, Epoch 114/170 => Loss 3.069, Train_accy 75.420, Test_accy 62.100
2022-05-25 11:04:53,810 [bic.py] => bias_correction => Task 3, Epoch 115/170 => Loss 3.051, Train_accy 74.170, Test_accy 62.150
2022-05-25 11:04:55,640 [bic.py] => bias_correction => Task 3, Epoch 116/170 => Loss 3.061, Train_accy 75.420, Test_accy 62.050
2022-05-25 11:04:57,367 [bic.py] => bias_correction => Task 3, Epoch 117/170 => Loss 3.047, Train_accy 73.330, Test_accy 61.980
2022-05-25 11:04:59,232 [bic.py] => bias_correction => Task 3, Epoch 118/170 => Loss 3.070, Train_accy 73.750, Test_accy 62.080
2022-05-25 11:05:01,052 [bic.py] => bias_correction => Task 3, Epoch 119/170 => Loss 3.058, Train_accy 76.670, Test_accy 62.120
2022-05-25 11:05:02,775 [bic.py] => bias_correction => Task 3, Epoch 120/170 => Loss 3.063, Train_accy 75.000, Test_accy 62.250
2022-05-25 11:05:04,520 [bic.py] => bias_correction => Task 3, Epoch 121/170 => Loss 3.063, Train_accy 75.420, Test_accy 62.180
2022-05-25 11:05:06,304 [bic.py] => bias_correction => Task 3, Epoch 122/170 => Loss 3.053, Train_accy 77.500, Test_accy 62.150
2022-05-25 11:05:08,135 [bic.py] => bias_correction => Task 3, Epoch 123/170 => Loss 3.080, Train_accy 77.500, Test_accy 62.080
2022-05-25 11:05:09,932 [bic.py] => bias_correction => Task 3, Epoch 124/170 => Loss 3.061, Train_accy 75.420, Test_accy 62.080
2022-05-25 11:05:11,689 [bic.py] => bias_correction => Task 3, Epoch 125/170 => Loss 3.061, Train_accy 75.830, Test_accy 62.150
2022-05-25 11:05:13,512 [bic.py] => bias_correction => Task 3, Epoch 126/170 => Loss 3.049, Train_accy 75.420, Test_accy 62.150
2022-05-25 11:05:15,321 [bic.py] => bias_correction => Task 3, Epoch 127/170 => Loss 3.052, Train_accy 73.330, Test_accy 62.050
2022-05-25 11:05:17,134 [bic.py] => bias_correction => Task 3, Epoch 128/170 => Loss 3.062, Train_accy 77.080, Test_accy 62.050
2022-05-25 11:05:18,836 [bic.py] => bias_correction => Task 3, Epoch 129/170 => Loss 3.061, Train_accy 76.670, Test_accy 62.080
2022-05-25 11:05:20,548 [bic.py] => bias_correction => Task 3, Epoch 130/170 => Loss 3.055, Train_accy 72.080, Test_accy 62.100
2022-05-25 11:05:22,274 [bic.py] => bias_correction => Task 3, Epoch 131/170 => Loss 3.064, Train_accy 77.500, Test_accy 62.080
2022-05-25 11:05:24,219 [bic.py] => bias_correction => Task 3, Epoch 132/170 => Loss 3.071, Train_accy 77.080, Test_accy 62.150
2022-05-25 11:05:25,968 [bic.py] => bias_correction => Task 3, Epoch 133/170 => Loss 3.065, Train_accy 75.420, Test_accy 62.120
2022-05-25 11:05:27,731 [bic.py] => bias_correction => Task 3, Epoch 134/170 => Loss 3.063, Train_accy 77.080, Test_accy 62.120
2022-05-25 11:05:29,524 [bic.py] => bias_correction => Task 3, Epoch 135/170 => Loss 3.070, Train_accy 76.250, Test_accy 62.150
2022-05-25 11:05:31,321 [bic.py] => bias_correction => Task 3, Epoch 136/170 => Loss 3.055, Train_accy 77.080, Test_accy 62.120
2022-05-25 11:05:33,093 [bic.py] => bias_correction => Task 3, Epoch 137/170 => Loss 3.056, Train_accy 77.080, Test_accy 62.100
2022-05-25 11:05:34,807 [bic.py] => bias_correction => Task 3, Epoch 138/170 => Loss 3.070, Train_accy 76.250, Test_accy 62.050
2022-05-25 11:05:36,587 [bic.py] => bias_correction => Task 3, Epoch 139/170 => Loss 3.067, Train_accy 75.420, Test_accy 62.100
2022-05-25 11:05:38,422 [bic.py] => bias_correction => Task 3, Epoch 140/170 => Loss 3.048, Train_accy 75.420, Test_accy 62.100
2022-05-25 11:05:40,258 [bic.py] => bias_correction => Task 3, Epoch 141/170 => Loss 3.049, Train_accy 76.670, Test_accy 62.120
2022-05-25 11:05:41,976 [bic.py] => bias_correction => Task 3, Epoch 142/170 => Loss 3.042, Train_accy 77.080, Test_accy 62.100
2022-05-25 11:05:43,728 [bic.py] => bias_correction => Task 3, Epoch 143/170 => Loss 3.062, Train_accy 78.330, Test_accy 62.100
2022-05-25 11:05:45,506 [bic.py] => bias_correction => Task 3, Epoch 144/170 => Loss 3.063, Train_accy 78.330, Test_accy 62.050
2022-05-25 11:05:47,224 [bic.py] => bias_correction => Task 3, Epoch 145/170 => Loss 3.059, Train_accy 75.420, Test_accy 62.000
2022-05-25 11:05:49,060 [bic.py] => bias_correction => Task 3, Epoch 146/170 => Loss 3.070, Train_accy 75.830, Test_accy 61.950
2022-05-25 11:05:50,904 [bic.py] => bias_correction => Task 3, Epoch 147/170 => Loss 3.071, Train_accy 75.000, Test_accy 62.020
2022-05-25 11:05:52,643 [bic.py] => bias_correction => Task 3, Epoch 148/170 => Loss 3.060, Train_accy 75.000, Test_accy 62.050
2022-05-25 11:05:54,402 [bic.py] => bias_correction => Task 3, Epoch 149/170 => Loss 3.063, Train_accy 75.000, Test_accy 62.050
2022-05-25 11:05:56,208 [bic.py] => bias_correction => Task 3, Epoch 150/170 => Loss 3.054, Train_accy 76.670, Test_accy 62.100
2022-05-25 11:05:58,004 [bic.py] => bias_correction => Task 3, Epoch 151/170 => Loss 3.069, Train_accy 76.670, Test_accy 62.080
2022-05-25 11:05:59,807 [bic.py] => bias_correction => Task 3, Epoch 152/170 => Loss 3.063, Train_accy 75.420, Test_accy 62.050
2022-05-25 11:06:01,541 [bic.py] => bias_correction => Task 3, Epoch 153/170 => Loss 3.046, Train_accy 76.250, Test_accy 62.000
2022-05-25 11:06:03,253 [bic.py] => bias_correction => Task 3, Epoch 154/170 => Loss 3.060, Train_accy 77.920, Test_accy 62.120
2022-05-25 11:06:05,000 [bic.py] => bias_correction => Task 3, Epoch 155/170 => Loss 3.064, Train_accy 79.170, Test_accy 62.180
2022-05-25 11:06:06,745 [bic.py] => bias_correction => Task 3, Epoch 156/170 => Loss 3.049, Train_accy 77.920, Test_accy 62.050
2022-05-25 11:06:08,510 [bic.py] => bias_correction => Task 3, Epoch 157/170 => Loss 3.044, Train_accy 77.080, Test_accy 62.120
2022-05-25 11:06:10,382 [bic.py] => bias_correction => Task 3, Epoch 158/170 => Loss 3.069, Train_accy 78.750, Test_accy 62.120
2022-05-25 11:06:12,091 [bic.py] => bias_correction => Task 3, Epoch 159/170 => Loss 3.061, Train_accy 76.250, Test_accy 62.220
2022-05-25 11:06:13,830 [bic.py] => bias_correction => Task 3, Epoch 160/170 => Loss 3.050, Train_accy 75.830, Test_accy 62.120
2022-05-25 11:06:15,599 [bic.py] => bias_correction => Task 3, Epoch 161/170 => Loss 3.063, Train_accy 75.830, Test_accy 62.080
2022-05-25 11:06:17,462 [bic.py] => bias_correction => Task 3, Epoch 162/170 => Loss 3.044, Train_accy 75.420, Test_accy 62.080
2022-05-25 11:06:19,212 [bic.py] => bias_correction => Task 3, Epoch 163/170 => Loss 3.070, Train_accy 76.250, Test_accy 62.100
2022-05-25 11:06:21,082 [bic.py] => bias_correction => Task 3, Epoch 164/170 => Loss 3.053, Train_accy 75.000, Test_accy 62.150
2022-05-25 11:06:22,866 [bic.py] => bias_correction => Task 3, Epoch 165/170 => Loss 3.058, Train_accy 75.830, Test_accy 62.100
2022-05-25 11:06:24,739 [bic.py] => bias_correction => Task 3, Epoch 166/170 => Loss 3.048, Train_accy 75.830, Test_accy 62.150
2022-05-25 11:06:26,537 [bic.py] => bias_correction => Task 3, Epoch 167/170 => Loss 3.051, Train_accy 73.330, Test_accy 62.080
2022-05-25 11:06:28,284 [bic.py] => bias_correction => Task 3, Epoch 168/170 => Loss 3.057, Train_accy 76.670, Test_accy 62.150
2022-05-25 11:06:29,842 [bic.py] => bias_correction => Task 3, Epoch 169/170 => Loss 3.081, Train_accy 77.500, Test_accy 62.180
2022-05-25 11:06:31,614 [bic.py] => bias_correction => Task 3, Epoch 170/170 => Loss 3.047, Train_accy 77.920, Test_accy 62.200
2022-05-25 11:06:31,615 [base.py] => Reducing exemplars...(50 per classes)
2022-05-25 11:06:39,062 [base.py] => Constructing exemplars...(50 per classes)
2022-05-25 11:06:44,853 [bic.py] => Parameters of bias layer:
2022-05-25 11:06:44,854 [bic.py] => 0 => 1.000, 0.000
2022-05-25 11:06:44,854 [bic.py] => 1 => 0.904, -1.125
2022-05-25 11:06:44,854 [bic.py] => 2 => 0.889, -1.948
2022-05-25 11:06:44,854 [bic.py] => 3 => 0.729, -1.345
2022-05-25 11:06:46,331 [bic.py] => Exemplar size: 2000
2022-05-25 11:06:46,332 [trainer.py] => CNN: {'total': 62.2, '00-09': 65.3, '10-19': 60.1, '20-29': 64.6, '30-39': 58.8, 'old': 63.33, 'new': 58.8}
2022-05-25 11:06:46,332 [trainer.py] => NME: {'total': 61.9, '00-09': 60.2, '10-19': 55.3, '20-29': 66.7, '30-39': 65.4, 'old': 60.73, 'new': 65.4}
2022-05-25 11:06:46,332 [trainer.py] => CNN top1 curve: [83.0, 73.7, 68.1, 62.2]
2022-05-25 11:06:46,332 [trainer.py] => CNN top5 curve: [99.1, 95.65, 92.07, 89.1]
2022-05-25 11:06:46,332 [trainer.py] => NME top1 curve: [82.8, 74.15, 67.37, 61.9]
2022-05-25 11:06:46,332 [trainer.py] => NME top5 curve: [99.0, 95.75, 92.47, 89.32]

2022-05-25 11:06:46,332 [trainer.py] => All params: 466762
2022-05-25 11:06:46,333 [trainer.py] => Trainable params: 466762
2022-05-25 11:06:46,334 [bic.py] => Learning on 40-50
2022-05-25 11:06:46,394 [bic.py] => Stage1 dset: 6750, Stage2 dset: 250
2022-05-25 11:06:46,394 [bic.py] => Lambda: 0.800
2022-05-25 11:06:46,406 [bic.py] => Parameters of bias layer:
2022-05-25 11:06:46,406 [bic.py] => 0 => 1.000, 0.000
2022-05-25 11:06:46,406 [bic.py] => 1 => 0.904, -1.125
2022-05-25 11:06:46,406 [bic.py] => 2 => 0.889, -1.948
2022-05-25 11:06:46,406 [bic.py] => 3 => 0.729, -1.345
2022-05-25 11:06:46,406 [bic.py] => 4 => 1.000, 0.000
2022-05-25 11:06:50,834 [bic.py] => training => Task 4, Epoch 1/170 => Loss 2.263, Train_accy 65.190, Test_accy 38.580
2022-05-25 11:06:55,360 [bic.py] => training => Task 4, Epoch 2/170 => Loss 2.078, Train_accy 72.620, Test_accy 42.780
2022-05-25 11:06:59,760 [bic.py] => training => Task 4, Epoch 3/170 => Loss 2.049, Train_accy 75.670, Test_accy 43.400
2022-05-25 11:07:04,239 [bic.py] => training => Task 4, Epoch 4/170 => Loss 2.036, Train_accy 72.770, Test_accy 44.020
2022-05-25 11:07:08,683 [bic.py] => training => Task 4, Epoch 5/170 => Loss 2.030, Train_accy 78.040, Test_accy 45.500
2022-05-25 11:07:13,162 [bic.py] => training => Task 4, Epoch 6/170 => Loss 2.019, Train_accy 79.960, Test_accy 44.920
2022-05-25 11:07:17,479 [bic.py] => training => Task 4, Epoch 7/170 => Loss 2.010, Train_accy 79.820, Test_accy 44.240
2022-05-25 11:07:21,887 [bic.py] => training => Task 4, Epoch 8/170 => Loss 2.000, Train_accy 78.710, Test_accy 44.520
2022-05-25 11:07:26,387 [bic.py] => training => Task 4, Epoch 9/170 => Loss 2.004, Train_accy 81.760, Test_accy 45.340
2022-05-25 11:07:30,894 [bic.py] => training => Task 4, Epoch 10/170 => Loss 1.998, Train_accy 81.440, Test_accy 45.620
2022-05-25 11:07:35,337 [bic.py] => training => Task 4, Epoch 11/170 => Loss 1.992, Train_accy 75.930, Test_accy 42.760
2022-05-25 11:07:39,840 [bic.py] => training => Task 4, Epoch 12/170 => Loss 1.985, Train_accy 79.140, Test_accy 42.160
2022-05-25 11:07:44,305 [bic.py] => training => Task 4, Epoch 13/170 => Loss 1.985, Train_accy 84.610, Test_accy 45.100
2022-05-25 11:07:48,744 [bic.py] => training => Task 4, Epoch 14/170 => Loss 1.987, Train_accy 87.420, Test_accy 47.540
2022-05-25 11:07:53,314 [bic.py] => training => Task 4, Epoch 15/170 => Loss 1.980, Train_accy 82.490, Test_accy 45.940
2022-05-25 11:07:57,858 [bic.py] => training => Task 4, Epoch 16/170 => Loss 1.974, Train_accy 83.760, Test_accy 44.700
2022-05-25 11:08:02,376 [bic.py] => training => Task 4, Epoch 17/170 => Loss 1.976, Train_accy 85.040, Test_accy 46.400
2022-05-25 11:08:06,860 [bic.py] => training => Task 4, Epoch 18/170 => Loss 1.976, Train_accy 87.540, Test_accy 46.300
2022-05-25 11:08:11,358 [bic.py] => training => Task 4, Epoch 19/170 => Loss 1.981, Train_accy 86.670, Test_accy 45.800
2022-05-25 11:08:15,802 [bic.py] => training => Task 4, Epoch 20/170 => Loss 1.970, Train_accy 83.970, Test_accy 44.900
2022-05-25 11:08:20,293 [bic.py] => training => Task 4, Epoch 21/170 => Loss 1.971, Train_accy 87.230, Test_accy 46.440
2022-05-25 11:08:24,695 [bic.py] => training => Task 4, Epoch 22/170 => Loss 1.975, Train_accy 87.320, Test_accy 43.900
2022-05-25 11:08:29,350 [bic.py] => training => Task 4, Epoch 23/170 => Loss 1.968, Train_accy 83.470, Test_accy 43.300
2022-05-25 11:08:33,788 [bic.py] => training => Task 4, Epoch 24/170 => Loss 1.978, Train_accy 84.930, Test_accy 45.000
2022-05-25 11:08:38,265 [bic.py] => training => Task 4, Epoch 25/170 => Loss 1.972, Train_accy 86.520, Test_accy 43.860
2022-05-25 11:08:42,551 [bic.py] => training => Task 4, Epoch 26/170 => Loss 1.967, Train_accy 88.580, Test_accy 46.200
2022-05-25 11:08:47,126 [bic.py] => training => Task 4, Epoch 27/170 => Loss 1.959, Train_accy 88.430, Test_accy 45.760
2022-05-25 11:08:51,526 [bic.py] => training => Task 4, Epoch 28/170 => Loss 1.964, Train_accy 88.580, Test_accy 46.340
2022-05-25 11:08:55,971 [bic.py] => training => Task 4, Epoch 29/170 => Loss 1.968, Train_accy 89.070, Test_accy 46.640
2022-05-25 11:09:00,379 [bic.py] => training => Task 4, Epoch 30/170 => Loss 1.958, Train_accy 91.360, Test_accy 46.680
2022-05-25 11:09:04,861 [bic.py] => training => Task 4, Epoch 31/170 => Loss 1.959, Train_accy 84.270, Test_accy 44.660
2022-05-25 11:09:09,330 [bic.py] => training => Task 4, Epoch 32/170 => Loss 1.961, Train_accy 89.140, Test_accy 46.380
2022-05-25 11:09:13,867 [bic.py] => training => Task 4, Epoch 33/170 => Loss 1.954, Train_accy 89.670, Test_accy 45.060
2022-05-25 11:09:18,416 [bic.py] => training => Task 4, Epoch 34/170 => Loss 1.954, Train_accy 86.930, Test_accy 46.180
2022-05-25 11:09:22,863 [bic.py] => training => Task 4, Epoch 35/170 => Loss 1.952, Train_accy 87.100, Test_accy 43.660
2022-05-25 11:09:27,312 [bic.py] => training => Task 4, Epoch 36/170 => Loss 1.958, Train_accy 88.220, Test_accy 47.800
2022-05-25 11:09:31,738 [bic.py] => training => Task 4, Epoch 37/170 => Loss 1.953, Train_accy 89.380, Test_accy 45.120
2022-05-25 11:09:36,049 [bic.py] => training => Task 4, Epoch 38/170 => Loss 1.947, Train_accy 90.060, Test_accy 47.400
2022-05-25 11:09:40,621 [bic.py] => training => Task 4, Epoch 39/170 => Loss 1.961, Train_accy 86.800, Test_accy 46.800
2022-05-25 11:09:45,038 [bic.py] => training => Task 4, Epoch 40/170 => Loss 1.957, Train_accy 86.590, Test_accy 42.080
2022-05-25 11:09:49,424 [bic.py] => training => Task 4, Epoch 41/170 => Loss 1.953, Train_accy 91.100, Test_accy 47.180
2022-05-25 11:09:54,060 [bic.py] => training => Task 4, Epoch 42/170 => Loss 1.953, Train_accy 87.690, Test_accy 43.560
2022-05-25 11:09:58,567 [bic.py] => training => Task 4, Epoch 43/170 => Loss 1.954, Train_accy 88.040, Test_accy 42.660
2022-05-25 11:10:03,066 [bic.py] => training => Task 4, Epoch 44/170 => Loss 1.950, Train_accy 91.230, Test_accy 47.380
2022-05-25 11:10:07,374 [bic.py] => training => Task 4, Epoch 45/170 => Loss 1.951, Train_accy 89.080, Test_accy 44.720
2022-05-25 11:10:11,962 [bic.py] => training => Task 4, Epoch 46/170 => Loss 1.948, Train_accy 86.220, Test_accy 41.900
2022-05-25 11:10:16,255 [bic.py] => training => Task 4, Epoch 47/170 => Loss 1.942, Train_accy 87.130, Test_accy 43.900
2022-05-25 11:10:20,633 [bic.py] => training => Task 4, Epoch 48/170 => Loss 1.947, Train_accy 91.440, Test_accy 47.400
2022-05-25 11:10:25,020 [bic.py] => training => Task 4, Epoch 49/170 => Loss 1.946, Train_accy 91.110, Test_accy 46.220
2022-05-25 11:10:29,431 [bic.py] => training => Task 4, Epoch 50/170 => Loss 1.954, Train_accy 89.820, Test_accy 48.660
2022-05-25 11:10:33,891 [bic.py] => training => Task 4, Epoch 51/170 => Loss 1.946, Train_accy 90.810, Test_accy 47.000
2022-05-25 11:10:38,288 [bic.py] => training => Task 4, Epoch 52/170 => Loss 1.954, Train_accy 90.990, Test_accy 46.800
2022-05-25 11:10:42,686 [bic.py] => training => Task 4, Epoch 53/170 => Loss 1.946, Train_accy 89.930, Test_accy 44.460
2022-05-25 11:10:47,232 [bic.py] => training => Task 4, Epoch 54/170 => Loss 1.948, Train_accy 88.530, Test_accy 46.580
2022-05-25 11:10:51,568 [bic.py] => training => Task 4, Epoch 55/170 => Loss 1.945, Train_accy 90.390, Test_accy 45.800
2022-05-25 11:10:56,027 [bic.py] => training => Task 4, Epoch 56/170 => Loss 1.948, Train_accy 87.870, Test_accy 42.460
2022-05-25 11:11:00,401 [bic.py] => training => Task 4, Epoch 57/170 => Loss 1.941, Train_accy 91.970, Test_accy 47.440
2022-05-25 11:11:04,851 [bic.py] => training => Task 4, Epoch 58/170 => Loss 1.943, Train_accy 92.530, Test_accy 47.940
2022-05-25 11:11:09,250 [bic.py] => training => Task 4, Epoch 59/170 => Loss 1.941, Train_accy 91.350, Test_accy 48.300
2022-05-25 11:11:13,629 [bic.py] => training => Task 4, Epoch 60/170 => Loss 1.948, Train_accy 89.300, Test_accy 45.520
2022-05-25 11:11:18,048 [bic.py] => training => Task 4, Epoch 61/170 => Loss 1.915, Train_accy 97.810, Test_accy 50.960
2022-05-25 11:11:22,444 [bic.py] => training => Task 4, Epoch 62/170 => Loss 1.888, Train_accy 98.310, Test_accy 50.900
2022-05-25 11:11:27,030 [bic.py] => training => Task 4, Epoch 63/170 => Loss 1.888, Train_accy 98.500, Test_accy 50.660
2022-05-25 11:11:31,553 [bic.py] => training => Task 4, Epoch 64/170 => Loss 1.887, Train_accy 98.580, Test_accy 51.240
2022-05-25 11:11:36,009 [bic.py] => training => Task 4, Epoch 65/170 => Loss 1.883, Train_accy 98.640, Test_accy 50.740
2022-05-25 11:11:40,400 [bic.py] => training => Task 4, Epoch 66/170 => Loss 1.881, Train_accy 99.010, Test_accy 51.280
2022-05-25 11:11:44,853 [bic.py] => training => Task 4, Epoch 67/170 => Loss 1.881, Train_accy 98.650, Test_accy 50.980
2022-05-25 11:11:49,295 [bic.py] => training => Task 4, Epoch 68/170 => Loss 1.882, Train_accy 98.870, Test_accy 50.640
2022-05-25 11:11:53,812 [bic.py] => training => Task 4, Epoch 69/170 => Loss 1.882, Train_accy 98.950, Test_accy 50.960
2022-05-25 11:11:58,404 [bic.py] => training => Task 4, Epoch 70/170 => Loss 1.878, Train_accy 99.020, Test_accy 50.800
2022-05-25 11:12:02,883 [bic.py] => training => Task 4, Epoch 71/170 => Loss 1.878, Train_accy 98.920, Test_accy 50.760
2022-05-25 11:12:07,286 [bic.py] => training => Task 4, Epoch 72/170 => Loss 1.876, Train_accy 99.100, Test_accy 51.200
2022-05-25 11:12:11,679 [bic.py] => training => Task 4, Epoch 73/170 => Loss 1.873, Train_accy 98.960, Test_accy 50.720
2022-05-25 11:12:16,122 [bic.py] => training => Task 4, Epoch 74/170 => Loss 1.873, Train_accy 99.260, Test_accy 51.240
2022-05-25 11:12:20,567 [bic.py] => training => Task 4, Epoch 75/170 => Loss 1.876, Train_accy 99.100, Test_accy 50.820
2022-05-25 11:12:25,049 [bic.py] => training => Task 4, Epoch 76/170 => Loss 1.872, Train_accy 99.190, Test_accy 50.780
2022-05-25 11:12:29,660 [bic.py] => training => Task 4, Epoch 77/170 => Loss 1.876, Train_accy 99.140, Test_accy 50.740
2022-05-25 11:12:34,180 [bic.py] => training => Task 4, Epoch 78/170 => Loss 1.876, Train_accy 99.260, Test_accy 50.760
2022-05-25 11:12:38,576 [bic.py] => training => Task 4, Epoch 79/170 => Loss 1.872, Train_accy 99.240, Test_accy 50.660
2022-05-25 11:12:43,282 [bic.py] => training => Task 4, Epoch 80/170 => Loss 1.870, Train_accy 99.300, Test_accy 51.220
2022-05-25 11:12:47,847 [bic.py] => training => Task 4, Epoch 81/170 => Loss 1.870, Train_accy 99.260, Test_accy 50.760
2022-05-25 11:12:52,276 [bic.py] => training => Task 4, Epoch 82/170 => Loss 1.869, Train_accy 99.160, Test_accy 50.880
2022-05-25 11:12:56,778 [bic.py] => training => Task 4, Epoch 83/170 => Loss 1.874, Train_accy 99.210, Test_accy 51.140
2022-05-25 11:13:01,298 [bic.py] => training => Task 4, Epoch 84/170 => Loss 1.873, Train_accy 99.300, Test_accy 50.940
2022-05-25 11:13:05,823 [bic.py] => training => Task 4, Epoch 85/170 => Loss 1.873, Train_accy 99.300, Test_accy 51.200
2022-05-25 11:13:10,579 [bic.py] => training => Task 4, Epoch 86/170 => Loss 1.869, Train_accy 99.260, Test_accy 51.220
2022-05-25 11:13:15,194 [bic.py] => training => Task 4, Epoch 87/170 => Loss 1.875, Train_accy 99.360, Test_accy 51.060
2022-05-25 11:13:19,807 [bic.py] => training => Task 4, Epoch 88/170 => Loss 1.873, Train_accy 99.210, Test_accy 50.580
2022-05-25 11:13:24,243 [bic.py] => training => Task 4, Epoch 89/170 => Loss 1.869, Train_accy 99.290, Test_accy 50.600
2022-05-25 11:13:28,650 [bic.py] => training => Task 4, Epoch 90/170 => Loss 1.868, Train_accy 99.260, Test_accy 51.000
2022-05-25 11:13:33,039 [bic.py] => training => Task 4, Epoch 91/170 => Loss 1.873, Train_accy 99.320, Test_accy 50.840
2022-05-25 11:13:37,398 [bic.py] => training => Task 4, Epoch 92/170 => Loss 1.867, Train_accy 99.130, Test_accy 50.980
2022-05-25 11:13:41,793 [bic.py] => training => Task 4, Epoch 93/170 => Loss 1.872, Train_accy 99.420, Test_accy 51.140
2022-05-25 11:13:46,387 [bic.py] => training => Task 4, Epoch 94/170 => Loss 1.864, Train_accy 99.300, Test_accy 50.760
2022-05-25 11:13:50,816 [bic.py] => training => Task 4, Epoch 95/170 => Loss 1.870, Train_accy 99.210, Test_accy 50.680
2022-05-25 11:13:55,227 [bic.py] => training => Task 4, Epoch 96/170 => Loss 1.870, Train_accy 99.470, Test_accy 50.900
2022-05-25 11:13:59,699 [bic.py] => training => Task 4, Epoch 97/170 => Loss 1.865, Train_accy 99.230, Test_accy 50.920
2022-05-25 11:14:03,979 [bic.py] => training => Task 4, Epoch 98/170 => Loss 1.867, Train_accy 99.330, Test_accy 50.640
2022-05-25 11:14:08,366 [bic.py] => training => Task 4, Epoch 99/170 => Loss 1.868, Train_accy 99.450, Test_accy 50.920
2022-05-25 11:14:12,690 [bic.py] => training => Task 4, Epoch 100/170 => Loss 1.866, Train_accy 99.450, Test_accy 51.160
2022-05-25 11:14:17,075 [bic.py] => training => Task 4, Epoch 101/170 => Loss 1.864, Train_accy 99.350, Test_accy 50.820
2022-05-25 11:14:21,429 [bic.py] => training => Task 4, Epoch 102/170 => Loss 1.865, Train_accy 99.500, Test_accy 50.860
2022-05-25 11:14:25,838 [bic.py] => training => Task 4, Epoch 103/170 => Loss 1.866, Train_accy 99.270, Test_accy 50.840
2022-05-25 11:14:30,246 [bic.py] => training => Task 4, Epoch 104/170 => Loss 1.859, Train_accy 99.440, Test_accy 50.760
2022-05-25 11:14:34,837 [bic.py] => training => Task 4, Epoch 105/170 => Loss 1.869, Train_accy 99.480, Test_accy 50.820
2022-05-25 11:14:39,240 [bic.py] => training => Task 4, Epoch 106/170 => Loss 1.866, Train_accy 99.380, Test_accy 50.880
2022-05-25 11:14:43,709 [bic.py] => training => Task 4, Epoch 107/170 => Loss 1.867, Train_accy 99.380, Test_accy 50.800
2022-05-25 11:14:48,191 [bic.py] => training => Task 4, Epoch 108/170 => Loss 1.867, Train_accy 99.480, Test_accy 50.700
2022-05-25 11:14:52,716 [bic.py] => training => Task 4, Epoch 109/170 => Loss 1.861, Train_accy 99.610, Test_accy 50.840
2022-05-25 11:14:57,071 [bic.py] => training => Task 4, Epoch 110/170 => Loss 1.869, Train_accy 99.530, Test_accy 50.840
2022-05-25 11:15:01,459 [bic.py] => training => Task 4, Epoch 111/170 => Loss 1.867, Train_accy 99.500, Test_accy 50.800
2022-05-25 11:15:05,935 [bic.py] => training => Task 4, Epoch 112/170 => Loss 1.861, Train_accy 99.590, Test_accy 50.660
2022-05-25 11:15:10,480 [bic.py] => training => Task 4, Epoch 113/170 => Loss 1.869, Train_accy 99.420, Test_accy 50.960
2022-05-25 11:15:14,831 [bic.py] => training => Task 4, Epoch 114/170 => Loss 1.866, Train_accy 99.480, Test_accy 50.740
2022-05-25 11:15:19,224 [bic.py] => training => Task 4, Epoch 115/170 => Loss 1.862, Train_accy 99.420, Test_accy 50.780
2022-05-25 11:15:23,714 [bic.py] => training => Task 4, Epoch 116/170 => Loss 1.867, Train_accy 99.440, Test_accy 50.880
2022-05-25 11:15:28,075 [bic.py] => training => Task 4, Epoch 117/170 => Loss 1.867, Train_accy 99.590, Test_accy 50.820
2022-05-25 11:15:32,417 [bic.py] => training => Task 4, Epoch 118/170 => Loss 1.864, Train_accy 99.410, Test_accy 50.840
2022-05-25 11:15:36,785 [bic.py] => training => Task 4, Epoch 119/170 => Loss 1.861, Train_accy 99.190, Test_accy 50.560
2022-05-25 11:15:41,234 [bic.py] => training => Task 4, Epoch 120/170 => Loss 1.865, Train_accy 99.270, Test_accy 50.820
2022-05-25 11:15:45,681 [bic.py] => training => Task 4, Epoch 121/170 => Loss 1.866, Train_accy 99.440, Test_accy 50.780
2022-05-25 11:15:50,186 [bic.py] => training => Task 4, Epoch 122/170 => Loss 1.866, Train_accy 99.510, Test_accy 51.000
2022-05-25 11:15:54,555 [bic.py] => training => Task 4, Epoch 123/170 => Loss 1.862, Train_accy 99.500, Test_accy 50.780
2022-05-25 11:15:59,043 [bic.py] => training => Task 4, Epoch 124/170 => Loss 1.863, Train_accy 99.420, Test_accy 50.740
2022-05-25 11:16:03,335 [bic.py] => training => Task 4, Epoch 125/170 => Loss 1.863, Train_accy 99.480, Test_accy 51.080
2022-05-25 11:16:07,731 [bic.py] => training => Task 4, Epoch 126/170 => Loss 1.862, Train_accy 99.380, Test_accy 50.680
2022-05-25 11:16:12,148 [bic.py] => training => Task 4, Epoch 127/170 => Loss 1.864, Train_accy 99.560, Test_accy 50.760
2022-05-25 11:16:16,520 [bic.py] => training => Task 4, Epoch 128/170 => Loss 1.862, Train_accy 99.590, Test_accy 50.860
2022-05-25 11:16:20,898 [bic.py] => training => Task 4, Epoch 129/170 => Loss 1.865, Train_accy 99.440, Test_accy 50.900
2022-05-25 11:16:25,322 [bic.py] => training => Task 4, Epoch 130/170 => Loss 1.863, Train_accy 99.630, Test_accy 50.720
2022-05-25 11:16:29,675 [bic.py] => training => Task 4, Epoch 131/170 => Loss 1.864, Train_accy 99.500, Test_accy 50.840
2022-05-25 11:16:34,254 [bic.py] => training => Task 4, Epoch 132/170 => Loss 1.864, Train_accy 99.450, Test_accy 50.860
2022-05-25 11:16:38,777 [bic.py] => training => Task 4, Epoch 133/170 => Loss 1.865, Train_accy 99.380, Test_accy 50.840
2022-05-25 11:16:43,214 [bic.py] => training => Task 4, Epoch 134/170 => Loss 1.862, Train_accy 99.410, Test_accy 51.000
2022-05-25 11:16:47,885 [bic.py] => training => Task 4, Epoch 135/170 => Loss 1.862, Train_accy 99.450, Test_accy 50.840
2022-05-25 11:16:52,415 [bic.py] => training => Task 4, Epoch 136/170 => Loss 1.865, Train_accy 99.510, Test_accy 50.580
2022-05-25 11:16:56,804 [bic.py] => training => Task 4, Epoch 137/170 => Loss 1.863, Train_accy 99.420, Test_accy 50.980
2022-05-25 11:17:01,211 [bic.py] => training => Task 4, Epoch 138/170 => Loss 1.867, Train_accy 99.470, Test_accy 50.800
2022-05-25 11:17:05,585 [bic.py] => training => Task 4, Epoch 139/170 => Loss 1.865, Train_accy 99.410, Test_accy 50.580
2022-05-25 11:17:09,965 [bic.py] => training => Task 4, Epoch 140/170 => Loss 1.862, Train_accy 99.560, Test_accy 50.940
2022-05-25 11:17:14,502 [bic.py] => training => Task 4, Epoch 141/170 => Loss 1.862, Train_accy 99.470, Test_accy 50.840
2022-05-25 11:17:18,933 [bic.py] => training => Task 4, Epoch 142/170 => Loss 1.869, Train_accy 99.500, Test_accy 50.540
2022-05-25 11:17:23,245 [bic.py] => training => Task 4, Epoch 143/170 => Loss 1.866, Train_accy 99.570, Test_accy 50.800
2022-05-25 11:17:27,563 [bic.py] => training => Task 4, Epoch 144/170 => Loss 1.867, Train_accy 99.500, Test_accy 50.700
2022-05-25 11:17:31,979 [bic.py] => training => Task 4, Epoch 145/170 => Loss 1.861, Train_accy 99.360, Test_accy 50.820
2022-05-25 11:17:36,328 [bic.py] => training => Task 4, Epoch 146/170 => Loss 1.864, Train_accy 99.410, Test_accy 50.680
2022-05-25 11:17:40,684 [bic.py] => training => Task 4, Epoch 147/170 => Loss 1.864, Train_accy 99.420, Test_accy 50.700
2022-05-25 11:17:45,119 [bic.py] => training => Task 4, Epoch 148/170 => Loss 1.863, Train_accy 99.530, Test_accy 50.720
2022-05-25 11:17:49,649 [bic.py] => training => Task 4, Epoch 149/170 => Loss 1.866, Train_accy 99.420, Test_accy 50.740
2022-05-25 11:17:53,999 [bic.py] => training => Task 4, Epoch 150/170 => Loss 1.861, Train_accy 99.530, Test_accy 50.760
2022-05-25 11:17:58,465 [bic.py] => training => Task 4, Epoch 151/170 => Loss 1.867, Train_accy 99.440, Test_accy 50.660
2022-05-25 11:18:02,832 [bic.py] => training => Task 4, Epoch 152/170 => Loss 1.864, Train_accy 99.480, Test_accy 50.800
2022-05-25 11:18:07,161 [bic.py] => training => Task 4, Epoch 153/170 => Loss 1.864, Train_accy 99.390, Test_accy 50.880
2022-05-25 11:18:11,605 [bic.py] => training => Task 4, Epoch 154/170 => Loss 1.859, Train_accy 99.500, Test_accy 50.720
2022-05-25 11:18:15,996 [bic.py] => training => Task 4, Epoch 155/170 => Loss 1.865, Train_accy 99.560, Test_accy 50.720
2022-05-25 11:18:20,273 [bic.py] => training => Task 4, Epoch 156/170 => Loss 1.864, Train_accy 99.380, Test_accy 50.840
2022-05-25 11:18:24,646 [bic.py] => training => Task 4, Epoch 157/170 => Loss 1.861, Train_accy 99.570, Test_accy 51.040
2022-05-25 11:18:29,168 [bic.py] => training => Task 4, Epoch 158/170 => Loss 1.863, Train_accy 99.440, Test_accy 50.840
2022-05-25 11:18:33,514 [bic.py] => training => Task 4, Epoch 159/170 => Loss 1.860, Train_accy 99.540, Test_accy 50.840
2022-05-25 11:18:37,905 [bic.py] => training => Task 4, Epoch 160/170 => Loss 1.861, Train_accy 99.600, Test_accy 50.900
2022-05-25 11:18:42,362 [bic.py] => training => Task 4, Epoch 161/170 => Loss 1.864, Train_accy 99.530, Test_accy 50.640
2022-05-25 11:18:46,700 [bic.py] => training => Task 4, Epoch 162/170 => Loss 1.863, Train_accy 99.600, Test_accy 50.760
2022-05-25 11:18:51,030 [bic.py] => training => Task 4, Epoch 163/170 => Loss 1.861, Train_accy 99.330, Test_accy 50.700
2022-05-25 11:18:55,429 [bic.py] => training => Task 4, Epoch 164/170 => Loss 1.870, Train_accy 99.570, Test_accy 50.480
2022-05-25 11:18:59,953 [bic.py] => training => Task 4, Epoch 165/170 => Loss 1.869, Train_accy 99.350, Test_accy 50.900
2022-05-25 11:19:04,397 [bic.py] => training => Task 4, Epoch 166/170 => Loss 1.860, Train_accy 99.330, Test_accy 50.940
2022-05-25 11:19:08,777 [bic.py] => training => Task 4, Epoch 167/170 => Loss 1.870, Train_accy 99.330, Test_accy 50.720
2022-05-25 11:19:13,138 [bic.py] => training => Task 4, Epoch 168/170 => Loss 1.861, Train_accy 99.510, Test_accy 51.020
2022-05-25 11:19:17,443 [bic.py] => training => Task 4, Epoch 169/170 => Loss 1.865, Train_accy 99.450, Test_accy 51.000
2022-05-25 11:19:21,875 [bic.py] => training => Task 4, Epoch 170/170 => Loss 1.865, Train_accy 99.440, Test_accy 51.100
2022-05-25 11:19:23,564 [bic.py] => bias_correction => Task 4, Epoch 1/170 => Loss 3.398, Train_accy 67.600, Test_accy 54.380
2022-05-25 11:19:25,335 [bic.py] => bias_correction => Task 4, Epoch 2/170 => Loss 3.352, Train_accy 75.600, Test_accy 58.180
2022-05-25 11:19:27,090 [bic.py] => bias_correction => Task 4, Epoch 3/170 => Loss 3.301, Train_accy 72.800, Test_accy 53.520
2022-05-25 11:19:28,959 [bic.py] => bias_correction => Task 4, Epoch 4/170 => Loss 3.344, Train_accy 69.600, Test_accy 50.360
2022-05-25 11:19:30,657 [bic.py] => bias_correction => Task 4, Epoch 5/170 => Loss 3.351, Train_accy 67.600, Test_accy 49.460
2022-05-25 11:19:32,365 [bic.py] => bias_correction => Task 4, Epoch 6/170 => Loss 3.358, Train_accy 67.600, Test_accy 49.380
2022-05-25 11:19:34,143 [bic.py] => bias_correction => Task 4, Epoch 7/170 => Loss 3.354, Train_accy 68.400, Test_accy 50.140
2022-05-25 11:19:35,889 [bic.py] => bias_correction => Task 4, Epoch 8/170 => Loss 3.344, Train_accy 70.800, Test_accy 52.160
2022-05-25 11:19:37,701 [bic.py] => bias_correction => Task 4, Epoch 9/170 => Loss 3.333, Train_accy 77.200, Test_accy 56.400
2022-05-25 11:19:39,411 [bic.py] => bias_correction => Task 4, Epoch 10/170 => Loss 3.309, Train_accy 74.800, Test_accy 58.180
2022-05-25 11:19:41,133 [bic.py] => bias_correction => Task 4, Epoch 11/170 => Loss 3.300, Train_accy 74.800, Test_accy 56.640
2022-05-25 11:19:42,805 [bic.py] => bias_correction => Task 4, Epoch 12/170 => Loss 3.326, Train_accy 74.800, Test_accy 56.660
2022-05-25 11:19:44,549 [bic.py] => bias_correction => Task 4, Epoch 13/170 => Loss 3.318, Train_accy 76.400, Test_accy 57.920
2022-05-25 11:19:46,305 [bic.py] => bias_correction => Task 4, Epoch 14/170 => Loss 3.295, Train_accy 75.600, Test_accy 58.140
2022-05-25 11:19:48,020 [bic.py] => bias_correction => Task 4, Epoch 15/170 => Loss 3.298, Train_accy 76.400, Test_accy 57.100
2022-05-25 11:19:49,737 [bic.py] => bias_correction => Task 4, Epoch 16/170 => Loss 3.293, Train_accy 74.000, Test_accy 56.900
2022-05-25 11:19:51,379 [bic.py] => bias_correction => Task 4, Epoch 17/170 => Loss 3.317, Train_accy 73.600, Test_accy 58.140
2022-05-25 11:19:53,079 [bic.py] => bias_correction => Task 4, Epoch 18/170 => Loss 3.284, Train_accy 73.600, Test_accy 58.220
2022-05-25 11:19:54,767 [bic.py] => bias_correction => Task 4, Epoch 19/170 => Loss 3.301, Train_accy 73.600, Test_accy 57.760
2022-05-25 11:19:56,566 [bic.py] => bias_correction => Task 4, Epoch 20/170 => Loss 3.293, Train_accy 75.200, Test_accy 58.180
2022-05-25 11:19:58,252 [bic.py] => bias_correction => Task 4, Epoch 21/170 => Loss 3.295, Train_accy 76.000, Test_accy 58.240
2022-05-25 11:19:59,867 [bic.py] => bias_correction => Task 4, Epoch 22/170 => Loss 3.308, Train_accy 73.600, Test_accy 58.000
2022-05-25 11:20:01,636 [bic.py] => bias_correction => Task 4, Epoch 23/170 => Loss 3.296, Train_accy 75.600, Test_accy 57.740
2022-05-25 11:20:03,413 [bic.py] => bias_correction => Task 4, Epoch 24/170 => Loss 3.276, Train_accy 77.200, Test_accy 58.060
2022-05-25 11:20:05,083 [bic.py] => bias_correction => Task 4, Epoch 25/170 => Loss 3.303, Train_accy 72.400, Test_accy 58.240
2022-05-25 11:20:06,792 [bic.py] => bias_correction => Task 4, Epoch 26/170 => Loss 3.284, Train_accy 76.400, Test_accy 58.120
2022-05-25 11:20:08,502 [bic.py] => bias_correction => Task 4, Epoch 27/170 => Loss 3.288, Train_accy 75.200, Test_accy 58.180
2022-05-25 11:20:10,163 [bic.py] => bias_correction => Task 4, Epoch 28/170 => Loss 3.297, Train_accy 75.200, Test_accy 58.300
2022-05-25 11:20:11,950 [bic.py] => bias_correction => Task 4, Epoch 29/170 => Loss 3.289, Train_accy 78.000, Test_accy 58.200
2022-05-25 11:20:13,733 [bic.py] => bias_correction => Task 4, Epoch 30/170 => Loss 3.288, Train_accy 74.400, Test_accy 58.060
2022-05-25 11:20:15,386 [bic.py] => bias_correction => Task 4, Epoch 31/170 => Loss 3.289, Train_accy 76.400, Test_accy 58.300
2022-05-25 11:20:17,089 [bic.py] => bias_correction => Task 4, Epoch 32/170 => Loss 3.307, Train_accy 76.000, Test_accy 58.260
2022-05-25 11:20:18,838 [bic.py] => bias_correction => Task 4, Epoch 33/170 => Loss 3.290, Train_accy 74.000, Test_accy 58.140
2022-05-25 11:20:20,549 [bic.py] => bias_correction => Task 4, Epoch 34/170 => Loss 3.300, Train_accy 73.600, Test_accy 57.920
2022-05-25 11:20:22,341 [bic.py] => bias_correction => Task 4, Epoch 35/170 => Loss 3.299, Train_accy 74.800, Test_accy 58.220
2022-05-25 11:20:24,096 [bic.py] => bias_correction => Task 4, Epoch 36/170 => Loss 3.282, Train_accy 75.200, Test_accy 58.280
2022-05-25 11:20:25,829 [bic.py] => bias_correction => Task 4, Epoch 37/170 => Loss 3.304, Train_accy 74.000, Test_accy 58.140
2022-05-25 11:20:27,505 [bic.py] => bias_correction => Task 4, Epoch 38/170 => Loss 3.289, Train_accy 78.000, Test_accy 58.040
2022-05-25 11:20:29,208 [bic.py] => bias_correction => Task 4, Epoch 39/170 => Loss 3.302, Train_accy 76.400, Test_accy 58.100
2022-05-25 11:20:30,909 [bic.py] => bias_correction => Task 4, Epoch 40/170 => Loss 3.291, Train_accy 75.200, Test_accy 58.280
2022-05-25 11:20:32,603 [bic.py] => bias_correction => Task 4, Epoch 41/170 => Loss 3.294, Train_accy 76.800, Test_accy 58.180
2022-05-25 11:20:34,358 [bic.py] => bias_correction => Task 4, Epoch 42/170 => Loss 3.296, Train_accy 74.800, Test_accy 58.200
2022-05-25 11:20:36,028 [bic.py] => bias_correction => Task 4, Epoch 43/170 => Loss 3.285, Train_accy 78.800, Test_accy 58.200
2022-05-25 11:20:37,751 [bic.py] => bias_correction => Task 4, Epoch 44/170 => Loss 3.290, Train_accy 77.600, Test_accy 58.020
2022-05-25 11:20:39,508 [bic.py] => bias_correction => Task 4, Epoch 45/170 => Loss 3.288, Train_accy 77.600, Test_accy 58.140
2022-05-25 11:20:41,271 [bic.py] => bias_correction => Task 4, Epoch 46/170 => Loss 3.293, Train_accy 73.200, Test_accy 58.160
2022-05-25 11:20:42,970 [bic.py] => bias_correction => Task 4, Epoch 47/170 => Loss 3.289, Train_accy 74.000, Test_accy 58.280
2022-05-25 11:20:44,857 [bic.py] => bias_correction => Task 4, Epoch 48/170 => Loss 3.299, Train_accy 77.600, Test_accy 58.280
2022-05-25 11:20:46,509 [bic.py] => bias_correction => Task 4, Epoch 49/170 => Loss 3.292, Train_accy 76.800, Test_accy 58.240
2022-05-25 11:20:48,325 [bic.py] => bias_correction => Task 4, Epoch 50/170 => Loss 3.278, Train_accy 75.200, Test_accy 58.280
2022-05-25 11:20:50,075 [bic.py] => bias_correction => Task 4, Epoch 51/170 => Loss 3.272, Train_accy 76.400, Test_accy 58.360
2022-05-25 11:20:51,917 [bic.py] => bias_correction => Task 4, Epoch 52/170 => Loss 3.292, Train_accy 77.200, Test_accy 58.220
2022-05-25 11:20:53,666 [bic.py] => bias_correction => Task 4, Epoch 53/170 => Loss 3.302, Train_accy 77.200, Test_accy 58.300
2022-05-25 11:20:55,427 [bic.py] => bias_correction => Task 4, Epoch 54/170 => Loss 3.284, Train_accy 75.200, Test_accy 58.320
2022-05-25 11:20:57,151 [bic.py] => bias_correction => Task 4, Epoch 55/170 => Loss 3.288, Train_accy 75.600, Test_accy 58.220
2022-05-25 11:20:58,913 [bic.py] => bias_correction => Task 4, Epoch 56/170 => Loss 3.283, Train_accy 77.200, Test_accy 58.320
2022-05-25 11:21:00,611 [bic.py] => bias_correction => Task 4, Epoch 57/170 => Loss 3.292, Train_accy 78.000, Test_accy 58.420
2022-05-25 11:21:02,384 [bic.py] => bias_correction => Task 4, Epoch 58/170 => Loss 3.289, Train_accy 78.400, Test_accy 58.400
2022-05-25 11:21:04,096 [bic.py] => bias_correction => Task 4, Epoch 59/170 => Loss 3.287, Train_accy 76.800, Test_accy 58.280
2022-05-25 11:21:05,790 [bic.py] => bias_correction => Task 4, Epoch 60/170 => Loss 3.288, Train_accy 74.000, Test_accy 58.160
2022-05-25 11:21:07,526 [bic.py] => bias_correction => Task 4, Epoch 61/170 => Loss 3.287, Train_accy 74.800, Test_accy 58.100
2022-05-25 11:21:09,288 [bic.py] => bias_correction => Task 4, Epoch 62/170 => Loss 3.292, Train_accy 77.600, Test_accy 58.140
2022-05-25 11:21:10,991 [bic.py] => bias_correction => Task 4, Epoch 63/170 => Loss 3.293, Train_accy 76.800, Test_accy 58.120
2022-05-25 11:21:12,740 [bic.py] => bias_correction => Task 4, Epoch 64/170 => Loss 3.282, Train_accy 75.200, Test_accy 58.200
2022-05-25 11:21:14,486 [bic.py] => bias_correction => Task 4, Epoch 65/170 => Loss 3.293, Train_accy 75.200, Test_accy 58.240
2022-05-25 11:21:16,241 [bic.py] => bias_correction => Task 4, Epoch 66/170 => Loss 3.273, Train_accy 75.600, Test_accy 58.260
2022-05-25 11:21:18,006 [bic.py] => bias_correction => Task 4, Epoch 67/170 => Loss 3.291, Train_accy 75.600, Test_accy 58.140
2022-05-25 11:21:19,618 [bic.py] => bias_correction => Task 4, Epoch 68/170 => Loss 3.279, Train_accy 77.200, Test_accy 58.200
2022-05-25 11:21:21,341 [bic.py] => bias_correction => Task 4, Epoch 69/170 => Loss 3.291, Train_accy 77.200, Test_accy 58.240
2022-05-25 11:21:23,056 [bic.py] => bias_correction => Task 4, Epoch 70/170 => Loss 3.283, Train_accy 74.400, Test_accy 58.240
2022-05-25 11:21:24,747 [bic.py] => bias_correction => Task 4, Epoch 71/170 => Loss 3.299, Train_accy 77.600, Test_accy 58.260
2022-05-25 11:21:26,535 [bic.py] => bias_correction => Task 4, Epoch 72/170 => Loss 3.290, Train_accy 77.600, Test_accy 58.200
2022-05-25 11:21:28,271 [bic.py] => bias_correction => Task 4, Epoch 73/170 => Loss 3.275, Train_accy 75.200, Test_accy 58.200
2022-05-25 11:21:30,051 [bic.py] => bias_correction => Task 4, Epoch 74/170 => Loss 3.292, Train_accy 77.600, Test_accy 58.360
2022-05-25 11:21:31,765 [bic.py] => bias_correction => Task 4, Epoch 75/170 => Loss 3.281, Train_accy 75.600, Test_accy 58.320
2022-05-25 11:21:33,517 [bic.py] => bias_correction => Task 4, Epoch 76/170 => Loss 3.296, Train_accy 76.000, Test_accy 58.280
2022-05-25 11:21:35,151 [bic.py] => bias_correction => Task 4, Epoch 77/170 => Loss 3.301, Train_accy 76.800, Test_accy 58.240
2022-05-25 11:21:36,798 [bic.py] => bias_correction => Task 4, Epoch 78/170 => Loss 3.284, Train_accy 78.400, Test_accy 58.140
2022-05-25 11:21:38,462 [bic.py] => bias_correction => Task 4, Epoch 79/170 => Loss 3.283, Train_accy 77.200, Test_accy 58.220
2022-05-25 11:21:40,206 [bic.py] => bias_correction => Task 4, Epoch 80/170 => Loss 3.292, Train_accy 73.200, Test_accy 58.380
2022-05-25 11:21:41,954 [bic.py] => bias_correction => Task 4, Epoch 81/170 => Loss 3.294, Train_accy 75.200, Test_accy 58.380
2022-05-25 11:21:43,618 [bic.py] => bias_correction => Task 4, Epoch 82/170 => Loss 3.299, Train_accy 74.000, Test_accy 58.520
2022-05-25 11:21:45,400 [bic.py] => bias_correction => Task 4, Epoch 83/170 => Loss 3.295, Train_accy 77.200, Test_accy 58.380
2022-05-25 11:21:47,081 [bic.py] => bias_correction => Task 4, Epoch 84/170 => Loss 3.266, Train_accy 77.200, Test_accy 58.320
2022-05-25 11:21:48,872 [bic.py] => bias_correction => Task 4, Epoch 85/170 => Loss 3.285, Train_accy 77.200, Test_accy 58.380
2022-05-25 11:21:50,651 [bic.py] => bias_correction => Task 4, Epoch 86/170 => Loss 3.300, Train_accy 78.000, Test_accy 58.260
2022-05-25 11:21:52,460 [bic.py] => bias_correction => Task 4, Epoch 87/170 => Loss 3.278, Train_accy 74.400, Test_accy 58.380
2022-05-25 11:21:54,250 [bic.py] => bias_correction => Task 4, Epoch 88/170 => Loss 3.298, Train_accy 78.000, Test_accy 58.400
2022-05-25 11:21:55,988 [bic.py] => bias_correction => Task 4, Epoch 89/170 => Loss 3.298, Train_accy 75.600, Test_accy 58.400
2022-05-25 11:21:57,655 [bic.py] => bias_correction => Task 4, Epoch 90/170 => Loss 3.298, Train_accy 76.000, Test_accy 58.320
2022-05-25 11:21:59,338 [bic.py] => bias_correction => Task 4, Epoch 91/170 => Loss 3.278, Train_accy 77.200, Test_accy 58.300
2022-05-25 11:22:01,075 [bic.py] => bias_correction => Task 4, Epoch 92/170 => Loss 3.298, Train_accy 77.600, Test_accy 58.380
2022-05-25 11:22:02,833 [bic.py] => bias_correction => Task 4, Epoch 93/170 => Loss 3.279, Train_accy 74.800, Test_accy 58.340
2022-05-25 11:22:04,547 [bic.py] => bias_correction => Task 4, Epoch 94/170 => Loss 3.288, Train_accy 76.400, Test_accy 58.360
2022-05-25 11:22:06,292 [bic.py] => bias_correction => Task 4, Epoch 95/170 => Loss 3.297, Train_accy 76.400, Test_accy 58.300
2022-05-25 11:22:08,077 [bic.py] => bias_correction => Task 4, Epoch 96/170 => Loss 3.294, Train_accy 75.600, Test_accy 58.300
2022-05-25 11:22:09,812 [bic.py] => bias_correction => Task 4, Epoch 97/170 => Loss 3.281, Train_accy 77.600, Test_accy 58.260
2022-05-25 11:22:11,573 [bic.py] => bias_correction => Task 4, Epoch 98/170 => Loss 3.280, Train_accy 76.000, Test_accy 58.300
2022-05-25 11:22:13,246 [bic.py] => bias_correction => Task 4, Epoch 99/170 => Loss 3.283, Train_accy 78.400, Test_accy 58.360
2022-05-25 11:22:15,022 [bic.py] => bias_correction => Task 4, Epoch 100/170 => Loss 3.294, Train_accy 77.200, Test_accy 58.320
2022-05-25 11:22:16,796 [bic.py] => bias_correction => Task 4, Epoch 101/170 => Loss 3.291, Train_accy 76.000, Test_accy 58.300
2022-05-25 11:22:18,561 [bic.py] => bias_correction => Task 4, Epoch 102/170 => Loss 3.293, Train_accy 76.000, Test_accy 58.160
2022-05-25 11:22:20,231 [bic.py] => bias_correction => Task 4, Epoch 103/170 => Loss 3.298, Train_accy 76.400, Test_accy 58.240
2022-05-25 11:22:21,974 [bic.py] => bias_correction => Task 4, Epoch 104/170 => Loss 3.277, Train_accy 79.200, Test_accy 58.240
2022-05-25 11:22:23,741 [bic.py] => bias_correction => Task 4, Epoch 105/170 => Loss 3.286, Train_accy 77.200, Test_accy 58.200
2022-05-25 11:22:25,570 [bic.py] => bias_correction => Task 4, Epoch 106/170 => Loss 3.285, Train_accy 74.800, Test_accy 58.120
2022-05-25 11:22:27,261 [bic.py] => bias_correction => Task 4, Epoch 107/170 => Loss 3.296, Train_accy 76.400, Test_accy 58.240
2022-05-25 11:22:28,965 [bic.py] => bias_correction => Task 4, Epoch 108/170 => Loss 3.290, Train_accy 77.600, Test_accy 58.160
2022-05-25 11:22:30,784 [bic.py] => bias_correction => Task 4, Epoch 109/170 => Loss 3.281, Train_accy 78.400, Test_accy 58.260
2022-05-25 11:22:32,458 [bic.py] => bias_correction => Task 4, Epoch 110/170 => Loss 3.286, Train_accy 77.200, Test_accy 58.240
2022-05-25 11:22:34,183 [bic.py] => bias_correction => Task 4, Epoch 111/170 => Loss 3.292, Train_accy 76.400, Test_accy 58.240
2022-05-25 11:22:35,836 [bic.py] => bias_correction => Task 4, Epoch 112/170 => Loss 3.301, Train_accy 75.600, Test_accy 58.260
2022-05-25 11:22:37,627 [bic.py] => bias_correction => Task 4, Epoch 113/170 => Loss 3.287, Train_accy 77.200, Test_accy 58.240
2022-05-25 11:22:39,315 [bic.py] => bias_correction => Task 4, Epoch 114/170 => Loss 3.278, Train_accy 75.200, Test_accy 58.280
2022-05-25 11:22:40,994 [bic.py] => bias_correction => Task 4, Epoch 115/170 => Loss 3.279, Train_accy 77.200, Test_accy 58.340
2022-05-25 11:22:42,781 [bic.py] => bias_correction => Task 4, Epoch 116/170 => Loss 3.276, Train_accy 74.400, Test_accy 58.360
2022-05-25 11:22:44,439 [bic.py] => bias_correction => Task 4, Epoch 117/170 => Loss 3.291, Train_accy 76.800, Test_accy 58.300
2022-05-25 11:22:46,140 [bic.py] => bias_correction => Task 4, Epoch 118/170 => Loss 3.280, Train_accy 75.200, Test_accy 58.280
2022-05-25 11:22:47,901 [bic.py] => bias_correction => Task 4, Epoch 119/170 => Loss 3.286, Train_accy 78.000, Test_accy 58.260
2022-05-25 11:22:49,818 [bic.py] => bias_correction => Task 4, Epoch 120/170 => Loss 3.297, Train_accy 75.200, Test_accy 58.220
2022-05-25 11:22:51,563 [bic.py] => bias_correction => Task 4, Epoch 121/170 => Loss 3.280, Train_accy 76.800, Test_accy 58.300
2022-05-25 11:22:53,205 [bic.py] => bias_correction => Task 4, Epoch 122/170 => Loss 3.299, Train_accy 73.600, Test_accy 58.320
2022-05-25 11:22:54,893 [bic.py] => bias_correction => Task 4, Epoch 123/170 => Loss 3.283, Train_accy 74.800, Test_accy 58.260
2022-05-25 11:22:56,632 [bic.py] => bias_correction => Task 4, Epoch 124/170 => Loss 3.293, Train_accy 77.200, Test_accy 58.360
2022-05-25 11:22:58,400 [bic.py] => bias_correction => Task 4, Epoch 125/170 => Loss 3.288, Train_accy 75.200, Test_accy 58.280
2022-05-25 11:23:00,132 [bic.py] => bias_correction => Task 4, Epoch 126/170 => Loss 3.282, Train_accy 76.800, Test_accy 58.380
2022-05-25 11:23:01,798 [bic.py] => bias_correction => Task 4, Epoch 127/170 => Loss 3.286, Train_accy 77.200, Test_accy 58.380
2022-05-25 11:23:03,494 [bic.py] => bias_correction => Task 4, Epoch 128/170 => Loss 3.295, Train_accy 73.200, Test_accy 58.420
2022-05-25 11:23:05,333 [bic.py] => bias_correction => Task 4, Epoch 129/170 => Loss 3.273, Train_accy 76.800, Test_accy 58.280
2022-05-25 11:23:07,087 [bic.py] => bias_correction => Task 4, Epoch 130/170 => Loss 3.289, Train_accy 76.000, Test_accy 58.300
2022-05-25 11:23:08,828 [bic.py] => bias_correction => Task 4, Epoch 131/170 => Loss 3.295, Train_accy 78.400, Test_accy 58.360
2022-05-25 11:23:10,610 [bic.py] => bias_correction => Task 4, Epoch 132/170 => Loss 3.276, Train_accy 76.400, Test_accy 58.380
2022-05-25 11:23:12,402 [bic.py] => bias_correction => Task 4, Epoch 133/170 => Loss 3.286, Train_accy 78.400, Test_accy 58.420
2022-05-25 11:23:14,297 [bic.py] => bias_correction => Task 4, Epoch 134/170 => Loss 3.294, Train_accy 74.000, Test_accy 58.520
2022-05-25 11:23:16,078 [bic.py] => bias_correction => Task 4, Epoch 135/170 => Loss 3.286, Train_accy 77.200, Test_accy 58.520
2022-05-25 11:23:17,865 [bic.py] => bias_correction => Task 4, Epoch 136/170 => Loss 3.292, Train_accy 75.600, Test_accy 58.320
2022-05-25 11:23:19,689 [bic.py] => bias_correction => Task 4, Epoch 137/170 => Loss 3.298, Train_accy 78.000, Test_accy 58.400
2022-05-25 11:23:21,421 [bic.py] => bias_correction => Task 4, Epoch 138/170 => Loss 3.289, Train_accy 76.000, Test_accy 58.300
2022-05-25 11:23:23,052 [bic.py] => bias_correction => Task 4, Epoch 139/170 => Loss 3.280, Train_accy 74.800, Test_accy 58.280
2022-05-25 11:23:24,732 [bic.py] => bias_correction => Task 4, Epoch 140/170 => Loss 3.267, Train_accy 78.800, Test_accy 58.200
2022-05-25 11:23:26,512 [bic.py] => bias_correction => Task 4, Epoch 141/170 => Loss 3.291, Train_accy 74.400, Test_accy 58.260
2022-05-25 11:23:28,243 [bic.py] => bias_correction => Task 4, Epoch 142/170 => Loss 3.286, Train_accy 77.200, Test_accy 58.320
2022-05-25 11:23:29,949 [bic.py] => bias_correction => Task 4, Epoch 143/170 => Loss 3.283, Train_accy 76.800, Test_accy 58.340
2022-05-25 11:23:31,781 [bic.py] => bias_correction => Task 4, Epoch 144/170 => Loss 3.287, Train_accy 77.200, Test_accy 58.340
2022-05-25 11:23:33,551 [bic.py] => bias_correction => Task 4, Epoch 145/170 => Loss 3.290, Train_accy 77.200, Test_accy 58.340
2022-05-25 11:23:35,383 [bic.py] => bias_correction => Task 4, Epoch 146/170 => Loss 3.299, Train_accy 74.800, Test_accy 58.260
2022-05-25 11:23:37,084 [bic.py] => bias_correction => Task 4, Epoch 147/170 => Loss 3.290, Train_accy 77.600, Test_accy 58.280
2022-05-25 11:23:38,844 [bic.py] => bias_correction => Task 4, Epoch 148/170 => Loss 3.293, Train_accy 75.600, Test_accy 58.180
2022-05-25 11:23:40,612 [bic.py] => bias_correction => Task 4, Epoch 149/170 => Loss 3.285, Train_accy 74.400, Test_accy 58.120
2022-05-25 11:23:42,317 [bic.py] => bias_correction => Task 4, Epoch 150/170 => Loss 3.293, Train_accy 74.800, Test_accy 58.300
2022-05-25 11:23:44,070 [bic.py] => bias_correction => Task 4, Epoch 151/170 => Loss 3.286, Train_accy 74.400, Test_accy 58.340
2022-05-25 11:23:45,831 [bic.py] => bias_correction => Task 4, Epoch 152/170 => Loss 3.279, Train_accy 73.200, Test_accy 58.300
2022-05-25 11:23:47,590 [bic.py] => bias_correction => Task 4, Epoch 153/170 => Loss 3.270, Train_accy 78.000, Test_accy 58.240
2022-05-25 11:23:49,299 [bic.py] => bias_correction => Task 4, Epoch 154/170 => Loss 3.273, Train_accy 77.600, Test_accy 58.320
2022-05-25 11:23:51,114 [bic.py] => bias_correction => Task 4, Epoch 155/170 => Loss 3.273, Train_accy 78.400, Test_accy 58.380
2022-05-25 11:23:52,880 [bic.py] => bias_correction => Task 4, Epoch 156/170 => Loss 3.293, Train_accy 78.800, Test_accy 58.380
2022-05-25 11:23:54,581 [bic.py] => bias_correction => Task 4, Epoch 157/170 => Loss 3.288, Train_accy 72.800, Test_accy 58.320
2022-05-25 11:23:56,247 [bic.py] => bias_correction => Task 4, Epoch 158/170 => Loss 3.281, Train_accy 76.800, Test_accy 58.440
2022-05-25 11:23:57,841 [bic.py] => bias_correction => Task 4, Epoch 159/170 => Loss 3.283, Train_accy 74.400, Test_accy 58.240
2022-05-25 11:23:59,593 [bic.py] => bias_correction => Task 4, Epoch 160/170 => Loss 3.281, Train_accy 76.000, Test_accy 58.240
2022-05-25 11:24:01,388 [bic.py] => bias_correction => Task 4, Epoch 161/170 => Loss 3.281, Train_accy 73.200, Test_accy 58.340
2022-05-25 11:24:03,160 [bic.py] => bias_correction => Task 4, Epoch 162/170 => Loss 3.287, Train_accy 80.000, Test_accy 58.260
2022-05-25 11:24:04,877 [bic.py] => bias_correction => Task 4, Epoch 163/170 => Loss 3.290, Train_accy 79.200, Test_accy 58.240
2022-05-25 11:24:06,626 [bic.py] => bias_correction => Task 4, Epoch 164/170 => Loss 3.292, Train_accy 76.400, Test_accy 58.360
2022-05-25 11:24:08,355 [bic.py] => bias_correction => Task 4, Epoch 165/170 => Loss 3.295, Train_accy 79.600, Test_accy 58.340
2022-05-25 11:24:10,059 [bic.py] => bias_correction => Task 4, Epoch 166/170 => Loss 3.294, Train_accy 76.800, Test_accy 58.380
2022-05-25 11:24:11,734 [bic.py] => bias_correction => Task 4, Epoch 167/170 => Loss 3.297, Train_accy 73.600, Test_accy 58.380
2022-05-25 11:24:13,446 [bic.py] => bias_correction => Task 4, Epoch 168/170 => Loss 3.282, Train_accy 78.800, Test_accy 58.320
2022-05-25 11:24:15,166 [bic.py] => bias_correction => Task 4, Epoch 169/170 => Loss 3.275, Train_accy 75.200, Test_accy 58.320
2022-05-25 11:24:17,050 [bic.py] => bias_correction => Task 4, Epoch 170/170 => Loss 3.289, Train_accy 78.800, Test_accy 58.380
2022-05-25 11:24:17,051 [base.py] => Reducing exemplars...(40 per classes)
2022-05-25 11:24:26,305 [base.py] => Constructing exemplars...(40 per classes)
2022-05-25 11:24:31,738 [bic.py] => Parameters of bias layer:
2022-05-25 11:24:31,738 [bic.py] => 0 => 1.000, 0.000
2022-05-25 11:24:31,739 [bic.py] => 1 => 0.904, -1.125
2022-05-25 11:24:31,739 [bic.py] => 2 => 0.889, -1.948
2022-05-25 11:24:31,739 [bic.py] => 3 => 0.729, -1.345
2022-05-25 11:24:31,739 [bic.py] => 4 => 0.731, -1.321
2022-05-25 11:24:33,376 [bic.py] => Exemplar size: 2000
2022-05-25 11:24:33,376 [trainer.py] => CNN: {'total': 58.38, '00-09': 61.2, '10-19': 56.0, '20-29': 62.4, '30-39': 51.6, '40-49': 60.7, 'old': 57.8, 'new': 60.7}
2022-05-25 11:24:33,376 [trainer.py] => NME: {'total': 58.1, '00-09': 55.6, '10-19': 52.5, '20-29': 61.3, '30-39': 56.1, '40-49': 65.0, 'old': 56.38, 'new': 65.0}
2022-05-25 11:24:33,376 [trainer.py] => CNN top1 curve: [83.0, 73.7, 68.1, 62.2, 58.38]
2022-05-25 11:24:33,376 [trainer.py] => CNN top5 curve: [99.1, 95.65, 92.07, 89.1, 86.2]
2022-05-25 11:24:33,376 [trainer.py] => NME top1 curve: [82.8, 74.15, 67.37, 61.9, 58.1]
2022-05-25 11:24:33,376 [trainer.py] => NME top5 curve: [99.0, 95.75, 92.47, 89.32, 86.1]

2022-05-25 11:24:33,377 [trainer.py] => All params: 467414
2022-05-25 11:24:33,377 [trainer.py] => Trainable params: 467414
2022-05-25 11:24:33,379 [bic.py] => Learning on 50-60
2022-05-25 11:24:33,435 [bic.py] => Stage1 dset: 6760, Stage2 dset: 240
2022-05-25 11:24:33,435 [bic.py] => Lambda: 0.833
2022-05-25 11:24:33,450 [bic.py] => Parameters of bias layer:
2022-05-25 11:24:33,451 [bic.py] => 0 => 1.000, 0.000
2022-05-25 11:24:33,451 [bic.py] => 1 => 0.904, -1.125
2022-05-25 11:24:33,451 [bic.py] => 2 => 0.889, -1.948
2022-05-25 11:24:33,451 [bic.py] => 3 => 0.729, -1.345
2022-05-25 11:24:33,451 [bic.py] => 4 => 0.731, -1.321
2022-05-25 11:24:33,451 [bic.py] => 5 => 1.000, 0.000
2022-05-25 11:24:37,868 [bic.py] => training => Task 5, Epoch 1/170 => Loss 2.477, Train_accy 65.100, Test_accy 40.980
2022-05-25 11:24:42,430 [bic.py] => training => Task 5, Epoch 2/170 => Loss 2.340, Train_accy 70.920, Test_accy 41.800
2022-05-25 11:24:46,987 [bic.py] => training => Task 5, Epoch 3/170 => Loss 2.317, Train_accy 74.070, Test_accy 43.730
2022-05-25 11:24:51,468 [bic.py] => training => Task 5, Epoch 4/170 => Loss 2.294, Train_accy 77.430, Test_accy 43.930
2022-05-25 11:24:55,920 [bic.py] => training => Task 5, Epoch 5/170 => Loss 2.294, Train_accy 79.260, Test_accy 44.850
2022-05-25 11:25:00,440 [bic.py] => training => Task 5, Epoch 6/170 => Loss 2.283, Train_accy 77.540, Test_accy 41.920
2022-05-25 11:25:05,062 [bic.py] => training => Task 5, Epoch 7/170 => Loss 2.284, Train_accy 79.360, Test_accy 43.070
2022-05-25 11:25:09,651 [bic.py] => training => Task 5, Epoch 8/170 => Loss 2.270, Train_accy 82.160, Test_accy 45.430
2022-05-25 11:25:14,121 [bic.py] => training => Task 5, Epoch 9/170 => Loss 2.267, Train_accy 80.960, Test_accy 43.680
2022-05-25 11:25:18,551 [bic.py] => training => Task 5, Epoch 10/170 => Loss 2.269, Train_accy 82.310, Test_accy 43.870
2022-05-25 11:25:23,106 [bic.py] => training => Task 5, Epoch 11/170 => Loss 2.265, Train_accy 77.770, Test_accy 39.220
2022-05-25 11:25:27,934 [bic.py] => training => Task 5, Epoch 12/170 => Loss 2.265, Train_accy 82.540, Test_accy 43.130
2022-05-25 11:25:32,485 [bic.py] => training => Task 5, Epoch 13/170 => Loss 2.260, Train_accy 86.510, Test_accy 44.900
2022-05-25 11:25:37,218 [bic.py] => training => Task 5, Epoch 14/170 => Loss 2.256, Train_accy 85.740, Test_accy 44.020
2022-05-25 11:25:41,917 [bic.py] => training => Task 5, Epoch 15/170 => Loss 2.249, Train_accy 86.040, Test_accy 44.000
2022-05-25 11:25:46,601 [bic.py] => training => Task 5, Epoch 16/170 => Loss 2.251, Train_accy 85.370, Test_accy 45.700
2022-05-25 11:25:51,211 [bic.py] => training => Task 5, Epoch 17/170 => Loss 2.254, Train_accy 86.760, Test_accy 44.720
2022-05-25 11:25:55,713 [bic.py] => training => Task 5, Epoch 18/170 => Loss 2.250, Train_accy 82.130, Test_accy 44.680
2022-05-25 11:26:00,306 [bic.py] => training => Task 5, Epoch 19/170 => Loss 2.245, Train_accy 86.140, Test_accy 45.220
2022-05-25 11:26:05,072 [bic.py] => training => Task 5, Epoch 20/170 => Loss 2.240, Train_accy 80.720, Test_accy 40.700
2022-05-25 11:26:09,828 [bic.py] => training => Task 5, Epoch 21/170 => Loss 2.243, Train_accy 86.520, Test_accy 44.100
2022-05-25 11:26:14,590 [bic.py] => training => Task 5, Epoch 22/170 => Loss 2.236, Train_accy 88.250, Test_accy 44.780
2022-05-25 11:26:19,100 [bic.py] => training => Task 5, Epoch 23/170 => Loss 2.234, Train_accy 86.800, Test_accy 44.970
2022-05-25 11:26:23,594 [bic.py] => training => Task 5, Epoch 24/170 => Loss 2.232, Train_accy 87.940, Test_accy 44.880
2022-05-25 11:26:28,132 [bic.py] => training => Task 5, Epoch 25/170 => Loss 2.236, Train_accy 87.900, Test_accy 44.770
2022-05-25 11:26:32,595 [bic.py] => training => Task 5, Epoch 26/170 => Loss 2.238, Train_accy 88.510, Test_accy 45.300
2022-05-25 11:26:37,166 [bic.py] => training => Task 5, Epoch 27/170 => Loss 2.237, Train_accy 88.000, Test_accy 44.330
2022-05-25 11:26:41,752 [bic.py] => training => Task 5, Epoch 28/170 => Loss 2.232, Train_accy 88.080, Test_accy 45.550
2022-05-25 11:26:46,244 [bic.py] => training => Task 5, Epoch 29/170 => Loss 2.232, Train_accy 87.750, Test_accy 41.800
2022-05-25 11:26:50,682 [bic.py] => training => Task 5, Epoch 30/170 => Loss 2.232, Train_accy 86.410, Test_accy 41.380
2022-05-25 11:26:55,178 [bic.py] => training => Task 5, Epoch 31/170 => Loss 2.235, Train_accy 88.860, Test_accy 45.180
2022-05-25 11:26:59,682 [bic.py] => training => Task 5, Epoch 32/170 => Loss 2.226, Train_accy 87.310, Test_accy 43.100
2022-05-25 11:27:04,163 [bic.py] => training => Task 5, Epoch 33/170 => Loss 2.225, Train_accy 90.490, Test_accy 44.930
2022-05-25 11:27:08,701 [bic.py] => training => Task 5, Epoch 34/170 => Loss 2.232, Train_accy 89.530, Test_accy 44.250
2022-05-25 11:27:13,190 [bic.py] => training => Task 5, Epoch 35/170 => Loss 2.220, Train_accy 89.540, Test_accy 46.970
2022-05-25 11:27:17,785 [bic.py] => training => Task 5, Epoch 36/170 => Loss 2.227, Train_accy 89.510, Test_accy 45.020
2022-05-25 11:27:22,489 [bic.py] => training => Task 5, Epoch 37/170 => Loss 2.219, Train_accy 89.050, Test_accy 44.330
2022-05-25 11:27:26,826 [bic.py] => training => Task 5, Epoch 38/170 => Loss 2.220, Train_accy 90.830, Test_accy 45.950
2022-05-25 11:27:31,334 [bic.py] => training => Task 5, Epoch 39/170 => Loss 2.223, Train_accy 89.480, Test_accy 44.820
2022-05-25 11:27:35,872 [bic.py] => training => Task 5, Epoch 40/170 => Loss 2.231, Train_accy 91.920, Test_accy 44.470
2022-05-25 11:27:40,272 [bic.py] => training => Task 5, Epoch 41/170 => Loss 2.230, Train_accy 84.470, Test_accy 40.380
2022-05-25 11:27:44,655 [bic.py] => training => Task 5, Epoch 42/170 => Loss 2.229, Train_accy 90.010, Test_accy 44.020
2022-05-25 11:27:49,103 [bic.py] => training => Task 5, Epoch 43/170 => Loss 2.224, Train_accy 91.800, Test_accy 45.270
2022-05-25 11:27:53,304 [bic.py] => training => Task 5, Epoch 44/170 => Loss 2.226, Train_accy 88.730, Test_accy 42.330
2022-05-25 11:27:57,813 [bic.py] => training => Task 5, Epoch 45/170 => Loss 2.228, Train_accy 90.240, Test_accy 44.670
2022-05-25 11:28:02,358 [bic.py] => training => Task 5, Epoch 46/170 => Loss 2.223, Train_accy 91.780, Test_accy 44.430
2022-05-25 11:28:06,889 [bic.py] => training => Task 5, Epoch 47/170 => Loss 2.223, Train_accy 88.310, Test_accy 41.770
2022-05-25 11:28:11,374 [bic.py] => training => Task 5, Epoch 48/170 => Loss 2.223, Train_accy 84.970, Test_accy 42.200
2022-05-25 11:28:15,884 [bic.py] => training => Task 5, Epoch 49/170 => Loss 2.218, Train_accy 88.680, Test_accy 43.250
2022-05-25 11:28:20,358 [bic.py] => training => Task 5, Epoch 50/170 => Loss 2.223, Train_accy 90.400, Test_accy 41.580
2022-05-25 11:28:24,638 [bic.py] => training => Task 5, Epoch 51/170 => Loss 2.226, Train_accy 91.520, Test_accy 45.370
2022-05-25 11:28:29,131 [bic.py] => training => Task 5, Epoch 52/170 => Loss 2.223, Train_accy 90.620, Test_accy 44.420
2022-05-25 11:28:33,624 [bic.py] => training => Task 5, Epoch 53/170 => Loss 2.217, Train_accy 91.760, Test_accy 44.400
2022-05-25 11:28:38,154 [bic.py] => training => Task 5, Epoch 54/170 => Loss 2.224, Train_accy 92.220, Test_accy 48.030
2022-05-25 11:28:42,542 [bic.py] => training => Task 5, Epoch 55/170 => Loss 2.224, Train_accy 78.930, Test_accy 34.550
2022-05-25 11:28:47,055 [bic.py] => training => Task 5, Epoch 56/170 => Loss 2.225, Train_accy 91.630, Test_accy 44.630
2022-05-25 11:28:51,645 [bic.py] => training => Task 5, Epoch 57/170 => Loss 2.222, Train_accy 91.800, Test_accy 47.220
2022-05-25 11:28:56,142 [bic.py] => training => Task 5, Epoch 58/170 => Loss 2.214, Train_accy 90.250, Test_accy 43.300
2022-05-25 11:29:00,690 [bic.py] => training => Task 5, Epoch 59/170 => Loss 2.212, Train_accy 93.620, Test_accy 44.850
2022-05-25 11:29:05,164 [bic.py] => training => Task 5, Epoch 60/170 => Loss 2.211, Train_accy 90.120, Test_accy 43.450
2022-05-25 11:29:09,666 [bic.py] => training => Task 5, Epoch 61/170 => Loss 2.190, Train_accy 98.000, Test_accy 49.120
2022-05-25 11:29:14,246 [bic.py] => training => Task 5, Epoch 62/170 => Loss 2.178, Train_accy 98.310, Test_accy 49.800
2022-05-25 11:29:18,865 [bic.py] => training => Task 5, Epoch 63/170 => Loss 2.178, Train_accy 98.570, Test_accy 49.720
2022-05-25 11:29:23,331 [bic.py] => training => Task 5, Epoch 64/170 => Loss 2.171, Train_accy 98.760, Test_accy 50.570
2022-05-25 11:29:27,819 [bic.py] => training => Task 5, Epoch 65/170 => Loss 2.163, Train_accy 98.850, Test_accy 49.700
2022-05-25 11:29:32,407 [bic.py] => training => Task 5, Epoch 66/170 => Loss 2.163, Train_accy 98.890, Test_accy 49.950
2022-05-25 11:29:36,886 [bic.py] => training => Task 5, Epoch 67/170 => Loss 2.166, Train_accy 98.910, Test_accy 49.830
2022-05-25 11:29:41,408 [bic.py] => training => Task 5, Epoch 68/170 => Loss 2.165, Train_accy 98.990, Test_accy 49.550
2022-05-25 11:29:45,914 [bic.py] => training => Task 5, Epoch 69/170 => Loss 2.162, Train_accy 98.880, Test_accy 49.730
2022-05-25 11:29:50,410 [bic.py] => training => Task 5, Epoch 70/170 => Loss 2.166, Train_accy 99.080, Test_accy 49.820
2022-05-25 11:29:54,933 [bic.py] => training => Task 5, Epoch 71/170 => Loss 2.166, Train_accy 99.040, Test_accy 49.580
2022-05-25 11:29:59,345 [bic.py] => training => Task 5, Epoch 72/170 => Loss 2.157, Train_accy 99.020, Test_accy 49.780
2022-05-25 11:30:03,823 [bic.py] => training => Task 5, Epoch 73/170 => Loss 2.157, Train_accy 99.200, Test_accy 49.570
2022-05-25 11:30:08,326 [bic.py] => training => Task 5, Epoch 74/170 => Loss 2.157, Train_accy 99.190, Test_accy 49.600
2022-05-25 11:30:12,968 [bic.py] => training => Task 5, Epoch 75/170 => Loss 2.160, Train_accy 99.140, Test_accy 49.950
2022-05-25 11:30:17,468 [bic.py] => training => Task 5, Epoch 76/170 => Loss 2.157, Train_accy 99.020, Test_accy 49.880
2022-05-25 11:30:21,962 [bic.py] => training => Task 5, Epoch 77/170 => Loss 2.161, Train_accy 99.220, Test_accy 49.550
2022-05-25 11:30:26,432 [bic.py] => training => Task 5, Epoch 78/170 => Loss 2.159, Train_accy 99.190, Test_accy 49.430
2022-05-25 11:30:30,920 [bic.py] => training => Task 5, Epoch 79/170 => Loss 2.159, Train_accy 99.250, Test_accy 49.680
2022-05-25 11:30:35,461 [bic.py] => training => Task 5, Epoch 80/170 => Loss 2.160, Train_accy 99.160, Test_accy 49.680
2022-05-25 11:30:39,988 [bic.py] => training => Task 5, Epoch 81/170 => Loss 2.159, Train_accy 99.320, Test_accy 49.200
2022-05-25 11:30:44,589 [bic.py] => training => Task 5, Epoch 82/170 => Loss 2.157, Train_accy 99.260, Test_accy 49.380
2022-05-25 11:30:49,155 [bic.py] => training => Task 5, Epoch 83/170 => Loss 2.160, Train_accy 99.130, Test_accy 49.380
2022-05-25 11:30:53,602 [bic.py] => training => Task 5, Epoch 84/170 => Loss 2.155, Train_accy 99.200, Test_accy 49.450
2022-05-25 11:30:58,095 [bic.py] => training => Task 5, Epoch 85/170 => Loss 2.152, Train_accy 99.230, Test_accy 49.780
2022-05-25 11:31:02,614 [bic.py] => training => Task 5, Epoch 86/170 => Loss 2.156, Train_accy 99.320, Test_accy 49.720
2022-05-25 11:31:07,181 [bic.py] => training => Task 5, Epoch 87/170 => Loss 2.158, Train_accy 99.290, Test_accy 49.050
2022-05-25 11:31:11,599 [bic.py] => training => Task 5, Epoch 88/170 => Loss 2.157, Train_accy 99.230, Test_accy 49.580
2022-05-25 11:31:16,086 [bic.py] => training => Task 5, Epoch 89/170 => Loss 2.152, Train_accy 99.380, Test_accy 49.280
2022-05-25 11:31:20,583 [bic.py] => training => Task 5, Epoch 90/170 => Loss 2.155, Train_accy 99.280, Test_accy 49.380
2022-05-25 11:31:24,987 [bic.py] => training => Task 5, Epoch 91/170 => Loss 2.155, Train_accy 99.260, Test_accy 49.450
2022-05-25 11:31:29,570 [bic.py] => training => Task 5, Epoch 92/170 => Loss 2.156, Train_accy 99.220, Test_accy 49.450
2022-05-25 11:31:34,092 [bic.py] => training => Task 5, Epoch 93/170 => Loss 2.150, Train_accy 99.380, Test_accy 49.620
2022-05-25 11:31:38,675 [bic.py] => training => Task 5, Epoch 94/170 => Loss 2.153, Train_accy 99.290, Test_accy 49.720
2022-05-25 11:31:43,122 [bic.py] => training => Task 5, Epoch 95/170 => Loss 2.154, Train_accy 99.230, Test_accy 50.030
2022-05-25 11:31:47,699 [bic.py] => training => Task 5, Epoch 96/170 => Loss 2.156, Train_accy 99.290, Test_accy 49.670
2022-05-25 11:31:52,174 [bic.py] => training => Task 5, Epoch 97/170 => Loss 2.157, Train_accy 99.300, Test_accy 49.700
2022-05-25 11:31:56,705 [bic.py] => training => Task 5, Epoch 98/170 => Loss 2.155, Train_accy 99.320, Test_accy 49.720
2022-05-25 11:32:01,143 [bic.py] => training => Task 5, Epoch 99/170 => Loss 2.153, Train_accy 99.470, Test_accy 49.430
2022-05-25 11:32:05,582 [bic.py] => training => Task 5, Epoch 100/170 => Loss 2.156, Train_accy 99.450, Test_accy 49.800
2022-05-25 11:32:10,122 [bic.py] => training => Task 5, Epoch 101/170 => Loss 2.153, Train_accy 99.440, Test_accy 49.620
2022-05-25 11:32:14,727 [bic.py] => training => Task 5, Epoch 102/170 => Loss 2.151, Train_accy 99.500, Test_accy 49.700
2022-05-25 11:32:19,120 [bic.py] => training => Task 5, Epoch 103/170 => Loss 2.149, Train_accy 99.500, Test_accy 49.880
2022-05-25 11:32:23,738 [bic.py] => training => Task 5, Epoch 104/170 => Loss 2.158, Train_accy 99.410, Test_accy 50.100
2022-05-25 11:32:28,295 [bic.py] => training => Task 5, Epoch 105/170 => Loss 2.152, Train_accy 99.560, Test_accy 49.580
2022-05-25 11:32:32,887 [bic.py] => training => Task 5, Epoch 106/170 => Loss 2.154, Train_accy 99.440, Test_accy 49.830
2022-05-25 11:32:37,378 [bic.py] => training => Task 5, Epoch 107/170 => Loss 2.150, Train_accy 99.570, Test_accy 49.620
2022-05-25 11:32:41,849 [bic.py] => training => Task 5, Epoch 108/170 => Loss 2.151, Train_accy 99.450, Test_accy 49.800
2022-05-25 11:32:46,362 [bic.py] => training => Task 5, Epoch 109/170 => Loss 2.149, Train_accy 99.590, Test_accy 49.700
2022-05-25 11:32:51,017 [bic.py] => training => Task 5, Epoch 110/170 => Loss 2.148, Train_accy 99.530, Test_accy 49.520
2022-05-25 11:32:55,555 [bic.py] => training => Task 5, Epoch 111/170 => Loss 2.150, Train_accy 99.480, Test_accy 49.500
2022-05-25 11:33:00,002 [bic.py] => training => Task 5, Epoch 112/170 => Loss 2.149, Train_accy 99.450, Test_accy 49.580
2022-05-25 11:33:04,465 [bic.py] => training => Task 5, Epoch 113/170 => Loss 2.147, Train_accy 99.530, Test_accy 49.730
2022-05-25 11:33:09,005 [bic.py] => training => Task 5, Epoch 114/170 => Loss 2.149, Train_accy 99.510, Test_accy 49.720
2022-05-25 11:33:13,504 [bic.py] => training => Task 5, Epoch 115/170 => Loss 2.152, Train_accy 99.530, Test_accy 49.980
2022-05-25 11:33:18,058 [bic.py] => training => Task 5, Epoch 116/170 => Loss 2.152, Train_accy 99.510, Test_accy 49.780
2022-05-25 11:33:22,573 [bic.py] => training => Task 5, Epoch 117/170 => Loss 2.155, Train_accy 99.360, Test_accy 49.870
2022-05-25 11:33:27,114 [bic.py] => training => Task 5, Epoch 118/170 => Loss 2.148, Train_accy 99.380, Test_accy 49.650
2022-05-25 11:33:31,750 [bic.py] => training => Task 5, Epoch 119/170 => Loss 2.155, Train_accy 99.470, Test_accy 49.700
2022-05-25 11:33:36,454 [bic.py] => training => Task 5, Epoch 120/170 => Loss 2.149, Train_accy 99.600, Test_accy 49.780
2022-05-25 11:33:40,945 [bic.py] => training => Task 5, Epoch 121/170 => Loss 2.152, Train_accy 99.560, Test_accy 49.870
2022-05-25 11:33:45,377 [bic.py] => training => Task 5, Epoch 122/170 => Loss 2.147, Train_accy 99.380, Test_accy 49.570
2022-05-25 11:33:49,882 [bic.py] => training => Task 5, Epoch 123/170 => Loss 2.156, Train_accy 99.500, Test_accy 49.770
2022-05-25 11:33:54,490 [bic.py] => training => Task 5, Epoch 124/170 => Loss 2.147, Train_accy 99.470, Test_accy 49.920
2022-05-25 11:33:58,971 [bic.py] => training => Task 5, Epoch 125/170 => Loss 2.150, Train_accy 99.450, Test_accy 49.680
2022-05-25 11:34:03,510 [bic.py] => training => Task 5, Epoch 126/170 => Loss 2.149, Train_accy 99.500, Test_accy 49.780
2022-05-25 11:34:07,996 [bic.py] => training => Task 5, Epoch 127/170 => Loss 2.148, Train_accy 99.330, Test_accy 49.420
2022-05-25 11:34:12,513 [bic.py] => training => Task 5, Epoch 128/170 => Loss 2.153, Train_accy 99.440, Test_accy 49.550
2022-05-25 11:34:17,155 [bic.py] => training => Task 5, Epoch 129/170 => Loss 2.153, Train_accy 99.410, Test_accy 49.580
2022-05-25 11:34:21,683 [bic.py] => training => Task 5, Epoch 130/170 => Loss 2.154, Train_accy 99.470, Test_accy 49.670
2022-05-25 11:34:26,404 [bic.py] => training => Task 5, Epoch 131/170 => Loss 2.152, Train_accy 99.350, Test_accy 49.820
2022-05-25 11:34:31,072 [bic.py] => training => Task 5, Epoch 132/170 => Loss 2.151, Train_accy 99.540, Test_accy 49.870
2022-05-25 11:34:35,767 [bic.py] => training => Task 5, Epoch 133/170 => Loss 2.153, Train_accy 99.480, Test_accy 49.670
2022-05-25 11:34:40,394 [bic.py] => training => Task 5, Epoch 134/170 => Loss 2.149, Train_accy 99.470, Test_accy 49.120
2022-05-25 11:34:44,787 [bic.py] => training => Task 5, Epoch 135/170 => Loss 2.151, Train_accy 99.300, Test_accy 49.570
2022-05-25 11:34:49,220 [bic.py] => training => Task 5, Epoch 136/170 => Loss 2.151, Train_accy 99.510, Test_accy 49.730
2022-05-25 11:34:53,656 [bic.py] => training => Task 5, Epoch 137/170 => Loss 2.152, Train_accy 99.470, Test_accy 49.570
2022-05-25 11:34:58,173 [bic.py] => training => Task 5, Epoch 138/170 => Loss 2.152, Train_accy 99.570, Test_accy 49.630
2022-05-25 11:35:02,723 [bic.py] => training => Task 5, Epoch 139/170 => Loss 2.147, Train_accy 99.590, Test_accy 49.730
2022-05-25 11:35:07,114 [bic.py] => training => Task 5, Epoch 140/170 => Loss 2.150, Train_accy 99.420, Test_accy 49.970
2022-05-25 11:35:11,545 [bic.py] => training => Task 5, Epoch 141/170 => Loss 2.150, Train_accy 99.450, Test_accy 49.380
2022-05-25 11:35:15,989 [bic.py] => training => Task 5, Epoch 142/170 => Loss 2.149, Train_accy 99.480, Test_accy 49.420
2022-05-25 11:35:20,457 [bic.py] => training => Task 5, Epoch 143/170 => Loss 2.151, Train_accy 99.480, Test_accy 49.650
2022-05-25 11:35:24,960 [bic.py] => training => Task 5, Epoch 144/170 => Loss 2.151, Train_accy 99.500, Test_accy 49.850
2022-05-25 11:35:29,571 [bic.py] => training => Task 5, Epoch 145/170 => Loss 2.147, Train_accy 99.510, Test_accy 49.650
2022-05-25 11:35:34,061 [bic.py] => training => Task 5, Epoch 146/170 => Loss 2.151, Train_accy 99.640, Test_accy 49.650
2022-05-25 11:35:38,400 [bic.py] => training => Task 5, Epoch 147/170 => Loss 2.150, Train_accy 99.630, Test_accy 49.580
2022-05-25 11:35:42,878 [bic.py] => training => Task 5, Epoch 148/170 => Loss 2.144, Train_accy 99.540, Test_accy 49.380
2022-05-25 11:35:47,342 [bic.py] => training => Task 5, Epoch 149/170 => Loss 2.154, Train_accy 99.350, Test_accy 49.630
2022-05-25 11:35:51,719 [bic.py] => training => Task 5, Epoch 150/170 => Loss 2.147, Train_accy 99.360, Test_accy 49.730
2022-05-25 11:35:56,042 [bic.py] => training => Task 5, Epoch 151/170 => Loss 2.151, Train_accy 99.470, Test_accy 49.720
2022-05-25 11:36:00,411 [bic.py] => training => Task 5, Epoch 152/170 => Loss 2.148, Train_accy 99.510, Test_accy 49.520
2022-05-25 11:36:04,809 [bic.py] => training => Task 5, Epoch 153/170 => Loss 2.148, Train_accy 99.440, Test_accy 49.500
2022-05-25 11:36:09,209 [bic.py] => training => Task 5, Epoch 154/170 => Loss 2.145, Train_accy 99.480, Test_accy 49.670
2022-05-25 11:36:13,702 [bic.py] => training => Task 5, Epoch 155/170 => Loss 2.153, Train_accy 99.530, Test_accy 49.550
2022-05-25 11:36:18,165 [bic.py] => training => Task 5, Epoch 156/170 => Loss 2.151, Train_accy 99.230, Test_accy 49.580
2022-05-25 11:36:22,505 [bic.py] => training => Task 5, Epoch 157/170 => Loss 2.149, Train_accy 99.390, Test_accy 49.830
2022-05-25 11:36:26,963 [bic.py] => training => Task 5, Epoch 158/170 => Loss 2.154, Train_accy 99.320, Test_accy 49.670
2022-05-25 11:36:31,296 [bic.py] => training => Task 5, Epoch 159/170 => Loss 2.150, Train_accy 99.500, Test_accy 49.530
2022-05-25 11:36:35,689 [bic.py] => training => Task 5, Epoch 160/170 => Loss 2.150, Train_accy 99.480, Test_accy 49.630
2022-05-25 11:36:40,241 [bic.py] => training => Task 5, Epoch 161/170 => Loss 2.146, Train_accy 99.470, Test_accy 49.420
2022-05-25 11:36:44,573 [bic.py] => training => Task 5, Epoch 162/170 => Loss 2.151, Train_accy 99.620, Test_accy 49.680
2022-05-25 11:36:48,973 [bic.py] => training => Task 5, Epoch 163/170 => Loss 2.151, Train_accy 99.500, Test_accy 49.370
2022-05-25 11:36:53,543 [bic.py] => training => Task 5, Epoch 164/170 => Loss 2.152, Train_accy 99.480, Test_accy 49.670
2022-05-25 11:36:57,972 [bic.py] => training => Task 5, Epoch 165/170 => Loss 2.155, Train_accy 99.510, Test_accy 49.800
2022-05-25 11:37:02,318 [bic.py] => training => Task 5, Epoch 166/170 => Loss 2.146, Train_accy 99.290, Test_accy 49.470
2022-05-25 11:37:06,717 [bic.py] => training => Task 5, Epoch 167/170 => Loss 2.146, Train_accy 99.410, Test_accy 49.700
2022-05-25 11:37:11,065 [bic.py] => training => Task 5, Epoch 168/170 => Loss 2.149, Train_accy 99.350, Test_accy 49.430
2022-05-25 11:37:15,389 [bic.py] => training => Task 5, Epoch 169/170 => Loss 2.153, Train_accy 99.360, Test_accy 49.580
2022-05-25 11:37:19,885 [bic.py] => training => Task 5, Epoch 170/170 => Loss 2.149, Train_accy 99.500, Test_accy 49.600
2022-05-25 11:37:21,592 [bic.py] => bias_correction => Task 5, Epoch 1/170 => Loss 3.620, Train_accy 65.000, Test_accy 52.500
2022-05-25 11:37:23,362 [bic.py] => bias_correction => Task 5, Epoch 2/170 => Loss 3.578, Train_accy 72.080, Test_accy 56.280
2022-05-25 11:37:25,089 [bic.py] => bias_correction => Task 5, Epoch 3/170 => Loss 3.530, Train_accy 68.330, Test_accy 54.350
2022-05-25 11:37:26,889 [bic.py] => bias_correction => Task 5, Epoch 4/170 => Loss 3.565, Train_accy 67.500, Test_accy 51.300
2022-05-25 11:37:28,558 [bic.py] => bias_correction => Task 5, Epoch 5/170 => Loss 3.573, Train_accy 67.500, Test_accy 49.680
2022-05-25 11:37:30,284 [bic.py] => bias_correction => Task 5, Epoch 6/170 => Loss 3.575, Train_accy 69.580, Test_accy 49.080
2022-05-25 11:37:32,088 [bic.py] => bias_correction => Task 5, Epoch 7/170 => Loss 3.563, Train_accy 68.330, Test_accy 48.650
2022-05-25 11:37:33,780 [bic.py] => bias_correction => Task 5, Epoch 8/170 => Loss 3.563, Train_accy 67.920, Test_accy 48.500
2022-05-25 11:37:35,513 [bic.py] => bias_correction => Task 5, Epoch 9/170 => Loss 3.555, Train_accy 66.250, Test_accy 48.330
2022-05-25 11:37:37,313 [bic.py] => bias_correction => Task 5, Epoch 10/170 => Loss 3.568, Train_accy 65.830, Test_accy 48.320
2022-05-25 11:37:39,034 [bic.py] => bias_correction => Task 5, Epoch 11/170 => Loss 3.570, Train_accy 66.670, Test_accy 48.230
2022-05-25 11:37:40,787 [bic.py] => bias_correction => Task 5, Epoch 12/170 => Loss 3.581, Train_accy 66.670, Test_accy 48.180
2022-05-25 11:37:42,606 [bic.py] => bias_correction => Task 5, Epoch 13/170 => Loss 3.565, Train_accy 65.830, Test_accy 48.130
2022-05-25 11:37:44,330 [bic.py] => bias_correction => Task 5, Epoch 14/170 => Loss 3.582, Train_accy 67.500, Test_accy 48.080
2022-05-25 11:37:46,070 [bic.py] => bias_correction => Task 5, Epoch 15/170 => Loss 3.582, Train_accy 65.830, Test_accy 48.080
2022-05-25 11:37:47,912 [bic.py] => bias_correction => Task 5, Epoch 16/170 => Loss 3.564, Train_accy 67.920, Test_accy 48.130
2022-05-25 11:37:49,643 [bic.py] => bias_correction => Task 5, Epoch 17/170 => Loss 3.562, Train_accy 65.830, Test_accy 48.220
2022-05-25 11:37:51,341 [bic.py] => bias_correction => Task 5, Epoch 18/170 => Loss 3.573, Train_accy 69.580, Test_accy 48.220
2022-05-25 11:37:53,091 [bic.py] => bias_correction => Task 5, Epoch 19/170 => Loss 3.566, Train_accy 66.670, Test_accy 48.370
2022-05-25 11:37:54,760 [bic.py] => bias_correction => Task 5, Epoch 20/170 => Loss 3.573, Train_accy 66.670, Test_accy 48.700
2022-05-25 11:37:56,494 [bic.py] => bias_correction => Task 5, Epoch 21/170 => Loss 3.553, Train_accy 65.000, Test_accy 48.680
2022-05-25 11:37:58,202 [bic.py] => bias_correction => Task 5, Epoch 22/170 => Loss 3.573, Train_accy 65.830, Test_accy 49.070
2022-05-25 11:37:59,972 [bic.py] => bias_correction => Task 5, Epoch 23/170 => Loss 3.571, Train_accy 68.750, Test_accy 49.830
2022-05-25 11:38:01,666 [bic.py] => bias_correction => Task 5, Epoch 24/170 => Loss 3.553, Train_accy 64.580, Test_accy 50.780
2022-05-25 11:38:03,465 [bic.py] => bias_correction => Task 5, Epoch 25/170 => Loss 3.560, Train_accy 66.670, Test_accy 52.320
2022-05-25 11:38:05,154 [bic.py] => bias_correction => Task 5, Epoch 26/170 => Loss 3.546, Train_accy 70.830, Test_accy 53.870
2022-05-25 11:38:06,929 [bic.py] => bias_correction => Task 5, Epoch 27/170 => Loss 3.554, Train_accy 70.420, Test_accy 55.280
2022-05-25 11:38:08,694 [bic.py] => bias_correction => Task 5, Epoch 28/170 => Loss 3.535, Train_accy 70.000, Test_accy 54.280
2022-05-25 11:38:10,354 [bic.py] => bias_correction => Task 5, Epoch 29/170 => Loss 3.546, Train_accy 71.250, Test_accy 54.070
2022-05-25 11:38:12,089 [bic.py] => bias_correction => Task 5, Epoch 30/170 => Loss 3.564, Train_accy 70.830, Test_accy 54.550
2022-05-25 11:38:13,841 [bic.py] => bias_correction => Task 5, Epoch 31/170 => Loss 3.546, Train_accy 71.250, Test_accy 55.280
2022-05-25 11:38:15,480 [bic.py] => bias_correction => Task 5, Epoch 32/170 => Loss 3.528, Train_accy 73.330, Test_accy 54.580
2022-05-25 11:38:17,159 [bic.py] => bias_correction => Task 5, Epoch 33/170 => Loss 3.535, Train_accy 68.750, Test_accy 53.900
2022-05-25 11:38:18,844 [bic.py] => bias_correction => Task 5, Epoch 34/170 => Loss 3.540, Train_accy 71.250, Test_accy 53.980
2022-05-25 11:38:20,575 [bic.py] => bias_correction => Task 5, Epoch 35/170 => Loss 3.539, Train_accy 70.000, Test_accy 54.900
2022-05-25 11:38:22,279 [bic.py] => bias_correction => Task 5, Epoch 36/170 => Loss 3.536, Train_accy 72.500, Test_accy 55.250
2022-05-25 11:38:24,008 [bic.py] => bias_correction => Task 5, Epoch 37/170 => Loss 3.541, Train_accy 70.830, Test_accy 54.780
2022-05-25 11:38:25,725 [bic.py] => bias_correction => Task 5, Epoch 38/170 => Loss 3.533, Train_accy 71.250, Test_accy 54.680
2022-05-25 11:38:27,441 [bic.py] => bias_correction => Task 5, Epoch 39/170 => Loss 3.544, Train_accy 73.330, Test_accy 54.780
2022-05-25 11:38:29,210 [bic.py] => bias_correction => Task 5, Epoch 40/170 => Loss 3.530, Train_accy 73.750, Test_accy 55.280
2022-05-25 11:38:30,882 [bic.py] => bias_correction => Task 5, Epoch 41/170 => Loss 3.522, Train_accy 68.330, Test_accy 54.970
2022-05-25 11:38:32,635 [bic.py] => bias_correction => Task 5, Epoch 42/170 => Loss 3.539, Train_accy 67.920, Test_accy 54.850
2022-05-25 11:38:34,273 [bic.py] => bias_correction => Task 5, Epoch 43/170 => Loss 3.532, Train_accy 72.920, Test_accy 54.930
2022-05-25 11:38:36,021 [bic.py] => bias_correction => Task 5, Epoch 44/170 => Loss 3.530, Train_accy 74.170, Test_accy 55.230
2022-05-25 11:38:37,823 [bic.py] => bias_correction => Task 5, Epoch 45/170 => Loss 3.539, Train_accy 69.580, Test_accy 55.370
2022-05-25 11:38:39,614 [bic.py] => bias_correction => Task 5, Epoch 46/170 => Loss 3.525, Train_accy 72.080, Test_accy 55.230
2022-05-25 11:38:41,350 [bic.py] => bias_correction => Task 5, Epoch 47/170 => Loss 3.534, Train_accy 70.000, Test_accy 55.030
2022-05-25 11:38:43,016 [bic.py] => bias_correction => Task 5, Epoch 48/170 => Loss 3.523, Train_accy 74.170, Test_accy 54.880
2022-05-25 11:38:44,743 [bic.py] => bias_correction => Task 5, Epoch 49/170 => Loss 3.538, Train_accy 70.830, Test_accy 55.200
2022-05-25 11:38:46,414 [bic.py] => bias_correction => Task 5, Epoch 50/170 => Loss 3.541, Train_accy 73.330, Test_accy 55.350
2022-05-25 11:38:48,161 [bic.py] => bias_correction => Task 5, Epoch 51/170 => Loss 3.540, Train_accy 74.170, Test_accy 55.420
2022-05-25 11:38:49,921 [bic.py] => bias_correction => Task 5, Epoch 52/170 => Loss 3.534, Train_accy 72.080, Test_accy 55.380
2022-05-25 11:38:51,651 [bic.py] => bias_correction => Task 5, Epoch 53/170 => Loss 3.533, Train_accy 68.750, Test_accy 55.470
2022-05-25 11:38:53,442 [bic.py] => bias_correction => Task 5, Epoch 54/170 => Loss 3.535, Train_accy 70.830, Test_accy 55.400
2022-05-25 11:38:55,205 [bic.py] => bias_correction => Task 5, Epoch 55/170 => Loss 3.528, Train_accy 70.420, Test_accy 55.530
2022-05-25 11:38:56,912 [bic.py] => bias_correction => Task 5, Epoch 56/170 => Loss 3.519, Train_accy 71.250, Test_accy 55.500
2022-05-25 11:38:58,644 [bic.py] => bias_correction => Task 5, Epoch 57/170 => Loss 3.525, Train_accy 74.170, Test_accy 55.480
2022-05-25 11:39:00,392 [bic.py] => bias_correction => Task 5, Epoch 58/170 => Loss 3.534, Train_accy 72.500, Test_accy 55.500
2022-05-25 11:39:02,034 [bic.py] => bias_correction => Task 5, Epoch 59/170 => Loss 3.522, Train_accy 67.920, Test_accy 55.480
2022-05-25 11:39:03,752 [bic.py] => bias_correction => Task 5, Epoch 60/170 => Loss 3.537, Train_accy 70.000, Test_accy 55.420
2022-05-25 11:39:05,496 [bic.py] => bias_correction => Task 5, Epoch 61/170 => Loss 3.533, Train_accy 70.830, Test_accy 55.370
2022-05-25 11:39:07,271 [bic.py] => bias_correction => Task 5, Epoch 62/170 => Loss 3.529, Train_accy 70.830, Test_accy 55.300
2022-05-25 11:39:08,995 [bic.py] => bias_correction => Task 5, Epoch 63/170 => Loss 3.539, Train_accy 71.670, Test_accy 55.330
2022-05-25 11:39:10,674 [bic.py] => bias_correction => Task 5, Epoch 64/170 => Loss 3.534, Train_accy 72.080, Test_accy 55.300
2022-05-25 11:39:12,323 [bic.py] => bias_correction => Task 5, Epoch 65/170 => Loss 3.543, Train_accy 68.750, Test_accy 55.380
2022-05-25 11:39:14,060 [bic.py] => bias_correction => Task 5, Epoch 66/170 => Loss 3.541, Train_accy 75.000, Test_accy 55.500
2022-05-25 11:39:15,737 [bic.py] => bias_correction => Task 5, Epoch 67/170 => Loss 3.541, Train_accy 70.830, Test_accy 55.520
2022-05-25 11:39:17,441 [bic.py] => bias_correction => Task 5, Epoch 68/170 => Loss 3.538, Train_accy 72.920, Test_accy 55.550
2022-05-25 11:39:19,190 [bic.py] => bias_correction => Task 5, Epoch 69/170 => Loss 3.535, Train_accy 70.420, Test_accy 55.580
2022-05-25 11:39:20,856 [bic.py] => bias_correction => Task 5, Epoch 70/170 => Loss 3.531, Train_accy 68.750, Test_accy 55.530
2022-05-25 11:39:22,602 [bic.py] => bias_correction => Task 5, Epoch 71/170 => Loss 3.523, Train_accy 71.670, Test_accy 55.530
2022-05-25 11:39:24,285 [bic.py] => bias_correction => Task 5, Epoch 72/170 => Loss 3.535, Train_accy 71.250, Test_accy 55.450
2022-05-25 11:39:26,080 [bic.py] => bias_correction => Task 5, Epoch 73/170 => Loss 3.547, Train_accy 72.920, Test_accy 55.380
2022-05-25 11:39:27,807 [bic.py] => bias_correction => Task 5, Epoch 74/170 => Loss 3.530, Train_accy 71.250, Test_accy 55.480
2022-05-25 11:39:29,534 [bic.py] => bias_correction => Task 5, Epoch 75/170 => Loss 3.542, Train_accy 72.920, Test_accy 55.480
2022-05-25 11:39:31,267 [bic.py] => bias_correction => Task 5, Epoch 76/170 => Loss 3.538, Train_accy 71.250, Test_accy 55.480
2022-05-25 11:39:33,073 [bic.py] => bias_correction => Task 5, Epoch 77/170 => Loss 3.534, Train_accy 74.170, Test_accy 55.300
2022-05-25 11:39:34,757 [bic.py] => bias_correction => Task 5, Epoch 78/170 => Loss 3.521, Train_accy 71.670, Test_accy 55.430
2022-05-25 11:39:36,449 [bic.py] => bias_correction => Task 5, Epoch 79/170 => Loss 3.525, Train_accy 68.750, Test_accy 55.500
2022-05-25 11:39:38,104 [bic.py] => bias_correction => Task 5, Epoch 80/170 => Loss 3.525, Train_accy 69.580, Test_accy 55.480
2022-05-25 11:39:39,892 [bic.py] => bias_correction => Task 5, Epoch 81/170 => Loss 3.539, Train_accy 71.250, Test_accy 55.500
2022-05-25 11:39:41,634 [bic.py] => bias_correction => Task 5, Epoch 82/170 => Loss 3.529, Train_accy 72.500, Test_accy 55.530
2022-05-25 11:39:43,295 [bic.py] => bias_correction => Task 5, Epoch 83/170 => Loss 3.530, Train_accy 70.000, Test_accy 55.420
2022-05-25 11:39:45,012 [bic.py] => bias_correction => Task 5, Epoch 84/170 => Loss 3.532, Train_accy 71.670, Test_accy 55.380
2022-05-25 11:39:46,686 [bic.py] => bias_correction => Task 5, Epoch 85/170 => Loss 3.538, Train_accy 72.500, Test_accy 55.450
2022-05-25 11:39:48,470 [bic.py] => bias_correction => Task 5, Epoch 86/170 => Loss 3.536, Train_accy 69.580, Test_accy 55.450
2022-05-25 11:39:50,189 [bic.py] => bias_correction => Task 5, Epoch 87/170 => Loss 3.523, Train_accy 72.080, Test_accy 55.450
2022-05-25 11:39:51,889 [bic.py] => bias_correction => Task 5, Epoch 88/170 => Loss 3.542, Train_accy 69.170, Test_accy 55.380
2022-05-25 11:39:53,677 [bic.py] => bias_correction => Task 5, Epoch 89/170 => Loss 3.522, Train_accy 71.250, Test_accy 55.400
2022-05-25 11:39:55,339 [bic.py] => bias_correction => Task 5, Epoch 90/170 => Loss 3.521, Train_accy 70.420, Test_accy 55.480
2022-05-25 11:39:57,002 [bic.py] => bias_correction => Task 5, Epoch 91/170 => Loss 3.533, Train_accy 72.500, Test_accy 55.450
2022-05-25 11:39:58,595 [bic.py] => bias_correction => Task 5, Epoch 92/170 => Loss 3.532, Train_accy 72.080, Test_accy 55.550
2022-05-25 11:40:00,292 [bic.py] => bias_correction => Task 5, Epoch 93/170 => Loss 3.531, Train_accy 70.830, Test_accy 55.520
2022-05-25 11:40:02,076 [bic.py] => bias_correction => Task 5, Epoch 94/170 => Loss 3.529, Train_accy 73.330, Test_accy 55.530
2022-05-25 11:40:03,837 [bic.py] => bias_correction => Task 5, Epoch 95/170 => Loss 3.547, Train_accy 72.500, Test_accy 55.450
2022-05-25 11:40:05,546 [bic.py] => bias_correction => Task 5, Epoch 96/170 => Loss 3.523, Train_accy 72.080, Test_accy 55.520
2022-05-25 11:40:07,182 [bic.py] => bias_correction => Task 5, Epoch 97/170 => Loss 3.527, Train_accy 72.500, Test_accy 55.550
2022-05-25 11:40:08,931 [bic.py] => bias_correction => Task 5, Epoch 98/170 => Loss 3.524, Train_accy 72.920, Test_accy 55.550
2022-05-25 11:40:10,668 [bic.py] => bias_correction => Task 5, Epoch 99/170 => Loss 3.526, Train_accy 71.670, Test_accy 55.530
2022-05-25 11:40:12,387 [bic.py] => bias_correction => Task 5, Epoch 100/170 => Loss 3.522, Train_accy 72.500, Test_accy 55.550
2022-05-25 11:40:14,140 [bic.py] => bias_correction => Task 5, Epoch 101/170 => Loss 3.525, Train_accy 72.080, Test_accy 55.500
2022-05-25 11:40:15,913 [bic.py] => bias_correction => Task 5, Epoch 102/170 => Loss 3.523, Train_accy 72.080, Test_accy 55.420
2022-05-25 11:40:17,673 [bic.py] => bias_correction => Task 5, Epoch 103/170 => Loss 3.542, Train_accy 71.250, Test_accy 55.420
2022-05-25 11:40:19,394 [bic.py] => bias_correction => Task 5, Epoch 104/170 => Loss 3.529, Train_accy 71.250, Test_accy 55.430
2022-05-25 11:40:21,239 [bic.py] => bias_correction => Task 5, Epoch 105/170 => Loss 3.535, Train_accy 72.920, Test_accy 55.450
2022-05-25 11:40:23,043 [bic.py] => bias_correction => Task 5, Epoch 106/170 => Loss 3.532, Train_accy 72.920, Test_accy 55.480
2022-05-25 11:40:24,818 [bic.py] => bias_correction => Task 5, Epoch 107/170 => Loss 3.528, Train_accy 74.170, Test_accy 55.420
2022-05-25 11:40:26,631 [bic.py] => bias_correction => Task 5, Epoch 108/170 => Loss 3.522, Train_accy 72.080, Test_accy 55.450
2022-05-25 11:40:28,367 [bic.py] => bias_correction => Task 5, Epoch 109/170 => Loss 3.539, Train_accy 72.080, Test_accy 55.380
2022-05-25 11:40:30,153 [bic.py] => bias_correction => Task 5, Epoch 110/170 => Loss 3.533, Train_accy 71.670, Test_accy 55.520
2022-05-25 11:40:31,910 [bic.py] => bias_correction => Task 5, Epoch 111/170 => Loss 3.526, Train_accy 71.670, Test_accy 55.500
2022-05-25 11:40:33,688 [bic.py] => bias_correction => Task 5, Epoch 112/170 => Loss 3.528, Train_accy 71.670, Test_accy 55.470
2022-05-25 11:40:35,479 [bic.py] => bias_correction => Task 5, Epoch 113/170 => Loss 3.542, Train_accy 73.330, Test_accy 55.500
2022-05-25 11:40:37,411 [bic.py] => bias_correction => Task 5, Epoch 114/170 => Loss 3.532, Train_accy 71.250, Test_accy 55.570
2022-05-25 11:40:39,196 [bic.py] => bias_correction => Task 5, Epoch 115/170 => Loss 3.531, Train_accy 72.080, Test_accy 55.520
2022-05-25 11:40:40,948 [bic.py] => bias_correction => Task 5, Epoch 116/170 => Loss 3.520, Train_accy 70.830, Test_accy 55.630
2022-05-25 11:40:42,830 [bic.py] => bias_correction => Task 5, Epoch 117/170 => Loss 3.533, Train_accy 72.500, Test_accy 55.600
2022-05-25 11:40:44,632 [bic.py] => bias_correction => Task 5, Epoch 118/170 => Loss 3.520, Train_accy 69.580, Test_accy 55.550
2022-05-25 11:40:46,419 [bic.py] => bias_correction => Task 5, Epoch 119/170 => Loss 3.532, Train_accy 68.750, Test_accy 55.630
2022-05-25 11:40:48,159 [bic.py] => bias_correction => Task 5, Epoch 120/170 => Loss 3.531, Train_accy 72.920, Test_accy 55.550
2022-05-25 11:40:49,822 [bic.py] => bias_correction => Task 5, Epoch 121/170 => Loss 3.526, Train_accy 70.420, Test_accy 55.550
2022-05-25 11:40:51,496 [bic.py] => bias_correction => Task 5, Epoch 122/170 => Loss 3.526, Train_accy 71.250, Test_accy 55.570
2022-05-25 11:40:53,167 [bic.py] => bias_correction => Task 5, Epoch 123/170 => Loss 3.522, Train_accy 71.250, Test_accy 55.500
2022-05-25 11:40:54,925 [bic.py] => bias_correction => Task 5, Epoch 124/170 => Loss 3.526, Train_accy 71.250, Test_accy 55.420
2022-05-25 11:40:56,675 [bic.py] => bias_correction => Task 5, Epoch 125/170 => Loss 3.533, Train_accy 70.420, Test_accy 55.500
2022-05-25 11:40:58,404 [bic.py] => bias_correction => Task 5, Epoch 126/170 => Loss 3.532, Train_accy 71.670, Test_accy 55.450
2022-05-25 11:41:00,153 [bic.py] => bias_correction => Task 5, Epoch 127/170 => Loss 3.531, Train_accy 70.830, Test_accy 55.480
2022-05-25 11:41:01,886 [bic.py] => bias_correction => Task 5, Epoch 128/170 => Loss 3.530, Train_accy 72.080, Test_accy 55.450
2022-05-25 11:41:03,602 [bic.py] => bias_correction => Task 5, Epoch 129/170 => Loss 3.517, Train_accy 71.250, Test_accy 55.430
2022-05-25 11:41:05,245 [bic.py] => bias_correction => Task 5, Epoch 130/170 => Loss 3.536, Train_accy 71.250, Test_accy 55.530
2022-05-25 11:41:06,918 [bic.py] => bias_correction => Task 5, Epoch 131/170 => Loss 3.529, Train_accy 72.500, Test_accy 55.550
2022-05-25 11:41:08,661 [bic.py] => bias_correction => Task 5, Epoch 132/170 => Loss 3.532, Train_accy 70.000, Test_accy 55.550
2022-05-25 11:41:10,450 [bic.py] => bias_correction => Task 5, Epoch 133/170 => Loss 3.533, Train_accy 74.170, Test_accy 55.580
2022-05-25 11:41:12,225 [bic.py] => bias_correction => Task 5, Epoch 134/170 => Loss 3.534, Train_accy 72.920, Test_accy 55.530
2022-05-25 11:41:14,008 [bic.py] => bias_correction => Task 5, Epoch 135/170 => Loss 3.528, Train_accy 72.920, Test_accy 55.500
2022-05-25 11:41:15,754 [bic.py] => bias_correction => Task 5, Epoch 136/170 => Loss 3.539, Train_accy 70.830, Test_accy 55.420
2022-05-25 11:41:17,456 [bic.py] => bias_correction => Task 5, Epoch 137/170 => Loss 3.532, Train_accy 72.080, Test_accy 55.480
2022-05-25 11:41:19,185 [bic.py] => bias_correction => Task 5, Epoch 138/170 => Loss 3.519, Train_accy 70.420, Test_accy 55.470
2022-05-25 11:41:20,813 [bic.py] => bias_correction => Task 5, Epoch 139/170 => Loss 3.521, Train_accy 70.830, Test_accy 55.350
2022-05-25 11:41:22,510 [bic.py] => bias_correction => Task 5, Epoch 140/170 => Loss 3.522, Train_accy 73.750, Test_accy 55.520
2022-05-25 11:41:24,177 [bic.py] => bias_correction => Task 5, Epoch 141/170 => Loss 3.534, Train_accy 71.670, Test_accy 55.450
2022-05-25 11:41:25,860 [bic.py] => bias_correction => Task 5, Epoch 142/170 => Loss 3.538, Train_accy 70.420, Test_accy 55.530
2022-05-25 11:41:27,561 [bic.py] => bias_correction => Task 5, Epoch 143/170 => Loss 3.529, Train_accy 71.250, Test_accy 55.430
2022-05-25 11:41:29,324 [bic.py] => bias_correction => Task 5, Epoch 144/170 => Loss 3.529, Train_accy 74.170, Test_accy 55.430
2022-05-25 11:41:31,041 [bic.py] => bias_correction => Task 5, Epoch 145/170 => Loss 3.534, Train_accy 71.250, Test_accy 55.500
2022-05-25 11:41:32,798 [bic.py] => bias_correction => Task 5, Epoch 146/170 => Loss 3.528, Train_accy 69.170, Test_accy 55.400
2022-05-25 11:41:34,434 [bic.py] => bias_correction => Task 5, Epoch 147/170 => Loss 3.524, Train_accy 72.920, Test_accy 55.450
2022-05-25 11:41:36,140 [bic.py] => bias_correction => Task 5, Epoch 148/170 => Loss 3.524, Train_accy 74.170, Test_accy 55.450
2022-05-25 11:41:37,862 [bic.py] => bias_correction => Task 5, Epoch 149/170 => Loss 3.520, Train_accy 72.500, Test_accy 55.430
2022-05-25 11:41:39,601 [bic.py] => bias_correction => Task 5, Epoch 150/170 => Loss 3.535, Train_accy 70.000, Test_accy 55.470
2022-05-25 11:41:41,393 [bic.py] => bias_correction => Task 5, Epoch 151/170 => Loss 3.528, Train_accy 72.080, Test_accy 55.520
2022-05-25 11:41:43,087 [bic.py] => bias_correction => Task 5, Epoch 152/170 => Loss 3.533, Train_accy 72.920, Test_accy 55.450
2022-05-25 11:41:44,768 [bic.py] => bias_correction => Task 5, Epoch 153/170 => Loss 3.531, Train_accy 71.250, Test_accy 55.470
2022-05-25 11:41:46,553 [bic.py] => bias_correction => Task 5, Epoch 154/170 => Loss 3.535, Train_accy 71.670, Test_accy 55.530
2022-05-25 11:41:48,291 [bic.py] => bias_correction => Task 5, Epoch 155/170 => Loss 3.521, Train_accy 69.170, Test_accy 55.470
2022-05-25 11:41:49,984 [bic.py] => bias_correction => Task 5, Epoch 156/170 => Loss 3.527, Train_accy 72.920, Test_accy 55.520
2022-05-25 11:41:51,695 [bic.py] => bias_correction => Task 5, Epoch 157/170 => Loss 3.533, Train_accy 68.330, Test_accy 55.480
2022-05-25 11:41:53,471 [bic.py] => bias_correction => Task 5, Epoch 158/170 => Loss 3.537, Train_accy 70.000, Test_accy 55.580
2022-05-25 11:41:55,279 [bic.py] => bias_correction => Task 5, Epoch 159/170 => Loss 3.519, Train_accy 71.670, Test_accy 55.480
2022-05-25 11:41:56,920 [bic.py] => bias_correction => Task 5, Epoch 160/170 => Loss 3.535, Train_accy 71.670, Test_accy 55.500
2022-05-25 11:41:58,546 [bic.py] => bias_correction => Task 5, Epoch 161/170 => Loss 3.523, Train_accy 67.500, Test_accy 55.550
2022-05-25 11:42:00,334 [bic.py] => bias_correction => Task 5, Epoch 162/170 => Loss 3.543, Train_accy 71.250, Test_accy 55.570
2022-05-25 11:42:02,114 [bic.py] => bias_correction => Task 5, Epoch 163/170 => Loss 3.519, Train_accy 71.670, Test_accy 55.570
2022-05-25 11:42:03,852 [bic.py] => bias_correction => Task 5, Epoch 164/170 => Loss 3.540, Train_accy 74.580, Test_accy 55.530
2022-05-25 11:42:05,612 [bic.py] => bias_correction => Task 5, Epoch 165/170 => Loss 3.523, Train_accy 69.170, Test_accy 55.630
2022-05-25 11:42:07,347 [bic.py] => bias_correction => Task 5, Epoch 166/170 => Loss 3.533, Train_accy 70.830, Test_accy 55.580
2022-05-25 11:42:09,098 [bic.py] => bias_correction => Task 5, Epoch 167/170 => Loss 3.517, Train_accy 72.920, Test_accy 55.580
2022-05-25 11:42:10,818 [bic.py] => bias_correction => Task 5, Epoch 168/170 => Loss 3.531, Train_accy 69.580, Test_accy 55.480
2022-05-25 11:42:12,478 [bic.py] => bias_correction => Task 5, Epoch 169/170 => Loss 3.535, Train_accy 71.670, Test_accy 55.520
2022-05-25 11:42:14,170 [bic.py] => bias_correction => Task 5, Epoch 170/170 => Loss 3.534, Train_accy 72.080, Test_accy 55.520
2022-05-25 11:42:14,171 [base.py] => Reducing exemplars...(33 per classes)
2022-05-25 11:42:24,638 [base.py] => Constructing exemplars...(33 per classes)
2022-05-25 11:42:29,770 [bic.py] => Parameters of bias layer:
2022-05-25 11:42:29,771 [bic.py] => 0 => 1.000, 0.000
2022-05-25 11:42:29,771 [bic.py] => 1 => 0.904, -1.125
2022-05-25 11:42:29,771 [bic.py] => 2 => 0.889, -1.948
2022-05-25 11:42:29,771 [bic.py] => 3 => 0.729, -1.345
2022-05-25 11:42:29,771 [bic.py] => 4 => 0.731, -1.321
2022-05-25 11:42:29,772 [bic.py] => 5 => 0.734, -1.140
2022-05-25 11:42:31,561 [bic.py] => Exemplar size: 1980
2022-05-25 11:42:31,562 [trainer.py] => CNN: {'total': 55.52, '00-09': 58.5, '10-19': 52.8, '20-29': 59.7, '30-39': 48.9, '40-49': 53.0, '50-59': 60.2, 'old': 54.58, 'new': 60.2}
2022-05-25 11:42:31,562 [trainer.py] => NME: {'total': 56.52, '00-09': 52.7, '10-19': 49.0, '20-29': 61.1, '30-39': 54.3, '40-49': 57.8, '50-59': 64.2, 'old': 54.98, 'new': 64.2}
2022-05-25 11:42:31,562 [trainer.py] => CNN top1 curve: [83.0, 73.7, 68.1, 62.2, 58.38, 55.52]
2022-05-25 11:42:31,562 [trainer.py] => CNN top5 curve: [99.1, 95.65, 92.07, 89.1, 86.2, 84.27]
2022-05-25 11:42:31,562 [trainer.py] => NME top1 curve: [82.8, 74.15, 67.37, 61.9, 58.1, 56.52]
2022-05-25 11:42:31,562 [trainer.py] => NME top5 curve: [99.0, 95.75, 92.47, 89.32, 86.1, 84.15]

2022-05-25 11:42:31,562 [trainer.py] => All params: 468066
2022-05-25 11:42:31,563 [trainer.py] => Trainable params: 468066
2022-05-25 11:42:31,564 [bic.py] => Learning on 60-70
2022-05-25 11:42:31,611 [bic.py] => Stage1 dset: 6770, Stage2 dset: 210
2022-05-25 11:42:31,611 [bic.py] => Lambda: 0.857
2022-05-25 11:42:31,627 [bic.py] => Parameters of bias layer:
2022-05-25 11:42:31,628 [bic.py] => 0 => 1.000, 0.000
2022-05-25 11:42:31,628 [bic.py] => 1 => 0.904, -1.125
2022-05-25 11:42:31,628 [bic.py] => 2 => 0.889, -1.948
2022-05-25 11:42:31,628 [bic.py] => 3 => 0.729, -1.345
2022-05-25 11:42:31,628 [bic.py] => 4 => 0.731, -1.321
2022-05-25 11:42:31,628 [bic.py] => 5 => 0.734, -1.140
2022-05-25 11:42:31,628 [bic.py] => 6 => 1.000, 0.000
2022-05-25 11:42:36,135 [bic.py] => training => Task 6, Epoch 1/170 => Loss 2.775, Train_accy 67.960, Test_accy 37.130
2022-05-25 11:42:40,761 [bic.py] => training => Task 6, Epoch 2/170 => Loss 2.655, Train_accy 73.690, Test_accy 38.670
2022-05-25 11:42:45,167 [bic.py] => training => Task 6, Epoch 3/170 => Loss 2.633, Train_accy 73.750, Test_accy 36.660
2022-05-25 11:42:49,641 [bic.py] => training => Task 6, Epoch 4/170 => Loss 2.613, Train_accy 75.270, Test_accy 38.240
2022-05-25 11:42:54,195 [bic.py] => training => Task 6, Epoch 5/170 => Loss 2.615, Train_accy 78.890, Test_accy 39.140
2022-05-25 11:42:58,693 [bic.py] => training => Task 6, Epoch 6/170 => Loss 2.605, Train_accy 81.830, Test_accy 40.070
2022-05-25 11:43:03,352 [bic.py] => training => Task 6, Epoch 7/170 => Loss 2.611, Train_accy 78.760, Test_accy 38.530
2022-05-25 11:43:07,886 [bic.py] => training => Task 6, Epoch 8/170 => Loss 2.602, Train_accy 82.410, Test_accy 41.740
2022-05-25 11:43:12,352 [bic.py] => training => Task 6, Epoch 9/170 => Loss 2.596, Train_accy 85.070, Test_accy 41.730
2022-05-25 11:43:16,785 [bic.py] => training => Task 6, Epoch 10/170 => Loss 2.601, Train_accy 81.670, Test_accy 39.570
2022-05-25 11:43:21,322 [bic.py] => training => Task 6, Epoch 11/170 => Loss 2.595, Train_accy 83.810, Test_accy 39.340
2022-05-25 11:43:25,770 [bic.py] => training => Task 6, Epoch 12/170 => Loss 2.587, Train_accy 85.830, Test_accy 41.400
2022-05-25 11:43:30,280 [bic.py] => training => Task 6, Epoch 13/170 => Loss 2.580, Train_accy 84.580, Test_accy 38.800
2022-05-25 11:43:34,742 [bic.py] => training => Task 6, Epoch 14/170 => Loss 2.588, Train_accy 82.070, Test_accy 37.700
2022-05-25 11:43:39,239 [bic.py] => training => Task 6, Epoch 15/170 => Loss 2.590, Train_accy 85.630, Test_accy 42.000
2022-05-25 11:43:43,805 [bic.py] => training => Task 6, Epoch 16/170 => Loss 2.587, Train_accy 86.630, Test_accy 40.390
2022-05-25 11:43:48,113 [bic.py] => training => Task 6, Epoch 17/170 => Loss 2.579, Train_accy 87.680, Test_accy 40.930
2022-05-25 11:43:52,590 [bic.py] => training => Task 6, Epoch 18/170 => Loss 2.590, Train_accy 86.350, Test_accy 39.370
2022-05-25 11:43:57,202 [bic.py] => training => Task 6, Epoch 19/170 => Loss 2.579, Train_accy 84.740, Test_accy 37.270
2022-05-25 11:44:01,671 [bic.py] => training => Task 6, Epoch 20/170 => Loss 2.578, Train_accy 88.180, Test_accy 43.910
2022-05-25 11:44:05,964 [bic.py] => training => Task 6, Epoch 21/170 => Loss 2.582, Train_accy 89.130, Test_accy 42.470
2022-05-25 11:44:10,722 [bic.py] => training => Task 6, Epoch 22/170 => Loss 2.577, Train_accy 84.870, Test_accy 41.840
2022-05-25 11:44:15,273 [bic.py] => training => Task 6, Epoch 23/170 => Loss 2.575, Train_accy 88.330, Test_accy 42.270
2022-05-25 11:44:19,761 [bic.py] => training => Task 6, Epoch 24/170 => Loss 2.580, Train_accy 89.600, Test_accy 42.030
2022-05-25 11:44:24,142 [bic.py] => training => Task 6, Epoch 25/170 => Loss 2.574, Train_accy 86.770, Test_accy 40.570
2022-05-25 11:44:28,610 [bic.py] => training => Task 6, Epoch 26/170 => Loss 2.569, Train_accy 90.580, Test_accy 42.400
2022-05-25 11:44:33,070 [bic.py] => training => Task 6, Epoch 27/170 => Loss 2.571, Train_accy 90.100, Test_accy 42.440
2022-05-25 11:44:37,657 [bic.py] => training => Task 6, Epoch 28/170 => Loss 2.567, Train_accy 88.510, Test_accy 41.290
2022-05-25 11:44:42,162 [bic.py] => training => Task 6, Epoch 29/170 => Loss 2.570, Train_accy 90.060, Test_accy 41.470
2022-05-25 11:44:46,585 [bic.py] => training => Task 6, Epoch 30/170 => Loss 2.571, Train_accy 91.210, Test_accy 44.040
2022-05-25 11:44:51,108 [bic.py] => training => Task 6, Epoch 31/170 => Loss 2.561, Train_accy 89.540, Test_accy 43.940
2022-05-25 11:44:55,579 [bic.py] => training => Task 6, Epoch 32/170 => Loss 2.562, Train_accy 90.060, Test_accy 42.090
2022-05-25 11:45:00,064 [bic.py] => training => Task 6, Epoch 33/170 => Loss 2.569, Train_accy 92.300, Test_accy 43.470
2022-05-25 11:45:04,612 [bic.py] => training => Task 6, Epoch 34/170 => Loss 2.569, Train_accy 83.630, Test_accy 37.540
2022-05-25 11:45:09,071 [bic.py] => training => Task 6, Epoch 35/170 => Loss 2.561, Train_accy 93.000, Test_accy 43.710
2022-05-25 11:45:13,544 [bic.py] => training => Task 6, Epoch 36/170 => Loss 2.563, Train_accy 90.400, Test_accy 43.000
2022-05-25 11:45:17,999 [bic.py] => training => Task 6, Epoch 37/170 => Loss 2.568, Train_accy 88.890, Test_accy 42.890
2022-05-25 11:45:22,516 [bic.py] => training => Task 6, Epoch 38/170 => Loss 2.576, Train_accy 88.910, Test_accy 41.270
2022-05-25 11:45:27,034 [bic.py] => training => Task 6, Epoch 39/170 => Loss 2.569, Train_accy 91.980, Test_accy 43.710
2022-05-25 11:45:31,545 [bic.py] => training => Task 6, Epoch 40/170 => Loss 2.560, Train_accy 85.300, Test_accy 39.360
2022-05-25 11:45:36,177 [bic.py] => training => Task 6, Epoch 41/170 => Loss 2.565, Train_accy 91.200, Test_accy 40.730
2022-05-25 11:45:40,452 [bic.py] => training => Task 6, Epoch 42/170 => Loss 2.565, Train_accy 92.570, Test_accy 44.260
2022-05-25 11:45:44,748 [bic.py] => training => Task 6, Epoch 43/170 => Loss 2.563, Train_accy 91.290, Test_accy 42.090
2022-05-25 11:45:49,235 [bic.py] => training => Task 6, Epoch 44/170 => Loss 2.553, Train_accy 91.650, Test_accy 43.040
2022-05-25 11:45:53,738 [bic.py] => training => Task 6, Epoch 45/170 => Loss 2.559, Train_accy 92.790, Test_accy 44.960
2022-05-25 11:45:58,029 [bic.py] => training => Task 6, Epoch 46/170 => Loss 2.561, Train_accy 92.810, Test_accy 43.940
2022-05-25 11:46:02,540 [bic.py] => training => Task 6, Epoch 47/170 => Loss 2.560, Train_accy 92.780, Test_accy 41.940
2022-05-25 11:46:07,013 [bic.py] => training => Task 6, Epoch 48/170 => Loss 2.562, Train_accy 90.310, Test_accy 40.530
2022-05-25 11:46:11,768 [bic.py] => training => Task 6, Epoch 49/170 => Loss 2.561, Train_accy 91.300, Test_accy 41.000
2022-05-25 11:46:16,293 [bic.py] => training => Task 6, Epoch 50/170 => Loss 2.555, Train_accy 93.230, Test_accy 43.990
2022-05-25 11:46:20,775 [bic.py] => training => Task 6, Epoch 51/170 => Loss 2.559, Train_accy 93.210, Test_accy 44.300
2022-05-25 11:46:25,522 [bic.py] => training => Task 6, Epoch 52/170 => Loss 2.559, Train_accy 90.680, Test_accy 40.590
2022-05-25 11:46:30,272 [bic.py] => training => Task 6, Epoch 53/170 => Loss 2.558, Train_accy 91.300, Test_accy 42.230
2022-05-25 11:46:34,739 [bic.py] => training => Task 6, Epoch 54/170 => Loss 2.555, Train_accy 92.610, Test_accy 41.610
2022-05-25 11:46:39,247 [bic.py] => training => Task 6, Epoch 55/170 => Loss 2.558, Train_accy 90.070, Test_accy 40.300
2022-05-25 11:46:43,776 [bic.py] => training => Task 6, Epoch 56/170 => Loss 2.560, Train_accy 90.900, Test_accy 37.630
2022-05-25 11:46:48,173 [bic.py] => training => Task 6, Epoch 57/170 => Loss 2.553, Train_accy 91.770, Test_accy 39.660
2022-05-25 11:46:52,732 [bic.py] => training => Task 6, Epoch 58/170 => Loss 2.553, Train_accy 90.100, Test_accy 42.310
2022-05-25 11:46:57,191 [bic.py] => training => Task 6, Epoch 59/170 => Loss 2.558, Train_accy 89.530, Test_accy 37.960
2022-05-25 11:47:01,735 [bic.py] => training => Task 6, Epoch 60/170 => Loss 2.554, Train_accy 94.090, Test_accy 42.510
2022-05-25 11:47:06,251 [bic.py] => training => Task 6, Epoch 61/170 => Loss 2.532, Train_accy 98.140, Test_accy 46.340
2022-05-25 11:47:10,790 [bic.py] => training => Task 6, Epoch 62/170 => Loss 2.527, Train_accy 98.430, Test_accy 47.490
2022-05-25 11:47:15,351 [bic.py] => training => Task 6, Epoch 63/170 => Loss 2.515, Train_accy 98.520, Test_accy 46.240
2022-05-25 11:47:19,647 [bic.py] => training => Task 6, Epoch 64/170 => Loss 2.514, Train_accy 98.760, Test_accy 47.330
2022-05-25 11:47:24,196 [bic.py] => training => Task 6, Epoch 65/170 => Loss 2.516, Train_accy 98.830, Test_accy 47.190
2022-05-25 11:47:28,683 [bic.py] => training => Task 6, Epoch 66/170 => Loss 2.509, Train_accy 98.790, Test_accy 46.660
2022-05-25 11:47:33,188 [bic.py] => training => Task 6, Epoch 67/170 => Loss 2.506, Train_accy 99.070, Test_accy 47.170
2022-05-25 11:47:38,021 [bic.py] => training => Task 6, Epoch 68/170 => Loss 2.507, Train_accy 99.040, Test_accy 46.640
2022-05-25 11:47:42,700 [bic.py] => training => Task 6, Epoch 69/170 => Loss 2.505, Train_accy 98.880, Test_accy 46.430
2022-05-25 11:47:47,332 [bic.py] => training => Task 6, Epoch 70/170 => Loss 2.509, Train_accy 99.050, Test_accy 46.470
2022-05-25 11:47:51,904 [bic.py] => training => Task 6, Epoch 71/170 => Loss 2.510, Train_accy 99.310, Test_accy 46.560
2022-05-25 11:47:56,563 [bic.py] => training => Task 6, Epoch 72/170 => Loss 2.510, Train_accy 99.130, Test_accy 47.130
2022-05-25 11:48:01,187 [bic.py] => training => Task 6, Epoch 73/170 => Loss 2.507, Train_accy 99.110, Test_accy 46.990
2022-05-25 11:48:05,783 [bic.py] => training => Task 6, Epoch 74/170 => Loss 2.504, Train_accy 99.050, Test_accy 46.970
2022-05-25 11:48:10,309 [bic.py] => training => Task 6, Epoch 75/170 => Loss 2.509, Train_accy 99.280, Test_accy 47.070
2022-05-25 11:48:14,836 [bic.py] => training => Task 6, Epoch 76/170 => Loss 2.505, Train_accy 99.000, Test_accy 46.600
2022-05-25 11:48:19,206 [bic.py] => training => Task 6, Epoch 77/170 => Loss 2.504, Train_accy 99.160, Test_accy 47.170
2022-05-25 11:48:23,687 [bic.py] => training => Task 6, Epoch 78/170 => Loss 2.508, Train_accy 99.310, Test_accy 46.840
2022-05-25 11:48:28,147 [bic.py] => training => Task 6, Epoch 79/170 => Loss 2.502, Train_accy 99.250, Test_accy 47.400
2022-05-25 11:48:32,693 [bic.py] => training => Task 6, Epoch 80/170 => Loss 2.507, Train_accy 99.340, Test_accy 47.010
2022-05-25 11:48:37,180 [bic.py] => training => Task 6, Epoch 81/170 => Loss 2.502, Train_accy 99.360, Test_accy 47.560
2022-05-25 11:48:41,772 [bic.py] => training => Task 6, Epoch 82/170 => Loss 2.502, Train_accy 99.220, Test_accy 46.800
2022-05-25 11:48:46,118 [bic.py] => training => Task 6, Epoch 83/170 => Loss 2.506, Train_accy 99.100, Test_accy 46.740
2022-05-25 11:48:50,703 [bic.py] => training => Task 6, Epoch 84/170 => Loss 2.505, Train_accy 99.280, Test_accy 46.490
2022-05-25 11:48:55,288 [bic.py] => training => Task 6, Epoch 85/170 => Loss 2.506, Train_accy 99.290, Test_accy 46.570
2022-05-25 11:48:59,790 [bic.py] => training => Task 6, Epoch 86/170 => Loss 2.508, Train_accy 99.280, Test_accy 46.670
2022-05-25 11:49:04,301 [bic.py] => training => Task 6, Epoch 87/170 => Loss 2.505, Train_accy 99.390, Test_accy 46.960
2022-05-25 11:49:08,831 [bic.py] => training => Task 6, Epoch 88/170 => Loss 2.505, Train_accy 99.380, Test_accy 46.700
2022-05-25 11:49:13,321 [bic.py] => training => Task 6, Epoch 89/170 => Loss 2.497, Train_accy 99.290, Test_accy 46.000
2022-05-25 11:49:18,041 [bic.py] => training => Task 6, Epoch 90/170 => Loss 2.505, Train_accy 99.350, Test_accy 46.890
2022-05-25 11:49:22,555 [bic.py] => training => Task 6, Epoch 91/170 => Loss 2.502, Train_accy 99.320, Test_accy 46.470
2022-05-25 11:49:26,988 [bic.py] => training => Task 6, Epoch 92/170 => Loss 2.503, Train_accy 99.340, Test_accy 46.840
2022-05-25 11:49:31,491 [bic.py] => training => Task 6, Epoch 93/170 => Loss 2.502, Train_accy 99.360, Test_accy 46.770
2022-05-25 11:49:36,079 [bic.py] => training => Task 6, Epoch 94/170 => Loss 2.508, Train_accy 99.450, Test_accy 47.190
2022-05-25 11:49:40,647 [bic.py] => training => Task 6, Epoch 95/170 => Loss 2.502, Train_accy 99.390, Test_accy 47.170
2022-05-25 11:49:45,323 [bic.py] => training => Task 6, Epoch 96/170 => Loss 2.502, Train_accy 99.560, Test_accy 47.090
2022-05-25 11:49:49,825 [bic.py] => training => Task 6, Epoch 97/170 => Loss 2.494, Train_accy 99.360, Test_accy 46.800
2022-05-25 11:49:54,382 [bic.py] => training => Task 6, Epoch 98/170 => Loss 2.503, Train_accy 99.480, Test_accy 46.910
2022-05-25 11:49:59,180 [bic.py] => training => Task 6, Epoch 99/170 => Loss 2.500, Train_accy 99.290, Test_accy 46.870
2022-05-25 11:50:03,630 [bic.py] => training => Task 6, Epoch 100/170 => Loss 2.501, Train_accy 99.390, Test_accy 46.400
2022-05-25 11:50:08,115 [bic.py] => training => Task 6, Epoch 101/170 => Loss 2.501, Train_accy 99.570, Test_accy 46.810
2022-05-25 11:50:12,612 [bic.py] => training => Task 6, Epoch 102/170 => Loss 2.501, Train_accy 99.420, Test_accy 46.790
2022-05-25 11:50:17,030 [bic.py] => training => Task 6, Epoch 103/170 => Loss 2.502, Train_accy 99.340, Test_accy 46.810
2022-05-25 11:50:21,544 [bic.py] => training => Task 6, Epoch 104/170 => Loss 2.498, Train_accy 99.420, Test_accy 46.660
2022-05-25 11:50:26,046 [bic.py] => training => Task 6, Epoch 105/170 => Loss 2.501, Train_accy 99.290, Test_accy 46.700
2022-05-25 11:50:30,535 [bic.py] => training => Task 6, Epoch 106/170 => Loss 2.498, Train_accy 99.390, Test_accy 46.610
2022-05-25 11:50:35,064 [bic.py] => training => Task 6, Epoch 107/170 => Loss 2.500, Train_accy 99.310, Test_accy 46.770
2022-05-25 11:50:39,564 [bic.py] => training => Task 6, Epoch 108/170 => Loss 2.497, Train_accy 99.630, Test_accy 47.030
2022-05-25 11:50:44,133 [bic.py] => training => Task 6, Epoch 109/170 => Loss 2.497, Train_accy 99.480, Test_accy 46.760
2022-05-25 11:50:48,617 [bic.py] => training => Task 6, Epoch 110/170 => Loss 2.501, Train_accy 99.470, Test_accy 46.640
2022-05-25 11:50:53,112 [bic.py] => training => Task 6, Epoch 111/170 => Loss 2.498, Train_accy 99.390, Test_accy 46.770
2022-05-25 11:50:57,750 [bic.py] => training => Task 6, Epoch 112/170 => Loss 2.496, Train_accy 99.440, Test_accy 46.810
2022-05-25 11:51:02,240 [bic.py] => training => Task 6, Epoch 113/170 => Loss 2.494, Train_accy 99.380, Test_accy 46.740
2022-05-25 11:51:06,764 [bic.py] => training => Task 6, Epoch 114/170 => Loss 2.501, Train_accy 99.390, Test_accy 46.900
2022-05-25 11:51:11,255 [bic.py] => training => Task 6, Epoch 115/170 => Loss 2.500, Train_accy 99.440, Test_accy 46.530
2022-05-25 11:51:15,729 [bic.py] => training => Task 6, Epoch 116/170 => Loss 2.498, Train_accy 99.510, Test_accy 46.860
2022-05-25 11:51:20,220 [bic.py] => training => Task 6, Epoch 117/170 => Loss 2.501, Train_accy 99.290, Test_accy 46.740
2022-05-25 11:51:24,694 [bic.py] => training => Task 6, Epoch 118/170 => Loss 2.499, Train_accy 99.320, Test_accy 47.030
2022-05-25 11:51:29,223 [bic.py] => training => Task 6, Epoch 119/170 => Loss 2.496, Train_accy 99.540, Test_accy 46.800
2022-05-25 11:51:33,793 [bic.py] => training => Task 6, Epoch 120/170 => Loss 2.499, Train_accy 99.410, Test_accy 46.670
2022-05-25 11:51:38,161 [bic.py] => training => Task 6, Epoch 121/170 => Loss 2.501, Train_accy 99.420, Test_accy 46.630
2022-05-25 11:51:42,817 [bic.py] => training => Task 6, Epoch 122/170 => Loss 2.502, Train_accy 99.450, Test_accy 46.970
2022-05-25 11:51:47,282 [bic.py] => training => Task 6, Epoch 123/170 => Loss 2.502, Train_accy 99.350, Test_accy 46.740
2022-05-25 11:51:51,778 [bic.py] => training => Task 6, Epoch 124/170 => Loss 2.497, Train_accy 99.390, Test_accy 46.710
2022-05-25 11:51:56,384 [bic.py] => training => Task 6, Epoch 125/170 => Loss 2.496, Train_accy 99.320, Test_accy 46.400
2022-05-25 11:52:01,005 [bic.py] => training => Task 6, Epoch 126/170 => Loss 2.495, Train_accy 99.450, Test_accy 46.660
2022-05-25 11:52:05,454 [bic.py] => training => Task 6, Epoch 127/170 => Loss 2.499, Train_accy 99.480, Test_accy 46.540
2022-05-25 11:52:10,097 [bic.py] => training => Task 6, Epoch 128/170 => Loss 2.500, Train_accy 99.450, Test_accy 46.490
2022-05-25 11:52:14,736 [bic.py] => training => Task 6, Epoch 129/170 => Loss 2.497, Train_accy 99.410, Test_accy 46.890
2022-05-25 11:52:19,215 [bic.py] => training => Task 6, Epoch 130/170 => Loss 2.499, Train_accy 99.470, Test_accy 46.570
2022-05-25 11:52:23,707 [bic.py] => training => Task 6, Epoch 131/170 => Loss 2.502, Train_accy 99.480, Test_accy 46.590
2022-05-25 11:52:28,231 [bic.py] => training => Task 6, Epoch 132/170 => Loss 2.497, Train_accy 99.540, Test_accy 46.600
2022-05-25 11:52:32,772 [bic.py] => training => Task 6, Epoch 133/170 => Loss 2.499, Train_accy 99.260, Test_accy 46.740
2022-05-25 11:52:37,292 [bic.py] => training => Task 6, Epoch 134/170 => Loss 2.497, Train_accy 99.380, Test_accy 46.790
2022-05-25 11:52:41,788 [bic.py] => training => Task 6, Epoch 135/170 => Loss 2.498, Train_accy 99.540, Test_accy 46.800
2022-05-25 11:52:46,058 [bic.py] => training => Task 6, Epoch 136/170 => Loss 2.498, Train_accy 99.420, Test_accy 46.960
2022-05-25 11:52:50,515 [bic.py] => training => Task 6, Epoch 137/170 => Loss 2.499, Train_accy 99.450, Test_accy 46.640
2022-05-25 11:52:54,731 [bic.py] => training => Task 6, Epoch 138/170 => Loss 2.501, Train_accy 99.340, Test_accy 46.600
2022-05-25 11:52:59,344 [bic.py] => training => Task 6, Epoch 139/170 => Loss 2.502, Train_accy 99.360, Test_accy 46.600
2022-05-25 11:53:03,905 [bic.py] => training => Task 6, Epoch 140/170 => Loss 2.499, Train_accy 99.380, Test_accy 46.360
2022-05-25 11:53:08,364 [bic.py] => training => Task 6, Epoch 141/170 => Loss 2.499, Train_accy 99.570, Test_accy 46.710
2022-05-25 11:53:13,131 [bic.py] => training => Task 6, Epoch 142/170 => Loss 2.497, Train_accy 99.480, Test_accy 46.940
2022-05-25 11:53:17,515 [bic.py] => training => Task 6, Epoch 143/170 => Loss 2.499, Train_accy 99.540, Test_accy 46.740
2022-05-25 11:53:22,053 [bic.py] => training => Task 6, Epoch 144/170 => Loss 2.501, Train_accy 99.500, Test_accy 46.770
2022-05-25 11:53:26,632 [bic.py] => training => Task 6, Epoch 145/170 => Loss 2.501, Train_accy 99.480, Test_accy 46.760
2022-05-25 11:53:31,175 [bic.py] => training => Task 6, Epoch 146/170 => Loss 2.500, Train_accy 99.380, Test_accy 46.870
2022-05-25 11:53:35,464 [bic.py] => training => Task 6, Epoch 147/170 => Loss 2.497, Train_accy 99.510, Test_accy 46.560
2022-05-25 11:53:40,106 [bic.py] => training => Task 6, Epoch 148/170 => Loss 2.499, Train_accy 99.380, Test_accy 46.590
2022-05-25 11:53:44,615 [bic.py] => training => Task 6, Epoch 149/170 => Loss 2.494, Train_accy 99.480, Test_accy 46.860
2022-05-25 11:53:49,066 [bic.py] => training => Task 6, Epoch 150/170 => Loss 2.500, Train_accy 99.450, Test_accy 46.700
2022-05-25 11:53:53,495 [bic.py] => training => Task 6, Epoch 151/170 => Loss 2.499, Train_accy 99.390, Test_accy 46.590
2022-05-25 11:53:58,205 [bic.py] => training => Task 6, Epoch 152/170 => Loss 2.503, Train_accy 99.540, Test_accy 46.800
2022-05-25 11:54:02,657 [bic.py] => training => Task 6, Epoch 153/170 => Loss 2.495, Train_accy 99.470, Test_accy 46.900
2022-05-25 11:54:07,330 [bic.py] => training => Task 6, Epoch 154/170 => Loss 2.496, Train_accy 99.340, Test_accy 46.640
2022-05-25 11:54:11,884 [bic.py] => training => Task 6, Epoch 155/170 => Loss 2.495, Train_accy 99.420, Test_accy 46.710
2022-05-25 11:54:16,543 [bic.py] => training => Task 6, Epoch 156/170 => Loss 2.497, Train_accy 99.470, Test_accy 46.690
2022-05-25 11:54:21,009 [bic.py] => training => Task 6, Epoch 157/170 => Loss 2.500, Train_accy 99.530, Test_accy 46.730
2022-05-25 11:54:25,458 [bic.py] => training => Task 6, Epoch 158/170 => Loss 2.499, Train_accy 99.420, Test_accy 46.510
2022-05-25 11:54:29,895 [bic.py] => training => Task 6, Epoch 159/170 => Loss 2.494, Train_accy 99.470, Test_accy 46.730
2022-05-25 11:54:34,456 [bic.py] => training => Task 6, Epoch 160/170 => Loss 2.497, Train_accy 99.500, Test_accy 46.640
2022-05-25 11:54:38,905 [bic.py] => training => Task 6, Epoch 161/170 => Loss 2.501, Train_accy 99.310, Test_accy 46.530
2022-05-25 11:54:43,327 [bic.py] => training => Task 6, Epoch 162/170 => Loss 2.499, Train_accy 99.510, Test_accy 47.030
2022-05-25 11:54:47,569 [bic.py] => training => Task 6, Epoch 163/170 => Loss 2.499, Train_accy 99.510, Test_accy 46.510
2022-05-25 11:54:52,031 [bic.py] => training => Task 6, Epoch 164/170 => Loss 2.497, Train_accy 99.390, Test_accy 46.700
2022-05-25 11:54:56,452 [bic.py] => training => Task 6, Epoch 165/170 => Loss 2.498, Train_accy 99.440, Test_accy 46.510
2022-05-25 11:55:01,092 [bic.py] => training => Task 6, Epoch 166/170 => Loss 2.500, Train_accy 99.480, Test_accy 46.860
2022-05-25 11:55:05,810 [bic.py] => training => Task 6, Epoch 167/170 => Loss 2.498, Train_accy 99.510, Test_accy 46.430
2022-05-25 11:55:10,317 [bic.py] => training => Task 6, Epoch 168/170 => Loss 2.502, Train_accy 99.570, Test_accy 46.700
2022-05-25 11:55:14,734 [bic.py] => training => Task 6, Epoch 169/170 => Loss 2.497, Train_accy 99.360, Test_accy 46.800
2022-05-25 11:55:19,173 [bic.py] => training => Task 6, Epoch 170/170 => Loss 2.494, Train_accy 99.360, Test_accy 46.900
2022-05-25 11:55:20,912 [bic.py] => bias_correction => Task 6, Epoch 1/170 => Loss 3.798, Train_accy 65.710, Test_accy 49.230
2022-05-25 11:55:22,729 [bic.py] => bias_correction => Task 6, Epoch 2/170 => Loss 3.750, Train_accy 73.330, Test_accy 53.230
2022-05-25 11:55:24,597 [bic.py] => bias_correction => Task 6, Epoch 3/170 => Loss 3.716, Train_accy 74.760, Test_accy 51.930
2022-05-25 11:55:26,358 [bic.py] => bias_correction => Task 6, Epoch 4/170 => Loss 3.709, Train_accy 72.860, Test_accy 49.230
2022-05-25 11:55:28,210 [bic.py] => bias_correction => Task 6, Epoch 5/170 => Loss 3.728, Train_accy 70.000, Test_accy 47.900
2022-05-25 11:55:29,970 [bic.py] => bias_correction => Task 6, Epoch 6/170 => Loss 3.741, Train_accy 70.000, Test_accy 47.470
2022-05-25 11:55:31,740 [bic.py] => bias_correction => Task 6, Epoch 7/170 => Loss 3.745, Train_accy 70.480, Test_accy 47.300
2022-05-25 11:55:33,595 [bic.py] => bias_correction => Task 6, Epoch 8/170 => Loss 3.747, Train_accy 66.670, Test_accy 47.360
2022-05-25 11:55:35,329 [bic.py] => bias_correction => Task 6, Epoch 9/170 => Loss 3.740, Train_accy 70.950, Test_accy 47.770
2022-05-25 11:55:37,053 [bic.py] => bias_correction => Task 6, Epoch 10/170 => Loss 3.722, Train_accy 72.380, Test_accy 48.800
2022-05-25 11:55:38,804 [bic.py] => bias_correction => Task 6, Epoch 11/170 => Loss 3.736, Train_accy 70.950, Test_accy 50.330
2022-05-25 11:55:40,549 [bic.py] => bias_correction => Task 6, Epoch 12/170 => Loss 3.731, Train_accy 72.380, Test_accy 52.340
2022-05-25 11:55:42,380 [bic.py] => bias_correction => Task 6, Epoch 13/170 => Loss 3.708, Train_accy 71.430, Test_accy 52.560
2022-05-25 11:55:44,269 [bic.py] => bias_correction => Task 6, Epoch 14/170 => Loss 3.713, Train_accy 73.330, Test_accy 51.560
2022-05-25 11:55:45,996 [bic.py] => bias_correction => Task 6, Epoch 15/170 => Loss 3.734, Train_accy 70.000, Test_accy 51.210
2022-05-25 11:55:47,854 [bic.py] => bias_correction => Task 6, Epoch 16/170 => Loss 3.721, Train_accy 70.950, Test_accy 51.930
2022-05-25 11:55:49,666 [bic.py] => bias_correction => Task 6, Epoch 17/170 => Loss 3.713, Train_accy 71.900, Test_accy 52.500
2022-05-25 11:55:51,478 [bic.py] => bias_correction => Task 6, Epoch 18/170 => Loss 3.720, Train_accy 75.710, Test_accy 52.310
2022-05-25 11:55:53,200 [bic.py] => bias_correction => Task 6, Epoch 19/170 => Loss 3.700, Train_accy 72.380, Test_accy 51.930
2022-05-25 11:55:54,943 [bic.py] => bias_correction => Task 6, Epoch 20/170 => Loss 3.719, Train_accy 77.620, Test_accy 52.130
2022-05-25 11:55:56,657 [bic.py] => bias_correction => Task 6, Epoch 21/170 => Loss 3.725, Train_accy 74.290, Test_accy 52.690
2022-05-25 11:55:58,410 [bic.py] => bias_correction => Task 6, Epoch 22/170 => Loss 3.701, Train_accy 71.430, Test_accy 52.670
2022-05-25 11:56:00,224 [bic.py] => bias_correction => Task 6, Epoch 23/170 => Loss 3.717, Train_accy 71.430, Test_accy 52.460
2022-05-25 11:56:01,983 [bic.py] => bias_correction => Task 6, Epoch 24/170 => Loss 3.703, Train_accy 74.760, Test_accy 52.370
2022-05-25 11:56:03,832 [bic.py] => bias_correction => Task 6, Epoch 25/170 => Loss 3.709, Train_accy 72.860, Test_accy 52.540
2022-05-25 11:56:06,024 [bic.py] => bias_correction => Task 6, Epoch 26/170 => Loss 3.688, Train_accy 76.190, Test_accy 52.710
2022-05-25 11:56:08,041 [bic.py] => bias_correction => Task 6, Epoch 27/170 => Loss 3.720, Train_accy 72.860, Test_accy 52.760
2022-05-25 11:56:09,939 [bic.py] => bias_correction => Task 6, Epoch 28/170 => Loss 3.719, Train_accy 73.330, Test_accy 52.730
2022-05-25 11:56:11,851 [bic.py] => bias_correction => Task 6, Epoch 29/170 => Loss 3.715, Train_accy 75.710, Test_accy 52.710
2022-05-25 11:56:13,742 [bic.py] => bias_correction => Task 6, Epoch 30/170 => Loss 3.703, Train_accy 73.810, Test_accy 52.700
2022-05-25 11:56:15,535 [bic.py] => bias_correction => Task 6, Epoch 31/170 => Loss 3.710, Train_accy 73.330, Test_accy 52.470
2022-05-25 11:56:17,432 [bic.py] => bias_correction => Task 6, Epoch 32/170 => Loss 3.699, Train_accy 73.330, Test_accy 52.530
2022-05-25 11:56:19,248 [bic.py] => bias_correction => Task 6, Epoch 33/170 => Loss 3.687, Train_accy 70.000, Test_accy 52.670
2022-05-25 11:56:21,014 [bic.py] => bias_correction => Task 6, Epoch 34/170 => Loss 3.704, Train_accy 71.900, Test_accy 52.860
2022-05-25 11:56:22,928 [bic.py] => bias_correction => Task 6, Epoch 35/170 => Loss 3.716, Train_accy 74.760, Test_accy 52.790
2022-05-25 11:56:24,786 [bic.py] => bias_correction => Task 6, Epoch 36/170 => Loss 3.730, Train_accy 73.330, Test_accy 52.760
2022-05-25 11:56:26,528 [bic.py] => bias_correction => Task 6, Epoch 37/170 => Loss 3.706, Train_accy 74.760, Test_accy 52.740
2022-05-25 11:56:28,305 [bic.py] => bias_correction => Task 6, Epoch 38/170 => Loss 3.699, Train_accy 71.900, Test_accy 52.770
2022-05-25 11:56:30,051 [bic.py] => bias_correction => Task 6, Epoch 39/170 => Loss 3.707, Train_accy 72.860, Test_accy 52.640
2022-05-25 11:56:31,888 [bic.py] => bias_correction => Task 6, Epoch 40/170 => Loss 3.717, Train_accy 74.760, Test_accy 52.600
2022-05-25 11:56:33,638 [bic.py] => bias_correction => Task 6, Epoch 41/170 => Loss 3.684, Train_accy 73.810, Test_accy 52.510
2022-05-25 11:56:35,423 [bic.py] => bias_correction => Task 6, Epoch 42/170 => Loss 3.708, Train_accy 75.240, Test_accy 52.590
2022-05-25 11:56:37,255 [bic.py] => bias_correction => Task 6, Epoch 43/170 => Loss 3.718, Train_accy 74.760, Test_accy 52.770
2022-05-25 11:56:39,111 [bic.py] => bias_correction => Task 6, Epoch 44/170 => Loss 3.723, Train_accy 73.330, Test_accy 52.910
2022-05-25 11:56:40,893 [bic.py] => bias_correction => Task 6, Epoch 45/170 => Loss 3.704, Train_accy 73.810, Test_accy 52.910
2022-05-25 11:56:42,604 [bic.py] => bias_correction => Task 6, Epoch 46/170 => Loss 3.698, Train_accy 75.240, Test_accy 52.890
2022-05-25 11:56:44,428 [bic.py] => bias_correction => Task 6, Epoch 47/170 => Loss 3.695, Train_accy 71.430, Test_accy 52.890
2022-05-25 11:56:46,276 [bic.py] => bias_correction => Task 6, Epoch 48/170 => Loss 3.709, Train_accy 74.760, Test_accy 52.870
2022-05-25 11:56:48,004 [bic.py] => bias_correction => Task 6, Epoch 49/170 => Loss 3.702, Train_accy 70.950, Test_accy 52.910
2022-05-25 11:56:49,770 [bic.py] => bias_correction => Task 6, Epoch 50/170 => Loss 3.714, Train_accy 74.290, Test_accy 52.840
2022-05-25 11:56:51,629 [bic.py] => bias_correction => Task 6, Epoch 51/170 => Loss 3.681, Train_accy 71.900, Test_accy 52.860
2022-05-25 11:56:53,452 [bic.py] => bias_correction => Task 6, Epoch 52/170 => Loss 3.700, Train_accy 71.900, Test_accy 52.910
2022-05-25 11:56:55,338 [bic.py] => bias_correction => Task 6, Epoch 53/170 => Loss 3.702, Train_accy 75.240, Test_accy 52.930
2022-05-25 11:56:57,216 [bic.py] => bias_correction => Task 6, Epoch 54/170 => Loss 3.715, Train_accy 72.380, Test_accy 52.870
2022-05-25 11:56:58,999 [bic.py] => bias_correction => Task 6, Epoch 55/170 => Loss 3.711, Train_accy 70.480, Test_accy 52.890
2022-05-25 11:57:00,817 [bic.py] => bias_correction => Task 6, Epoch 56/170 => Loss 3.717, Train_accy 78.570, Test_accy 52.800
2022-05-25 11:57:02,659 [bic.py] => bias_correction => Task 6, Epoch 57/170 => Loss 3.709, Train_accy 75.240, Test_accy 52.810
2022-05-25 11:57:04,421 [bic.py] => bias_correction => Task 6, Epoch 58/170 => Loss 3.716, Train_accy 72.380, Test_accy 52.810
2022-05-25 11:57:06,202 [bic.py] => bias_correction => Task 6, Epoch 59/170 => Loss 3.691, Train_accy 74.760, Test_accy 52.710
2022-05-25 11:57:07,936 [bic.py] => bias_correction => Task 6, Epoch 60/170 => Loss 3.686, Train_accy 75.240, Test_accy 52.560
2022-05-25 11:57:09,625 [bic.py] => bias_correction => Task 6, Epoch 61/170 => Loss 3.706, Train_accy 73.810, Test_accy 52.500
2022-05-25 11:57:11,369 [bic.py] => bias_correction => Task 6, Epoch 62/170 => Loss 3.702, Train_accy 70.950, Test_accy 52.530
2022-05-25 11:57:13,157 [bic.py] => bias_correction => Task 6, Epoch 63/170 => Loss 3.717, Train_accy 70.950, Test_accy 52.470
2022-05-25 11:57:14,908 [bic.py] => bias_correction => Task 6, Epoch 64/170 => Loss 3.705, Train_accy 72.380, Test_accy 52.510
2022-05-25 11:57:16,627 [bic.py] => bias_correction => Task 6, Epoch 65/170 => Loss 3.711, Train_accy 77.140, Test_accy 52.610
2022-05-25 11:57:18,468 [bic.py] => bias_correction => Task 6, Epoch 66/170 => Loss 3.694, Train_accy 77.140, Test_accy 52.710
2022-05-25 11:57:20,214 [bic.py] => bias_correction => Task 6, Epoch 67/170 => Loss 3.706, Train_accy 72.860, Test_accy 52.790
2022-05-25 11:57:21,963 [bic.py] => bias_correction => Task 6, Epoch 68/170 => Loss 3.687, Train_accy 72.380, Test_accy 52.800
2022-05-25 11:57:23,674 [bic.py] => bias_correction => Task 6, Epoch 69/170 => Loss 3.693, Train_accy 71.900, Test_accy 52.970
2022-05-25 11:57:25,517 [bic.py] => bias_correction => Task 6, Epoch 70/170 => Loss 3.695, Train_accy 74.290, Test_accy 52.900
2022-05-25 11:57:27,299 [bic.py] => bias_correction => Task 6, Epoch 71/170 => Loss 3.704, Train_accy 76.190, Test_accy 53.000
2022-05-25 11:57:29,106 [bic.py] => bias_correction => Task 6, Epoch 72/170 => Loss 3.706, Train_accy 74.290, Test_accy 53.000
2022-05-25 11:57:30,823 [bic.py] => bias_correction => Task 6, Epoch 73/170 => Loss 3.711, Train_accy 74.760, Test_accy 53.040
2022-05-25 11:57:32,659 [bic.py] => bias_correction => Task 6, Epoch 74/170 => Loss 3.711, Train_accy 74.760, Test_accy 52.890
2022-05-25 11:57:34,389 [bic.py] => bias_correction => Task 6, Epoch 75/170 => Loss 3.702, Train_accy 73.810, Test_accy 53.030
2022-05-25 11:57:36,201 [bic.py] => bias_correction => Task 6, Epoch 76/170 => Loss 3.706, Train_accy 70.480, Test_accy 52.940
2022-05-25 11:57:37,921 [bic.py] => bias_correction => Task 6, Epoch 77/170 => Loss 3.714, Train_accy 74.290, Test_accy 52.930
2022-05-25 11:57:39,678 [bic.py] => bias_correction => Task 6, Epoch 78/170 => Loss 3.701, Train_accy 76.670, Test_accy 52.840
2022-05-25 11:57:41,366 [bic.py] => bias_correction => Task 6, Epoch 79/170 => Loss 3.688, Train_accy 74.290, Test_accy 52.910
2022-05-25 11:57:43,108 [bic.py] => bias_correction => Task 6, Epoch 80/170 => Loss 3.700, Train_accy 75.240, Test_accy 52.930
2022-05-25 11:57:44,910 [bic.py] => bias_correction => Task 6, Epoch 81/170 => Loss 3.699, Train_accy 74.760, Test_accy 52.930
2022-05-25 11:57:46,676 [bic.py] => bias_correction => Task 6, Epoch 82/170 => Loss 3.689, Train_accy 72.860, Test_accy 53.090
2022-05-25 11:57:48,433 [bic.py] => bias_correction => Task 6, Epoch 83/170 => Loss 3.716, Train_accy 70.950, Test_accy 52.910
2022-05-25 11:57:50,330 [bic.py] => bias_correction => Task 6, Epoch 84/170 => Loss 3.712, Train_accy 73.810, Test_accy 52.990
2022-05-25 11:57:52,118 [bic.py] => bias_correction => Task 6, Epoch 85/170 => Loss 3.712, Train_accy 76.670, Test_accy 53.010
2022-05-25 11:57:53,822 [bic.py] => bias_correction => Task 6, Epoch 86/170 => Loss 3.707, Train_accy 73.810, Test_accy 53.010
2022-05-25 11:57:55,624 [bic.py] => bias_correction => Task 6, Epoch 87/170 => Loss 3.703, Train_accy 73.330, Test_accy 52.990
2022-05-25 11:57:57,471 [bic.py] => bias_correction => Task 6, Epoch 88/170 => Loss 3.731, Train_accy 74.290, Test_accy 52.900
2022-05-25 11:57:59,320 [bic.py] => bias_correction => Task 6, Epoch 89/170 => Loss 3.712, Train_accy 72.860, Test_accy 52.940
2022-05-25 11:58:01,153 [bic.py] => bias_correction => Task 6, Epoch 90/170 => Loss 3.705, Train_accy 74.290, Test_accy 53.000
2022-05-25 11:58:02,982 [bic.py] => bias_correction => Task 6, Epoch 91/170 => Loss 3.707, Train_accy 77.140, Test_accy 52.990
2022-05-25 11:58:04,711 [bic.py] => bias_correction => Task 6, Epoch 92/170 => Loss 3.697, Train_accy 74.760, Test_accy 52.960
2022-05-25 11:58:06,387 [bic.py] => bias_correction => Task 6, Epoch 93/170 => Loss 3.714, Train_accy 74.760, Test_accy 52.910
2022-05-25 11:58:08,095 [bic.py] => bias_correction => Task 6, Epoch 94/170 => Loss 3.695, Train_accy 75.710, Test_accy 52.940
2022-05-25 11:58:09,886 [bic.py] => bias_correction => Task 6, Epoch 95/170 => Loss 3.708, Train_accy 76.670, Test_accy 52.900
2022-05-25 11:58:11,681 [bic.py] => bias_correction => Task 6, Epoch 96/170 => Loss 3.703, Train_accy 77.140, Test_accy 52.940
2022-05-25 11:58:13,474 [bic.py] => bias_correction => Task 6, Epoch 97/170 => Loss 3.725, Train_accy 74.290, Test_accy 52.940
2022-05-25 11:58:15,319 [bic.py] => bias_correction => Task 6, Epoch 98/170 => Loss 3.709, Train_accy 73.810, Test_accy 52.930
2022-05-25 11:58:17,170 [bic.py] => bias_correction => Task 6, Epoch 99/170 => Loss 3.702, Train_accy 72.380, Test_accy 52.870
2022-05-25 11:58:18,883 [bic.py] => bias_correction => Task 6, Epoch 100/170 => Loss 3.704, Train_accy 74.760, Test_accy 52.960
2022-05-25 11:58:20,635 [bic.py] => bias_correction => Task 6, Epoch 101/170 => Loss 3.687, Train_accy 75.240, Test_accy 53.030
2022-05-25 11:58:22,315 [bic.py] => bias_correction => Task 6, Epoch 102/170 => Loss 3.698, Train_accy 75.710, Test_accy 53.040
2022-05-25 11:58:24,087 [bic.py] => bias_correction => Task 6, Epoch 103/170 => Loss 3.694, Train_accy 72.380, Test_accy 53.000
2022-05-25 11:58:25,778 [bic.py] => bias_correction => Task 6, Epoch 104/170 => Loss 3.697, Train_accy 72.860, Test_accy 52.940
2022-05-25 11:58:27,520 [bic.py] => bias_correction => Task 6, Epoch 105/170 => Loss 3.698, Train_accy 75.240, Test_accy 52.870
2022-05-25 11:58:29,298 [bic.py] => bias_correction => Task 6, Epoch 106/170 => Loss 3.688, Train_accy 71.900, Test_accy 52.890
2022-05-25 11:58:31,127 [bic.py] => bias_correction => Task 6, Epoch 107/170 => Loss 3.690, Train_accy 73.810, Test_accy 52.870
2022-05-25 11:58:32,771 [bic.py] => bias_correction => Task 6, Epoch 108/170 => Loss 3.724, Train_accy 73.810, Test_accy 52.990
2022-05-25 11:58:34,473 [bic.py] => bias_correction => Task 6, Epoch 109/170 => Loss 3.710, Train_accy 72.380, Test_accy 52.930
2022-05-25 11:58:36,256 [bic.py] => bias_correction => Task 6, Epoch 110/170 => Loss 3.711, Train_accy 77.140, Test_accy 52.870
2022-05-25 11:58:38,012 [bic.py] => bias_correction => Task 6, Epoch 111/170 => Loss 3.723, Train_accy 71.900, Test_accy 52.960
2022-05-25 11:58:39,776 [bic.py] => bias_correction => Task 6, Epoch 112/170 => Loss 3.712, Train_accy 74.760, Test_accy 53.000
2022-05-25 11:58:41,561 [bic.py] => bias_correction => Task 6, Epoch 113/170 => Loss 3.688, Train_accy 73.330, Test_accy 52.890
2022-05-25 11:58:43,391 [bic.py] => bias_correction => Task 6, Epoch 114/170 => Loss 3.670, Train_accy 74.760, Test_accy 52.910
2022-05-25 11:58:45,187 [bic.py] => bias_correction => Task 6, Epoch 115/170 => Loss 3.706, Train_accy 73.810, Test_accy 53.060
2022-05-25 11:58:46,892 [bic.py] => bias_correction => Task 6, Epoch 116/170 => Loss 3.720, Train_accy 74.290, Test_accy 53.010
2022-05-25 11:58:48,601 [bic.py] => bias_correction => Task 6, Epoch 117/170 => Loss 3.707, Train_accy 77.140, Test_accy 53.000
2022-05-25 11:58:50,495 [bic.py] => bias_correction => Task 6, Epoch 118/170 => Loss 3.720, Train_accy 74.760, Test_accy 53.060
2022-05-25 11:58:52,226 [bic.py] => bias_correction => Task 6, Epoch 119/170 => Loss 3.714, Train_accy 72.860, Test_accy 53.140
2022-05-25 11:58:54,009 [bic.py] => bias_correction => Task 6, Epoch 120/170 => Loss 3.689, Train_accy 73.330, Test_accy 53.060
2022-05-25 11:58:55,845 [bic.py] => bias_correction => Task 6, Epoch 121/170 => Loss 3.715, Train_accy 76.190, Test_accy 52.990
2022-05-25 11:58:57,681 [bic.py] => bias_correction => Task 6, Epoch 122/170 => Loss 3.702, Train_accy 72.860, Test_accy 52.960
2022-05-25 11:58:59,392 [bic.py] => bias_correction => Task 6, Epoch 123/170 => Loss 3.702, Train_accy 73.810, Test_accy 53.040
2022-05-25 11:59:01,221 [bic.py] => bias_correction => Task 6, Epoch 124/170 => Loss 3.699, Train_accy 75.710, Test_accy 52.970
2022-05-25 11:59:03,017 [bic.py] => bias_correction => Task 6, Epoch 125/170 => Loss 3.706, Train_accy 72.380, Test_accy 52.960
2022-05-25 11:59:04,838 [bic.py] => bias_correction => Task 6, Epoch 126/170 => Loss 3.708, Train_accy 75.240, Test_accy 52.940
2022-05-25 11:59:06,587 [bic.py] => bias_correction => Task 6, Epoch 127/170 => Loss 3.713, Train_accy 72.860, Test_accy 52.890
2022-05-25 11:59:08,331 [bic.py] => bias_correction => Task 6, Epoch 128/170 => Loss 3.703, Train_accy 70.000, Test_accy 52.910
2022-05-25 11:59:10,161 [bic.py] => bias_correction => Task 6, Epoch 129/170 => Loss 3.708, Train_accy 72.380, Test_accy 52.930
2022-05-25 11:59:11,931 [bic.py] => bias_correction => Task 6, Epoch 130/170 => Loss 3.709, Train_accy 75.710, Test_accy 52.740
2022-05-25 11:59:13,799 [bic.py] => bias_correction => Task 6, Epoch 131/170 => Loss 3.702, Train_accy 72.380, Test_accy 52.870
2022-05-25 11:59:15,694 [bic.py] => bias_correction => Task 6, Epoch 132/170 => Loss 3.695, Train_accy 72.380, Test_accy 52.870
2022-05-25 11:59:17,528 [bic.py] => bias_correction => Task 6, Epoch 133/170 => Loss 3.694, Train_accy 73.810, Test_accy 52.970
2022-05-25 11:59:19,233 [bic.py] => bias_correction => Task 6, Epoch 134/170 => Loss 3.699, Train_accy 72.380, Test_accy 53.000
2022-05-25 11:59:21,111 [bic.py] => bias_correction => Task 6, Epoch 135/170 => Loss 3.703, Train_accy 77.620, Test_accy 52.960
2022-05-25 11:59:22,849 [bic.py] => bias_correction => Task 6, Epoch 136/170 => Loss 3.688, Train_accy 77.140, Test_accy 52.860
2022-05-25 11:59:24,626 [bic.py] => bias_correction => Task 6, Epoch 137/170 => Loss 3.697, Train_accy 72.860, Test_accy 52.940
2022-05-25 11:59:26,465 [bic.py] => bias_correction => Task 6, Epoch 138/170 => Loss 3.681, Train_accy 75.710, Test_accy 52.960
2022-05-25 11:59:28,360 [bic.py] => bias_correction => Task 6, Epoch 139/170 => Loss 3.707, Train_accy 74.290, Test_accy 53.000
2022-05-25 11:59:30,188 [bic.py] => bias_correction => Task 6, Epoch 140/170 => Loss 3.707, Train_accy 73.330, Test_accy 53.040
2022-05-25 11:59:31,888 [bic.py] => bias_correction => Task 6, Epoch 141/170 => Loss 3.716, Train_accy 75.240, Test_accy 53.040
2022-05-25 11:59:33,649 [bic.py] => bias_correction => Task 6, Epoch 142/170 => Loss 3.706, Train_accy 72.380, Test_accy 53.060
2022-05-25 11:59:35,517 [bic.py] => bias_correction => Task 6, Epoch 143/170 => Loss 3.701, Train_accy 74.290, Test_accy 53.040
2022-05-25 11:59:37,292 [bic.py] => bias_correction => Task 6, Epoch 144/170 => Loss 3.720, Train_accy 70.950, Test_accy 53.000
2022-05-25 11:59:39,038 [bic.py] => bias_correction => Task 6, Epoch 145/170 => Loss 3.701, Train_accy 76.670, Test_accy 53.010
2022-05-25 11:59:40,821 [bic.py] => bias_correction => Task 6, Epoch 146/170 => Loss 3.695, Train_accy 74.290, Test_accy 52.940
2022-05-25 11:59:42,532 [bic.py] => bias_correction => Task 6, Epoch 147/170 => Loss 3.712, Train_accy 75.710, Test_accy 52.960
2022-05-25 11:59:44,293 [bic.py] => bias_correction => Task 6, Epoch 148/170 => Loss 3.711, Train_accy 73.330, Test_accy 53.000
2022-05-25 11:59:46,071 [bic.py] => bias_correction => Task 6, Epoch 149/170 => Loss 3.706, Train_accy 73.330, Test_accy 52.870
2022-05-25 11:59:47,900 [bic.py] => bias_correction => Task 6, Epoch 150/170 => Loss 3.711, Train_accy 77.140, Test_accy 52.960
2022-05-25 11:59:49,598 [bic.py] => bias_correction => Task 6, Epoch 151/170 => Loss 3.707, Train_accy 71.900, Test_accy 52.930
2022-05-25 11:59:51,373 [bic.py] => bias_correction => Task 6, Epoch 152/170 => Loss 3.695, Train_accy 75.240, Test_accy 52.990
2022-05-25 11:59:53,155 [bic.py] => bias_correction => Task 6, Epoch 153/170 => Loss 3.711, Train_accy 75.240, Test_accy 52.840
2022-05-25 11:59:54,928 [bic.py] => bias_correction => Task 6, Epoch 154/170 => Loss 3.701, Train_accy 76.190, Test_accy 52.990
2022-05-25 11:59:56,658 [bic.py] => bias_correction => Task 6, Epoch 155/170 => Loss 3.705, Train_accy 73.330, Test_accy 52.940
2022-05-25 11:59:58,437 [bic.py] => bias_correction => Task 6, Epoch 156/170 => Loss 3.691, Train_accy 71.900, Test_accy 52.990
2022-05-25 12:00:00,179 [bic.py] => bias_correction => Task 6, Epoch 157/170 => Loss 3.698, Train_accy 75.710, Test_accy 52.910
2022-05-25 12:00:02,002 [bic.py] => bias_correction => Task 6, Epoch 158/170 => Loss 3.707, Train_accy 73.810, Test_accy 52.900
2022-05-25 12:00:03,737 [bic.py] => bias_correction => Task 6, Epoch 159/170 => Loss 3.709, Train_accy 71.430, Test_accy 52.930
2022-05-25 12:00:05,542 [bic.py] => bias_correction => Task 6, Epoch 160/170 => Loss 3.694, Train_accy 75.240, Test_accy 52.940
2022-05-25 12:00:07,264 [bic.py] => bias_correction => Task 6, Epoch 161/170 => Loss 3.714, Train_accy 72.860, Test_accy 53.000
2022-05-25 12:00:09,015 [bic.py] => bias_correction => Task 6, Epoch 162/170 => Loss 3.710, Train_accy 75.710, Test_accy 53.000
2022-05-25 12:00:10,795 [bic.py] => bias_correction => Task 6, Epoch 163/170 => Loss 3.713, Train_accy 73.810, Test_accy 52.970
2022-05-25 12:00:12,597 [bic.py] => bias_correction => Task 6, Epoch 164/170 => Loss 3.698, Train_accy 76.190, Test_accy 53.040
2022-05-25 12:00:14,426 [bic.py] => bias_correction => Task 6, Epoch 165/170 => Loss 3.710, Train_accy 71.900, Test_accy 52.910
2022-05-25 12:00:16,201 [bic.py] => bias_correction => Task 6, Epoch 166/170 => Loss 3.701, Train_accy 74.290, Test_accy 52.900
2022-05-25 12:00:17,936 [bic.py] => bias_correction => Task 6, Epoch 167/170 => Loss 3.697, Train_accy 76.670, Test_accy 52.890
2022-05-25 12:00:19,731 [bic.py] => bias_correction => Task 6, Epoch 168/170 => Loss 3.698, Train_accy 75.710, Test_accy 52.910
2022-05-25 12:00:21,512 [bic.py] => bias_correction => Task 6, Epoch 169/170 => Loss 3.696, Train_accy 72.860, Test_accy 52.970
2022-05-25 12:00:23,271 [bic.py] => bias_correction => Task 6, Epoch 170/170 => Loss 3.702, Train_accy 74.760, Test_accy 52.990
2022-05-25 12:00:23,272 [base.py] => Reducing exemplars...(28 per classes)
2022-05-25 12:00:35,787 [base.py] => Constructing exemplars...(28 per classes)
2022-05-25 12:00:40,817 [bic.py] => Parameters of bias layer:
2022-05-25 12:00:40,818 [bic.py] => 0 => 1.000, 0.000
2022-05-25 12:00:40,818 [bic.py] => 1 => 0.904, -1.125
2022-05-25 12:00:40,818 [bic.py] => 2 => 0.889, -1.948
2022-05-25 12:00:40,818 [bic.py] => 3 => 0.729, -1.345
2022-05-25 12:00:40,819 [bic.py] => 4 => 0.731, -1.321
2022-05-25 12:00:40,819 [bic.py] => 5 => 0.734, -1.140
2022-05-25 12:00:40,819 [bic.py] => 6 => 0.749, -1.468
2022-05-25 12:00:42,741 [bic.py] => Exemplar size: 1960
2022-05-25 12:00:42,741 [trainer.py] => CNN: {'total': 52.99, '00-09': 52.9, '10-19': 49.2, '20-29': 57.5, '30-39': 43.5, '40-49': 49.3, '50-59': 56.5, '60-69': 62.0, 'old': 51.48, 'new': 62.0}
2022-05-25 12:00:42,741 [trainer.py] => NME: {'total': 53.94, '00-09': 50.5, '10-19': 46.2, '20-29': 56.1, '30-39': 49.7, '40-49': 54.3, '50-59': 57.4, '60-69': 63.4, 'old': 52.37, 'new': 63.4}
2022-05-25 12:00:42,741 [trainer.py] => CNN top1 curve: [83.0, 73.7, 68.1, 62.2, 58.38, 55.52, 52.99]
2022-05-25 12:00:42,742 [trainer.py] => CNN top5 curve: [99.1, 95.65, 92.07, 89.1, 86.2, 84.27, 81.76]
2022-05-25 12:00:42,742 [trainer.py] => NME top1 curve: [82.8, 74.15, 67.37, 61.9, 58.1, 56.52, 53.94]
2022-05-25 12:00:42,742 [trainer.py] => NME top5 curve: [99.0, 95.75, 92.47, 89.32, 86.1, 84.15, 81.77]

2022-05-25 12:00:42,742 [trainer.py] => All params: 468718
2022-05-25 12:00:42,743 [trainer.py] => Trainable params: 468718
2022-05-25 12:00:42,744 [bic.py] => Learning on 70-80
2022-05-25 12:00:42,803 [bic.py] => Stage1 dset: 6800, Stage2 dset: 160
2022-05-25 12:00:42,803 [bic.py] => Lambda: 0.875
2022-05-25 12:00:42,830 [bic.py] => Parameters of bias layer:
2022-05-25 12:00:42,831 [bic.py] => 0 => 1.000, 0.000
2022-05-25 12:00:42,831 [bic.py] => 1 => 0.904, -1.125
2022-05-25 12:00:42,831 [bic.py] => 2 => 0.889, -1.948
2022-05-25 12:00:42,831 [bic.py] => 3 => 0.729, -1.345
2022-05-25 12:00:42,831 [bic.py] => 4 => 0.731, -1.321
2022-05-25 12:00:42,831 [bic.py] => 5 => 0.734, -1.140
2022-05-25 12:00:42,831 [bic.py] => 6 => 0.749, -1.468
2022-05-25 12:00:42,831 [bic.py] => 7 => 1.000, 0.000
2022-05-25 12:00:47,390 [bic.py] => training => Task 7, Epoch 1/170 => Loss 2.964, Train_accy 66.010, Test_accy 29.720
2022-05-25 12:00:51,934 [bic.py] => training => Task 7, Epoch 2/170 => Loss 2.900, Train_accy 68.060, Test_accy 30.510
2022-05-25 12:00:56,523 [bic.py] => training => Task 7, Epoch 3/170 => Loss 2.889, Train_accy 72.740, Test_accy 34.240
2022-05-25 12:01:01,165 [bic.py] => training => Task 7, Epoch 4/170 => Loss 2.892, Train_accy 73.280, Test_accy 35.800
2022-05-25 12:01:05,655 [bic.py] => training => Task 7, Epoch 5/170 => Loss 2.880, Train_accy 77.440, Test_accy 35.240
2022-05-25 12:01:10,204 [bic.py] => training => Task 7, Epoch 6/170 => Loss 2.865, Train_accy 72.600, Test_accy 33.750
2022-05-25 12:01:14,716 [bic.py] => training => Task 7, Epoch 7/170 => Loss 2.853, Train_accy 76.740, Test_accy 37.810
2022-05-25 12:01:19,237 [bic.py] => training => Task 7, Epoch 8/170 => Loss 2.864, Train_accy 75.990, Test_accy 33.060
2022-05-25 12:01:23,777 [bic.py] => training => Task 7, Epoch 9/170 => Loss 2.855, Train_accy 77.220, Test_accy 36.790
2022-05-25 12:01:28,394 [bic.py] => training => Task 7, Epoch 10/170 => Loss 2.845, Train_accy 75.040, Test_accy 34.200
2022-05-25 12:01:32,984 [bic.py] => training => Task 7, Epoch 11/170 => Loss 2.846, Train_accy 79.500, Test_accy 36.840
2022-05-25 12:01:37,511 [bic.py] => training => Task 7, Epoch 12/170 => Loss 2.839, Train_accy 82.400, Test_accy 38.950
2022-05-25 12:01:42,129 [bic.py] => training => Task 7, Epoch 13/170 => Loss 2.846, Train_accy 80.400, Test_accy 36.620
2022-05-25 12:01:46,765 [bic.py] => training => Task 7, Epoch 14/170 => Loss 2.839, Train_accy 81.820, Test_accy 34.670
2022-05-25 12:01:51,423 [bic.py] => training => Task 7, Epoch 15/170 => Loss 2.833, Train_accy 83.410, Test_accy 37.170
2022-05-25 12:01:56,013 [bic.py] => training => Task 7, Epoch 16/170 => Loss 2.839, Train_accy 81.790, Test_accy 35.920
2022-05-25 12:02:00,626 [bic.py] => training => Task 7, Epoch 17/170 => Loss 2.830, Train_accy 82.320, Test_accy 34.800
2022-05-25 12:02:05,052 [bic.py] => training => Task 7, Epoch 18/170 => Loss 2.832, Train_accy 80.760, Test_accy 34.290
2022-05-25 12:02:09,653 [bic.py] => training => Task 7, Epoch 19/170 => Loss 2.837, Train_accy 84.430, Test_accy 36.840
2022-05-25 12:02:14,375 [bic.py] => training => Task 7, Epoch 20/170 => Loss 2.839, Train_accy 84.490, Test_accy 36.640
2022-05-25 12:02:18,918 [bic.py] => training => Task 7, Epoch 21/170 => Loss 2.834, Train_accy 84.220, Test_accy 34.020
2022-05-25 12:02:23,536 [bic.py] => training => Task 7, Epoch 22/170 => Loss 2.829, Train_accy 84.310, Test_accy 36.960
2022-05-25 12:02:28,129 [bic.py] => training => Task 7, Epoch 23/170 => Loss 2.824, Train_accy 84.680, Test_accy 34.210
2022-05-25 12:02:32,783 [bic.py] => training => Task 7, Epoch 24/170 => Loss 2.820, Train_accy 86.510, Test_accy 35.760
2022-05-25 12:02:37,370 [bic.py] => training => Task 7, Epoch 25/170 => Loss 2.820, Train_accy 83.810, Test_accy 39.000
2022-05-25 12:02:41,911 [bic.py] => training => Task 7, Epoch 26/170 => Loss 2.831, Train_accy 84.220, Test_accy 35.420
2022-05-25 12:02:46,465 [bic.py] => training => Task 7, Epoch 27/170 => Loss 2.821, Train_accy 85.500, Test_accy 34.840
2022-05-25 12:02:51,331 [bic.py] => training => Task 7, Epoch 28/170 => Loss 2.818, Train_accy 82.320, Test_accy 38.940
2022-05-25 12:02:55,876 [bic.py] => training => Task 7, Epoch 29/170 => Loss 2.840, Train_accy 80.070, Test_accy 32.510
2022-05-25 12:03:00,535 [bic.py] => training => Task 7, Epoch 30/170 => Loss 2.819, Train_accy 86.660, Test_accy 38.750
2022-05-25 12:03:05,056 [bic.py] => training => Task 7, Epoch 31/170 => Loss 2.824, Train_accy 84.760, Test_accy 34.120
2022-05-25 12:03:09,707 [bic.py] => training => Task 7, Epoch 32/170 => Loss 2.834, Train_accy 88.780, Test_accy 40.160
2022-05-25 12:03:14,351 [bic.py] => training => Task 7, Epoch 33/170 => Loss 2.823, Train_accy 86.990, Test_accy 35.670
2022-05-25 12:03:19,201 [bic.py] => training => Task 7, Epoch 34/170 => Loss 2.810, Train_accy 86.880, Test_accy 35.220
2022-05-25 12:03:23,802 [bic.py] => training => Task 7, Epoch 35/170 => Loss 2.833, Train_accy 86.810, Test_accy 38.110
2022-05-25 12:03:28,398 [bic.py] => training => Task 7, Epoch 36/170 => Loss 2.814, Train_accy 87.910, Test_accy 36.400
2022-05-25 12:03:32,948 [bic.py] => training => Task 7, Epoch 37/170 => Loss 2.811, Train_accy 89.820, Test_accy 36.380
2022-05-25 12:03:37,472 [bic.py] => training => Task 7, Epoch 38/170 => Loss 2.816, Train_accy 86.510, Test_accy 32.690
2022-05-25 12:03:41,953 [bic.py] => training => Task 7, Epoch 39/170 => Loss 2.800, Train_accy 89.340, Test_accy 37.750
2022-05-25 12:03:46,270 [bic.py] => training => Task 7, Epoch 40/170 => Loss 2.810, Train_accy 88.410, Test_accy 36.220
2022-05-25 12:03:50,643 [bic.py] => training => Task 7, Epoch 41/170 => Loss 2.817, Train_accy 90.190, Test_accy 39.120
2022-05-25 12:03:55,237 [bic.py] => training => Task 7, Epoch 42/170 => Loss 2.811, Train_accy 88.400, Test_accy 35.860
2022-05-25 12:03:59,820 [bic.py] => training => Task 7, Epoch 43/170 => Loss 2.809, Train_accy 89.310, Test_accy 36.480
2022-05-25 12:04:04,448 [bic.py] => training => Task 7, Epoch 44/170 => Loss 2.817, Train_accy 90.060, Test_accy 38.450
2022-05-25 12:04:09,232 [bic.py] => training => Task 7, Epoch 45/170 => Loss 2.805, Train_accy 85.430, Test_accy 31.390
2022-05-25 12:04:13,893 [bic.py] => training => Task 7, Epoch 46/170 => Loss 2.815, Train_accy 87.150, Test_accy 36.300
2022-05-25 12:04:18,336 [bic.py] => training => Task 7, Epoch 47/170 => Loss 2.823, Train_accy 87.510, Test_accy 34.290
2022-05-25 12:04:22,970 [bic.py] => training => Task 7, Epoch 48/170 => Loss 2.809, Train_accy 89.970, Test_accy 37.670
2022-05-25 12:04:27,568 [bic.py] => training => Task 7, Epoch 49/170 => Loss 2.820, Train_accy 87.160, Test_accy 35.420
2022-05-25 12:04:32,261 [bic.py] => training => Task 7, Epoch 50/170 => Loss 2.819, Train_accy 90.570, Test_accy 37.460
2022-05-25 12:04:36,856 [bic.py] => training => Task 7, Epoch 51/170 => Loss 2.805, Train_accy 90.010, Test_accy 38.610
2022-05-25 12:04:41,610 [bic.py] => training => Task 7, Epoch 52/170 => Loss 2.805, Train_accy 88.210, Test_accy 40.410
2022-05-25 12:04:46,184 [bic.py] => training => Task 7, Epoch 53/170 => Loss 2.800, Train_accy 86.900, Test_accy 33.980
2022-05-25 12:04:50,716 [bic.py] => training => Task 7, Epoch 54/170 => Loss 2.806, Train_accy 85.350, Test_accy 33.610
2022-05-25 12:04:55,283 [bic.py] => training => Task 7, Epoch 55/170 => Loss 2.822, Train_accy 89.260, Test_accy 37.330
2022-05-25 12:04:59,922 [bic.py] => training => Task 7, Epoch 56/170 => Loss 2.811, Train_accy 88.240, Test_accy 34.420
2022-05-25 12:05:04,569 [bic.py] => training => Task 7, Epoch 57/170 => Loss 2.800, Train_accy 91.380, Test_accy 40.100
2022-05-25 12:05:09,182 [bic.py] => training => Task 7, Epoch 58/170 => Loss 2.809, Train_accy 89.750, Test_accy 40.490
2022-05-25 12:05:13,834 [bic.py] => training => Task 7, Epoch 59/170 => Loss 2.814, Train_accy 92.090, Test_accy 37.240
2022-05-25 12:05:18,436 [bic.py] => training => Task 7, Epoch 60/170 => Loss 2.807, Train_accy 86.970, Test_accy 35.590
2022-05-25 12:05:22,995 [bic.py] => training => Task 7, Epoch 61/170 => Loss 2.783, Train_accy 96.780, Test_accy 40.670
2022-05-25 12:05:27,607 [bic.py] => training => Task 7, Epoch 62/170 => Loss 2.773, Train_accy 97.280, Test_accy 41.810
2022-05-25 12:05:32,249 [bic.py] => training => Task 7, Epoch 63/170 => Loss 2.768, Train_accy 97.690, Test_accy 42.400
2022-05-25 12:05:37,013 [bic.py] => training => Task 7, Epoch 64/170 => Loss 2.765, Train_accy 97.710, Test_accy 41.440
2022-05-25 12:05:41,621 [bic.py] => training => Task 7, Epoch 65/170 => Loss 2.760, Train_accy 98.060, Test_accy 42.460
2022-05-25 12:05:46,262 [bic.py] => training => Task 7, Epoch 66/170 => Loss 2.760, Train_accy 98.030, Test_accy 41.960
2022-05-25 12:05:50,845 [bic.py] => training => Task 7, Epoch 67/170 => Loss 2.757, Train_accy 98.070, Test_accy 42.160
2022-05-25 12:05:55,450 [bic.py] => training => Task 7, Epoch 68/170 => Loss 2.760, Train_accy 98.210, Test_accy 42.140
2022-05-25 12:06:00,108 [bic.py] => training => Task 7, Epoch 69/170 => Loss 2.752, Train_accy 98.030, Test_accy 41.450
2022-05-25 12:06:04,911 [bic.py] => training => Task 7, Epoch 70/170 => Loss 2.755, Train_accy 98.000, Test_accy 41.690
2022-05-25 12:06:09,623 [bic.py] => training => Task 7, Epoch 71/170 => Loss 2.748, Train_accy 98.290, Test_accy 41.890
2022-05-25 12:06:14,281 [bic.py] => training => Task 7, Epoch 72/170 => Loss 2.746, Train_accy 98.500, Test_accy 42.080
2022-05-25 12:06:18,944 [bic.py] => training => Task 7, Epoch 73/170 => Loss 2.749, Train_accy 98.040, Test_accy 41.810
2022-05-25 12:06:23,873 [bic.py] => training => Task 7, Epoch 74/170 => Loss 2.754, Train_accy 98.560, Test_accy 42.380
2022-05-25 12:06:28,599 [bic.py] => training => Task 7, Epoch 75/170 => Loss 2.747, Train_accy 98.430, Test_accy 41.620
2022-05-25 12:06:33,403 [bic.py] => training => Task 7, Epoch 76/170 => Loss 2.748, Train_accy 98.740, Test_accy 41.780
2022-05-25 12:06:38,099 [bic.py] => training => Task 7, Epoch 77/170 => Loss 2.748, Train_accy 98.570, Test_accy 42.100
2022-05-25 12:06:42,728 [bic.py] => training => Task 7, Epoch 78/170 => Loss 2.746, Train_accy 98.350, Test_accy 41.980
2022-05-25 12:06:47,373 [bic.py] => training => Task 7, Epoch 79/170 => Loss 2.755, Train_accy 98.710, Test_accy 42.300
2022-05-25 12:06:52,073 [bic.py] => training => Task 7, Epoch 80/170 => Loss 2.749, Train_accy 98.620, Test_accy 41.710
2022-05-25 12:06:56,728 [bic.py] => training => Task 7, Epoch 81/170 => Loss 2.756, Train_accy 98.680, Test_accy 41.910
2022-05-25 12:07:01,366 [bic.py] => training => Task 7, Epoch 82/170 => Loss 2.745, Train_accy 98.510, Test_accy 41.910
2022-05-25 12:07:05,927 [bic.py] => training => Task 7, Epoch 83/170 => Loss 2.749, Train_accy 98.590, Test_accy 41.840
2022-05-25 12:07:10,493 [bic.py] => training => Task 7, Epoch 84/170 => Loss 2.742, Train_accy 98.620, Test_accy 41.510
2022-05-25 12:07:14,952 [bic.py] => training => Task 7, Epoch 85/170 => Loss 2.750, Train_accy 98.680, Test_accy 42.140
2022-05-25 12:07:19,658 [bic.py] => training => Task 7, Epoch 86/170 => Loss 2.748, Train_accy 98.680, Test_accy 41.760
2022-05-25 12:07:24,448 [bic.py] => training => Task 7, Epoch 87/170 => Loss 2.748, Train_accy 98.710, Test_accy 41.840
2022-05-25 12:07:29,037 [bic.py] => training => Task 7, Epoch 88/170 => Loss 2.747, Train_accy 98.350, Test_accy 41.500
2022-05-25 12:07:33,571 [bic.py] => training => Task 7, Epoch 89/170 => Loss 2.741, Train_accy 98.740, Test_accy 42.100
2022-05-25 12:07:38,160 [bic.py] => training => Task 7, Epoch 90/170 => Loss 2.747, Train_accy 98.930, Test_accy 41.910
2022-05-25 12:07:42,805 [bic.py] => training => Task 7, Epoch 91/170 => Loss 2.742, Train_accy 98.410, Test_accy 41.590
2022-05-25 12:07:47,497 [bic.py] => training => Task 7, Epoch 92/170 => Loss 2.750, Train_accy 98.960, Test_accy 41.520
2022-05-25 12:07:52,032 [bic.py] => training => Task 7, Epoch 93/170 => Loss 2.744, Train_accy 98.970, Test_accy 41.940
2022-05-25 12:07:56,605 [bic.py] => training => Task 7, Epoch 94/170 => Loss 2.745, Train_accy 98.720, Test_accy 41.900
2022-05-25 12:08:01,310 [bic.py] => training => Task 7, Epoch 95/170 => Loss 2.745, Train_accy 98.760, Test_accy 42.120
2022-05-25 12:08:05,901 [bic.py] => training => Task 7, Epoch 96/170 => Loss 2.745, Train_accy 98.870, Test_accy 42.360
2022-05-25 12:08:10,601 [bic.py] => training => Task 7, Epoch 97/170 => Loss 2.733, Train_accy 99.090, Test_accy 42.000
2022-05-25 12:08:15,226 [bic.py] => training => Task 7, Epoch 98/170 => Loss 2.748, Train_accy 99.010, Test_accy 42.200
2022-05-25 12:08:19,832 [bic.py] => training => Task 7, Epoch 99/170 => Loss 2.742, Train_accy 98.430, Test_accy 41.980
2022-05-25 12:08:24,404 [bic.py] => training => Task 7, Epoch 100/170 => Loss 2.744, Train_accy 98.680, Test_accy 41.980
2022-05-25 12:08:29,004 [bic.py] => training => Task 7, Epoch 101/170 => Loss 2.748, Train_accy 98.840, Test_accy 42.110
2022-05-25 12:08:33,835 [bic.py] => training => Task 7, Epoch 102/170 => Loss 2.751, Train_accy 99.070, Test_accy 42.360
2022-05-25 12:08:38,425 [bic.py] => training => Task 7, Epoch 103/170 => Loss 2.749, Train_accy 98.910, Test_accy 41.690
2022-05-25 12:08:42,971 [bic.py] => training => Task 7, Epoch 104/170 => Loss 2.744, Train_accy 98.880, Test_accy 41.700
2022-05-25 12:08:47,612 [bic.py] => training => Task 7, Epoch 105/170 => Loss 2.746, Train_accy 99.000, Test_accy 41.810
2022-05-25 12:08:52,234 [bic.py] => training => Task 7, Epoch 106/170 => Loss 2.746, Train_accy 98.740, Test_accy 41.660
2022-05-25 12:08:56,916 [bic.py] => training => Task 7, Epoch 107/170 => Loss 2.739, Train_accy 99.000, Test_accy 42.060
2022-05-25 12:09:01,594 [bic.py] => training => Task 7, Epoch 108/170 => Loss 2.749, Train_accy 98.990, Test_accy 41.560
2022-05-25 12:09:06,138 [bic.py] => training => Task 7, Epoch 109/170 => Loss 2.744, Train_accy 99.030, Test_accy 42.500
2022-05-25 12:09:10,828 [bic.py] => training => Task 7, Epoch 110/170 => Loss 2.740, Train_accy 98.870, Test_accy 42.190
2022-05-25 12:09:15,439 [bic.py] => training => Task 7, Epoch 111/170 => Loss 2.737, Train_accy 98.940, Test_accy 41.280
2022-05-25 12:09:20,104 [bic.py] => training => Task 7, Epoch 112/170 => Loss 2.743, Train_accy 98.930, Test_accy 41.310
2022-05-25 12:09:24,753 [bic.py] => training => Task 7, Epoch 113/170 => Loss 2.741, Train_accy 99.160, Test_accy 42.500
2022-05-25 12:09:29,404 [bic.py] => training => Task 7, Epoch 114/170 => Loss 2.740, Train_accy 99.040, Test_accy 42.160
2022-05-25 12:09:33,986 [bic.py] => training => Task 7, Epoch 115/170 => Loss 2.741, Train_accy 99.190, Test_accy 41.880
2022-05-25 12:09:38,659 [bic.py] => training => Task 7, Epoch 116/170 => Loss 2.738, Train_accy 99.060, Test_accy 41.860
2022-05-25 12:09:43,397 [bic.py] => training => Task 7, Epoch 117/170 => Loss 2.744, Train_accy 99.120, Test_accy 42.010
2022-05-25 12:09:48,149 [bic.py] => training => Task 7, Epoch 118/170 => Loss 2.741, Train_accy 98.820, Test_accy 42.240
2022-05-25 12:09:52,844 [bic.py] => training => Task 7, Epoch 119/170 => Loss 2.741, Train_accy 99.010, Test_accy 41.940
2022-05-25 12:09:57,574 [bic.py] => training => Task 7, Epoch 120/170 => Loss 2.740, Train_accy 99.000, Test_accy 42.240
2022-05-25 12:10:02,183 [bic.py] => training => Task 7, Epoch 121/170 => Loss 2.746, Train_accy 98.910, Test_accy 41.900
2022-05-25 12:10:06,778 [bic.py] => training => Task 7, Epoch 122/170 => Loss 2.745, Train_accy 99.130, Test_accy 42.100
2022-05-25 12:10:11,451 [bic.py] => training => Task 7, Epoch 123/170 => Loss 2.744, Train_accy 99.030, Test_accy 42.890
2022-05-25 12:10:16,061 [bic.py] => training => Task 7, Epoch 124/170 => Loss 2.743, Train_accy 98.790, Test_accy 42.020
2022-05-25 12:10:20,645 [bic.py] => training => Task 7, Epoch 125/170 => Loss 2.745, Train_accy 99.000, Test_accy 41.820
2022-05-25 12:10:25,236 [bic.py] => training => Task 7, Epoch 126/170 => Loss 2.748, Train_accy 98.870, Test_accy 41.820
2022-05-25 12:10:29,804 [bic.py] => training => Task 7, Epoch 127/170 => Loss 2.740, Train_accy 99.240, Test_accy 42.080
2022-05-25 12:10:34,287 [bic.py] => training => Task 7, Epoch 128/170 => Loss 2.735, Train_accy 99.120, Test_accy 41.650
2022-05-25 12:10:38,836 [bic.py] => training => Task 7, Epoch 129/170 => Loss 2.741, Train_accy 99.190, Test_accy 42.350
2022-05-25 12:10:43,609 [bic.py] => training => Task 7, Epoch 130/170 => Loss 2.735, Train_accy 99.010, Test_accy 42.080
2022-05-25 12:10:48,322 [bic.py] => training => Task 7, Epoch 131/170 => Loss 2.745, Train_accy 99.150, Test_accy 42.160
2022-05-25 12:10:52,926 [bic.py] => training => Task 7, Epoch 132/170 => Loss 2.740, Train_accy 99.220, Test_accy 41.700
2022-05-25 12:10:57,565 [bic.py] => training => Task 7, Epoch 133/170 => Loss 2.746, Train_accy 99.060, Test_accy 41.880
2022-05-25 12:11:02,102 [bic.py] => training => Task 7, Epoch 134/170 => Loss 2.736, Train_accy 99.240, Test_accy 42.260
2022-05-25 12:11:06,774 [bic.py] => training => Task 7, Epoch 135/170 => Loss 2.744, Train_accy 99.070, Test_accy 42.190
2022-05-25 12:11:11,469 [bic.py] => training => Task 7, Epoch 136/170 => Loss 2.748, Train_accy 99.040, Test_accy 42.150
2022-05-25 12:11:16,223 [bic.py] => training => Task 7, Epoch 137/170 => Loss 2.740, Train_accy 99.030, Test_accy 42.690
2022-05-25 12:11:20,820 [bic.py] => training => Task 7, Epoch 138/170 => Loss 2.741, Train_accy 99.060, Test_accy 41.800
2022-05-25 12:11:25,506 [bic.py] => training => Task 7, Epoch 139/170 => Loss 2.742, Train_accy 99.010, Test_accy 42.250
2022-05-25 12:11:30,109 [bic.py] => training => Task 7, Epoch 140/170 => Loss 2.741, Train_accy 98.960, Test_accy 41.580
2022-05-25 12:11:34,752 [bic.py] => training => Task 7, Epoch 141/170 => Loss 2.748, Train_accy 99.160, Test_accy 42.400
2022-05-25 12:11:39,334 [bic.py] => training => Task 7, Epoch 142/170 => Loss 2.735, Train_accy 98.990, Test_accy 41.590
2022-05-25 12:11:43,911 [bic.py] => training => Task 7, Epoch 143/170 => Loss 2.744, Train_accy 99.090, Test_accy 41.690
2022-05-25 12:11:48,583 [bic.py] => training => Task 7, Epoch 144/170 => Loss 2.739, Train_accy 99.130, Test_accy 42.420
2022-05-25 12:11:53,168 [bic.py] => training => Task 7, Epoch 145/170 => Loss 2.735, Train_accy 99.130, Test_accy 41.960
2022-05-25 12:11:57,803 [bic.py] => training => Task 7, Epoch 146/170 => Loss 2.745, Train_accy 99.130, Test_accy 42.010
2022-05-25 12:12:02,376 [bic.py] => training => Task 7, Epoch 147/170 => Loss 2.742, Train_accy 99.030, Test_accy 41.980
2022-05-25 12:12:06,934 [bic.py] => training => Task 7, Epoch 148/170 => Loss 2.739, Train_accy 99.090, Test_accy 42.410
2022-05-25 12:12:11,511 [bic.py] => training => Task 7, Epoch 149/170 => Loss 2.738, Train_accy 98.930, Test_accy 42.040
2022-05-25 12:12:16,225 [bic.py] => training => Task 7, Epoch 150/170 => Loss 2.747, Train_accy 98.740, Test_accy 41.920
2022-05-25 12:12:20,932 [bic.py] => training => Task 7, Epoch 151/170 => Loss 2.746, Train_accy 98.990, Test_accy 42.190
2022-05-25 12:12:25,618 [bic.py] => training => Task 7, Epoch 152/170 => Loss 2.742, Train_accy 98.900, Test_accy 42.040
2022-05-25 12:12:30,454 [bic.py] => training => Task 7, Epoch 153/170 => Loss 2.747, Train_accy 99.030, Test_accy 41.950
2022-05-25 12:12:35,098 [bic.py] => training => Task 7, Epoch 154/170 => Loss 2.741, Train_accy 98.960, Test_accy 41.640
2022-05-25 12:12:39,709 [bic.py] => training => Task 7, Epoch 155/170 => Loss 2.742, Train_accy 99.070, Test_accy 42.010
2022-05-25 12:12:44,366 [bic.py] => training => Task 7, Epoch 156/170 => Loss 2.740, Train_accy 99.090, Test_accy 41.560
2022-05-25 12:12:48,894 [bic.py] => training => Task 7, Epoch 157/170 => Loss 2.745, Train_accy 98.960, Test_accy 41.680
2022-05-25 12:12:53,530 [bic.py] => training => Task 7, Epoch 158/170 => Loss 2.743, Train_accy 99.070, Test_accy 42.400
2022-05-25 12:12:58,028 [bic.py] => training => Task 7, Epoch 159/170 => Loss 2.738, Train_accy 99.100, Test_accy 42.180
2022-05-25 12:13:02,884 [bic.py] => training => Task 7, Epoch 160/170 => Loss 2.738, Train_accy 99.030, Test_accy 42.100
2022-05-25 12:13:07,572 [bic.py] => training => Task 7, Epoch 161/170 => Loss 2.741, Train_accy 99.040, Test_accy 41.760
2022-05-25 12:13:11,955 [bic.py] => training => Task 7, Epoch 162/170 => Loss 2.744, Train_accy 99.120, Test_accy 41.920
2022-05-25 12:13:16,622 [bic.py] => training => Task 7, Epoch 163/170 => Loss 2.741, Train_accy 99.180, Test_accy 42.040
2022-05-25 12:13:21,274 [bic.py] => training => Task 7, Epoch 164/170 => Loss 2.736, Train_accy 99.010, Test_accy 41.820
2022-05-25 12:13:26,114 [bic.py] => training => Task 7, Epoch 165/170 => Loss 2.745, Train_accy 99.010, Test_accy 42.200
2022-05-25 12:13:30,851 [bic.py] => training => Task 7, Epoch 166/170 => Loss 2.739, Train_accy 99.190, Test_accy 42.160
2022-05-25 12:13:35,604 [bic.py] => training => Task 7, Epoch 167/170 => Loss 2.744, Train_accy 98.840, Test_accy 42.060
2022-05-25 12:13:40,398 [bic.py] => training => Task 7, Epoch 168/170 => Loss 2.740, Train_accy 98.880, Test_accy 42.350
2022-05-25 12:13:45,217 [bic.py] => training => Task 7, Epoch 169/170 => Loss 2.739, Train_accy 99.000, Test_accy 41.950
2022-05-25 12:13:49,808 [bic.py] => training => Task 7, Epoch 170/170 => Loss 2.740, Train_accy 98.930, Test_accy 41.700
2022-05-25 12:13:51,581 [bic.py] => bias_correction => Task 7, Epoch 1/170 => Loss 3.992, Train_accy 60.000, Test_accy 44.320
2022-05-25 12:13:53,418 [bic.py] => bias_correction => Task 7, Epoch 2/170 => Loss 4.026, Train_accy 70.620, Test_accy 48.720
2022-05-25 12:13:55,266 [bic.py] => bias_correction => Task 7, Epoch 3/170 => Loss 3.914, Train_accy 75.620, Test_accy 49.420
2022-05-25 12:13:57,063 [bic.py] => bias_correction => Task 7, Epoch 4/170 => Loss 3.899, Train_accy 68.750, Test_accy 46.600
2022-05-25 12:13:58,881 [bic.py] => bias_correction => Task 7, Epoch 5/170 => Loss 3.909, Train_accy 70.000, Test_accy 45.550
2022-05-25 12:14:00,769 [bic.py] => bias_correction => Task 7, Epoch 6/170 => Loss 3.907, Train_accy 65.620, Test_accy 45.520
2022-05-25 12:14:02,576 [bic.py] => bias_correction => Task 7, Epoch 7/170 => Loss 3.930, Train_accy 65.620, Test_accy 45.220
2022-05-25 12:14:04,369 [bic.py] => bias_correction => Task 7, Epoch 8/170 => Loss 3.927, Train_accy 68.120, Test_accy 45.290
2022-05-25 12:14:06,121 [bic.py] => bias_correction => Task 7, Epoch 9/170 => Loss 3.940, Train_accy 67.500, Test_accy 45.100
2022-05-25 12:14:08,004 [bic.py] => bias_correction => Task 7, Epoch 10/170 => Loss 3.953, Train_accy 68.750, Test_accy 45.100
2022-05-25 12:14:09,817 [bic.py] => bias_correction => Task 7, Epoch 11/170 => Loss 3.929, Train_accy 67.500, Test_accy 45.060
2022-05-25 12:14:11,633 [bic.py] => bias_correction => Task 7, Epoch 12/170 => Loss 3.944, Train_accy 65.620, Test_accy 45.040
2022-05-25 12:14:13,501 [bic.py] => bias_correction => Task 7, Epoch 13/170 => Loss 3.903, Train_accy 66.250, Test_accy 45.010
2022-05-25 12:14:15,292 [bic.py] => bias_correction => Task 7, Epoch 14/170 => Loss 3.949, Train_accy 65.620, Test_accy 44.820
2022-05-25 12:14:17,128 [bic.py] => bias_correction => Task 7, Epoch 15/170 => Loss 3.895, Train_accy 69.380, Test_accy 45.060
2022-05-25 12:14:18,908 [bic.py] => bias_correction => Task 7, Epoch 16/170 => Loss 3.933, Train_accy 65.620, Test_accy 44.880
2022-05-25 12:14:20,698 [bic.py] => bias_correction => Task 7, Epoch 17/170 => Loss 3.915, Train_accy 66.250, Test_accy 44.850
2022-05-25 12:14:22,487 [bic.py] => bias_correction => Task 7, Epoch 18/170 => Loss 3.900, Train_accy 64.380, Test_accy 44.920
2022-05-25 12:14:24,313 [bic.py] => bias_correction => Task 7, Epoch 19/170 => Loss 3.914, Train_accy 70.000, Test_accy 44.850
2022-05-25 12:14:26,099 [bic.py] => bias_correction => Task 7, Epoch 20/170 => Loss 3.959, Train_accy 68.120, Test_accy 44.820
2022-05-25 12:14:27,982 [bic.py] => bias_correction => Task 7, Epoch 21/170 => Loss 3.922, Train_accy 69.380, Test_accy 44.600
2022-05-25 12:14:29,794 [bic.py] => bias_correction => Task 7, Epoch 22/170 => Loss 3.930, Train_accy 67.500, Test_accy 44.610
2022-05-25 12:14:31,657 [bic.py] => bias_correction => Task 7, Epoch 23/170 => Loss 3.920, Train_accy 65.000, Test_accy 44.520
2022-05-25 12:14:33,515 [bic.py] => bias_correction => Task 7, Epoch 24/170 => Loss 3.942, Train_accy 69.380, Test_accy 44.500
2022-05-25 12:14:35,370 [bic.py] => bias_correction => Task 7, Epoch 25/170 => Loss 3.956, Train_accy 67.500, Test_accy 44.640
2022-05-25 12:14:37,206 [bic.py] => bias_correction => Task 7, Epoch 26/170 => Loss 3.912, Train_accy 66.250, Test_accy 44.510
2022-05-25 12:14:39,068 [bic.py] => bias_correction => Task 7, Epoch 27/170 => Loss 3.922, Train_accy 65.620, Test_accy 44.420
2022-05-25 12:14:40,954 [bic.py] => bias_correction => Task 7, Epoch 28/170 => Loss 3.915, Train_accy 68.120, Test_accy 44.600
2022-05-25 12:14:42,822 [bic.py] => bias_correction => Task 7, Epoch 29/170 => Loss 3.878, Train_accy 65.000, Test_accy 44.510
2022-05-25 12:14:44,661 [bic.py] => bias_correction => Task 7, Epoch 30/170 => Loss 3.902, Train_accy 68.750, Test_accy 44.410
2022-05-25 12:14:46,490 [bic.py] => bias_correction => Task 7, Epoch 31/170 => Loss 3.937, Train_accy 69.380, Test_accy 44.540
2022-05-25 12:14:48,305 [bic.py] => bias_correction => Task 7, Epoch 32/170 => Loss 3.908, Train_accy 66.250, Test_accy 44.790
2022-05-25 12:14:50,150 [bic.py] => bias_correction => Task 7, Epoch 33/170 => Loss 3.915, Train_accy 69.380, Test_accy 44.840
2022-05-25 12:14:51,991 [bic.py] => bias_correction => Task 7, Epoch 34/170 => Loss 3.922, Train_accy 68.120, Test_accy 44.890
2022-05-25 12:14:53,841 [bic.py] => bias_correction => Task 7, Epoch 35/170 => Loss 3.889, Train_accy 66.250, Test_accy 44.840
2022-05-25 12:14:55,676 [bic.py] => bias_correction => Task 7, Epoch 36/170 => Loss 3.919, Train_accy 69.380, Test_accy 44.890
2022-05-25 12:14:57,496 [bic.py] => bias_correction => Task 7, Epoch 37/170 => Loss 3.939, Train_accy 68.750, Test_accy 44.660
2022-05-25 12:14:59,267 [bic.py] => bias_correction => Task 7, Epoch 38/170 => Loss 3.931, Train_accy 65.620, Test_accy 44.640
2022-05-25 12:15:01,116 [bic.py] => bias_correction => Task 7, Epoch 39/170 => Loss 3.951, Train_accy 68.120, Test_accy 44.760
2022-05-25 12:15:03,038 [bic.py] => bias_correction => Task 7, Epoch 40/170 => Loss 3.908, Train_accy 70.620, Test_accy 44.650
2022-05-25 12:15:04,893 [bic.py] => bias_correction => Task 7, Epoch 41/170 => Loss 3.875, Train_accy 65.620, Test_accy 44.490
2022-05-25 12:15:06,721 [bic.py] => bias_correction => Task 7, Epoch 42/170 => Loss 3.904, Train_accy 71.250, Test_accy 44.440
2022-05-25 12:15:08,515 [bic.py] => bias_correction => Task 7, Epoch 43/170 => Loss 3.905, Train_accy 68.120, Test_accy 44.510
2022-05-25 12:15:10,344 [bic.py] => bias_correction => Task 7, Epoch 44/170 => Loss 3.939, Train_accy 66.880, Test_accy 44.540
2022-05-25 12:15:12,176 [bic.py] => bias_correction => Task 7, Epoch 45/170 => Loss 3.926, Train_accy 67.500, Test_accy 44.520
2022-05-25 12:15:13,960 [bic.py] => bias_correction => Task 7, Epoch 46/170 => Loss 3.921, Train_accy 70.000, Test_accy 44.610
2022-05-25 12:15:15,827 [bic.py] => bias_correction => Task 7, Epoch 47/170 => Loss 3.959, Train_accy 65.000, Test_accy 44.610
2022-05-25 12:15:17,544 [bic.py] => bias_correction => Task 7, Epoch 48/170 => Loss 3.957, Train_accy 66.880, Test_accy 44.610
2022-05-25 12:15:19,324 [bic.py] => bias_correction => Task 7, Epoch 49/170 => Loss 3.896, Train_accy 65.000, Test_accy 44.710
2022-05-25 12:15:21,175 [bic.py] => bias_correction => Task 7, Epoch 50/170 => Loss 3.908, Train_accy 63.120, Test_accy 44.700
2022-05-25 12:15:22,926 [bic.py] => bias_correction => Task 7, Epoch 51/170 => Loss 3.932, Train_accy 70.000, Test_accy 44.540
2022-05-25 12:15:24,635 [bic.py] => bias_correction => Task 7, Epoch 52/170 => Loss 3.972, Train_accy 68.750, Test_accy 44.660
2022-05-25 12:15:26,526 [bic.py] => bias_correction => Task 7, Epoch 53/170 => Loss 3.925, Train_accy 67.500, Test_accy 44.760
2022-05-25 12:15:28,303 [bic.py] => bias_correction => Task 7, Epoch 54/170 => Loss 3.920, Train_accy 69.380, Test_accy 44.780
2022-05-25 12:15:30,076 [bic.py] => bias_correction => Task 7, Epoch 55/170 => Loss 3.930, Train_accy 66.250, Test_accy 45.040
2022-05-25 12:15:31,870 [bic.py] => bias_correction => Task 7, Epoch 56/170 => Loss 3.935, Train_accy 66.880, Test_accy 44.910
2022-05-25 12:15:33,783 [bic.py] => bias_correction => Task 7, Epoch 57/170 => Loss 3.939, Train_accy 68.750, Test_accy 44.910
2022-05-25 12:15:35,615 [bic.py] => bias_correction => Task 7, Epoch 58/170 => Loss 3.914, Train_accy 67.500, Test_accy 44.950
2022-05-25 12:15:37,431 [bic.py] => bias_correction => Task 7, Epoch 59/170 => Loss 3.941, Train_accy 67.500, Test_accy 45.010
2022-05-25 12:15:39,271 [bic.py] => bias_correction => Task 7, Epoch 60/170 => Loss 3.887, Train_accy 67.500, Test_accy 44.900
2022-05-25 12:15:41,127 [bic.py] => bias_correction => Task 7, Epoch 61/170 => Loss 3.929, Train_accy 68.120, Test_accy 44.820
2022-05-25 12:15:43,037 [bic.py] => bias_correction => Task 7, Epoch 62/170 => Loss 3.921, Train_accy 67.500, Test_accy 44.780
2022-05-25 12:15:44,814 [bic.py] => bias_correction => Task 7, Epoch 63/170 => Loss 3.943, Train_accy 67.500, Test_accy 44.780
2022-05-25 12:15:46,523 [bic.py] => bias_correction => Task 7, Epoch 64/170 => Loss 3.930, Train_accy 64.380, Test_accy 44.700
2022-05-25 12:15:48,353 [bic.py] => bias_correction => Task 7, Epoch 65/170 => Loss 3.943, Train_accy 67.500, Test_accy 44.880
2022-05-25 12:15:50,181 [bic.py] => bias_correction => Task 7, Epoch 66/170 => Loss 3.936, Train_accy 68.750, Test_accy 44.950
2022-05-25 12:15:52,092 [bic.py] => bias_correction => Task 7, Epoch 67/170 => Loss 3.953, Train_accy 68.750, Test_accy 44.620
2022-05-25 12:15:54,196 [bic.py] => bias_correction => Task 7, Epoch 68/170 => Loss 3.931, Train_accy 65.620, Test_accy 44.660
2022-05-25 12:15:55,995 [bic.py] => bias_correction => Task 7, Epoch 69/170 => Loss 3.930, Train_accy 68.120, Test_accy 44.640
2022-05-25 12:15:57,788 [bic.py] => bias_correction => Task 7, Epoch 70/170 => Loss 3.906, Train_accy 67.500, Test_accy 44.460
2022-05-25 12:15:59,545 [bic.py] => bias_correction => Task 7, Epoch 71/170 => Loss 3.964, Train_accy 66.880, Test_accy 44.410
2022-05-25 12:16:01,429 [bic.py] => bias_correction => Task 7, Epoch 72/170 => Loss 3.965, Train_accy 63.750, Test_accy 44.490
2022-05-25 12:16:03,277 [bic.py] => bias_correction => Task 7, Epoch 73/170 => Loss 3.905, Train_accy 68.750, Test_accy 44.380
2022-05-25 12:16:05,102 [bic.py] => bias_correction => Task 7, Epoch 74/170 => Loss 3.921, Train_accy 67.500, Test_accy 44.510
2022-05-25 12:16:06,930 [bic.py] => bias_correction => Task 7, Epoch 75/170 => Loss 3.919, Train_accy 69.380, Test_accy 44.480
2022-05-25 12:16:08,708 [bic.py] => bias_correction => Task 7, Epoch 76/170 => Loss 3.905, Train_accy 66.880, Test_accy 44.380
2022-05-25 12:16:10,707 [bic.py] => bias_correction => Task 7, Epoch 77/170 => Loss 3.887, Train_accy 70.620, Test_accy 44.400
2022-05-25 12:16:12,506 [bic.py] => bias_correction => Task 7, Epoch 78/170 => Loss 3.921, Train_accy 69.380, Test_accy 44.590
2022-05-25 12:16:14,346 [bic.py] => bias_correction => Task 7, Epoch 79/170 => Loss 3.896, Train_accy 66.250, Test_accy 44.580
2022-05-25 12:16:16,192 [bic.py] => bias_correction => Task 7, Epoch 80/170 => Loss 3.947, Train_accy 65.000, Test_accy 44.540
2022-05-25 12:16:18,028 [bic.py] => bias_correction => Task 7, Epoch 81/170 => Loss 3.954, Train_accy 68.750, Test_accy 44.600
2022-05-25 12:16:19,927 [bic.py] => bias_correction => Task 7, Epoch 82/170 => Loss 3.913, Train_accy 66.880, Test_accy 44.680
2022-05-25 12:16:21,810 [bic.py] => bias_correction => Task 7, Epoch 83/170 => Loss 3.919, Train_accy 70.000, Test_accy 44.740
2022-05-25 12:16:23,558 [bic.py] => bias_correction => Task 7, Epoch 84/170 => Loss 3.919, Train_accy 71.880, Test_accy 44.520
2022-05-25 12:16:25,335 [bic.py] => bias_correction => Task 7, Epoch 85/170 => Loss 3.960, Train_accy 69.380, Test_accy 44.690
2022-05-25 12:16:27,102 [bic.py] => bias_correction => Task 7, Epoch 86/170 => Loss 3.941, Train_accy 65.000, Test_accy 44.810
2022-05-25 12:16:28,881 [bic.py] => bias_correction => Task 7, Epoch 87/170 => Loss 3.966, Train_accy 67.500, Test_accy 44.720
2022-05-25 12:16:30,724 [bic.py] => bias_correction => Task 7, Epoch 88/170 => Loss 3.926, Train_accy 68.120, Test_accy 44.560
2022-05-25 12:16:32,710 [bic.py] => bias_correction => Task 7, Epoch 89/170 => Loss 3.933, Train_accy 62.500, Test_accy 44.510
2022-05-25 12:16:34,489 [bic.py] => bias_correction => Task 7, Epoch 90/170 => Loss 3.947, Train_accy 67.500, Test_accy 44.700
2022-05-25 12:16:36,340 [bic.py] => bias_correction => Task 7, Epoch 91/170 => Loss 3.954, Train_accy 66.250, Test_accy 44.610
2022-05-25 12:16:38,204 [bic.py] => bias_correction => Task 7, Epoch 92/170 => Loss 3.938, Train_accy 67.500, Test_accy 44.520
2022-05-25 12:16:39,988 [bic.py] => bias_correction => Task 7, Epoch 93/170 => Loss 3.957, Train_accy 67.500, Test_accy 44.680
2022-05-25 12:16:41,762 [bic.py] => bias_correction => Task 7, Epoch 94/170 => Loss 3.915, Train_accy 69.380, Test_accy 44.580
2022-05-25 12:16:43,635 [bic.py] => bias_correction => Task 7, Epoch 95/170 => Loss 3.939, Train_accy 65.000, Test_accy 44.690
2022-05-25 12:16:45,524 [bic.py] => bias_correction => Task 7, Epoch 96/170 => Loss 3.913, Train_accy 67.500, Test_accy 44.600
2022-05-25 12:16:47,329 [bic.py] => bias_correction => Task 7, Epoch 97/170 => Loss 3.938, Train_accy 68.120, Test_accy 44.750
2022-05-25 12:16:49,271 [bic.py] => bias_correction => Task 7, Epoch 98/170 => Loss 3.930, Train_accy 66.250, Test_accy 44.740
2022-05-25 12:16:51,007 [bic.py] => bias_correction => Task 7, Epoch 99/170 => Loss 3.911, Train_accy 66.250, Test_accy 44.740
2022-05-25 12:16:52,854 [bic.py] => bias_correction => Task 7, Epoch 100/170 => Loss 3.942, Train_accy 68.120, Test_accy 45.050
2022-05-25 12:16:54,719 [bic.py] => bias_correction => Task 7, Epoch 101/170 => Loss 3.916, Train_accy 72.500, Test_accy 44.920
2022-05-25 12:16:56,460 [bic.py] => bias_correction => Task 7, Epoch 102/170 => Loss 3.907, Train_accy 68.750, Test_accy 44.900
2022-05-25 12:16:58,178 [bic.py] => bias_correction => Task 7, Epoch 103/170 => Loss 3.900, Train_accy 70.620, Test_accy 44.950
2022-05-25 12:17:00,049 [bic.py] => bias_correction => Task 7, Epoch 104/170 => Loss 3.882, Train_accy 65.620, Test_accy 44.780
2022-05-25 12:17:01,843 [bic.py] => bias_correction => Task 7, Epoch 105/170 => Loss 3.927, Train_accy 68.120, Test_accy 44.920
2022-05-25 12:17:03,570 [bic.py] => bias_correction => Task 7, Epoch 106/170 => Loss 3.930, Train_accy 68.120, Test_accy 44.710
2022-05-25 12:17:05,450 [bic.py] => bias_correction => Task 7, Epoch 107/170 => Loss 3.938, Train_accy 66.880, Test_accy 44.690
2022-05-25 12:17:07,236 [bic.py] => bias_correction => Task 7, Epoch 108/170 => Loss 3.904, Train_accy 66.880, Test_accy 44.750
2022-05-25 12:17:09,086 [bic.py] => bias_correction => Task 7, Epoch 109/170 => Loss 3.912, Train_accy 69.380, Test_accy 44.690
2022-05-25 12:17:10,967 [bic.py] => bias_correction => Task 7, Epoch 110/170 => Loss 3.916, Train_accy 68.120, Test_accy 44.740
2022-05-25 12:17:12,760 [bic.py] => bias_correction => Task 7, Epoch 111/170 => Loss 3.921, Train_accy 67.500, Test_accy 44.800
2022-05-25 12:17:14,613 [bic.py] => bias_correction => Task 7, Epoch 112/170 => Loss 3.903, Train_accy 66.250, Test_accy 44.680
2022-05-25 12:17:16,495 [bic.py] => bias_correction => Task 7, Epoch 113/170 => Loss 3.860, Train_accy 67.500, Test_accy 44.650
2022-05-25 12:17:18,347 [bic.py] => bias_correction => Task 7, Epoch 114/170 => Loss 3.984, Train_accy 71.250, Test_accy 44.700
2022-05-25 12:17:20,147 [bic.py] => bias_correction => Task 7, Epoch 115/170 => Loss 3.902, Train_accy 67.500, Test_accy 44.710
2022-05-25 12:17:22,000 [bic.py] => bias_correction => Task 7, Epoch 116/170 => Loss 3.935, Train_accy 70.000, Test_accy 44.760
2022-05-25 12:17:23,827 [bic.py] => bias_correction => Task 7, Epoch 117/170 => Loss 3.924, Train_accy 66.880, Test_accy 44.810
2022-05-25 12:17:25,563 [bic.py] => bias_correction => Task 7, Epoch 118/170 => Loss 3.927, Train_accy 63.120, Test_accy 44.690
2022-05-25 12:17:27,307 [bic.py] => bias_correction => Task 7, Epoch 119/170 => Loss 3.933, Train_accy 66.880, Test_accy 44.850
2022-05-25 12:17:29,166 [bic.py] => bias_correction => Task 7, Epoch 120/170 => Loss 3.912, Train_accy 70.000, Test_accy 44.820
2022-05-25 12:17:31,079 [bic.py] => bias_correction => Task 7, Epoch 121/170 => Loss 3.931, Train_accy 65.000, Test_accy 44.990
2022-05-25 12:17:32,981 [bic.py] => bias_correction => Task 7, Epoch 122/170 => Loss 3.903, Train_accy 69.380, Test_accy 44.820
2022-05-25 12:17:34,734 [bic.py] => bias_correction => Task 7, Epoch 123/170 => Loss 3.922, Train_accy 68.120, Test_accy 44.880
2022-05-25 12:17:36,632 [bic.py] => bias_correction => Task 7, Epoch 124/170 => Loss 3.913, Train_accy 68.750, Test_accy 44.840
2022-05-25 12:17:38,485 [bic.py] => bias_correction => Task 7, Epoch 125/170 => Loss 3.945, Train_accy 66.250, Test_accy 44.790
2022-05-25 12:17:40,366 [bic.py] => bias_correction => Task 7, Epoch 126/170 => Loss 3.918, Train_accy 70.000, Test_accy 44.600
2022-05-25 12:17:42,205 [bic.py] => bias_correction => Task 7, Epoch 127/170 => Loss 3.911, Train_accy 71.250, Test_accy 44.650
2022-05-25 12:17:43,935 [bic.py] => bias_correction => Task 7, Epoch 128/170 => Loss 3.881, Train_accy 67.500, Test_accy 44.750
2022-05-25 12:17:45,699 [bic.py] => bias_correction => Task 7, Epoch 129/170 => Loss 3.925, Train_accy 70.000, Test_accy 44.790
2022-05-25 12:17:47,521 [bic.py] => bias_correction => Task 7, Epoch 130/170 => Loss 3.943, Train_accy 66.250, Test_accy 44.850
2022-05-25 12:17:49,405 [bic.py] => bias_correction => Task 7, Epoch 131/170 => Loss 3.917, Train_accy 65.620, Test_accy 44.790
2022-05-25 12:17:51,204 [bic.py] => bias_correction => Task 7, Epoch 132/170 => Loss 3.907, Train_accy 68.120, Test_accy 44.910
2022-05-25 12:17:53,038 [bic.py] => bias_correction => Task 7, Epoch 133/170 => Loss 3.931, Train_accy 69.380, Test_accy 44.800
2022-05-25 12:17:54,761 [bic.py] => bias_correction => Task 7, Epoch 134/170 => Loss 3.893, Train_accy 69.380, Test_accy 44.740
2022-05-25 12:17:56,571 [bic.py] => bias_correction => Task 7, Epoch 135/170 => Loss 3.938, Train_accy 67.500, Test_accy 44.620
2022-05-25 12:17:58,421 [bic.py] => bias_correction => Task 7, Epoch 136/170 => Loss 3.943, Train_accy 70.620, Test_accy 44.390
2022-05-25 12:18:00,174 [bic.py] => bias_correction => Task 7, Epoch 137/170 => Loss 3.941, Train_accy 63.750, Test_accy 44.610
2022-05-25 12:18:01,886 [bic.py] => bias_correction => Task 7, Epoch 138/170 => Loss 3.911, Train_accy 67.500, Test_accy 44.690
2022-05-25 12:18:03,732 [bic.py] => bias_correction => Task 7, Epoch 139/170 => Loss 3.967, Train_accy 66.250, Test_accy 44.560
2022-05-25 12:18:05,568 [bic.py] => bias_correction => Task 7, Epoch 140/170 => Loss 3.929, Train_accy 73.120, Test_accy 44.640
2022-05-25 12:18:07,378 [bic.py] => bias_correction => Task 7, Epoch 141/170 => Loss 3.914, Train_accy 65.620, Test_accy 44.810
2022-05-25 12:18:09,228 [bic.py] => bias_correction => Task 7, Epoch 142/170 => Loss 3.947, Train_accy 67.500, Test_accy 44.490
2022-05-25 12:18:11,018 [bic.py] => bias_correction => Task 7, Epoch 143/170 => Loss 3.937, Train_accy 67.500, Test_accy 44.280
2022-05-25 12:18:12,736 [bic.py] => bias_correction => Task 7, Epoch 144/170 => Loss 3.958, Train_accy 67.500, Test_accy 44.450
2022-05-25 12:18:14,543 [bic.py] => bias_correction => Task 7, Epoch 145/170 => Loss 3.946, Train_accy 66.250, Test_accy 44.700
2022-05-25 12:18:16,373 [bic.py] => bias_correction => Task 7, Epoch 146/170 => Loss 3.928, Train_accy 71.250, Test_accy 44.800
2022-05-25 12:18:18,189 [bic.py] => bias_correction => Task 7, Epoch 147/170 => Loss 3.949, Train_accy 68.120, Test_accy 44.680
2022-05-25 12:18:19,998 [bic.py] => bias_correction => Task 7, Epoch 148/170 => Loss 3.945, Train_accy 67.500, Test_accy 44.750
2022-05-25 12:18:21,784 [bic.py] => bias_correction => Task 7, Epoch 149/170 => Loss 3.940, Train_accy 66.880, Test_accy 44.720
2022-05-25 12:18:23,567 [bic.py] => bias_correction => Task 7, Epoch 150/170 => Loss 3.959, Train_accy 68.120, Test_accy 44.700
2022-05-25 12:18:25,452 [bic.py] => bias_correction => Task 7, Epoch 151/170 => Loss 3.935, Train_accy 70.620, Test_accy 44.440
2022-05-25 12:18:27,334 [bic.py] => bias_correction => Task 7, Epoch 152/170 => Loss 3.946, Train_accy 67.500, Test_accy 44.420
2022-05-25 12:18:29,099 [bic.py] => bias_correction => Task 7, Epoch 153/170 => Loss 3.934, Train_accy 63.750, Test_accy 44.420
2022-05-25 12:18:30,901 [bic.py] => bias_correction => Task 7, Epoch 154/170 => Loss 3.917, Train_accy 69.380, Test_accy 44.600
2022-05-25 12:18:32,676 [bic.py] => bias_correction => Task 7, Epoch 155/170 => Loss 3.933, Train_accy 68.120, Test_accy 44.550
2022-05-25 12:18:34,458 [bic.py] => bias_correction => Task 7, Epoch 156/170 => Loss 3.941, Train_accy 66.250, Test_accy 44.620
2022-05-25 12:18:36,266 [bic.py] => bias_correction => Task 7, Epoch 157/170 => Loss 3.904, Train_accy 64.380, Test_accy 44.620
2022-05-25 12:18:38,057 [bic.py] => bias_correction => Task 7, Epoch 158/170 => Loss 3.906, Train_accy 69.380, Test_accy 44.640
2022-05-25 12:18:39,898 [bic.py] => bias_correction => Task 7, Epoch 159/170 => Loss 3.954, Train_accy 67.500, Test_accy 44.880
2022-05-25 12:18:41,726 [bic.py] => bias_correction => Task 7, Epoch 160/170 => Loss 3.948, Train_accy 69.380, Test_accy 44.810
2022-05-25 12:18:43,485 [bic.py] => bias_correction => Task 7, Epoch 161/170 => Loss 3.896, Train_accy 68.750, Test_accy 44.820
2022-05-25 12:18:45,230 [bic.py] => bias_correction => Task 7, Epoch 162/170 => Loss 3.899, Train_accy 68.750, Test_accy 44.760
2022-05-25 12:18:47,233 [bic.py] => bias_correction => Task 7, Epoch 163/170 => Loss 3.956, Train_accy 63.750, Test_accy 44.790
2022-05-25 12:18:49,123 [bic.py] => bias_correction => Task 7, Epoch 164/170 => Loss 3.925, Train_accy 65.620, Test_accy 44.940
2022-05-25 12:18:50,940 [bic.py] => bias_correction => Task 7, Epoch 165/170 => Loss 3.938, Train_accy 66.880, Test_accy 44.690
2022-05-25 12:18:52,777 [bic.py] => bias_correction => Task 7, Epoch 166/170 => Loss 3.921, Train_accy 68.750, Test_accy 44.760
2022-05-25 12:18:54,617 [bic.py] => bias_correction => Task 7, Epoch 167/170 => Loss 3.919, Train_accy 69.380, Test_accy 44.720
2022-05-25 12:18:56,433 [bic.py] => bias_correction => Task 7, Epoch 168/170 => Loss 3.902, Train_accy 68.750, Test_accy 44.410
2022-05-25 12:18:58,295 [bic.py] => bias_correction => Task 7, Epoch 169/170 => Loss 3.911, Train_accy 69.380, Test_accy 44.500
2022-05-25 12:19:00,077 [bic.py] => bias_correction => Task 7, Epoch 170/170 => Loss 3.946, Train_accy 68.750, Test_accy 44.450
2022-05-25 12:19:00,078 [base.py] => Reducing exemplars...(25 per classes)
2022-05-25 12:19:14,129 [base.py] => Constructing exemplars...(25 per classes)
2022-05-25 12:19:19,237 [bic.py] => Parameters of bias layer:
2022-05-25 12:19:19,237 [bic.py] => 0 => 1.000, 0.000
2022-05-25 12:19:19,493 [bic.py] => 1 => 0.904, -1.125
2022-05-25 12:19:19,493 [bic.py] => 2 => 0.889, -1.948
2022-05-25 12:19:19,493 [bic.py] => 3 => 0.729, -1.345
2022-05-25 12:19:19,493 [bic.py] => 4 => 0.731, -1.321
2022-05-25 12:19:19,493 [bic.py] => 5 => 0.734, -1.140
2022-05-25 12:19:19,493 [bic.py] => 6 => 0.749, -1.468
2022-05-25 12:19:19,494 [bic.py] => 7 => 0.022, -0.851
2022-05-25 12:19:21,540 [bic.py] => Exemplar size: 2000
2022-05-25 12:19:21,541 [trainer.py] => CNN: {'total': 44.45, '00-09': 51.0, '10-19': 44.9, '20-29': 55.4, '30-39': 41.7, '40-49': 46.7, '50-59': 55.8, '60-69': 60.1, '70-79': 0.0, 'old': 50.8, 'new': 0.0}
2022-05-25 12:19:21,541 [trainer.py] => NME: {'total': 50.61, '00-09': 48.1, '10-19': 42.8, '20-29': 53.3, '30-39': 44.7, '40-49': 49.0, '50-59': 53.0, '60-69': 53.9, '70-79': 60.1, 'old': 49.26, 'new': 60.1}
2022-05-25 12:19:21,541 [trainer.py] => CNN top1 curve: [83.0, 73.7, 68.1, 62.2, 58.38, 55.52, 52.99, 44.45]
2022-05-25 12:19:21,541 [trainer.py] => CNN top5 curve: [99.1, 95.65, 92.07, 89.1, 86.2, 84.27, 81.76, 70.06]
2022-05-25 12:19:21,541 [trainer.py] => NME top1 curve: [82.8, 74.15, 67.37, 61.9, 58.1, 56.52, 53.94, 50.61]
2022-05-25 12:19:21,541 [trainer.py] => NME top5 curve: [99.0, 95.75, 92.47, 89.32, 86.1, 84.15, 81.77, 79.03]

2022-05-25 12:19:21,541 [trainer.py] => All params: 469370
2022-05-25 12:19:21,542 [trainer.py] => Trainable params: 469370
2022-05-25 12:19:21,543 [bic.py] => Learning on 80-90
2022-05-25 12:19:21,596 [bic.py] => Stage1 dset: 6820, Stage2 dset: 180
2022-05-25 12:19:21,596 [bic.py] => Lambda: 0.889
2022-05-25 12:19:21,613 [bic.py] => Parameters of bias layer:
2022-05-25 12:19:21,614 [bic.py] => 0 => 1.000, 0.000
2022-05-25 12:19:21,614 [bic.py] => 1 => 0.904, -1.125
2022-05-25 12:19:21,614 [bic.py] => 2 => 0.889, -1.948
2022-05-25 12:19:21,614 [bic.py] => 3 => 0.729, -1.345
2022-05-25 12:19:21,614 [bic.py] => 4 => 0.731, -1.321
2022-05-25 12:19:21,614 [bic.py] => 5 => 0.734, -1.140
2022-05-25 12:19:21,614 [bic.py] => 6 => 0.749, -1.468
2022-05-25 12:19:21,614 [bic.py] => 7 => 0.022, -0.851
2022-05-25 12:19:21,614 [bic.py] => 8 => 1.000, 0.000
2022-05-25 12:19:26,315 [bic.py] => training => Task 8, Epoch 1/170 => Loss 3.338, Train_accy 70.870, Test_accy 31.690
2022-05-25 12:19:31,076 [bic.py] => training => Task 8, Epoch 2/170 => Loss 3.260, Train_accy 72.080, Test_accy 31.090
2022-05-25 12:19:35,656 [bic.py] => training => Task 8, Epoch 3/170 => Loss 3.247, Train_accy 75.190, Test_accy 32.220
2022-05-25 12:19:40,339 [bic.py] => training => Task 8, Epoch 4/170 => Loss 3.240, Train_accy 77.300, Test_accy 30.690
2022-05-25 12:19:45,043 [bic.py] => training => Task 8, Epoch 5/170 => Loss 3.223, Train_accy 77.180, Test_accy 31.570
2022-05-25 12:19:49,805 [bic.py] => training => Task 8, Epoch 6/170 => Loss 3.228, Train_accy 79.030, Test_accy 31.420
2022-05-25 12:19:54,739 [bic.py] => training => Task 8, Epoch 7/170 => Loss 3.229, Train_accy 78.860, Test_accy 31.780
2022-05-25 12:19:59,494 [bic.py] => training => Task 8, Epoch 8/170 => Loss 3.227, Train_accy 81.510, Test_accy 31.960
2022-05-25 12:20:04,223 [bic.py] => training => Task 8, Epoch 9/170 => Loss 3.223, Train_accy 82.300, Test_accy 32.020
2022-05-25 12:20:08,866 [bic.py] => training => Task 8, Epoch 10/170 => Loss 3.223, Train_accy 83.110, Test_accy 31.340
2022-05-25 12:20:13,663 [bic.py] => training => Task 8, Epoch 11/170 => Loss 3.213, Train_accy 83.610, Test_accy 33.380
2022-05-25 12:20:18,526 [bic.py] => training => Task 8, Epoch 12/170 => Loss 3.213, Train_accy 83.140, Test_accy 34.780
2022-05-25 12:20:23,376 [bic.py] => training => Task 8, Epoch 13/170 => Loss 3.221, Train_accy 84.350, Test_accy 31.940
2022-05-25 12:20:28,183 [bic.py] => training => Task 8, Epoch 14/170 => Loss 3.213, Train_accy 84.310, Test_accy 32.580
2022-05-25 12:20:32,879 [bic.py] => training => Task 8, Epoch 15/170 => Loss 3.211, Train_accy 82.820, Test_accy 30.910
2022-05-25 12:20:37,523 [bic.py] => training => Task 8, Epoch 16/170 => Loss 3.207, Train_accy 85.320, Test_accy 33.260
2022-05-25 12:20:42,312 [bic.py] => training => Task 8, Epoch 17/170 => Loss 3.212, Train_accy 88.050, Test_accy 33.700
2022-05-25 12:20:47,027 [bic.py] => training => Task 8, Epoch 18/170 => Loss 3.216, Train_accy 84.190, Test_accy 32.040
2022-05-25 12:20:51,831 [bic.py] => training => Task 8, Epoch 19/170 => Loss 3.206, Train_accy 85.950, Test_accy 31.110
2022-05-25 12:20:56,642 [bic.py] => training => Task 8, Epoch 20/170 => Loss 3.211, Train_accy 86.000, Test_accy 34.890
2022-05-25 12:21:01,429 [bic.py] => training => Task 8, Epoch 21/170 => Loss 3.210, Train_accy 82.100, Test_accy 31.920
2022-05-25 12:21:06,423 [bic.py] => training => Task 8, Epoch 22/170 => Loss 3.210, Train_accy 86.860, Test_accy 33.940
2022-05-25 12:21:11,253 [bic.py] => training => Task 8, Epoch 23/170 => Loss 3.206, Train_accy 86.910, Test_accy 34.110
2022-05-25 12:21:15,797 [bic.py] => training => Task 8, Epoch 24/170 => Loss 3.206, Train_accy 86.770, Test_accy 33.520
2022-05-25 12:21:20,444 [bic.py] => training => Task 8, Epoch 25/170 => Loss 3.203, Train_accy 89.570, Test_accy 34.530
2022-05-25 12:21:25,224 [bic.py] => training => Task 8, Epoch 26/170 => Loss 3.203, Train_accy 85.430, Test_accy 33.990
2022-05-25 12:21:30,059 [bic.py] => training => Task 8, Epoch 27/170 => Loss 3.202, Train_accy 87.330, Test_accy 34.170
2022-05-25 12:21:34,799 [bic.py] => training => Task 8, Epoch 28/170 => Loss 3.206, Train_accy 87.760, Test_accy 34.120
2022-05-25 12:21:39,457 [bic.py] => training => Task 8, Epoch 29/170 => Loss 3.206, Train_accy 86.830, Test_accy 30.700
2022-05-25 12:21:44,165 [bic.py] => training => Task 8, Epoch 30/170 => Loss 3.206, Train_accy 88.450, Test_accy 32.800
2022-05-25 12:21:48,798 [bic.py] => training => Task 8, Epoch 31/170 => Loss 3.209, Train_accy 87.960, Test_accy 33.560
2022-05-25 12:21:53,493 [bic.py] => training => Task 8, Epoch 32/170 => Loss 3.203, Train_accy 83.960, Test_accy 30.820
2022-05-25 12:21:58,134 [bic.py] => training => Task 8, Epoch 33/170 => Loss 3.204, Train_accy 88.370, Test_accy 31.630
2022-05-25 12:22:02,856 [bic.py] => training => Task 8, Epoch 34/170 => Loss 3.208, Train_accy 88.340, Test_accy 32.840
2022-05-25 12:22:07,591 [bic.py] => training => Task 8, Epoch 35/170 => Loss 3.204, Train_accy 88.780, Test_accy 34.180
2022-05-25 12:22:12,296 [bic.py] => training => Task 8, Epoch 36/170 => Loss 3.198, Train_accy 87.650, Test_accy 32.740
2022-05-25 12:22:17,022 [bic.py] => training => Task 8, Epoch 37/170 => Loss 3.200, Train_accy 88.940, Test_accy 32.010
2022-05-25 12:22:21,761 [bic.py] => training => Task 8, Epoch 38/170 => Loss 3.197, Train_accy 88.390, Test_accy 32.310
2022-05-25 12:22:26,511 [bic.py] => training => Task 8, Epoch 39/170 => Loss 3.191, Train_accy 88.580, Test_accy 33.300
2022-05-25 12:22:31,343 [bic.py] => training => Task 8, Epoch 40/170 => Loss 3.197, Train_accy 88.240, Test_accy 32.780
2022-05-25 12:22:36,024 [bic.py] => training => Task 8, Epoch 41/170 => Loss 3.199, Train_accy 86.450, Test_accy 31.840
2022-05-25 12:22:40,718 [bic.py] => training => Task 8, Epoch 42/170 => Loss 3.200, Train_accy 85.910, Test_accy 34.560
2022-05-25 12:22:45,387 [bic.py] => training => Task 8, Epoch 43/170 => Loss 3.209, Train_accy 91.440, Test_accy 35.560
2022-05-25 12:22:50,055 [bic.py] => training => Task 8, Epoch 44/170 => Loss 3.201, Train_accy 85.510, Test_accy 29.840
2022-05-25 12:22:54,736 [bic.py] => training => Task 8, Epoch 45/170 => Loss 3.199, Train_accy 89.160, Test_accy 35.000
2022-05-25 12:22:59,504 [bic.py] => training => Task 8, Epoch 46/170 => Loss 3.197, Train_accy 88.590, Test_accy 32.670
2022-05-25 12:23:04,345 [bic.py] => training => Task 8, Epoch 47/170 => Loss 3.193, Train_accy 86.540, Test_accy 32.390
2022-05-25 12:23:09,104 [bic.py] => training => Task 8, Epoch 48/170 => Loss 3.201, Train_accy 86.860, Test_accy 31.420
2022-05-25 12:23:13,815 [bic.py] => training => Task 8, Epoch 49/170 => Loss 3.193, Train_accy 90.280, Test_accy 35.060
2022-05-25 12:23:18,568 [bic.py] => training => Task 8, Epoch 50/170 => Loss 3.197, Train_accy 88.390, Test_accy 34.610
2022-05-25 12:23:23,318 [bic.py] => training => Task 8, Epoch 51/170 => Loss 3.194, Train_accy 89.970, Test_accy 33.200
2022-05-25 12:23:28,108 [bic.py] => training => Task 8, Epoch 52/170 => Loss 3.194, Train_accy 90.380, Test_accy 35.230
2022-05-25 12:23:32,918 [bic.py] => training => Task 8, Epoch 53/170 => Loss 3.191, Train_accy 83.840, Test_accy 29.600
2022-05-25 12:23:37,558 [bic.py] => training => Task 8, Epoch 54/170 => Loss 3.192, Train_accy 92.170, Test_accy 35.230
2022-05-25 12:23:42,366 [bic.py] => training => Task 8, Epoch 55/170 => Loss 3.192, Train_accy 90.760, Test_accy 35.820
2022-05-25 12:23:47,033 [bic.py] => training => Task 8, Epoch 56/170 => Loss 3.200, Train_accy 85.870, Test_accy 31.120
2022-05-25 12:23:51,794 [bic.py] => training => Task 8, Epoch 57/170 => Loss 3.205, Train_accy 88.990, Test_accy 35.210
2022-05-25 12:23:56,441 [bic.py] => training => Task 8, Epoch 58/170 => Loss 3.197, Train_accy 88.330, Test_accy 35.120
2022-05-25 12:24:01,325 [bic.py] => training => Task 8, Epoch 59/170 => Loss 3.196, Train_accy 90.450, Test_accy 32.840
2022-05-25 12:24:06,157 [bic.py] => training => Task 8, Epoch 60/170 => Loss 3.196, Train_accy 89.400, Test_accy 32.320
2022-05-25 12:24:10,931 [bic.py] => training => Task 8, Epoch 61/170 => Loss 3.174, Train_accy 95.190, Test_accy 37.320
2022-05-25 12:24:15,656 [bic.py] => training => Task 8, Epoch 62/170 => Loss 3.161, Train_accy 95.750, Test_accy 37.800
2022-05-25 12:24:20,424 [bic.py] => training => Task 8, Epoch 63/170 => Loss 3.165, Train_accy 95.790, Test_accy 38.010
2022-05-25 12:24:25,249 [bic.py] => training => Task 8, Epoch 64/170 => Loss 3.164, Train_accy 95.820, Test_accy 38.310
2022-05-25 12:24:29,985 [bic.py] => training => Task 8, Epoch 65/170 => Loss 3.161, Train_accy 95.820, Test_accy 37.430
2022-05-25 12:24:34,684 [bic.py] => training => Task 8, Epoch 66/170 => Loss 3.158, Train_accy 95.750, Test_accy 37.660
2022-05-25 12:24:39,605 [bic.py] => training => Task 8, Epoch 67/170 => Loss 3.161, Train_accy 96.010, Test_accy 37.620
2022-05-25 12:24:44,307 [bic.py] => training => Task 8, Epoch 68/170 => Loss 3.151, Train_accy 95.880, Test_accy 38.100
2022-05-25 12:24:48,911 [bic.py] => training => Task 8, Epoch 69/170 => Loss 3.152, Train_accy 96.040, Test_accy 38.220
2022-05-25 12:24:53,535 [bic.py] => training => Task 8, Epoch 70/170 => Loss 3.159, Train_accy 96.070, Test_accy 37.920
2022-05-25 12:24:58,079 [bic.py] => training => Task 8, Epoch 71/170 => Loss 3.154, Train_accy 96.040, Test_accy 37.590
2022-05-25 12:25:02,721 [bic.py] => training => Task 8, Epoch 72/170 => Loss 3.157, Train_accy 95.940, Test_accy 37.460
2022-05-25 12:25:07,472 [bic.py] => training => Task 8, Epoch 73/170 => Loss 3.157, Train_accy 96.100, Test_accy 37.700
2022-05-25 12:25:12,342 [bic.py] => training => Task 8, Epoch 74/170 => Loss 3.154, Train_accy 95.890, Test_accy 37.890
2022-05-25 12:25:17,071 [bic.py] => training => Task 8, Epoch 75/170 => Loss 3.152, Train_accy 96.060, Test_accy 37.970
2022-05-25 12:25:21,750 [bic.py] => training => Task 8, Epoch 76/170 => Loss 3.154, Train_accy 96.070, Test_accy 37.980
2022-05-25 12:25:26,392 [bic.py] => training => Task 8, Epoch 77/170 => Loss 3.154, Train_accy 96.090, Test_accy 37.870
2022-05-25 12:25:31,160 [bic.py] => training => Task 8, Epoch 78/170 => Loss 3.156, Train_accy 96.030, Test_accy 37.970
2022-05-25 12:25:35,740 [bic.py] => training => Task 8, Epoch 79/170 => Loss 3.157, Train_accy 95.980, Test_accy 37.280
2022-05-25 12:25:40,387 [bic.py] => training => Task 8, Epoch 80/170 => Loss 3.157, Train_accy 96.040, Test_accy 38.030
2022-05-25 12:25:45,134 [bic.py] => training => Task 8, Epoch 81/170 => Loss 3.156, Train_accy 96.130, Test_accy 38.110
2022-05-25 12:25:49,855 [bic.py] => training => Task 8, Epoch 82/170 => Loss 3.155, Train_accy 96.000, Test_accy 37.630
2022-05-25 12:25:54,623 [bic.py] => training => Task 8, Epoch 83/170 => Loss 3.157, Train_accy 96.060, Test_accy 38.140
2022-05-25 12:25:59,385 [bic.py] => training => Task 8, Epoch 84/170 => Loss 3.153, Train_accy 96.140, Test_accy 37.710
2022-05-25 12:26:04,117 [bic.py] => training => Task 8, Epoch 85/170 => Loss 3.151, Train_accy 96.130, Test_accy 37.280
2022-05-25 12:26:08,805 [bic.py] => training => Task 8, Epoch 86/170 => Loss 3.159, Train_accy 96.250, Test_accy 37.970
2022-05-25 12:26:13,529 [bic.py] => training => Task 8, Epoch 87/170 => Loss 3.153, Train_accy 96.190, Test_accy 37.880
2022-05-25 12:26:18,196 [bic.py] => training => Task 8, Epoch 88/170 => Loss 3.156, Train_accy 96.160, Test_accy 37.700
2022-05-25 12:26:22,899 [bic.py] => training => Task 8, Epoch 89/170 => Loss 3.153, Train_accy 96.200, Test_accy 38.220
2022-05-25 12:26:27,887 [bic.py] => training => Task 8, Epoch 90/170 => Loss 3.152, Train_accy 96.190, Test_accy 38.070
2022-05-25 12:26:32,583 [bic.py] => training => Task 8, Epoch 91/170 => Loss 3.150, Train_accy 96.140, Test_accy 37.580
2022-05-25 12:26:37,255 [bic.py] => training => Task 8, Epoch 92/170 => Loss 3.152, Train_accy 96.220, Test_accy 37.620
2022-05-25 12:26:42,031 [bic.py] => training => Task 8, Epoch 93/170 => Loss 3.156, Train_accy 96.200, Test_accy 37.830
2022-05-25 12:26:46,820 [bic.py] => training => Task 8, Epoch 94/170 => Loss 3.155, Train_accy 96.260, Test_accy 37.660
2022-05-25 12:26:51,565 [bic.py] => training => Task 8, Epoch 95/170 => Loss 3.153, Train_accy 96.100, Test_accy 38.060
2022-05-25 12:26:56,464 [bic.py] => training => Task 8, Epoch 96/170 => Loss 3.152, Train_accy 96.140, Test_accy 37.760
2022-05-25 12:27:01,150 [bic.py] => training => Task 8, Epoch 97/170 => Loss 3.153, Train_accy 96.140, Test_accy 37.520
2022-05-25 12:27:05,988 [bic.py] => training => Task 8, Epoch 98/170 => Loss 3.151, Train_accy 96.290, Test_accy 37.530
2022-05-25 12:27:10,820 [bic.py] => training => Task 8, Epoch 99/170 => Loss 3.150, Train_accy 96.140, Test_accy 38.070
2022-05-25 12:27:15,461 [bic.py] => training => Task 8, Epoch 100/170 => Loss 3.149, Train_accy 96.190, Test_accy 38.090
2022-05-25 12:27:20,072 [bic.py] => training => Task 8, Epoch 101/170 => Loss 3.148, Train_accy 96.130, Test_accy 37.740
2022-05-25 12:27:24,861 [bic.py] => training => Task 8, Epoch 102/170 => Loss 3.153, Train_accy 96.290, Test_accy 38.290
2022-05-25 12:27:29,547 [bic.py] => training => Task 8, Epoch 103/170 => Loss 3.151, Train_accy 96.290, Test_accy 37.930
2022-05-25 12:27:34,254 [bic.py] => training => Task 8, Epoch 104/170 => Loss 3.150, Train_accy 96.110, Test_accy 38.180
2022-05-25 12:27:38,914 [bic.py] => training => Task 8, Epoch 105/170 => Loss 3.153, Train_accy 96.300, Test_accy 37.610
2022-05-25 12:27:43,627 [bic.py] => training => Task 8, Epoch 106/170 => Loss 3.147, Train_accy 96.250, Test_accy 38.200
2022-05-25 12:27:48,323 [bic.py] => training => Task 8, Epoch 107/170 => Loss 3.148, Train_accy 96.290, Test_accy 38.180
2022-05-25 12:27:53,004 [bic.py] => training => Task 8, Epoch 108/170 => Loss 3.153, Train_accy 96.090, Test_accy 37.810
2022-05-25 12:27:57,661 [bic.py] => training => Task 8, Epoch 109/170 => Loss 3.153, Train_accy 96.260, Test_accy 37.580
2022-05-25 12:28:02,319 [bic.py] => training => Task 8, Epoch 110/170 => Loss 3.151, Train_accy 96.130, Test_accy 37.580
2022-05-25 12:28:07,174 [bic.py] => training => Task 8, Epoch 111/170 => Loss 3.151, Train_accy 96.300, Test_accy 38.090
2022-05-25 12:28:11,900 [bic.py] => training => Task 8, Epoch 112/170 => Loss 3.154, Train_accy 96.320, Test_accy 38.270
2022-05-25 12:28:16,738 [bic.py] => training => Task 8, Epoch 113/170 => Loss 3.152, Train_accy 96.160, Test_accy 37.590
2022-05-25 12:28:21,437 [bic.py] => training => Task 8, Epoch 114/170 => Loss 3.152, Train_accy 96.130, Test_accy 38.010
2022-05-25 12:28:26,104 [bic.py] => training => Task 8, Epoch 115/170 => Loss 3.150, Train_accy 96.230, Test_accy 38.090
2022-05-25 12:28:30,922 [bic.py] => training => Task 8, Epoch 116/170 => Loss 3.152, Train_accy 96.290, Test_accy 38.140
2022-05-25 12:28:35,592 [bic.py] => training => Task 8, Epoch 117/170 => Loss 3.154, Train_accy 96.320, Test_accy 37.940
2022-05-25 12:28:40,366 [bic.py] => training => Task 8, Epoch 118/170 => Loss 3.151, Train_accy 96.320, Test_accy 38.140
2022-05-25 12:28:45,130 [bic.py] => training => Task 8, Epoch 119/170 => Loss 3.151, Train_accy 96.230, Test_accy 38.490
2022-05-25 12:28:49,765 [bic.py] => training => Task 8, Epoch 120/170 => Loss 3.148, Train_accy 96.220, Test_accy 37.790
2022-05-25 12:28:54,545 [bic.py] => training => Task 8, Epoch 121/170 => Loss 3.149, Train_accy 96.260, Test_accy 38.080
2022-05-25 12:28:59,310 [bic.py] => training => Task 8, Epoch 122/170 => Loss 3.150, Train_accy 96.330, Test_accy 37.890
2022-05-25 12:29:03,990 [bic.py] => training => Task 8, Epoch 123/170 => Loss 3.144, Train_accy 96.260, Test_accy 38.020
2022-05-25 12:29:08,563 [bic.py] => training => Task 8, Epoch 124/170 => Loss 3.151, Train_accy 96.330, Test_accy 38.040
2022-05-25 12:29:13,023 [bic.py] => training => Task 8, Epoch 125/170 => Loss 3.146, Train_accy 96.230, Test_accy 37.990
2022-05-25 12:29:17,753 [bic.py] => training => Task 8, Epoch 126/170 => Loss 3.151, Train_accy 96.160, Test_accy 37.890
2022-05-25 12:29:22,538 [bic.py] => training => Task 8, Epoch 127/170 => Loss 3.147, Train_accy 96.220, Test_accy 38.470
2022-05-25 12:29:27,178 [bic.py] => training => Task 8, Epoch 128/170 => Loss 3.149, Train_accy 96.290, Test_accy 38.010
2022-05-25 12:29:31,853 [bic.py] => training => Task 8, Epoch 129/170 => Loss 3.146, Train_accy 96.200, Test_accy 38.020
2022-05-25 12:29:36,653 [bic.py] => training => Task 8, Epoch 130/170 => Loss 3.153, Train_accy 96.290, Test_accy 38.090
2022-05-25 12:29:41,380 [bic.py] => training => Task 8, Epoch 131/170 => Loss 3.152, Train_accy 96.280, Test_accy 37.970
2022-05-25 12:29:46,110 [bic.py] => training => Task 8, Epoch 132/170 => Loss 3.150, Train_accy 96.260, Test_accy 38.080
2022-05-25 12:29:50,807 [bic.py] => training => Task 8, Epoch 133/170 => Loss 3.154, Train_accy 96.250, Test_accy 38.180
2022-05-25 12:29:55,541 [bic.py] => training => Task 8, Epoch 134/170 => Loss 3.150, Train_accy 96.170, Test_accy 37.810
2022-05-25 12:30:00,211 [bic.py] => training => Task 8, Epoch 135/170 => Loss 3.153, Train_accy 96.280, Test_accy 38.280
2022-05-25 12:30:04,869 [bic.py] => training => Task 8, Epoch 136/170 => Loss 3.153, Train_accy 96.290, Test_accy 38.160
2022-05-25 12:30:09,620 [bic.py] => training => Task 8, Epoch 137/170 => Loss 3.147, Train_accy 96.360, Test_accy 38.330
2022-05-25 12:30:14,255 [bic.py] => training => Task 8, Epoch 138/170 => Loss 3.152, Train_accy 96.230, Test_accy 38.310
2022-05-25 12:30:19,001 [bic.py] => training => Task 8, Epoch 139/170 => Loss 3.152, Train_accy 96.290, Test_accy 37.790
2022-05-25 12:30:23,711 [bic.py] => training => Task 8, Epoch 140/170 => Loss 3.148, Train_accy 96.330, Test_accy 38.110
2022-05-25 12:30:28,511 [bic.py] => training => Task 8, Epoch 141/170 => Loss 3.151, Train_accy 96.260, Test_accy 37.960
2022-05-25 12:30:33,253 [bic.py] => training => Task 8, Epoch 142/170 => Loss 3.147, Train_accy 96.330, Test_accy 38.320
2022-05-25 12:30:38,060 [bic.py] => training => Task 8, Epoch 143/170 => Loss 3.151, Train_accy 96.250, Test_accy 38.280
2022-05-25 12:30:42,618 [bic.py] => training => Task 8, Epoch 144/170 => Loss 3.151, Train_accy 96.290, Test_accy 38.190
2022-05-25 12:30:47,290 [bic.py] => training => Task 8, Epoch 145/170 => Loss 3.149, Train_accy 96.280, Test_accy 37.860
2022-05-25 12:30:52,029 [bic.py] => training => Task 8, Epoch 146/170 => Loss 3.154, Train_accy 96.200, Test_accy 38.080
2022-05-25 12:30:56,538 [bic.py] => training => Task 8, Epoch 147/170 => Loss 3.145, Train_accy 96.290, Test_accy 38.380
2022-05-25 12:31:01,195 [bic.py] => training => Task 8, Epoch 148/170 => Loss 3.151, Train_accy 96.320, Test_accy 37.760
2022-05-25 12:31:05,915 [bic.py] => training => Task 8, Epoch 149/170 => Loss 3.149, Train_accy 96.260, Test_accy 38.070
2022-05-25 12:31:10,705 [bic.py] => training => Task 8, Epoch 150/170 => Loss 3.153, Train_accy 96.220, Test_accy 37.810
2022-05-25 12:31:15,470 [bic.py] => training => Task 8, Epoch 151/170 => Loss 3.148, Train_accy 96.330, Test_accy 38.110
2022-05-25 12:31:20,250 [bic.py] => training => Task 8, Epoch 152/170 => Loss 3.150, Train_accy 96.320, Test_accy 38.160
2022-05-25 12:31:24,902 [bic.py] => training => Task 8, Epoch 153/170 => Loss 3.152, Train_accy 96.170, Test_accy 37.940
2022-05-25 12:31:29,614 [bic.py] => training => Task 8, Epoch 154/170 => Loss 3.148, Train_accy 96.230, Test_accy 38.280
2022-05-25 12:31:34,379 [bic.py] => training => Task 8, Epoch 155/170 => Loss 3.149, Train_accy 96.280, Test_accy 38.360
2022-05-25 12:31:39,160 [bic.py] => training => Task 8, Epoch 156/170 => Loss 3.151, Train_accy 96.290, Test_accy 38.240
2022-05-25 12:31:43,886 [bic.py] => training => Task 8, Epoch 157/170 => Loss 3.146, Train_accy 96.200, Test_accy 37.870
2022-05-25 12:31:48,651 [bic.py] => training => Task 8, Epoch 158/170 => Loss 3.153, Train_accy 96.230, Test_accy 38.190
2022-05-25 12:31:53,364 [bic.py] => training => Task 8, Epoch 159/170 => Loss 3.153, Train_accy 96.420, Test_accy 37.760
2022-05-25 12:31:58,262 [bic.py] => training => Task 8, Epoch 160/170 => Loss 3.144, Train_accy 96.320, Test_accy 37.910
2022-05-25 12:32:03,050 [bic.py] => training => Task 8, Epoch 161/170 => Loss 3.153, Train_accy 96.280, Test_accy 38.340
2022-05-25 12:32:07,755 [bic.py] => training => Task 8, Epoch 162/170 => Loss 3.153, Train_accy 96.250, Test_accy 38.100
2022-05-25 12:32:12,464 [bic.py] => training => Task 8, Epoch 163/170 => Loss 3.153, Train_accy 96.420, Test_accy 38.130
2022-05-25 12:32:17,174 [bic.py] => training => Task 8, Epoch 164/170 => Loss 3.152, Train_accy 96.420, Test_accy 37.930
2022-05-25 12:32:22,043 [bic.py] => training => Task 8, Epoch 165/170 => Loss 3.148, Train_accy 96.220, Test_accy 37.790
2022-05-25 12:32:26,809 [bic.py] => training => Task 8, Epoch 166/170 => Loss 3.153, Train_accy 96.330, Test_accy 37.720
2022-05-25 12:32:31,501 [bic.py] => training => Task 8, Epoch 167/170 => Loss 3.151, Train_accy 96.380, Test_accy 38.140
2022-05-25 12:32:36,011 [bic.py] => training => Task 8, Epoch 168/170 => Loss 3.146, Train_accy 96.290, Test_accy 38.000
2022-05-25 12:32:40,792 [bic.py] => training => Task 8, Epoch 169/170 => Loss 3.146, Train_accy 96.380, Test_accy 37.860
2022-05-25 12:32:45,694 [bic.py] => training => Task 8, Epoch 170/170 => Loss 3.151, Train_accy 96.260, Test_accy 37.990
2022-05-25 12:32:47,655 [bic.py] => bias_correction => Task 8, Epoch 1/170 => Loss 4.063, Train_accy 60.000, Test_accy 40.070
2022-05-25 12:32:49,660 [bic.py] => bias_correction => Task 8, Epoch 2/170 => Loss 4.054, Train_accy 70.000, Test_accy 43.690
2022-05-25 12:32:51,669 [bic.py] => bias_correction => Task 8, Epoch 3/170 => Loss 3.998, Train_accy 71.670, Test_accy 45.300
2022-05-25 12:32:53,698 [bic.py] => bias_correction => Task 8, Epoch 4/170 => Loss 4.014, Train_accy 71.670, Test_accy 43.820
2022-05-25 12:32:55,636 [bic.py] => bias_correction => Task 8, Epoch 5/170 => Loss 4.023, Train_accy 70.000, Test_accy 42.060
2022-05-25 12:32:57,531 [bic.py] => bias_correction => Task 8, Epoch 6/170 => Loss 4.010, Train_accy 69.440, Test_accy 41.210
2022-05-25 12:32:59,389 [bic.py] => bias_correction => Task 8, Epoch 7/170 => Loss 3.998, Train_accy 70.000, Test_accy 40.900
2022-05-25 12:33:01,308 [bic.py] => bias_correction => Task 8, Epoch 8/170 => Loss 4.012, Train_accy 67.780, Test_accy 40.690
2022-05-25 12:33:03,227 [bic.py] => bias_correction => Task 8, Epoch 9/170 => Loss 4.014, Train_accy 69.440, Test_accy 40.540
2022-05-25 12:33:05,111 [bic.py] => bias_correction => Task 8, Epoch 10/170 => Loss 4.018, Train_accy 68.330, Test_accy 40.500
2022-05-25 12:33:07,033 [bic.py] => bias_correction => Task 8, Epoch 11/170 => Loss 4.000, Train_accy 70.000, Test_accy 40.600
2022-05-25 12:33:08,934 [bic.py] => bias_correction => Task 8, Epoch 12/170 => Loss 4.027, Train_accy 68.890, Test_accy 40.680
2022-05-25 12:33:10,848 [bic.py] => bias_correction => Task 8, Epoch 13/170 => Loss 4.021, Train_accy 70.000, Test_accy 40.820
2022-05-25 12:33:12,824 [bic.py] => bias_correction => Task 8, Epoch 14/170 => Loss 4.048, Train_accy 65.560, Test_accy 40.970
2022-05-25 12:33:14,762 [bic.py] => bias_correction => Task 8, Epoch 15/170 => Loss 4.025, Train_accy 70.000, Test_accy 41.490
2022-05-25 12:33:16,636 [bic.py] => bias_correction => Task 8, Epoch 16/170 => Loss 4.016, Train_accy 68.890, Test_accy 41.980
2022-05-25 12:33:18,505 [bic.py] => bias_correction => Task 8, Epoch 17/170 => Loss 3.995, Train_accy 68.890, Test_accy 42.780
2022-05-25 12:33:20,393 [bic.py] => bias_correction => Task 8, Epoch 18/170 => Loss 4.020, Train_accy 68.890, Test_accy 43.710
2022-05-25 12:33:22,283 [bic.py] => bias_correction => Task 8, Epoch 19/170 => Loss 4.003, Train_accy 71.670, Test_accy 44.590
2022-05-25 12:33:24,119 [bic.py] => bias_correction => Task 8, Epoch 20/170 => Loss 4.000, Train_accy 75.000, Test_accy 45.230
2022-05-25 12:33:25,905 [bic.py] => bias_correction => Task 8, Epoch 21/170 => Loss 4.013, Train_accy 72.780, Test_accy 44.990
2022-05-25 12:33:27,742 [bic.py] => bias_correction => Task 8, Epoch 22/170 => Loss 4.000, Train_accy 73.330, Test_accy 44.410
2022-05-25 12:33:29,644 [bic.py] => bias_correction => Task 8, Epoch 23/170 => Loss 3.993, Train_accy 72.780, Test_accy 44.120
2022-05-25 12:33:31,477 [bic.py] => bias_correction => Task 8, Epoch 24/170 => Loss 4.029, Train_accy 68.890, Test_accy 44.430
2022-05-25 12:33:33,361 [bic.py] => bias_correction => Task 8, Epoch 25/170 => Loss 4.002, Train_accy 73.330, Test_accy 44.730
2022-05-25 12:33:35,375 [bic.py] => bias_correction => Task 8, Epoch 26/170 => Loss 3.995, Train_accy 73.330, Test_accy 45.020
2022-05-25 12:33:37,257 [bic.py] => bias_correction => Task 8, Epoch 27/170 => Loss 4.006, Train_accy 75.000, Test_accy 45.270
2022-05-25 12:33:39,099 [bic.py] => bias_correction => Task 8, Epoch 28/170 => Loss 4.033, Train_accy 72.780, Test_accy 45.360
2022-05-25 12:33:41,100 [bic.py] => bias_correction => Task 8, Epoch 29/170 => Loss 3.998, Train_accy 74.440, Test_accy 45.310
2022-05-25 12:33:43,031 [bic.py] => bias_correction => Task 8, Epoch 30/170 => Loss 4.021, Train_accy 76.670, Test_accy 45.370
2022-05-25 12:33:44,871 [bic.py] => bias_correction => Task 8, Epoch 31/170 => Loss 3.970, Train_accy 73.890, Test_accy 45.220
2022-05-25 12:33:46,770 [bic.py] => bias_correction => Task 8, Epoch 32/170 => Loss 4.001, Train_accy 73.330, Test_accy 45.260
2022-05-25 12:33:48,606 [bic.py] => bias_correction => Task 8, Epoch 33/170 => Loss 3.997, Train_accy 75.000, Test_accy 45.200
2022-05-25 12:33:50,526 [bic.py] => bias_correction => Task 8, Epoch 34/170 => Loss 3.999, Train_accy 73.330, Test_accy 45.330
2022-05-25 12:33:52,429 [bic.py] => bias_correction => Task 8, Epoch 35/170 => Loss 4.003, Train_accy 72.780, Test_accy 45.320
2022-05-25 12:33:54,226 [bic.py] => bias_correction => Task 8, Epoch 36/170 => Loss 3.991, Train_accy 71.670, Test_accy 45.060
2022-05-25 12:33:56,184 [bic.py] => bias_correction => Task 8, Epoch 37/170 => Loss 4.018, Train_accy 75.560, Test_accy 44.640
2022-05-25 12:33:58,107 [bic.py] => bias_correction => Task 8, Epoch 38/170 => Loss 4.015, Train_accy 71.670, Test_accy 44.360
2022-05-25 12:33:59,973 [bic.py] => bias_correction => Task 8, Epoch 39/170 => Loss 3.994, Train_accy 75.560, Test_accy 44.520
2022-05-25 12:34:01,803 [bic.py] => bias_correction => Task 8, Epoch 40/170 => Loss 4.017, Train_accy 72.780, Test_accy 44.780
2022-05-25 12:34:03,669 [bic.py] => bias_correction => Task 8, Epoch 41/170 => Loss 4.010, Train_accy 72.220, Test_accy 45.180
2022-05-25 12:34:05,510 [bic.py] => bias_correction => Task 8, Epoch 42/170 => Loss 3.959, Train_accy 73.330, Test_accy 45.430
2022-05-25 12:34:07,387 [bic.py] => bias_correction => Task 8, Epoch 43/170 => Loss 3.989, Train_accy 72.220, Test_accy 45.480
2022-05-25 12:34:09,203 [bic.py] => bias_correction => Task 8, Epoch 44/170 => Loss 3.990, Train_accy 73.330, Test_accy 45.360
2022-05-25 12:34:11,178 [bic.py] => bias_correction => Task 8, Epoch 45/170 => Loss 3.991, Train_accy 72.780, Test_accy 45.060
2022-05-25 12:34:12,994 [bic.py] => bias_correction => Task 8, Epoch 46/170 => Loss 3.995, Train_accy 72.780, Test_accy 44.770
2022-05-25 12:34:14,878 [bic.py] => bias_correction => Task 8, Epoch 47/170 => Loss 3.990, Train_accy 70.560, Test_accy 44.320
2022-05-25 12:34:16,695 [bic.py] => bias_correction => Task 8, Epoch 48/170 => Loss 3.980, Train_accy 76.110, Test_accy 44.440
2022-05-25 12:34:18,579 [bic.py] => bias_correction => Task 8, Epoch 49/170 => Loss 4.000, Train_accy 73.330, Test_accy 44.960
2022-05-25 12:34:20,428 [bic.py] => bias_correction => Task 8, Epoch 50/170 => Loss 4.000, Train_accy 76.110, Test_accy 45.190
2022-05-25 12:34:22,309 [bic.py] => bias_correction => Task 8, Epoch 51/170 => Loss 3.982, Train_accy 72.220, Test_accy 45.320
2022-05-25 12:34:24,293 [bic.py] => bias_correction => Task 8, Epoch 52/170 => Loss 4.008, Train_accy 71.110, Test_accy 45.170
2022-05-25 12:34:26,210 [bic.py] => bias_correction => Task 8, Epoch 53/170 => Loss 3.986, Train_accy 75.560, Test_accy 45.200
2022-05-25 12:34:28,076 [bic.py] => bias_correction => Task 8, Epoch 54/170 => Loss 4.007, Train_accy 75.000, Test_accy 45.320
2022-05-25 12:34:29,963 [bic.py] => bias_correction => Task 8, Epoch 55/170 => Loss 3.982, Train_accy 75.000, Test_accy 44.910
2022-05-25 12:34:31,814 [bic.py] => bias_correction => Task 8, Epoch 56/170 => Loss 4.005, Train_accy 75.000, Test_accy 44.930
2022-05-25 12:34:33,603 [bic.py] => bias_correction => Task 8, Epoch 57/170 => Loss 4.003, Train_accy 76.110, Test_accy 44.940
2022-05-25 12:34:35,545 [bic.py] => bias_correction => Task 8, Epoch 58/170 => Loss 3.998, Train_accy 73.330, Test_accy 44.880
2022-05-25 12:34:37,464 [bic.py] => bias_correction => Task 8, Epoch 59/170 => Loss 3.984, Train_accy 74.440, Test_accy 44.840
2022-05-25 12:34:39,340 [bic.py] => bias_correction => Task 8, Epoch 60/170 => Loss 3.988, Train_accy 73.330, Test_accy 44.830
2022-05-25 12:34:41,259 [bic.py] => bias_correction => Task 8, Epoch 61/170 => Loss 4.000, Train_accy 72.780, Test_accy 44.660
2022-05-25 12:34:43,193 [bic.py] => bias_correction => Task 8, Epoch 62/170 => Loss 4.012, Train_accy 75.560, Test_accy 44.730
2022-05-25 12:34:45,125 [bic.py] => bias_correction => Task 8, Epoch 63/170 => Loss 4.014, Train_accy 75.560, Test_accy 44.800
2022-05-25 12:34:47,125 [bic.py] => bias_correction => Task 8, Epoch 64/170 => Loss 3.981, Train_accy 70.000, Test_accy 44.720
2022-05-25 12:34:49,020 [bic.py] => bias_correction => Task 8, Epoch 65/170 => Loss 3.989, Train_accy 73.890, Test_accy 44.800
2022-05-25 12:34:50,907 [bic.py] => bias_correction => Task 8, Epoch 66/170 => Loss 3.984, Train_accy 71.110, Test_accy 44.880
2022-05-25 12:34:52,794 [bic.py] => bias_correction => Task 8, Epoch 67/170 => Loss 3.997, Train_accy 74.440, Test_accy 44.900
2022-05-25 12:34:54,705 [bic.py] => bias_correction => Task 8, Epoch 68/170 => Loss 4.015, Train_accy 75.560, Test_accy 45.020
2022-05-25 12:34:56,492 [bic.py] => bias_correction => Task 8, Epoch 69/170 => Loss 4.012, Train_accy 72.780, Test_accy 45.070
2022-05-25 12:34:58,379 [bic.py] => bias_correction => Task 8, Epoch 70/170 => Loss 3.994, Train_accy 73.330, Test_accy 45.000
2022-05-25 12:35:00,366 [bic.py] => bias_correction => Task 8, Epoch 71/170 => Loss 3.983, Train_accy 70.560, Test_accy 45.100
2022-05-25 12:35:02,334 [bic.py] => bias_correction => Task 8, Epoch 72/170 => Loss 4.006, Train_accy 73.330, Test_accy 45.140
2022-05-25 12:35:04,192 [bic.py] => bias_correction => Task 8, Epoch 73/170 => Loss 4.005, Train_accy 73.330, Test_accy 45.070
2022-05-25 12:35:06,153 [bic.py] => bias_correction => Task 8, Epoch 74/170 => Loss 4.032, Train_accy 75.560, Test_accy 45.260
2022-05-25 12:35:08,138 [bic.py] => bias_correction => Task 8, Epoch 75/170 => Loss 4.009, Train_accy 75.000, Test_accy 45.220
2022-05-25 12:35:10,013 [bic.py] => bias_correction => Task 8, Epoch 76/170 => Loss 3.996, Train_accy 73.330, Test_accy 45.410
2022-05-25 12:35:11,946 [bic.py] => bias_correction => Task 8, Epoch 77/170 => Loss 3.988, Train_accy 75.000, Test_accy 45.480
2022-05-25 12:35:13,729 [bic.py] => bias_correction => Task 8, Epoch 78/170 => Loss 4.013, Train_accy 73.330, Test_accy 45.460
2022-05-25 12:35:15,612 [bic.py] => bias_correction => Task 8, Epoch 79/170 => Loss 3.993, Train_accy 73.890, Test_accy 45.510
2022-05-25 12:35:17,495 [bic.py] => bias_correction => Task 8, Epoch 80/170 => Loss 4.011, Train_accy 72.220, Test_accy 45.210
2022-05-25 12:35:19,453 [bic.py] => bias_correction => Task 8, Epoch 81/170 => Loss 4.014, Train_accy 72.220, Test_accy 45.310
2022-05-25 12:35:21,342 [bic.py] => bias_correction => Task 8, Epoch 82/170 => Loss 3.982, Train_accy 73.330, Test_accy 45.200
2022-05-25 12:35:23,185 [bic.py] => bias_correction => Task 8, Epoch 83/170 => Loss 3.996, Train_accy 73.330, Test_accy 45.120
2022-05-25 12:35:25,138 [bic.py] => bias_correction => Task 8, Epoch 84/170 => Loss 4.008, Train_accy 71.670, Test_accy 45.130
2022-05-25 12:35:27,040 [bic.py] => bias_correction => Task 8, Epoch 85/170 => Loss 3.986, Train_accy 72.220, Test_accy 45.330
2022-05-25 12:35:28,964 [bic.py] => bias_correction => Task 8, Epoch 86/170 => Loss 3.984, Train_accy 72.220, Test_accy 45.120
2022-05-25 12:35:30,794 [bic.py] => bias_correction => Task 8, Epoch 87/170 => Loss 3.992, Train_accy 71.670, Test_accy 45.160
2022-05-25 12:35:32,676 [bic.py] => bias_correction => Task 8, Epoch 88/170 => Loss 3.993, Train_accy 73.890, Test_accy 45.210
2022-05-25 12:35:34,586 [bic.py] => bias_correction => Task 8, Epoch 89/170 => Loss 3.982, Train_accy 73.330, Test_accy 45.240
2022-05-25 12:35:36,498 [bic.py] => bias_correction => Task 8, Epoch 90/170 => Loss 4.019, Train_accy 72.780, Test_accy 45.130
2022-05-25 12:35:38,398 [bic.py] => bias_correction => Task 8, Epoch 91/170 => Loss 4.004, Train_accy 74.440, Test_accy 45.120
2022-05-25 12:35:40,275 [bic.py] => bias_correction => Task 8, Epoch 92/170 => Loss 4.001, Train_accy 71.110, Test_accy 45.100
2022-05-25 12:35:42,249 [bic.py] => bias_correction => Task 8, Epoch 93/170 => Loss 4.001, Train_accy 72.780, Test_accy 45.090
2022-05-25 12:35:44,169 [bic.py] => bias_correction => Task 8, Epoch 94/170 => Loss 4.001, Train_accy 71.110, Test_accy 45.010
2022-05-25 12:35:46,047 [bic.py] => bias_correction => Task 8, Epoch 95/170 => Loss 3.995, Train_accy 75.000, Test_accy 44.910
2022-05-25 12:35:48,130 [bic.py] => bias_correction => Task 8, Epoch 96/170 => Loss 3.996, Train_accy 72.220, Test_accy 45.030
2022-05-25 12:35:49,959 [bic.py] => bias_correction => Task 8, Epoch 97/170 => Loss 3.975, Train_accy 72.780, Test_accy 44.910
2022-05-25 12:35:51,808 [bic.py] => bias_correction => Task 8, Epoch 98/170 => Loss 3.987, Train_accy 73.330, Test_accy 45.020
2022-05-25 12:35:53,625 [bic.py] => bias_correction => Task 8, Epoch 99/170 => Loss 4.005, Train_accy 71.670, Test_accy 45.030
2022-05-25 12:35:55,526 [bic.py] => bias_correction => Task 8, Epoch 100/170 => Loss 3.985, Train_accy 73.890, Test_accy 45.120
2022-05-25 12:35:57,431 [bic.py] => bias_correction => Task 8, Epoch 101/170 => Loss 4.016, Train_accy 76.670, Test_accy 45.080
2022-05-25 12:35:59,362 [bic.py] => bias_correction => Task 8, Epoch 102/170 => Loss 3.998, Train_accy 73.890, Test_accy 45.270
2022-05-25 12:36:01,242 [bic.py] => bias_correction => Task 8, Epoch 103/170 => Loss 3.990, Train_accy 73.330, Test_accy 45.260
2022-05-25 12:36:03,104 [bic.py] => bias_correction => Task 8, Epoch 104/170 => Loss 3.991, Train_accy 71.110, Test_accy 45.190
2022-05-25 12:36:05,127 [bic.py] => bias_correction => Task 8, Epoch 105/170 => Loss 3.979, Train_accy 73.890, Test_accy 45.160
2022-05-25 12:36:06,991 [bic.py] => bias_correction => Task 8, Epoch 106/170 => Loss 3.999, Train_accy 73.330, Test_accy 45.190
2022-05-25 12:36:08,838 [bic.py] => bias_correction => Task 8, Epoch 107/170 => Loss 4.025, Train_accy 75.000, Test_accy 45.300
2022-05-25 12:36:10,755 [bic.py] => bias_correction => Task 8, Epoch 108/170 => Loss 3.994, Train_accy 75.000, Test_accy 45.080
2022-05-25 12:36:12,599 [bic.py] => bias_correction => Task 8, Epoch 109/170 => Loss 3.989, Train_accy 73.330, Test_accy 44.990
2022-05-25 12:36:14,515 [bic.py] => bias_correction => Task 8, Epoch 110/170 => Loss 3.994, Train_accy 70.560, Test_accy 45.010
2022-05-25 12:36:16,423 [bic.py] => bias_correction => Task 8, Epoch 111/170 => Loss 4.002, Train_accy 71.670, Test_accy 45.110
2022-05-25 12:36:18,409 [bic.py] => bias_correction => Task 8, Epoch 112/170 => Loss 3.978, Train_accy 73.330, Test_accy 45.120
2022-05-25 12:36:20,321 [bic.py] => bias_correction => Task 8, Epoch 113/170 => Loss 3.999, Train_accy 74.440, Test_accy 45.140
2022-05-25 12:36:22,254 [bic.py] => bias_correction => Task 8, Epoch 114/170 => Loss 4.001, Train_accy 71.110, Test_accy 45.080
2022-05-25 12:36:24,193 [bic.py] => bias_correction => Task 8, Epoch 115/170 => Loss 3.983, Train_accy 72.780, Test_accy 45.000
2022-05-25 12:36:26,083 [bic.py] => bias_correction => Task 8, Epoch 116/170 => Loss 3.984, Train_accy 70.560, Test_accy 44.970
2022-05-25 12:36:27,944 [bic.py] => bias_correction => Task 8, Epoch 117/170 => Loss 3.990, Train_accy 75.560, Test_accy 44.870
2022-05-25 12:36:29,871 [bic.py] => bias_correction => Task 8, Epoch 118/170 => Loss 3.991, Train_accy 75.000, Test_accy 44.860
2022-05-25 12:36:31,761 [bic.py] => bias_correction => Task 8, Epoch 119/170 => Loss 3.984, Train_accy 73.330, Test_accy 44.930
2022-05-25 12:36:33,584 [bic.py] => bias_correction => Task 8, Epoch 120/170 => Loss 3.998, Train_accy 74.440, Test_accy 44.930
2022-05-25 12:36:35,490 [bic.py] => bias_correction => Task 8, Epoch 121/170 => Loss 3.993, Train_accy 75.000, Test_accy 44.880
2022-05-25 12:36:37,397 [bic.py] => bias_correction => Task 8, Epoch 122/170 => Loss 3.998, Train_accy 70.560, Test_accy 44.820
2022-05-25 12:36:39,263 [bic.py] => bias_correction => Task 8, Epoch 123/170 => Loss 3.973, Train_accy 72.780, Test_accy 44.930
2022-05-25 12:36:41,257 [bic.py] => bias_correction => Task 8, Epoch 124/170 => Loss 3.984, Train_accy 74.440, Test_accy 44.880
2022-05-25 12:36:43,141 [bic.py] => bias_correction => Task 8, Epoch 125/170 => Loss 4.005, Train_accy 73.890, Test_accy 44.870
2022-05-25 12:36:45,063 [bic.py] => bias_correction => Task 8, Epoch 126/170 => Loss 3.988, Train_accy 74.440, Test_accy 44.920
2022-05-25 12:36:46,955 [bic.py] => bias_correction => Task 8, Epoch 127/170 => Loss 3.999, Train_accy 72.220, Test_accy 45.060
2022-05-25 12:36:48,926 [bic.py] => bias_correction => Task 8, Epoch 128/170 => Loss 3.999, Train_accy 74.440, Test_accy 45.040
2022-05-25 12:36:50,771 [bic.py] => bias_correction => Task 8, Epoch 129/170 => Loss 3.995, Train_accy 75.000, Test_accy 45.030
2022-05-25 12:36:52,690 [bic.py] => bias_correction => Task 8, Epoch 130/170 => Loss 3.993, Train_accy 77.220, Test_accy 44.990
2022-05-25 12:36:54,642 [bic.py] => bias_correction => Task 8, Epoch 131/170 => Loss 3.989, Train_accy 74.440, Test_accy 45.010
2022-05-25 12:36:56,528 [bic.py] => bias_correction => Task 8, Epoch 132/170 => Loss 4.013, Train_accy 70.560, Test_accy 45.100
2022-05-25 12:36:58,378 [bic.py] => bias_correction => Task 8, Epoch 133/170 => Loss 3.983, Train_accy 71.670, Test_accy 45.060
2022-05-25 12:37:00,218 [bic.py] => bias_correction => Task 8, Epoch 134/170 => Loss 4.008, Train_accy 74.440, Test_accy 45.130
2022-05-25 12:37:02,048 [bic.py] => bias_correction => Task 8, Epoch 135/170 => Loss 3.989, Train_accy 74.440, Test_accy 45.060
2022-05-25 12:37:03,889 [bic.py] => bias_correction => Task 8, Epoch 136/170 => Loss 4.021, Train_accy 73.890, Test_accy 45.160
2022-05-25 12:37:05,771 [bic.py] => bias_correction => Task 8, Epoch 137/170 => Loss 3.994, Train_accy 73.330, Test_accy 45.090
2022-05-25 12:37:07,676 [bic.py] => bias_correction => Task 8, Epoch 138/170 => Loss 3.990, Train_accy 73.890, Test_accy 45.080
2022-05-25 12:37:09,584 [bic.py] => bias_correction => Task 8, Epoch 139/170 => Loss 3.996, Train_accy 74.440, Test_accy 45.170
2022-05-25 12:37:11,478 [bic.py] => bias_correction => Task 8, Epoch 140/170 => Loss 3.977, Train_accy 73.890, Test_accy 45.100
2022-05-25 12:37:13,386 [bic.py] => bias_correction => Task 8, Epoch 141/170 => Loss 4.002, Train_accy 72.780, Test_accy 45.070
2022-05-25 12:37:15,291 [bic.py] => bias_correction => Task 8, Epoch 142/170 => Loss 4.002, Train_accy 74.440, Test_accy 45.120
2022-05-25 12:37:17,129 [bic.py] => bias_correction => Task 8, Epoch 143/170 => Loss 3.991, Train_accy 73.330, Test_accy 45.120
2022-05-25 12:37:18,967 [bic.py] => bias_correction => Task 8, Epoch 144/170 => Loss 3.998, Train_accy 73.330, Test_accy 45.110
2022-05-25 12:37:20,824 [bic.py] => bias_correction => Task 8, Epoch 145/170 => Loss 3.992, Train_accy 75.560, Test_accy 45.110
2022-05-25 12:37:22,794 [bic.py] => bias_correction => Task 8, Epoch 146/170 => Loss 4.018, Train_accy 70.000, Test_accy 45.220
2022-05-25 12:37:24,824 [bic.py] => bias_correction => Task 8, Epoch 147/170 => Loss 3.996, Train_accy 73.330, Test_accy 45.180
2022-05-25 12:37:26,694 [bic.py] => bias_correction => Task 8, Epoch 148/170 => Loss 3.997, Train_accy 73.330, Test_accy 45.160
2022-05-25 12:37:28,588 [bic.py] => bias_correction => Task 8, Epoch 149/170 => Loss 4.004, Train_accy 74.440, Test_accy 45.090
2022-05-25 12:37:30,442 [bic.py] => bias_correction => Task 8, Epoch 150/170 => Loss 3.997, Train_accy 74.440, Test_accy 45.160
2022-05-25 12:37:32,332 [bic.py] => bias_correction => Task 8, Epoch 151/170 => Loss 3.979, Train_accy 72.780, Test_accy 45.030
2022-05-25 12:37:34,288 [bic.py] => bias_correction => Task 8, Epoch 152/170 => Loss 3.989, Train_accy 71.670, Test_accy 45.170
2022-05-25 12:37:36,220 [bic.py] => bias_correction => Task 8, Epoch 153/170 => Loss 4.003, Train_accy 72.780, Test_accy 45.070
2022-05-25 12:37:38,129 [bic.py] => bias_correction => Task 8, Epoch 154/170 => Loss 3.977, Train_accy 73.890, Test_accy 45.040
2022-05-25 12:37:40,049 [bic.py] => bias_correction => Task 8, Epoch 155/170 => Loss 3.993, Train_accy 72.780, Test_accy 45.060
2022-05-25 12:37:41,871 [bic.py] => bias_correction => Task 8, Epoch 156/170 => Loss 4.010, Train_accy 76.110, Test_accy 45.100
2022-05-25 12:37:43,728 [bic.py] => bias_correction => Task 8, Epoch 157/170 => Loss 4.027, Train_accy 73.330, Test_accy 45.070
2022-05-25 12:37:45,619 [bic.py] => bias_correction => Task 8, Epoch 158/170 => Loss 3.997, Train_accy 73.890, Test_accy 45.000
2022-05-25 12:37:47,503 [bic.py] => bias_correction => Task 8, Epoch 159/170 => Loss 3.991, Train_accy 74.440, Test_accy 45.030
2022-05-25 12:37:49,430 [bic.py] => bias_correction => Task 8, Epoch 160/170 => Loss 3.967, Train_accy 72.220, Test_accy 45.020
2022-05-25 12:37:51,315 [bic.py] => bias_correction => Task 8, Epoch 161/170 => Loss 3.988, Train_accy 71.110, Test_accy 45.040
2022-05-25 12:37:53,238 [bic.py] => bias_correction => Task 8, Epoch 162/170 => Loss 3.985, Train_accy 72.780, Test_accy 44.930
2022-05-25 12:37:55,155 [bic.py] => bias_correction => Task 8, Epoch 163/170 => Loss 4.000, Train_accy 72.780, Test_accy 44.980
2022-05-25 12:37:57,029 [bic.py] => bias_correction => Task 8, Epoch 164/170 => Loss 4.011, Train_accy 73.890, Test_accy 45.110
2022-05-25 12:37:58,905 [bic.py] => bias_correction => Task 8, Epoch 165/170 => Loss 3.992, Train_accy 72.220, Test_accy 45.030
2022-05-25 12:38:00,837 [bic.py] => bias_correction => Task 8, Epoch 166/170 => Loss 4.007, Train_accy 71.670, Test_accy 44.980
2022-05-25 12:38:02,725 [bic.py] => bias_correction => Task 8, Epoch 167/170 => Loss 3.980, Train_accy 73.330, Test_accy 45.060
2022-05-25 12:38:04,624 [bic.py] => bias_correction => Task 8, Epoch 168/170 => Loss 3.973, Train_accy 73.330, Test_accy 45.200
2022-05-25 12:38:06,591 [bic.py] => bias_correction => Task 8, Epoch 169/170 => Loss 4.006, Train_accy 72.220, Test_accy 45.030
2022-05-25 12:38:08,472 [bic.py] => bias_correction => Task 8, Epoch 170/170 => Loss 4.002, Train_accy 71.110, Test_accy 45.020
2022-05-25 12:38:08,472 [base.py] => Reducing exemplars...(22 per classes)
2022-05-25 12:38:24,888 [base.py] => Constructing exemplars...(22 per classes)
2022-05-25 12:38:29,946 [bic.py] => Parameters of bias layer:
2022-05-25 12:38:29,947 [bic.py] => 0 => 1.000, 0.000
2022-05-25 12:38:29,947 [bic.py] => 1 => 0.904, -1.125
2022-05-25 12:38:29,947 [bic.py] => 2 => 0.889, -1.948
2022-05-25 12:38:29,947 [bic.py] => 3 => 0.729, -1.345
2022-05-25 12:38:29,947 [bic.py] => 4 => 0.731, -1.321
2022-05-25 12:38:29,948 [bic.py] => 5 => 0.734, -1.140
2022-05-25 12:38:29,948 [bic.py] => 6 => 0.749, -1.468
2022-05-25 12:38:29,948 [bic.py] => 7 => 0.022, -0.851
2022-05-25 12:38:29,948 [bic.py] => 8 => 0.693, -1.091
2022-05-25 12:38:32,105 [bic.py] => Exemplar size: 1980
2022-05-25 12:38:32,106 [trainer.py] => CNN: {'total': 45.02, '00-09': 47.4, '10-19': 44.9, '20-29': 55.5, '30-39': 40.3, '40-49': 44.6, '50-59': 51.0, '60-69': 54.4, '70-79': 0.0, '80-89': 67.1, 'old': 42.26, 'new': 67.1}
2022-05-25 12:38:32,106 [trainer.py] => NME: {'total': 47.54, '00-09': 42.6, '10-19': 39.1, '20-29': 48.8, '30-39': 43.4, '40-49': 45.9, '50-59': 50.4, '60-69': 49.3, '70-79': 42.6, '80-89': 65.8, 'old': 45.26, 'new': 65.8}
2022-05-25 12:38:32,106 [trainer.py] => CNN top1 curve: [83.0, 73.7, 68.1, 62.2, 58.38, 55.52, 52.99, 44.45, 45.02]
2022-05-25 12:38:32,106 [trainer.py] => CNN top5 curve: [99.1, 95.65, 92.07, 89.1, 86.2, 84.27, 81.76, 70.06, 70.97]
2022-05-25 12:38:32,106 [trainer.py] => NME top1 curve: [82.8, 74.15, 67.37, 61.9, 58.1, 56.52, 53.94, 50.61, 47.54]
2022-05-25 12:38:32,106 [trainer.py] => NME top5 curve: [99.0, 95.75, 92.47, 89.32, 86.1, 84.15, 81.77, 79.03, 75.36]

2022-05-25 12:38:32,106 [trainer.py] => All params: 470022
2022-05-25 12:38:32,107 [trainer.py] => Trainable params: 470022
2022-05-25 12:38:32,108 [bic.py] => Learning on 90-100
2022-05-25 12:38:32,153 [bic.py] => Stage1 dset: 6780, Stage2 dset: 200
2022-05-25 12:38:32,153 [bic.py] => Lambda: 0.900
2022-05-25 12:38:32,176 [bic.py] => Parameters of bias layer:
2022-05-25 12:38:32,176 [bic.py] => 0 => 1.000, 0.000
2022-05-25 12:38:32,177 [bic.py] => 1 => 0.904, -1.125
2022-05-25 12:38:32,177 [bic.py] => 2 => 0.889, -1.948
2022-05-25 12:38:32,177 [bic.py] => 3 => 0.729, -1.345
2022-05-25 12:38:32,177 [bic.py] => 4 => 0.731, -1.321
2022-05-25 12:38:32,177 [bic.py] => 5 => 0.734, -1.140
2022-05-25 12:38:32,177 [bic.py] => 6 => 0.749, -1.468
2022-05-25 12:38:32,177 [bic.py] => 7 => 0.022, -0.851
2022-05-25 12:38:32,177 [bic.py] => 8 => 0.693, -1.091
2022-05-25 12:38:32,177 [bic.py] => 9 => 1.000, 0.000
2022-05-25 12:38:36,820 [bic.py] => training => Task 9, Epoch 1/170 => Loss 3.419, Train_accy 68.170, Test_accy 22.720
2022-05-25 12:38:41,400 [bic.py] => training => Task 9, Epoch 2/170 => Loss 3.342, Train_accy 75.380, Test_accy 26.600
2022-05-25 12:38:46,048 [bic.py] => training => Task 9, Epoch 3/170 => Loss 3.330, Train_accy 77.430, Test_accy 26.900
2022-05-25 12:38:50,740 [bic.py] => training => Task 9, Epoch 4/170 => Loss 3.329, Train_accy 79.900, Test_accy 29.930
2022-05-25 12:38:55,412 [bic.py] => training => Task 9, Epoch 5/170 => Loss 3.317, Train_accy 80.120, Test_accy 27.420
2022-05-25 12:39:00,135 [bic.py] => training => Task 9, Epoch 6/170 => Loss 3.313, Train_accy 80.860, Test_accy 27.530
2022-05-25 12:39:04,836 [bic.py] => training => Task 9, Epoch 7/170 => Loss 3.317, Train_accy 82.020, Test_accy 27.890
2022-05-25 12:39:09,627 [bic.py] => training => Task 9, Epoch 8/170 => Loss 3.309, Train_accy 82.020, Test_accy 28.490
2022-05-25 12:39:14,410 [bic.py] => training => Task 9, Epoch 9/170 => Loss 3.302, Train_accy 84.070, Test_accy 29.510
2022-05-25 12:39:18,985 [bic.py] => training => Task 9, Epoch 10/170 => Loss 3.298, Train_accy 84.420, Test_accy 26.020
2022-05-25 12:39:23,759 [bic.py] => training => Task 9, Epoch 11/170 => Loss 3.299, Train_accy 84.810, Test_accy 30.140
2022-05-25 12:39:28,283 [bic.py] => training => Task 9, Epoch 12/170 => Loss 3.301, Train_accy 85.430, Test_accy 31.200
2022-05-25 12:39:33,243 [bic.py] => training => Task 9, Epoch 13/170 => Loss 3.297, Train_accy 84.600, Test_accy 30.880
2022-05-25 12:39:38,204 [bic.py] => training => Task 9, Epoch 14/170 => Loss 3.299, Train_accy 85.220, Test_accy 27.910
2022-05-25 12:39:43,029 [bic.py] => training => Task 9, Epoch 15/170 => Loss 3.300, Train_accy 87.450, Test_accy 30.830
2022-05-25 12:39:47,740 [bic.py] => training => Task 9, Epoch 16/170 => Loss 3.305, Train_accy 87.010, Test_accy 31.450
2022-05-25 12:39:52,489 [bic.py] => training => Task 9, Epoch 17/170 => Loss 3.292, Train_accy 85.650, Test_accy 29.610
2022-05-25 12:39:57,347 [bic.py] => training => Task 9, Epoch 18/170 => Loss 3.293, Train_accy 84.910, Test_accy 27.960
2022-05-25 12:40:02,255 [bic.py] => training => Task 9, Epoch 19/170 => Loss 3.292, Train_accy 78.240, Test_accy 21.680
2022-05-25 12:40:07,272 [bic.py] => training => Task 9, Epoch 20/170 => Loss 3.290, Train_accy 84.400, Test_accy 28.050
2022-05-25 12:40:12,155 [bic.py] => training => Task 9, Epoch 21/170 => Loss 3.294, Train_accy 86.550, Test_accy 29.390
2022-05-25 12:40:16,954 [bic.py] => training => Task 9, Epoch 22/170 => Loss 3.297, Train_accy 85.340, Test_accy 29.420
2022-05-25 12:40:21,729 [bic.py] => training => Task 9, Epoch 23/170 => Loss 3.293, Train_accy 85.600, Test_accy 27.290
2022-05-25 12:40:26,532 [bic.py] => training => Task 9, Epoch 24/170 => Loss 3.291, Train_accy 84.880, Test_accy 29.070
2022-05-25 12:40:31,320 [bic.py] => training => Task 9, Epoch 25/170 => Loss 3.298, Train_accy 85.440, Test_accy 29.710
2022-05-25 12:40:36,146 [bic.py] => training => Task 9, Epoch 26/170 => Loss 3.292, Train_accy 86.250, Test_accy 26.600
2022-05-25 12:40:41,131 [bic.py] => training => Task 9, Epoch 27/170 => Loss 3.295, Train_accy 84.990, Test_accy 28.030
2022-05-25 12:40:46,142 [bic.py] => training => Task 9, Epoch 28/170 => Loss 3.288, Train_accy 85.150, Test_accy 30.970
2022-05-25 12:40:50,933 [bic.py] => training => Task 9, Epoch 29/170 => Loss 3.290, Train_accy 87.040, Test_accy 29.480
2022-05-25 12:40:55,611 [bic.py] => training => Task 9, Epoch 30/170 => Loss 3.291, Train_accy 87.230, Test_accy 27.840
2022-05-25 12:41:00,394 [bic.py] => training => Task 9, Epoch 31/170 => Loss 3.289, Train_accy 88.300, Test_accy 31.730
2022-05-25 12:41:05,097 [bic.py] => training => Task 9, Epoch 32/170 => Loss 3.292, Train_accy 87.630, Test_accy 28.560
2022-05-25 12:41:09,741 [bic.py] => training => Task 9, Epoch 33/170 => Loss 3.293, Train_accy 88.540, Test_accy 31.680
2022-05-25 12:41:14,571 [bic.py] => training => Task 9, Epoch 34/170 => Loss 3.292, Train_accy 88.020, Test_accy 30.710
2022-05-25 12:41:19,381 [bic.py] => training => Task 9, Epoch 35/170 => Loss 3.285, Train_accy 88.220, Test_accy 30.460
2022-05-25 12:41:24,089 [bic.py] => training => Task 9, Epoch 36/170 => Loss 3.290, Train_accy 84.320, Test_accy 28.690
2022-05-25 12:41:28,830 [bic.py] => training => Task 9, Epoch 37/170 => Loss 3.288, Train_accy 88.860, Test_accy 31.610
2022-05-25 12:41:33,585 [bic.py] => training => Task 9, Epoch 38/170 => Loss 3.283, Train_accy 89.190, Test_accy 31.570
2022-05-25 12:41:38,423 [bic.py] => training => Task 9, Epoch 39/170 => Loss 3.284, Train_accy 85.210, Test_accy 27.040
2022-05-25 12:41:43,193 [bic.py] => training => Task 9, Epoch 40/170 => Loss 3.286, Train_accy 89.900, Test_accy 30.990
2022-05-25 12:41:47,991 [bic.py] => training => Task 9, Epoch 41/170 => Loss 3.282, Train_accy 90.280, Test_accy 33.360
2022-05-25 12:41:52,809 [bic.py] => training => Task 9, Epoch 42/170 => Loss 3.285, Train_accy 87.360, Test_accy 27.270
2022-05-25 12:41:57,565 [bic.py] => training => Task 9, Epoch 43/170 => Loss 3.283, Train_accy 90.620, Test_accy 31.430
2022-05-25 12:42:02,438 [bic.py] => training => Task 9, Epoch 44/170 => Loss 3.283, Train_accy 86.900, Test_accy 31.270
2022-05-25 12:42:07,169 [bic.py] => training => Task 9, Epoch 45/170 => Loss 3.282, Train_accy 89.370, Test_accy 32.180
2022-05-25 12:42:12,110 [bic.py] => training => Task 9, Epoch 46/170 => Loss 3.286, Train_accy 85.280, Test_accy 28.540
2022-05-25 12:42:16,930 [bic.py] => training => Task 9, Epoch 47/170 => Loss 3.286, Train_accy 89.650, Test_accy 29.460
2022-05-25 12:42:21,705 [bic.py] => training => Task 9, Epoch 48/170 => Loss 3.284, Train_accy 91.470, Test_accy 30.910
2022-05-25 12:42:26,486 [bic.py] => training => Task 9, Epoch 49/170 => Loss 3.287, Train_accy 87.940, Test_accy 32.200
2022-05-25 12:42:31,465 [bic.py] => training => Task 9, Epoch 50/170 => Loss 3.282, Train_accy 87.210, Test_accy 26.910
2022-05-25 12:42:36,390 [bic.py] => training => Task 9, Epoch 51/170 => Loss 3.282, Train_accy 90.210, Test_accy 32.020
2022-05-25 12:42:41,227 [bic.py] => training => Task 9, Epoch 52/170 => Loss 3.285, Train_accy 90.270, Test_accy 29.320
2022-05-25 12:42:45,953 [bic.py] => training => Task 9, Epoch 53/170 => Loss 3.282, Train_accy 90.650, Test_accy 31.220
2022-05-25 12:42:50,487 [bic.py] => training => Task 9, Epoch 54/170 => Loss 3.284, Train_accy 90.960, Test_accy 31.840
2022-05-25 12:42:55,343 [bic.py] => training => Task 9, Epoch 55/170 => Loss 3.284, Train_accy 87.730, Test_accy 30.350
2022-05-25 12:43:00,141 [bic.py] => training => Task 9, Epoch 56/170 => Loss 3.282, Train_accy 87.040, Test_accy 26.400
2022-05-25 12:43:04,916 [bic.py] => training => Task 9, Epoch 57/170 => Loss 3.285, Train_accy 89.880, Test_accy 29.990
2022-05-25 12:43:09,739 [bic.py] => training => Task 9, Epoch 58/170 => Loss 3.281, Train_accy 91.580, Test_accy 33.080
2022-05-25 12:43:14,449 [bic.py] => training => Task 9, Epoch 59/170 => Loss 3.280, Train_accy 90.220, Test_accy 31.000
2022-05-25 12:43:19,215 [bic.py] => training => Task 9, Epoch 60/170 => Loss 3.281, Train_accy 89.200, Test_accy 32.040
2022-05-25 12:43:23,998 [bic.py] => training => Task 9, Epoch 61/170 => Loss 3.256, Train_accy 95.490, Test_accy 34.110
2022-05-25 12:43:28,844 [bic.py] => training => Task 9, Epoch 62/170 => Loss 3.254, Train_accy 96.060, Test_accy 34.930
2022-05-25 12:43:33,629 [bic.py] => training => Task 9, Epoch 63/170 => Loss 3.246, Train_accy 96.030, Test_accy 33.470
2022-05-25 12:43:38,345 [bic.py] => training => Task 9, Epoch 64/170 => Loss 3.252, Train_accy 95.830, Test_accy 33.750
2022-05-25 12:43:43,126 [bic.py] => training => Task 9, Epoch 65/170 => Loss 3.249, Train_accy 95.710, Test_accy 34.370
2022-05-25 12:43:48,060 [bic.py] => training => Task 9, Epoch 66/170 => Loss 3.250, Train_accy 96.150, Test_accy 33.670
2022-05-25 12:43:52,949 [bic.py] => training => Task 9, Epoch 67/170 => Loss 3.246, Train_accy 96.030, Test_accy 34.220
2022-05-25 12:43:57,855 [bic.py] => training => Task 9, Epoch 68/170 => Loss 3.244, Train_accy 95.970, Test_accy 34.150
2022-05-25 12:44:02,973 [bic.py] => training => Task 9, Epoch 69/170 => Loss 3.249, Train_accy 96.270, Test_accy 34.110
2022-05-25 12:44:07,781 [bic.py] => training => Task 9, Epoch 70/170 => Loss 3.244, Train_accy 95.940, Test_accy 34.240
2022-05-25 12:44:12,530 [bic.py] => training => Task 9, Epoch 71/170 => Loss 3.244, Train_accy 96.280, Test_accy 33.960
2022-05-25 12:44:17,233 [bic.py] => training => Task 9, Epoch 72/170 => Loss 3.240, Train_accy 96.300, Test_accy 33.790
2022-05-25 12:44:21,967 [bic.py] => training => Task 9, Epoch 73/170 => Loss 3.244, Train_accy 96.240, Test_accy 34.520
2022-05-25 12:44:26,539 [bic.py] => training => Task 9, Epoch 74/170 => Loss 3.245, Train_accy 96.090, Test_accy 34.380
2022-05-25 12:44:31,209 [bic.py] => training => Task 9, Epoch 75/170 => Loss 3.244, Train_accy 96.300, Test_accy 33.920
2022-05-25 12:44:36,046 [bic.py] => training => Task 9, Epoch 76/170 => Loss 3.248, Train_accy 96.330, Test_accy 34.150
2022-05-25 12:44:40,746 [bic.py] => training => Task 9, Epoch 77/170 => Loss 3.243, Train_accy 96.340, Test_accy 33.870
2022-05-25 12:44:45,583 [bic.py] => training => Task 9, Epoch 78/170 => Loss 3.242, Train_accy 96.180, Test_accy 34.310
2022-05-25 12:44:50,102 [bic.py] => training => Task 9, Epoch 79/170 => Loss 3.246, Train_accy 96.450, Test_accy 34.330
2022-05-25 12:44:54,972 [bic.py] => training => Task 9, Epoch 80/170 => Loss 3.244, Train_accy 96.460, Test_accy 34.150
2022-05-25 12:44:59,804 [bic.py] => training => Task 9, Epoch 81/170 => Loss 3.240, Train_accy 96.190, Test_accy 34.090
2022-05-25 12:45:04,495 [bic.py] => training => Task 9, Epoch 82/170 => Loss 3.247, Train_accy 96.300, Test_accy 33.760
2022-05-25 12:45:09,570 [bic.py] => training => Task 9, Epoch 83/170 => Loss 3.242, Train_accy 96.310, Test_accy 34.260
2022-05-25 12:45:14,348 [bic.py] => training => Task 9, Epoch 84/170 => Loss 3.237, Train_accy 96.370, Test_accy 34.660
2022-05-25 12:45:19,125 [bic.py] => training => Task 9, Epoch 85/170 => Loss 3.241, Train_accy 96.390, Test_accy 34.210
2022-05-25 12:45:23,914 [bic.py] => training => Task 9, Epoch 86/170 => Loss 3.244, Train_accy 96.420, Test_accy 34.610
2022-05-25 12:45:28,637 [bic.py] => training => Task 9, Epoch 87/170 => Loss 3.242, Train_accy 96.330, Test_accy 34.460
2022-05-25 12:45:33,470 [bic.py] => training => Task 9, Epoch 88/170 => Loss 3.241, Train_accy 96.500, Test_accy 33.780
2022-05-25 12:45:38,407 [bic.py] => training => Task 9, Epoch 89/170 => Loss 3.241, Train_accy 96.280, Test_accy 33.350
2022-05-25 12:45:43,322 [bic.py] => training => Task 9, Epoch 90/170 => Loss 3.243, Train_accy 96.300, Test_accy 33.800
2022-05-25 12:45:48,199 [bic.py] => training => Task 9, Epoch 91/170 => Loss 3.240, Train_accy 96.420, Test_accy 34.050
2022-05-25 12:45:53,074 [bic.py] => training => Task 9, Epoch 92/170 => Loss 3.243, Train_accy 96.370, Test_accy 34.030
2022-05-25 12:45:57,897 [bic.py] => training => Task 9, Epoch 93/170 => Loss 3.236, Train_accy 96.530, Test_accy 33.810
2022-05-25 12:46:02,633 [bic.py] => training => Task 9, Epoch 94/170 => Loss 3.238, Train_accy 96.580, Test_accy 34.570
2022-05-25 12:46:07,457 [bic.py] => training => Task 9, Epoch 95/170 => Loss 3.244, Train_accy 96.340, Test_accy 33.380
2022-05-25 12:46:12,227 [bic.py] => training => Task 9, Epoch 96/170 => Loss 3.245, Train_accy 96.470, Test_accy 34.150
2022-05-25 12:46:16,817 [bic.py] => training => Task 9, Epoch 97/170 => Loss 3.236, Train_accy 96.460, Test_accy 33.850
2022-05-25 12:46:21,535 [bic.py] => training => Task 9, Epoch 98/170 => Loss 3.242, Train_accy 96.420, Test_accy 33.380
2022-05-25 12:46:26,408 [bic.py] => training => Task 9, Epoch 99/170 => Loss 3.243, Train_accy 96.430, Test_accy 34.370
2022-05-25 12:46:31,307 [bic.py] => training => Task 9, Epoch 100/170 => Loss 3.239, Train_accy 96.500, Test_accy 34.270
2022-05-25 12:46:36,042 [bic.py] => training => Task 9, Epoch 101/170 => Loss 3.237, Train_accy 96.460, Test_accy 34.160
2022-05-25 12:46:40,910 [bic.py] => training => Task 9, Epoch 102/170 => Loss 3.242, Train_accy 96.520, Test_accy 34.220
2022-05-25 12:46:45,587 [bic.py] => training => Task 9, Epoch 103/170 => Loss 3.239, Train_accy 96.680, Test_accy 34.400
2022-05-25 12:46:50,085 [bic.py] => training => Task 9, Epoch 104/170 => Loss 3.240, Train_accy 96.610, Test_accy 34.300
2022-05-25 12:46:54,792 [bic.py] => training => Task 9, Epoch 105/170 => Loss 3.241, Train_accy 96.550, Test_accy 34.320
2022-05-25 12:46:59,363 [bic.py] => training => Task 9, Epoch 106/170 => Loss 3.239, Train_accy 96.560, Test_accy 34.160
2022-05-25 12:47:04,118 [bic.py] => training => Task 9, Epoch 107/170 => Loss 3.242, Train_accy 96.420, Test_accy 34.210
2022-05-25 12:47:08,891 [bic.py] => training => Task 9, Epoch 108/170 => Loss 3.238, Train_accy 96.560, Test_accy 34.490
2022-05-25 12:47:13,676 [bic.py] => training => Task 9, Epoch 109/170 => Loss 3.234, Train_accy 96.590, Test_accy 34.300
2022-05-25 12:47:18,441 [bic.py] => training => Task 9, Epoch 110/170 => Loss 3.240, Train_accy 96.460, Test_accy 34.320
2022-05-25 12:47:23,124 [bic.py] => training => Task 9, Epoch 111/170 => Loss 3.236, Train_accy 96.530, Test_accy 34.250
2022-05-25 12:47:27,843 [bic.py] => training => Task 9, Epoch 112/170 => Loss 3.238, Train_accy 96.670, Test_accy 34.450
2022-05-25 12:47:32,727 [bic.py] => training => Task 9, Epoch 113/170 => Loss 3.240, Train_accy 96.500, Test_accy 34.100
2022-05-25 12:47:37,685 [bic.py] => training => Task 9, Epoch 114/170 => Loss 3.242, Train_accy 96.620, Test_accy 34.400
2022-05-25 12:47:42,413 [bic.py] => training => Task 9, Epoch 115/170 => Loss 3.235, Train_accy 96.470, Test_accy 34.280
2022-05-25 12:47:47,235 [bic.py] => training => Task 9, Epoch 116/170 => Loss 3.236, Train_accy 96.670, Test_accy 34.490
2022-05-25 12:47:51,967 [bic.py] => training => Task 9, Epoch 117/170 => Loss 3.235, Train_accy 96.620, Test_accy 34.580
2022-05-25 12:47:56,955 [bic.py] => training => Task 9, Epoch 118/170 => Loss 3.234, Train_accy 96.450, Test_accy 34.190
2022-05-25 12:48:01,769 [bic.py] => training => Task 9, Epoch 119/170 => Loss 3.238, Train_accy 96.580, Test_accy 34.540
2022-05-25 12:48:06,665 [bic.py] => training => Task 9, Epoch 120/170 => Loss 3.235, Train_accy 96.580, Test_accy 34.290
2022-05-25 12:48:11,522 [bic.py] => training => Task 9, Epoch 121/170 => Loss 3.239, Train_accy 96.670, Test_accy 34.460
2022-05-25 12:48:16,138 [bic.py] => training => Task 9, Epoch 122/170 => Loss 3.238, Train_accy 96.650, Test_accy 34.290
2022-05-25 12:48:20,999 [bic.py] => training => Task 9, Epoch 123/170 => Loss 3.236, Train_accy 96.590, Test_accy 34.490
2022-05-25 12:48:25,853 [bic.py] => training => Task 9, Epoch 124/170 => Loss 3.239, Train_accy 96.500, Test_accy 34.230
2022-05-25 12:48:30,822 [bic.py] => training => Task 9, Epoch 125/170 => Loss 3.236, Train_accy 96.670, Test_accy 34.190
2022-05-25 12:48:35,899 [bic.py] => training => Task 9, Epoch 126/170 => Loss 3.239, Train_accy 96.620, Test_accy 34.200
2022-05-25 12:48:40,913 [bic.py] => training => Task 9, Epoch 127/170 => Loss 3.242, Train_accy 96.550, Test_accy 33.920
2022-05-25 12:48:45,743 [bic.py] => training => Task 9, Epoch 128/170 => Loss 3.238, Train_accy 96.580, Test_accy 34.450
2022-05-25 12:48:50,533 [bic.py] => training => Task 9, Epoch 129/170 => Loss 3.239, Train_accy 96.530, Test_accy 34.250
2022-05-25 12:48:55,486 [bic.py] => training => Task 9, Epoch 130/170 => Loss 3.237, Train_accy 96.490, Test_accy 34.490
2022-05-25 12:49:00,296 [bic.py] => training => Task 9, Epoch 131/170 => Loss 3.236, Train_accy 96.650, Test_accy 34.370
2022-05-25 12:49:04,958 [bic.py] => training => Task 9, Epoch 132/170 => Loss 3.238, Train_accy 96.550, Test_accy 34.310
2022-05-25 12:49:09,671 [bic.py] => training => Task 9, Epoch 133/170 => Loss 3.239, Train_accy 96.400, Test_accy 34.280
2022-05-25 12:49:14,541 [bic.py] => training => Task 9, Epoch 134/170 => Loss 3.237, Train_accy 96.580, Test_accy 34.350
2022-05-25 12:49:19,276 [bic.py] => training => Task 9, Epoch 135/170 => Loss 3.237, Train_accy 96.590, Test_accy 34.500
2022-05-25 12:49:24,029 [bic.py] => training => Task 9, Epoch 136/170 => Loss 3.238, Train_accy 96.560, Test_accy 33.950
2022-05-25 12:49:28,872 [bic.py] => training => Task 9, Epoch 137/170 => Loss 3.239, Train_accy 96.550, Test_accy 34.580
2022-05-25 12:49:33,588 [bic.py] => training => Task 9, Epoch 138/170 => Loss 3.239, Train_accy 96.560, Test_accy 34.270
2022-05-25 12:49:38,341 [bic.py] => training => Task 9, Epoch 139/170 => Loss 3.240, Train_accy 96.550, Test_accy 34.050
2022-05-25 12:49:43,045 [bic.py] => training => Task 9, Epoch 140/170 => Loss 3.241, Train_accy 96.550, Test_accy 34.310
2022-05-25 12:49:47,828 [bic.py] => training => Task 9, Epoch 141/170 => Loss 3.238, Train_accy 96.470, Test_accy 34.420
2022-05-25 12:49:52,550 [bic.py] => training => Task 9, Epoch 142/170 => Loss 3.238, Train_accy 96.640, Test_accy 34.400
2022-05-25 12:49:57,315 [bic.py] => training => Task 9, Epoch 143/170 => Loss 3.241, Train_accy 96.560, Test_accy 34.400
2022-05-25 12:50:02,175 [bic.py] => training => Task 9, Epoch 144/170 => Loss 3.237, Train_accy 96.400, Test_accy 34.070
2022-05-25 12:50:06,994 [bic.py] => training => Task 9, Epoch 145/170 => Loss 3.238, Train_accy 96.610, Test_accy 34.250
2022-05-25 12:50:11,935 [bic.py] => training => Task 9, Epoch 146/170 => Loss 3.240, Train_accy 96.550, Test_accy 34.540
2022-05-25 12:50:16,688 [bic.py] => training => Task 9, Epoch 147/170 => Loss 3.237, Train_accy 96.590, Test_accy 34.150
2022-05-25 12:50:21,434 [bic.py] => training => Task 9, Epoch 148/170 => Loss 3.237, Train_accy 96.620, Test_accy 34.530
2022-05-25 12:50:26,187 [bic.py] => training => Task 9, Epoch 149/170 => Loss 3.237, Train_accy 96.580, Test_accy 33.980
2022-05-25 12:50:30,940 [bic.py] => training => Task 9, Epoch 150/170 => Loss 3.240, Train_accy 96.590, Test_accy 34.210
2022-05-25 12:50:35,609 [bic.py] => training => Task 9, Epoch 151/170 => Loss 3.239, Train_accy 96.640, Test_accy 34.430
2022-05-25 12:50:40,461 [bic.py] => training => Task 9, Epoch 152/170 => Loss 3.238, Train_accy 96.580, Test_accy 33.970
2022-05-25 12:50:45,240 [bic.py] => training => Task 9, Epoch 153/170 => Loss 3.235, Train_accy 96.530, Test_accy 34.320
2022-05-25 12:50:49,975 [bic.py] => training => Task 9, Epoch 154/170 => Loss 3.240, Train_accy 96.610, Test_accy 34.190
2022-05-25 12:50:54,903 [bic.py] => training => Task 9, Epoch 155/170 => Loss 3.241, Train_accy 96.640, Test_accy 34.130
2022-05-25 12:50:59,582 [bic.py] => training => Task 9, Epoch 156/170 => Loss 3.239, Train_accy 96.590, Test_accy 34.170
2022-05-25 12:51:04,366 [bic.py] => training => Task 9, Epoch 157/170 => Loss 3.237, Train_accy 96.590, Test_accy 34.040
2022-05-25 12:51:09,217 [bic.py] => training => Task 9, Epoch 158/170 => Loss 3.239, Train_accy 96.520, Test_accy 34.140
2022-05-25 12:51:14,107 [bic.py] => training => Task 9, Epoch 159/170 => Loss 3.235, Train_accy 96.430, Test_accy 34.230
2022-05-25 12:51:18,827 [bic.py] => training => Task 9, Epoch 160/170 => Loss 3.239, Train_accy 96.580, Test_accy 34.400
2022-05-25 12:51:23,539 [bic.py] => training => Task 9, Epoch 161/170 => Loss 3.240, Train_accy 96.530, Test_accy 34.390
2022-05-25 12:51:28,166 [bic.py] => training => Task 9, Epoch 162/170 => Loss 3.236, Train_accy 96.530, Test_accy 34.220
2022-05-25 12:51:32,916 [bic.py] => training => Task 9, Epoch 163/170 => Loss 3.236, Train_accy 96.710, Test_accy 34.220
2022-05-25 12:51:37,764 [bic.py] => training => Task 9, Epoch 164/170 => Loss 3.244, Train_accy 96.560, Test_accy 34.310
2022-05-25 12:51:42,714 [bic.py] => training => Task 9, Epoch 165/170 => Loss 3.239, Train_accy 96.580, Test_accy 34.170
2022-05-25 12:51:47,473 [bic.py] => training => Task 9, Epoch 166/170 => Loss 3.235, Train_accy 96.520, Test_accy 34.450
2022-05-25 12:51:52,217 [bic.py] => training => Task 9, Epoch 167/170 => Loss 3.239, Train_accy 96.550, Test_accy 34.340
2022-05-25 12:51:56,999 [bic.py] => training => Task 9, Epoch 168/170 => Loss 3.241, Train_accy 96.590, Test_accy 34.260
2022-05-25 12:52:01,797 [bic.py] => training => Task 9, Epoch 169/170 => Loss 3.239, Train_accy 96.620, Test_accy 34.160
2022-05-25 12:52:06,540 [bic.py] => training => Task 9, Epoch 170/170 => Loss 3.235, Train_accy 96.640, Test_accy 34.240
2022-05-25 12:52:08,539 [bic.py] => bias_correction => Task 9, Epoch 1/170 => Loss 4.245, Train_accy 58.000, Test_accy 36.360
2022-05-25 12:52:10,488 [bic.py] => bias_correction => Task 9, Epoch 2/170 => Loss 4.215, Train_accy 65.500, Test_accy 41.890
2022-05-25 12:52:12,449 [bic.py] => bias_correction => Task 9, Epoch 3/170 => Loss 4.173, Train_accy 74.000, Test_accy 44.050
2022-05-25 12:52:14,433 [bic.py] => bias_correction => Task 9, Epoch 4/170 => Loss 4.167, Train_accy 69.000, Test_accy 41.150
2022-05-25 12:52:16,393 [bic.py] => bias_correction => Task 9, Epoch 5/170 => Loss 4.152, Train_accy 70.500, Test_accy 40.460
2022-05-25 12:52:18,352 [bic.py] => bias_correction => Task 9, Epoch 6/170 => Loss 4.149, Train_accy 63.500, Test_accy 40.390
2022-05-25 12:52:20,246 [bic.py] => bias_correction => Task 9, Epoch 7/170 => Loss 4.150, Train_accy 66.000, Test_accy 40.310
2022-05-25 12:52:22,159 [bic.py] => bias_correction => Task 9, Epoch 8/170 => Loss 4.156, Train_accy 71.000, Test_accy 40.160
2022-05-25 12:52:24,141 [bic.py] => bias_correction => Task 9, Epoch 9/170 => Loss 4.152, Train_accy 69.000, Test_accy 40.230
2022-05-25 12:52:26,128 [bic.py] => bias_correction => Task 9, Epoch 10/170 => Loss 4.158, Train_accy 67.500, Test_accy 40.210
2022-05-25 12:52:28,187 [bic.py] => bias_correction => Task 9, Epoch 11/170 => Loss 4.145, Train_accy 67.000, Test_accy 40.210
2022-05-25 12:52:30,310 [bic.py] => bias_correction => Task 9, Epoch 12/170 => Loss 4.158, Train_accy 68.500, Test_accy 40.110
2022-05-25 12:52:32,437 [bic.py] => bias_correction => Task 9, Epoch 13/170 => Loss 4.172, Train_accy 68.000, Test_accy 40.130
2022-05-25 12:52:34,405 [bic.py] => bias_correction => Task 9, Epoch 14/170 => Loss 4.146, Train_accy 68.500, Test_accy 40.150
2022-05-25 12:52:36,304 [bic.py] => bias_correction => Task 9, Epoch 15/170 => Loss 4.167, Train_accy 65.500, Test_accy 40.140
2022-05-25 12:52:38,255 [bic.py] => bias_correction => Task 9, Epoch 16/170 => Loss 4.155, Train_accy 67.500, Test_accy 40.130
2022-05-25 12:52:40,321 [bic.py] => bias_correction => Task 9, Epoch 17/170 => Loss 4.150, Train_accy 68.000, Test_accy 40.120
2022-05-25 12:52:42,349 [bic.py] => bias_correction => Task 9, Epoch 18/170 => Loss 4.160, Train_accy 66.500, Test_accy 40.070
2022-05-25 12:52:44,387 [bic.py] => bias_correction => Task 9, Epoch 19/170 => Loss 4.166, Train_accy 70.000, Test_accy 40.070
2022-05-25 12:52:46,392 [bic.py] => bias_correction => Task 9, Epoch 20/170 => Loss 4.151, Train_accy 68.000, Test_accy 40.030
2022-05-25 12:52:48,608 [bic.py] => bias_correction => Task 9, Epoch 21/170 => Loss 4.160, Train_accy 70.500, Test_accy 39.930
2022-05-25 12:52:50,735 [bic.py] => bias_correction => Task 9, Epoch 22/170 => Loss 4.146, Train_accy 67.500, Test_accy 40.010
2022-05-25 12:52:52,816 [bic.py] => bias_correction => Task 9, Epoch 23/170 => Loss 4.144, Train_accy 69.000, Test_accy 40.090
2022-05-25 12:52:54,822 [bic.py] => bias_correction => Task 9, Epoch 24/170 => Loss 4.158, Train_accy 64.500, Test_accy 40.160
2022-05-25 12:52:56,989 [bic.py] => bias_correction => Task 9, Epoch 25/170 => Loss 4.146, Train_accy 69.500, Test_accy 40.170
2022-05-25 12:52:59,157 [bic.py] => bias_correction => Task 9, Epoch 26/170 => Loss 4.159, Train_accy 69.000, Test_accy 40.180
2022-05-25 12:53:01,373 [bic.py] => bias_correction => Task 9, Epoch 27/170 => Loss 4.158, Train_accy 69.500, Test_accy 40.110
2022-05-25 12:53:03,269 [bic.py] => bias_correction => Task 9, Epoch 28/170 => Loss 4.155, Train_accy 67.500, Test_accy 40.120
2022-05-25 12:53:05,234 [bic.py] => bias_correction => Task 9, Epoch 29/170 => Loss 4.158, Train_accy 66.000, Test_accy 40.070
2022-05-25 12:53:07,237 [bic.py] => bias_correction => Task 9, Epoch 30/170 => Loss 4.147, Train_accy 67.000, Test_accy 40.100
2022-05-25 12:53:09,239 [bic.py] => bias_correction => Task 9, Epoch 31/170 => Loss 4.156, Train_accy 68.500, Test_accy 40.120
2022-05-25 12:53:11,205 [bic.py] => bias_correction => Task 9, Epoch 32/170 => Loss 4.148, Train_accy 67.000, Test_accy 40.050
2022-05-25 12:53:13,194 [bic.py] => bias_correction => Task 9, Epoch 33/170 => Loss 4.154, Train_accy 68.500, Test_accy 40.020
2022-05-25 12:53:15,258 [bic.py] => bias_correction => Task 9, Epoch 34/170 => Loss 4.140, Train_accy 66.000, Test_accy 40.020
2022-05-25 12:53:17,254 [bic.py] => bias_correction => Task 9, Epoch 35/170 => Loss 4.141, Train_accy 66.000, Test_accy 40.060
2022-05-25 12:53:19,160 [bic.py] => bias_correction => Task 9, Epoch 36/170 => Loss 4.168, Train_accy 68.500, Test_accy 40.040
2022-05-25 12:53:21,148 [bic.py] => bias_correction => Task 9, Epoch 37/170 => Loss 4.154, Train_accy 67.500, Test_accy 40.060
2022-05-25 12:53:23,086 [bic.py] => bias_correction => Task 9, Epoch 38/170 => Loss 4.156, Train_accy 67.000, Test_accy 40.060
2022-05-25 12:53:25,017 [bic.py] => bias_correction => Task 9, Epoch 39/170 => Loss 4.164, Train_accy 70.000, Test_accy 40.080
2022-05-25 12:53:27,009 [bic.py] => bias_correction => Task 9, Epoch 40/170 => Loss 4.151, Train_accy 67.000, Test_accy 40.120
2022-05-25 12:53:29,074 [bic.py] => bias_correction => Task 9, Epoch 41/170 => Loss 4.150, Train_accy 66.000, Test_accy 40.190
2022-05-25 12:53:31,043 [bic.py] => bias_correction => Task 9, Epoch 42/170 => Loss 4.156, Train_accy 67.500, Test_accy 40.190
2022-05-25 12:53:33,061 [bic.py] => bias_correction => Task 9, Epoch 43/170 => Loss 4.152, Train_accy 66.500, Test_accy 40.170
2022-05-25 12:53:35,097 [bic.py] => bias_correction => Task 9, Epoch 44/170 => Loss 4.149, Train_accy 66.500, Test_accy 40.200
2022-05-25 12:53:37,095 [bic.py] => bias_correction => Task 9, Epoch 45/170 => Loss 4.144, Train_accy 66.000, Test_accy 40.280
2022-05-25 12:53:39,074 [bic.py] => bias_correction => Task 9, Epoch 46/170 => Loss 4.149, Train_accy 67.500, Test_accy 40.390
2022-05-25 12:53:41,098 [bic.py] => bias_correction => Task 9, Epoch 47/170 => Loss 4.154, Train_accy 67.000, Test_accy 40.380
2022-05-25 12:53:43,159 [bic.py] => bias_correction => Task 9, Epoch 48/170 => Loss 4.137, Train_accy 68.000, Test_accy 40.490
2022-05-25 12:53:45,152 [bic.py] => bias_correction => Task 9, Epoch 49/170 => Loss 4.143, Train_accy 71.000, Test_accy 40.850
2022-05-25 12:53:47,135 [bic.py] => bias_correction => Task 9, Epoch 50/170 => Loss 4.159, Train_accy 71.000, Test_accy 41.040
2022-05-25 12:53:49,191 [bic.py] => bias_correction => Task 9, Epoch 51/170 => Loss 4.155, Train_accy 67.500, Test_accy 41.700
2022-05-25 12:53:51,221 [bic.py] => bias_correction => Task 9, Epoch 52/170 => Loss 4.125, Train_accy 68.500, Test_accy 42.310
2022-05-25 12:53:53,250 [bic.py] => bias_correction => Task 9, Epoch 53/170 => Loss 4.135, Train_accy 68.000, Test_accy 42.770
2022-05-25 12:53:55,273 [bic.py] => bias_correction => Task 9, Epoch 54/170 => Loss 4.164, Train_accy 68.500, Test_accy 43.230
2022-05-25 12:53:57,201 [bic.py] => bias_correction => Task 9, Epoch 55/170 => Loss 4.159, Train_accy 72.000, Test_accy 43.350
2022-05-25 12:53:59,245 [bic.py] => bias_correction => Task 9, Epoch 56/170 => Loss 4.143, Train_accy 71.500, Test_accy 43.250
2022-05-25 12:54:01,268 [bic.py] => bias_correction => Task 9, Epoch 57/170 => Loss 4.154, Train_accy 68.500, Test_accy 43.220
2022-05-25 12:54:03,281 [bic.py] => bias_correction => Task 9, Epoch 58/170 => Loss 4.150, Train_accy 69.500, Test_accy 43.300
2022-05-25 12:54:05,379 [bic.py] => bias_correction => Task 9, Epoch 59/170 => Loss 4.147, Train_accy 71.000, Test_accy 43.190
2022-05-25 12:54:07,466 [bic.py] => bias_correction => Task 9, Epoch 60/170 => Loss 4.158, Train_accy 70.000, Test_accy 43.170
2022-05-25 12:54:09,518 [bic.py] => bias_correction => Task 9, Epoch 61/170 => Loss 4.158, Train_accy 71.000, Test_accy 43.090
2022-05-25 12:54:11,664 [bic.py] => bias_correction => Task 9, Epoch 62/170 => Loss 4.137, Train_accy 71.000, Test_accy 42.960
2022-05-25 12:54:13,678 [bic.py] => bias_correction => Task 9, Epoch 63/170 => Loss 4.155, Train_accy 71.500, Test_accy 43.060
2022-05-25 12:54:15,707 [bic.py] => bias_correction => Task 9, Epoch 64/170 => Loss 4.125, Train_accy 71.000, Test_accy 43.030
2022-05-25 12:54:17,640 [bic.py] => bias_correction => Task 9, Epoch 65/170 => Loss 4.155, Train_accy 68.500, Test_accy 43.070
2022-05-25 12:54:19,553 [bic.py] => bias_correction => Task 9, Epoch 66/170 => Loss 4.157, Train_accy 72.500, Test_accy 43.180
2022-05-25 12:54:21,476 [bic.py] => bias_correction => Task 9, Epoch 67/170 => Loss 4.133, Train_accy 70.500, Test_accy 43.190
2022-05-25 12:54:23,406 [bic.py] => bias_correction => Task 9, Epoch 68/170 => Loss 4.139, Train_accy 72.000, Test_accy 43.110
2022-05-25 12:54:25,279 [bic.py] => bias_correction => Task 9, Epoch 69/170 => Loss 4.133, Train_accy 71.500, Test_accy 43.170
2022-05-25 12:54:27,242 [bic.py] => bias_correction => Task 9, Epoch 70/170 => Loss 4.139, Train_accy 72.000, Test_accy 43.080
2022-05-25 12:54:29,295 [bic.py] => bias_correction => Task 9, Epoch 71/170 => Loss 4.144, Train_accy 69.500, Test_accy 43.110
2022-05-25 12:54:31,245 [bic.py] => bias_correction => Task 9, Epoch 72/170 => Loss 4.139, Train_accy 72.000, Test_accy 43.130
2022-05-25 12:54:33,209 [bic.py] => bias_correction => Task 9, Epoch 73/170 => Loss 4.132, Train_accy 69.500, Test_accy 43.200
2022-05-25 12:54:35,230 [bic.py] => bias_correction => Task 9, Epoch 74/170 => Loss 4.130, Train_accy 72.000, Test_accy 43.160
2022-05-25 12:54:37,107 [bic.py] => bias_correction => Task 9, Epoch 75/170 => Loss 4.163, Train_accy 68.500, Test_accy 43.150
2022-05-25 12:54:39,039 [bic.py] => bias_correction => Task 9, Epoch 76/170 => Loss 4.139, Train_accy 73.000, Test_accy 43.150
2022-05-25 12:54:41,070 [bic.py] => bias_correction => Task 9, Epoch 77/170 => Loss 4.140, Train_accy 72.000, Test_accy 43.060
2022-05-25 12:54:43,096 [bic.py] => bias_correction => Task 9, Epoch 78/170 => Loss 4.135, Train_accy 71.500, Test_accy 43.280
2022-05-25 12:54:44,996 [bic.py] => bias_correction => Task 9, Epoch 79/170 => Loss 4.152, Train_accy 68.500, Test_accy 43.260
2022-05-25 12:54:46,929 [bic.py] => bias_correction => Task 9, Epoch 80/170 => Loss 4.133, Train_accy 70.000, Test_accy 43.240
2022-05-25 12:54:48,867 [bic.py] => bias_correction => Task 9, Epoch 81/170 => Loss 4.163, Train_accy 71.000, Test_accy 43.190
2022-05-25 12:54:50,888 [bic.py] => bias_correction => Task 9, Epoch 82/170 => Loss 4.145, Train_accy 69.500, Test_accy 43.200
2022-05-25 12:54:52,839 [bic.py] => bias_correction => Task 9, Epoch 83/170 => Loss 4.144, Train_accy 69.000, Test_accy 43.210
2022-05-25 12:54:54,782 [bic.py] => bias_correction => Task 9, Epoch 84/170 => Loss 4.124, Train_accy 71.000, Test_accy 43.160
2022-05-25 12:54:56,817 [bic.py] => bias_correction => Task 9, Epoch 85/170 => Loss 4.130, Train_accy 70.500, Test_accy 43.140
2022-05-25 12:54:58,752 [bic.py] => bias_correction => Task 9, Epoch 86/170 => Loss 4.167, Train_accy 69.500, Test_accy 43.070
2022-05-25 12:55:00,788 [bic.py] => bias_correction => Task 9, Epoch 87/170 => Loss 4.135, Train_accy 69.500, Test_accy 43.140
2022-05-25 12:55:02,823 [bic.py] => bias_correction => Task 9, Epoch 88/170 => Loss 4.143, Train_accy 71.000, Test_accy 43.120
2022-05-25 12:55:04,797 [bic.py] => bias_correction => Task 9, Epoch 89/170 => Loss 4.133, Train_accy 74.500, Test_accy 43.190
2022-05-25 12:55:06,720 [bic.py] => bias_correction => Task 9, Epoch 90/170 => Loss 4.141, Train_accy 70.500, Test_accy 43.160
2022-05-25 12:55:08,732 [bic.py] => bias_correction => Task 9, Epoch 91/170 => Loss 4.149, Train_accy 70.000, Test_accy 43.080
2022-05-25 12:55:10,618 [bic.py] => bias_correction => Task 9, Epoch 92/170 => Loss 4.153, Train_accy 70.000, Test_accy 43.120
2022-05-25 12:55:12,615 [bic.py] => bias_correction => Task 9, Epoch 93/170 => Loss 4.141, Train_accy 72.500, Test_accy 43.160
2022-05-25 12:55:14,625 [bic.py] => bias_correction => Task 9, Epoch 94/170 => Loss 4.131, Train_accy 67.000, Test_accy 43.140
2022-05-25 12:55:16,670 [bic.py] => bias_correction => Task 9, Epoch 95/170 => Loss 4.148, Train_accy 72.500, Test_accy 43.170
2022-05-25 12:55:18,630 [bic.py] => bias_correction => Task 9, Epoch 96/170 => Loss 4.146, Train_accy 68.000, Test_accy 43.190
2022-05-25 12:55:20,559 [bic.py] => bias_correction => Task 9, Epoch 97/170 => Loss 4.148, Train_accy 69.500, Test_accy 43.180
2022-05-25 12:55:22,564 [bic.py] => bias_correction => Task 9, Epoch 98/170 => Loss 4.147, Train_accy 71.500, Test_accy 43.140
2022-05-25 12:55:24,565 [bic.py] => bias_correction => Task 9, Epoch 99/170 => Loss 4.145, Train_accy 71.000, Test_accy 43.090
2022-05-25 12:55:26,580 [bic.py] => bias_correction => Task 9, Epoch 100/170 => Loss 4.147, Train_accy 69.500, Test_accy 43.150
2022-05-25 12:55:28,472 [bic.py] => bias_correction => Task 9, Epoch 101/170 => Loss 4.136, Train_accy 70.500, Test_accy 43.110
2022-05-25 12:55:30,482 [bic.py] => bias_correction => Task 9, Epoch 102/170 => Loss 4.145, Train_accy 68.000, Test_accy 43.210
2022-05-25 12:55:32,460 [bic.py] => bias_correction => Task 9, Epoch 103/170 => Loss 4.144, Train_accy 72.000, Test_accy 43.160
2022-05-25 12:55:34,370 [bic.py] => bias_correction => Task 9, Epoch 104/170 => Loss 4.133, Train_accy 71.500, Test_accy 43.160
2022-05-25 12:55:36,325 [bic.py] => bias_correction => Task 9, Epoch 105/170 => Loss 4.135, Train_accy 68.500, Test_accy 43.170
2022-05-25 12:55:38,260 [bic.py] => bias_correction => Task 9, Epoch 106/170 => Loss 4.143, Train_accy 72.000, Test_accy 43.280
2022-05-25 12:55:40,263 [bic.py] => bias_correction => Task 9, Epoch 107/170 => Loss 4.133, Train_accy 71.000, Test_accy 43.320
2022-05-25 12:55:42,257 [bic.py] => bias_correction => Task 9, Epoch 108/170 => Loss 4.144, Train_accy 72.000, Test_accy 43.320
2022-05-25 12:55:44,255 [bic.py] => bias_correction => Task 9, Epoch 109/170 => Loss 4.145, Train_accy 69.000, Test_accy 43.320
2022-05-25 12:55:46,292 [bic.py] => bias_correction => Task 9, Epoch 110/170 => Loss 4.143, Train_accy 70.500, Test_accy 43.220
2022-05-25 12:55:48,170 [bic.py] => bias_correction => Task 9, Epoch 111/170 => Loss 4.138, Train_accy 69.000, Test_accy 43.240
2022-05-25 12:55:50,222 [bic.py] => bias_correction => Task 9, Epoch 112/170 => Loss 4.127, Train_accy 68.500, Test_accy 43.180
2022-05-25 12:55:52,182 [bic.py] => bias_correction => Task 9, Epoch 113/170 => Loss 4.141, Train_accy 73.000, Test_accy 43.170
2022-05-25 12:55:54,329 [bic.py] => bias_correction => Task 9, Epoch 114/170 => Loss 4.140, Train_accy 70.500, Test_accy 43.160
2022-05-25 12:55:56,379 [bic.py] => bias_correction => Task 9, Epoch 115/170 => Loss 4.137, Train_accy 70.000, Test_accy 43.160
2022-05-25 12:55:58,438 [bic.py] => bias_correction => Task 9, Epoch 116/170 => Loss 4.146, Train_accy 70.000, Test_accy 43.170
2022-05-25 12:56:00,339 [bic.py] => bias_correction => Task 9, Epoch 117/170 => Loss 4.127, Train_accy 70.000, Test_accy 43.190
2022-05-25 12:56:02,497 [bic.py] => bias_correction => Task 9, Epoch 118/170 => Loss 4.139, Train_accy 74.000, Test_accy 43.100
2022-05-25 12:56:04,529 [bic.py] => bias_correction => Task 9, Epoch 119/170 => Loss 4.145, Train_accy 72.500, Test_accy 43.150
2022-05-25 12:56:06,567 [bic.py] => bias_correction => Task 9, Epoch 120/170 => Loss 4.151, Train_accy 71.500, Test_accy 43.160
2022-05-25 12:56:08,551 [bic.py] => bias_correction => Task 9, Epoch 121/170 => Loss 4.144, Train_accy 70.500, Test_accy 43.150
2022-05-25 12:56:10,643 [bic.py] => bias_correction => Task 9, Epoch 122/170 => Loss 4.130, Train_accy 72.000, Test_accy 43.130
2022-05-25 12:56:12,616 [bic.py] => bias_correction => Task 9, Epoch 123/170 => Loss 4.148, Train_accy 70.000, Test_accy 43.130
2022-05-25 12:56:14,595 [bic.py] => bias_correction => Task 9, Epoch 124/170 => Loss 4.148, Train_accy 71.000, Test_accy 43.110
2022-05-25 12:56:16,615 [bic.py] => bias_correction => Task 9, Epoch 125/170 => Loss 4.129, Train_accy 72.500, Test_accy 43.130
2022-05-25 12:56:18,559 [bic.py] => bias_correction => Task 9, Epoch 126/170 => Loss 4.139, Train_accy 70.000, Test_accy 43.140
2022-05-25 12:56:20,516 [bic.py] => bias_correction => Task 9, Epoch 127/170 => Loss 4.164, Train_accy 70.500, Test_accy 43.090
2022-05-25 12:56:22,535 [bic.py] => bias_correction => Task 9, Epoch 128/170 => Loss 4.147, Train_accy 70.000, Test_accy 43.230
2022-05-25 12:56:24,675 [bic.py] => bias_correction => Task 9, Epoch 129/170 => Loss 4.145, Train_accy 70.500, Test_accy 43.190
2022-05-25 12:56:26,750 [bic.py] => bias_correction => Task 9, Epoch 130/170 => Loss 4.150, Train_accy 70.500, Test_accy 43.200
2022-05-25 12:56:28,715 [bic.py] => bias_correction => Task 9, Epoch 131/170 => Loss 4.138, Train_accy 72.000, Test_accy 43.210
2022-05-25 12:56:30,796 [bic.py] => bias_correction => Task 9, Epoch 132/170 => Loss 4.144, Train_accy 69.000, Test_accy 43.270
2022-05-25 12:56:32,756 [bic.py] => bias_correction => Task 9, Epoch 133/170 => Loss 4.137, Train_accy 69.000, Test_accy 43.290
2022-05-25 12:56:34,719 [bic.py] => bias_correction => Task 9, Epoch 134/170 => Loss 4.140, Train_accy 69.500, Test_accy 43.280
2022-05-25 12:56:36,820 [bic.py] => bias_correction => Task 9, Epoch 135/170 => Loss 4.144, Train_accy 69.500, Test_accy 43.230
2022-05-25 12:56:38,758 [bic.py] => bias_correction => Task 9, Epoch 136/170 => Loss 4.136, Train_accy 70.500, Test_accy 43.240
2022-05-25 12:56:40,701 [bic.py] => bias_correction => Task 9, Epoch 137/170 => Loss 4.133, Train_accy 70.500, Test_accy 43.220
2022-05-25 12:56:42,660 [bic.py] => bias_correction => Task 9, Epoch 138/170 => Loss 4.141, Train_accy 72.000, Test_accy 43.170
2022-05-25 12:56:44,681 [bic.py] => bias_correction => Task 9, Epoch 139/170 => Loss 4.121, Train_accy 71.000, Test_accy 43.170
2022-05-25 12:56:46,729 [bic.py] => bias_correction => Task 9, Epoch 140/170 => Loss 4.127, Train_accy 70.500, Test_accy 43.260
2022-05-25 12:56:48,625 [bic.py] => bias_correction => Task 9, Epoch 141/170 => Loss 4.132, Train_accy 71.000, Test_accy 43.240
2022-05-25 12:56:50,650 [bic.py] => bias_correction => Task 9, Epoch 142/170 => Loss 4.146, Train_accy 72.000, Test_accy 43.180
2022-05-25 12:56:52,644 [bic.py] => bias_correction => Task 9, Epoch 143/170 => Loss 4.129, Train_accy 68.500, Test_accy 43.160
2022-05-25 12:56:54,607 [bic.py] => bias_correction => Task 9, Epoch 144/170 => Loss 4.119, Train_accy 71.000, Test_accy 43.110
2022-05-25 12:56:56,557 [bic.py] => bias_correction => Task 9, Epoch 145/170 => Loss 4.132, Train_accy 70.500, Test_accy 43.090
2022-05-25 12:56:58,517 [bic.py] => bias_correction => Task 9, Epoch 146/170 => Loss 4.149, Train_accy 70.500, Test_accy 43.170
2022-05-25 12:57:00,431 [bic.py] => bias_correction => Task 9, Epoch 147/170 => Loss 4.134, Train_accy 72.500, Test_accy 43.220
2022-05-25 12:57:02,390 [bic.py] => bias_correction => Task 9, Epoch 148/170 => Loss 4.133, Train_accy 69.500, Test_accy 43.250
2022-05-25 12:57:04,473 [bic.py] => bias_correction => Task 9, Epoch 149/170 => Loss 4.147, Train_accy 71.500, Test_accy 43.250
2022-05-25 12:57:06,412 [bic.py] => bias_correction => Task 9, Epoch 150/170 => Loss 4.140, Train_accy 69.000, Test_accy 43.370
2022-05-25 12:57:08,304 [bic.py] => bias_correction => Task 9, Epoch 151/170 => Loss 4.152, Train_accy 75.500, Test_accy 43.330
2022-05-25 12:57:10,363 [bic.py] => bias_correction => Task 9, Epoch 152/170 => Loss 4.144, Train_accy 71.000, Test_accy 43.310
2022-05-25 12:57:12,339 [bic.py] => bias_correction => Task 9, Epoch 153/170 => Loss 4.152, Train_accy 69.500, Test_accy 43.300
2022-05-25 12:57:14,443 [bic.py] => bias_correction => Task 9, Epoch 154/170 => Loss 4.154, Train_accy 73.500, Test_accy 43.280
2022-05-25 12:57:16,518 [bic.py] => bias_correction => Task 9, Epoch 155/170 => Loss 4.131, Train_accy 72.000, Test_accy 43.240
2022-05-25 12:57:18,475 [bic.py] => bias_correction => Task 9, Epoch 156/170 => Loss 4.137, Train_accy 71.500, Test_accy 43.140
2022-05-25 12:57:20,370 [bic.py] => bias_correction => Task 9, Epoch 157/170 => Loss 4.148, Train_accy 70.500, Test_accy 43.190
2022-05-25 12:57:22,372 [bic.py] => bias_correction => Task 9, Epoch 158/170 => Loss 4.155, Train_accy 71.500, Test_accy 43.160
2022-05-25 12:57:24,509 [bic.py] => bias_correction => Task 9, Epoch 159/170 => Loss 4.138, Train_accy 68.500, Test_accy 43.150
2022-05-25 12:57:26,422 [bic.py] => bias_correction => Task 9, Epoch 160/170 => Loss 4.125, Train_accy 72.000, Test_accy 43.100
2022-05-25 12:57:28,334 [bic.py] => bias_correction => Task 9, Epoch 161/170 => Loss 4.131, Train_accy 71.500, Test_accy 43.140
2022-05-25 12:57:30,383 [bic.py] => bias_correction => Task 9, Epoch 162/170 => Loss 4.139, Train_accy 71.500, Test_accy 43.140
2022-05-25 12:57:32,479 [bic.py] => bias_correction => Task 9, Epoch 163/170 => Loss 4.152, Train_accy 72.500, Test_accy 43.120
2022-05-25 12:57:34,545 [bic.py] => bias_correction => Task 9, Epoch 164/170 => Loss 4.143, Train_accy 67.000, Test_accy 43.140
2022-05-25 12:57:36,526 [bic.py] => bias_correction => Task 9, Epoch 165/170 => Loss 4.146, Train_accy 70.500, Test_accy 43.060
2022-05-25 12:57:38,483 [bic.py] => bias_correction => Task 9, Epoch 166/170 => Loss 4.149, Train_accy 71.500, Test_accy 43.070
2022-05-25 12:57:40,582 [bic.py] => bias_correction => Task 9, Epoch 167/170 => Loss 4.138, Train_accy 71.500, Test_accy 43.080
2022-05-25 12:57:42,740 [bic.py] => bias_correction => Task 9, Epoch 168/170 => Loss 4.154, Train_accy 69.500, Test_accy 43.150
2022-05-25 12:57:44,696 [bic.py] => bias_correction => Task 9, Epoch 169/170 => Loss 4.142, Train_accy 69.500, Test_accy 43.150
2022-05-25 12:57:46,633 [bic.py] => bias_correction => Task 9, Epoch 170/170 => Loss 4.140, Train_accy 71.500, Test_accy 43.300
2022-05-25 12:57:46,634 [base.py] => Reducing exemplars...(20 per classes)
2022-05-25 12:58:04,847 [base.py] => Constructing exemplars...(20 per classes)
2022-05-25 12:58:09,845 [bic.py] => Parameters of bias layer:
2022-05-25 12:58:09,846 [bic.py] => 0 => 1.000, 0.000
2022-05-25 12:58:09,846 [bic.py] => 1 => 0.904, -1.125
2022-05-25 12:58:09,847 [bic.py] => 2 => 0.889, -1.948
2022-05-25 12:58:09,847 [bic.py] => 3 => 0.729, -1.345
2022-05-25 12:58:09,847 [bic.py] => 4 => 0.731, -1.321
2022-05-25 12:58:09,847 [bic.py] => 5 => 0.734, -1.140
2022-05-25 12:58:09,847 [bic.py] => 6 => 0.749, -1.468
2022-05-25 12:58:09,847 [bic.py] => 7 => 0.022, -0.851
2022-05-25 12:58:09,847 [bic.py] => 8 => 0.693, -1.091
2022-05-25 12:58:09,847 [bic.py] => 9 => 0.554, -0.918
2022-05-25 12:58:12,238 [bic.py] => Exemplar size: 2000
2022-05-25 12:58:12,238 [trainer.py] => CNN: {'total': 43.3, '00-09': 44.2, '10-19': 44.4, '20-29': 53.4, '30-39': 40.4, '40-49': 45.3, '50-59': 50.7, '60-69': 53.6, '70-79': 0.0, '80-89': 60.0, '90-99': 41.0, 'old': 43.56, 'new': 41.0}
2022-05-25 12:58:12,238 [trainer.py] => NME: {'total': 44.27, '00-09': 39.1, '10-19': 37.4, '20-29': 46.6, '30-39': 35.1, '40-49': 40.9, '50-59': 46.5, '60-69': 46.7, '70-79': 36.0, '80-89': 56.5, '90-99': 57.9, 'old': 42.76, 'new': 57.9}
2022-05-25 12:58:12,238 [trainer.py] => CNN top1 curve: [83.0, 73.7, 68.1, 62.2, 58.38, 55.52, 52.99, 44.45, 45.02, 43.3]
2022-05-25 12:58:12,238 [trainer.py] => CNN top5 curve: [99.1, 95.65, 92.07, 89.1, 86.2, 84.27, 81.76, 70.06, 70.97, 70.34]
2022-05-25 12:58:12,238 [trainer.py] => NME top1 curve: [82.8, 74.15, 67.37, 61.9, 58.1, 56.52, 53.94, 50.61, 47.54, 44.27]
2022-05-25 12:58:12,239 [trainer.py] => NME top5 curve: [99.0, 95.75, 92.47, 89.32, 86.1, 84.15, 81.77, 79.03, 75.36, 73.45]

