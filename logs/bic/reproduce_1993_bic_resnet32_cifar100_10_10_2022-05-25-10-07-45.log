2022-05-25 10:07:45,196 [trainer.py] => config: options/bic.yaml
2022-05-25 10:07:45,196 [trainer.py] => prefix: reproduce
2022-05-25 10:07:45,196 [trainer.py] => device: [device(type='cuda', index=0)]
2022-05-25 10:07:45,196 [trainer.py] => seed: 1993
2022-05-25 10:07:45,196 [trainer.py] => num_workers: 8
2022-05-25 10:07:45,196 [trainer.py] => dataset: cifar100
2022-05-25 10:07:45,197 [trainer.py] => shuffle: False
2022-05-25 10:07:45,197 [trainer.py] => method: bic
2022-05-25 10:07:45,197 [trainer.py] => eval_metric: acc
2022-05-25 10:07:45,197 [trainer.py] => backbone: resnet32
2022-05-25 10:07:45,197 [trainer.py] => pretrained: True
2022-05-25 10:07:45,197 [trainer.py] => save_models: False
2022-05-25 10:07:45,197 [trainer.py] => memory_size: 2000
2022-05-25 10:07:45,197 [trainer.py] => fixed_memory: False
2022-05-25 10:07:45,197 [trainer.py] => sampling_method: icarl
2022-05-25 10:07:45,197 [trainer.py] => init_cls: 10
2022-05-25 10:07:45,197 [trainer.py] => increment: 10
2022-05-25 10:07:45,197 [trainer.py] => incre_type: cil
2022-05-25 10:07:45,197 [trainer.py] => T: 2
2022-05-25 10:07:45,197 [trainer.py] => split_ratio: 0.1
2022-05-25 10:07:45,197 [trainer.py] => epochs: 170
2022-05-25 10:07:45,197 [trainer.py] => lrate: 0.1
2022-05-25 10:07:45,197 [trainer.py] => milestones: [60, 100, 140]
2022-05-25 10:07:45,197 [trainer.py] => lrate_decay: 0.1
2022-05-25 10:07:45,197 [trainer.py] => batch_size: 128
2022-05-25 10:07:45,198 [trainer.py] => weight_decay: 0.0002
2022-05-25 10:07:46,944 [data_manager.py] => class order: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]
2022-05-25 10:07:47,291 [trainer.py] => All params: 464154
2022-05-25 10:07:47,291 [trainer.py] => Trainable params: 464154
2022-05-25 10:07:47,291 [bic.py] => Learning on 0-10
2022-05-25 10:07:47,303 [bic.py] => Parameters of bias layer:
2022-05-25 10:07:47,303 [bic.py] => 0 => 1.000, 0.000
2022-05-25 10:07:53,506 [bic.py] => training => Task 0, Epoch 1/170 => Loss 2.778, Train_accy 12.780, Test_accy 13.100
2022-05-25 10:07:56,502 [bic.py] => training => Task 0, Epoch 2/170 => Loss 2.231, Train_accy 20.280, Test_accy 23.300
2022-05-25 10:07:59,426 [bic.py] => training => Task 0, Epoch 3/170 => Loss 2.064, Train_accy 24.040, Test_accy 26.100
2022-05-25 10:08:02,275 [bic.py] => training => Task 0, Epoch 4/170 => Loss 1.959, Train_accy 30.720, Test_accy 33.700
2022-05-25 10:08:05,254 [bic.py] => training => Task 0, Epoch 5/170 => Loss 1.923, Train_accy 34.560, Test_accy 36.300
2022-05-25 10:08:08,225 [bic.py] => training => Task 0, Epoch 6/170 => Loss 1.864, Train_accy 33.020, Test_accy 34.800
2022-05-25 10:08:11,225 [bic.py] => training => Task 0, Epoch 7/170 => Loss 1.786, Train_accy 37.260, Test_accy 38.500
2022-05-25 10:08:14,180 [bic.py] => training => Task 0, Epoch 8/170 => Loss 1.712, Train_accy 34.700, Test_accy 38.100
2022-05-25 10:08:17,179 [bic.py] => training => Task 0, Epoch 9/170 => Loss 1.698, Train_accy 42.360, Test_accy 45.200
2022-05-25 10:08:20,105 [bic.py] => training => Task 0, Epoch 10/170 => Loss 1.616, Train_accy 43.140, Test_accy 48.900
2022-05-25 10:08:23,069 [bic.py] => training => Task 0, Epoch 11/170 => Loss 1.539, Train_accy 44.040, Test_accy 45.000
2022-05-25 10:08:25,963 [bic.py] => training => Task 0, Epoch 12/170 => Loss 1.465, Train_accy 49.480, Test_accy 50.100
2022-05-25 10:08:28,880 [bic.py] => training => Task 0, Epoch 13/170 => Loss 1.409, Train_accy 54.540, Test_accy 57.000
2022-05-25 10:08:31,831 [bic.py] => training => Task 0, Epoch 14/170 => Loss 1.324, Train_accy 50.420, Test_accy 52.800
2022-05-25 10:08:34,866 [bic.py] => training => Task 0, Epoch 15/170 => Loss 1.265, Train_accy 53.980, Test_accy 53.800
2022-05-25 10:08:37,871 [bic.py] => training => Task 0, Epoch 16/170 => Loss 1.257, Train_accy 49.660, Test_accy 51.000
2022-05-25 10:08:40,889 [bic.py] => training => Task 0, Epoch 17/170 => Loss 1.218, Train_accy 55.040, Test_accy 57.300
2022-05-25 10:08:43,916 [bic.py] => training => Task 0, Epoch 18/170 => Loss 1.114, Train_accy 58.020, Test_accy 57.500
2022-05-25 10:08:46,883 [bic.py] => training => Task 0, Epoch 19/170 => Loss 1.196, Train_accy 56.220, Test_accy 57.900
2022-05-25 10:08:49,885 [bic.py] => training => Task 0, Epoch 20/170 => Loss 1.090, Train_accy 55.420, Test_accy 55.200
2022-05-25 10:08:52,809 [bic.py] => training => Task 0, Epoch 21/170 => Loss 1.140, Train_accy 61.620, Test_accy 61.200
2022-05-25 10:08:55,775 [bic.py] => training => Task 0, Epoch 22/170 => Loss 1.003, Train_accy 66.580, Test_accy 65.400
2022-05-25 10:08:58,747 [bic.py] => training => Task 0, Epoch 23/170 => Loss 0.927, Train_accy 68.200, Test_accy 63.400
2022-05-25 10:09:01,764 [bic.py] => training => Task 0, Epoch 24/170 => Loss 0.927, Train_accy 62.760, Test_accy 61.600
2022-05-25 10:09:04,791 [bic.py] => training => Task 0, Epoch 25/170 => Loss 0.858, Train_accy 73.380, Test_accy 67.800
2022-05-25 10:09:07,802 [bic.py] => training => Task 0, Epoch 26/170 => Loss 0.835, Train_accy 72.320, Test_accy 69.500
2022-05-25 10:09:10,811 [bic.py] => training => Task 0, Epoch 27/170 => Loss 0.828, Train_accy 70.540, Test_accy 67.900
2022-05-25 10:09:13,820 [bic.py] => training => Task 0, Epoch 28/170 => Loss 0.766, Train_accy 70.960, Test_accy 67.900
2022-05-25 10:09:16,836 [bic.py] => training => Task 0, Epoch 29/170 => Loss 0.821, Train_accy 72.400, Test_accy 69.300
2022-05-25 10:09:19,919 [bic.py] => training => Task 0, Epoch 30/170 => Loss 0.779, Train_accy 72.700, Test_accy 71.200
2022-05-25 10:09:22,946 [bic.py] => training => Task 0, Epoch 31/170 => Loss 0.731, Train_accy 62.800, Test_accy 60.000
2022-05-25 10:09:25,985 [bic.py] => training => Task 0, Epoch 32/170 => Loss 0.737, Train_accy 65.320, Test_accy 61.800
2022-05-25 10:09:29,063 [bic.py] => training => Task 0, Epoch 33/170 => Loss 0.722, Train_accy 75.820, Test_accy 70.800
2022-05-25 10:09:32,088 [bic.py] => training => Task 0, Epoch 34/170 => Loss 0.617, Train_accy 72.460, Test_accy 67.400
2022-05-25 10:09:35,087 [bic.py] => training => Task 0, Epoch 35/170 => Loss 0.697, Train_accy 69.520, Test_accy 65.000
2022-05-25 10:09:38,155 [bic.py] => training => Task 0, Epoch 36/170 => Loss 0.751, Train_accy 70.560, Test_accy 65.500
2022-05-25 10:09:41,174 [bic.py] => training => Task 0, Epoch 37/170 => Loss 0.703, Train_accy 74.540, Test_accy 72.000
2022-05-25 10:09:44,237 [bic.py] => training => Task 0, Epoch 38/170 => Loss 0.688, Train_accy 78.580, Test_accy 74.500
2022-05-25 10:09:47,346 [bic.py] => training => Task 0, Epoch 39/170 => Loss 0.590, Train_accy 78.180, Test_accy 70.700
2022-05-25 10:09:50,410 [bic.py] => training => Task 0, Epoch 40/170 => Loss 0.592, Train_accy 73.620, Test_accy 73.100
2022-05-25 10:09:53,601 [bic.py] => training => Task 0, Epoch 41/170 => Loss 0.633, Train_accy 78.980, Test_accy 72.900
2022-05-25 10:09:56,677 [bic.py] => training => Task 0, Epoch 42/170 => Loss 0.564, Train_accy 79.960, Test_accy 70.800
2022-05-25 10:09:59,724 [bic.py] => training => Task 0, Epoch 43/170 => Loss 0.567, Train_accy 80.820, Test_accy 72.200
2022-05-25 10:10:02,862 [bic.py] => training => Task 0, Epoch 44/170 => Loss 0.618, Train_accy 76.020, Test_accy 68.400
2022-05-25 10:10:05,850 [bic.py] => training => Task 0, Epoch 45/170 => Loss 0.551, Train_accy 79.300, Test_accy 71.400
2022-05-25 10:10:08,870 [bic.py] => training => Task 0, Epoch 46/170 => Loss 0.526, Train_accy 80.960, Test_accy 71.600
2022-05-25 10:10:11,910 [bic.py] => training => Task 0, Epoch 47/170 => Loss 0.485, Train_accy 76.480, Test_accy 68.600
2022-05-25 10:10:14,880 [bic.py] => training => Task 0, Epoch 48/170 => Loss 0.473, Train_accy 77.780, Test_accy 71.400
2022-05-25 10:10:17,957 [bic.py] => training => Task 0, Epoch 49/170 => Loss 0.675, Train_accy 77.140, Test_accy 71.800
2022-05-25 10:10:20,995 [bic.py] => training => Task 0, Epoch 50/170 => Loss 0.535, Train_accy 79.380, Test_accy 73.400
2022-05-25 10:10:24,151 [bic.py] => training => Task 0, Epoch 51/170 => Loss 0.606, Train_accy 79.440, Test_accy 70.600
2022-05-25 10:10:27,175 [bic.py] => training => Task 0, Epoch 52/170 => Loss 0.529, Train_accy 82.200, Test_accy 75.000
2022-05-25 10:10:30,158 [bic.py] => training => Task 0, Epoch 53/170 => Loss 0.521, Train_accy 81.300, Test_accy 72.700
2022-05-25 10:10:33,087 [bic.py] => training => Task 0, Epoch 54/170 => Loss 0.485, Train_accy 83.380, Test_accy 75.400
2022-05-25 10:10:36,119 [bic.py] => training => Task 0, Epoch 55/170 => Loss 0.417, Train_accy 81.000, Test_accy 73.400
2022-05-25 10:10:39,162 [bic.py] => training => Task 0, Epoch 56/170 => Loss 0.387, Train_accy 87.540, Test_accy 77.600
2022-05-25 10:10:42,145 [bic.py] => training => Task 0, Epoch 57/170 => Loss 0.459, Train_accy 81.680, Test_accy 75.000
2022-05-25 10:10:45,185 [bic.py] => training => Task 0, Epoch 58/170 => Loss 0.454, Train_accy 81.520, Test_accy 72.200
2022-05-25 10:10:48,172 [bic.py] => training => Task 0, Epoch 59/170 => Loss 0.388, Train_accy 86.240, Test_accy 76.700
2022-05-25 10:10:51,192 [bic.py] => training => Task 0, Epoch 60/170 => Loss 0.407, Train_accy 81.820, Test_accy 72.500
2022-05-25 10:10:54,237 [bic.py] => training => Task 0, Epoch 61/170 => Loss 0.310, Train_accy 92.140, Test_accy 81.000
2022-05-25 10:10:57,244 [bic.py] => training => Task 0, Epoch 62/170 => Loss 0.243, Train_accy 93.900, Test_accy 82.400
2022-05-25 10:11:00,321 [bic.py] => training => Task 0, Epoch 63/170 => Loss 0.216, Train_accy 94.020, Test_accy 81.900
2022-05-25 10:11:03,443 [bic.py] => training => Task 0, Epoch 64/170 => Loss 0.200, Train_accy 94.380, Test_accy 82.600
2022-05-25 10:11:06,524 [bic.py] => training => Task 0, Epoch 65/170 => Loss 0.197, Train_accy 95.140, Test_accy 83.400
2022-05-25 10:11:09,554 [bic.py] => training => Task 0, Epoch 66/170 => Loss 0.189, Train_accy 94.860, Test_accy 82.400
2022-05-25 10:11:12,614 [bic.py] => training => Task 0, Epoch 67/170 => Loss 0.174, Train_accy 95.640, Test_accy 83.800
2022-05-25 10:11:15,716 [bic.py] => training => Task 0, Epoch 68/170 => Loss 0.174, Train_accy 95.680, Test_accy 83.400
2022-05-25 10:11:18,762 [bic.py] => training => Task 0, Epoch 69/170 => Loss 0.199, Train_accy 95.100, Test_accy 83.400
2022-05-25 10:11:21,783 [bic.py] => training => Task 0, Epoch 70/170 => Loss 0.185, Train_accy 95.660, Test_accy 83.300
2022-05-25 10:11:24,837 [bic.py] => training => Task 0, Epoch 71/170 => Loss 0.155, Train_accy 95.840, Test_accy 83.700
2022-05-25 10:11:27,918 [bic.py] => training => Task 0, Epoch 72/170 => Loss 0.164, Train_accy 96.220, Test_accy 82.300
2022-05-25 10:11:30,935 [bic.py] => training => Task 0, Epoch 73/170 => Loss 0.181, Train_accy 95.900, Test_accy 82.600
2022-05-25 10:11:33,876 [bic.py] => training => Task 0, Epoch 74/170 => Loss 0.161, Train_accy 95.980, Test_accy 83.400
2022-05-25 10:11:36,887 [bic.py] => training => Task 0, Epoch 75/170 => Loss 0.161, Train_accy 96.260, Test_accy 82.400
2022-05-25 10:11:39,910 [bic.py] => training => Task 0, Epoch 76/170 => Loss 0.147, Train_accy 95.480, Test_accy 82.500
2022-05-25 10:11:42,966 [bic.py] => training => Task 0, Epoch 77/170 => Loss 0.137, Train_accy 96.420, Test_accy 81.800
2022-05-25 10:11:46,021 [bic.py] => training => Task 0, Epoch 78/170 => Loss 0.155, Train_accy 96.380, Test_accy 82.100
2022-05-25 10:11:49,054 [bic.py] => training => Task 0, Epoch 79/170 => Loss 0.153, Train_accy 96.780, Test_accy 84.100
2022-05-25 10:11:52,124 [bic.py] => training => Task 0, Epoch 80/170 => Loss 0.135, Train_accy 96.840, Test_accy 83.800
2022-05-25 10:11:55,176 [bic.py] => training => Task 0, Epoch 81/170 => Loss 0.134, Train_accy 96.840, Test_accy 83.300
2022-05-25 10:11:58,252 [bic.py] => training => Task 0, Epoch 82/170 => Loss 0.125, Train_accy 96.540, Test_accy 82.800
2022-05-25 10:12:01,347 [bic.py] => training => Task 0, Epoch 83/170 => Loss 0.133, Train_accy 96.560, Test_accy 82.100
2022-05-25 10:12:04,383 [bic.py] => training => Task 0, Epoch 84/170 => Loss 0.134, Train_accy 96.520, Test_accy 83.700
2022-05-25 10:12:07,474 [bic.py] => training => Task 0, Epoch 85/170 => Loss 0.140, Train_accy 96.880, Test_accy 82.400
2022-05-25 10:12:10,511 [bic.py] => training => Task 0, Epoch 86/170 => Loss 0.113, Train_accy 97.860, Test_accy 82.000
2022-05-25 10:12:13,538 [bic.py] => training => Task 0, Epoch 87/170 => Loss 0.123, Train_accy 97.480, Test_accy 82.900
2022-05-25 10:12:16,474 [bic.py] => training => Task 0, Epoch 88/170 => Loss 0.109, Train_accy 97.720, Test_accy 83.100
2022-05-25 10:12:19,502 [bic.py] => training => Task 0, Epoch 89/170 => Loss 0.097, Train_accy 97.400, Test_accy 82.900
2022-05-25 10:12:22,553 [bic.py] => training => Task 0, Epoch 90/170 => Loss 0.114, Train_accy 97.640, Test_accy 83.000
2022-05-25 10:12:25,559 [bic.py] => training => Task 0, Epoch 91/170 => Loss 0.110, Train_accy 97.660, Test_accy 82.200
2022-05-25 10:12:28,559 [bic.py] => training => Task 0, Epoch 92/170 => Loss 0.109, Train_accy 97.780, Test_accy 82.600
2022-05-25 10:12:31,639 [bic.py] => training => Task 0, Epoch 93/170 => Loss 0.126, Train_accy 97.500, Test_accy 81.800
2022-05-25 10:12:34,606 [bic.py] => training => Task 0, Epoch 94/170 => Loss 0.130, Train_accy 97.680, Test_accy 82.600
2022-05-25 10:12:37,686 [bic.py] => training => Task 0, Epoch 95/170 => Loss 0.127, Train_accy 97.380, Test_accy 82.200
2022-05-25 10:12:40,723 [bic.py] => training => Task 0, Epoch 96/170 => Loss 0.114, Train_accy 97.560, Test_accy 82.200
2022-05-25 10:12:43,792 [bic.py] => training => Task 0, Epoch 97/170 => Loss 0.103, Train_accy 97.820, Test_accy 82.500
2022-05-25 10:12:46,871 [bic.py] => training => Task 0, Epoch 98/170 => Loss 0.109, Train_accy 98.060, Test_accy 82.200
2022-05-25 10:12:49,919 [bic.py] => training => Task 0, Epoch 99/170 => Loss 0.111, Train_accy 97.980, Test_accy 83.000
2022-05-25 10:12:52,954 [bic.py] => training => Task 0, Epoch 100/170 => Loss 0.123, Train_accy 97.300, Test_accy 82.300
2022-05-25 10:12:55,891 [bic.py] => training => Task 0, Epoch 101/170 => Loss 0.099, Train_accy 97.900, Test_accy 82.600
2022-05-25 10:12:58,946 [bic.py] => training => Task 0, Epoch 102/170 => Loss 0.092, Train_accy 97.580, Test_accy 82.400
2022-05-25 10:13:01,902 [bic.py] => training => Task 0, Epoch 103/170 => Loss 0.108, Train_accy 97.840, Test_accy 82.500
2022-05-25 10:13:04,899 [bic.py] => training => Task 0, Epoch 104/170 => Loss 0.085, Train_accy 98.080, Test_accy 82.800
2022-05-25 10:13:07,888 [bic.py] => training => Task 0, Epoch 105/170 => Loss 0.097, Train_accy 98.380, Test_accy 83.000
2022-05-25 10:13:10,914 [bic.py] => training => Task 0, Epoch 106/170 => Loss 0.084, Train_accy 98.460, Test_accy 83.000
2022-05-25 10:13:13,962 [bic.py] => training => Task 0, Epoch 107/170 => Loss 0.090, Train_accy 98.080, Test_accy 83.100
2022-05-25 10:13:16,992 [bic.py] => training => Task 0, Epoch 108/170 => Loss 0.080, Train_accy 98.360, Test_accy 82.700
2022-05-25 10:13:19,976 [bic.py] => training => Task 0, Epoch 109/170 => Loss 0.078, Train_accy 98.480, Test_accy 82.700
2022-05-25 10:13:22,961 [bic.py] => training => Task 0, Epoch 110/170 => Loss 0.115, Train_accy 98.200, Test_accy 81.900
2022-05-25 10:13:25,971 [bic.py] => training => Task 0, Epoch 111/170 => Loss 0.084, Train_accy 98.720, Test_accy 83.300
2022-05-25 10:13:28,999 [bic.py] => training => Task 0, Epoch 112/170 => Loss 0.091, Train_accy 98.200, Test_accy 82.900
2022-05-25 10:13:32,050 [bic.py] => training => Task 0, Epoch 113/170 => Loss 0.091, Train_accy 98.560, Test_accy 82.400
2022-05-25 10:13:35,114 [bic.py] => training => Task 0, Epoch 114/170 => Loss 0.101, Train_accy 98.040, Test_accy 83.100
2022-05-25 10:13:38,147 [bic.py] => training => Task 0, Epoch 115/170 => Loss 0.084, Train_accy 98.720, Test_accy 82.800
2022-05-25 10:13:41,207 [bic.py] => training => Task 0, Epoch 116/170 => Loss 0.092, Train_accy 98.460, Test_accy 82.900
2022-05-25 10:13:44,290 [bic.py] => training => Task 0, Epoch 117/170 => Loss 0.081, Train_accy 98.520, Test_accy 83.300
2022-05-25 10:13:47,277 [bic.py] => training => Task 0, Epoch 118/170 => Loss 0.079, Train_accy 98.280, Test_accy 82.000
2022-05-25 10:13:50,262 [bic.py] => training => Task 0, Epoch 119/170 => Loss 0.097, Train_accy 98.340, Test_accy 82.300
2022-05-25 10:13:53,248 [bic.py] => training => Task 0, Epoch 120/170 => Loss 0.074, Train_accy 98.660, Test_accy 82.500
2022-05-25 10:13:56,276 [bic.py] => training => Task 0, Epoch 121/170 => Loss 0.079, Train_accy 98.600, Test_accy 82.800
2022-05-25 10:13:59,294 [bic.py] => training => Task 0, Epoch 122/170 => Loss 0.078, Train_accy 98.160, Test_accy 83.300
2022-05-25 10:14:02,329 [bic.py] => training => Task 0, Epoch 123/170 => Loss 0.082, Train_accy 98.580, Test_accy 82.800
2022-05-25 10:14:05,359 [bic.py] => training => Task 0, Epoch 124/170 => Loss 0.072, Train_accy 98.260, Test_accy 82.400
2022-05-25 10:14:08,423 [bic.py] => training => Task 0, Epoch 125/170 => Loss 0.078, Train_accy 98.560, Test_accy 82.700
2022-05-25 10:14:11,386 [bic.py] => training => Task 0, Epoch 126/170 => Loss 0.086, Train_accy 98.380, Test_accy 82.500
2022-05-25 10:14:14,424 [bic.py] => training => Task 0, Epoch 127/170 => Loss 0.069, Train_accy 98.320, Test_accy 82.300
2022-05-25 10:14:17,358 [bic.py] => training => Task 0, Epoch 128/170 => Loss 0.076, Train_accy 98.360, Test_accy 82.200
2022-05-25 10:14:20,341 [bic.py] => training => Task 0, Epoch 129/170 => Loss 0.093, Train_accy 98.860, Test_accy 82.100
2022-05-25 10:14:23,370 [bic.py] => training => Task 0, Epoch 130/170 => Loss 0.081, Train_accy 98.700, Test_accy 82.200
2022-05-25 10:14:26,375 [bic.py] => training => Task 0, Epoch 131/170 => Loss 0.081, Train_accy 98.720, Test_accy 82.600
2022-05-25 10:14:29,426 [bic.py] => training => Task 0, Epoch 132/170 => Loss 0.072, Train_accy 98.820, Test_accy 82.200
2022-05-25 10:14:32,489 [bic.py] => training => Task 0, Epoch 133/170 => Loss 0.072, Train_accy 98.600, Test_accy 81.900
2022-05-25 10:14:35,546 [bic.py] => training => Task 0, Epoch 134/170 => Loss 0.072, Train_accy 98.760, Test_accy 82.700
2022-05-25 10:14:38,578 [bic.py] => training => Task 0, Epoch 135/170 => Loss 0.077, Train_accy 98.800, Test_accy 82.900
2022-05-25 10:14:41,611 [bic.py] => training => Task 0, Epoch 136/170 => Loss 0.078, Train_accy 98.680, Test_accy 83.200
2022-05-25 10:14:44,601 [bic.py] => training => Task 0, Epoch 137/170 => Loss 0.067, Train_accy 98.880, Test_accy 82.700
2022-05-25 10:14:47,672 [bic.py] => training => Task 0, Epoch 138/170 => Loss 0.070, Train_accy 98.940, Test_accy 83.000
2022-05-25 10:14:50,694 [bic.py] => training => Task 0, Epoch 139/170 => Loss 0.069, Train_accy 98.880, Test_accy 83.300
2022-05-25 10:14:53,785 [bic.py] => training => Task 0, Epoch 140/170 => Loss 0.103, Train_accy 99.040, Test_accy 82.700
2022-05-25 10:14:56,832 [bic.py] => training => Task 0, Epoch 141/170 => Loss 0.077, Train_accy 98.620, Test_accy 82.800
2022-05-25 10:14:59,821 [bic.py] => training => Task 0, Epoch 142/170 => Loss 0.069, Train_accy 98.840, Test_accy 82.800
2022-05-25 10:15:02,872 [bic.py] => training => Task 0, Epoch 143/170 => Loss 0.074, Train_accy 98.600, Test_accy 82.200
2022-05-25 10:15:05,934 [bic.py] => training => Task 0, Epoch 144/170 => Loss 0.082, Train_accy 98.400, Test_accy 83.000
2022-05-25 10:15:09,066 [bic.py] => training => Task 0, Epoch 145/170 => Loss 0.067, Train_accy 98.960, Test_accy 83.000
2022-05-25 10:15:12,172 [bic.py] => training => Task 0, Epoch 146/170 => Loss 0.076, Train_accy 98.840, Test_accy 83.100
2022-05-25 10:15:15,162 [bic.py] => training => Task 0, Epoch 147/170 => Loss 0.075, Train_accy 98.720, Test_accy 83.000
2022-05-25 10:15:18,143 [bic.py] => training => Task 0, Epoch 148/170 => Loss 0.067, Train_accy 98.400, Test_accy 82.900
2022-05-25 10:15:21,150 [bic.py] => training => Task 0, Epoch 149/170 => Loss 0.080, Train_accy 98.740, Test_accy 83.200
2022-05-25 10:15:24,215 [bic.py] => training => Task 0, Epoch 150/170 => Loss 0.090, Train_accy 98.760, Test_accy 82.700
2022-05-25 10:15:27,202 [bic.py] => training => Task 0, Epoch 151/170 => Loss 0.064, Train_accy 98.600, Test_accy 82.600
2022-05-25 10:15:30,320 [bic.py] => training => Task 0, Epoch 152/170 => Loss 0.075, Train_accy 98.680, Test_accy 83.100
2022-05-25 10:15:33,335 [bic.py] => training => Task 0, Epoch 153/170 => Loss 0.086, Train_accy 98.500, Test_accy 82.500
2022-05-25 10:15:36,420 [bic.py] => training => Task 0, Epoch 154/170 => Loss 0.067, Train_accy 98.640, Test_accy 82.800
2022-05-25 10:15:39,456 [bic.py] => training => Task 0, Epoch 155/170 => Loss 0.091, Train_accy 98.380, Test_accy 82.100
2022-05-25 10:15:42,454 [bic.py] => training => Task 0, Epoch 156/170 => Loss 0.087, Train_accy 98.720, Test_accy 83.200
2022-05-25 10:15:45,484 [bic.py] => training => Task 0, Epoch 157/170 => Loss 0.064, Train_accy 98.840, Test_accy 83.100
2022-05-25 10:15:48,481 [bic.py] => training => Task 0, Epoch 158/170 => Loss 0.064, Train_accy 98.760, Test_accy 82.600
2022-05-25 10:15:51,670 [bic.py] => training => Task 0, Epoch 159/170 => Loss 0.077, Train_accy 98.400, Test_accy 82.200
2022-05-25 10:15:54,660 [bic.py] => training => Task 0, Epoch 160/170 => Loss 0.071, Train_accy 98.760, Test_accy 82.700
2022-05-25 10:15:57,736 [bic.py] => training => Task 0, Epoch 161/170 => Loss 0.092, Train_accy 98.940, Test_accy 82.500
2022-05-25 10:16:00,759 [bic.py] => training => Task 0, Epoch 162/170 => Loss 0.064, Train_accy 98.540, Test_accy 82.800
2022-05-25 10:16:03,757 [bic.py] => training => Task 0, Epoch 163/170 => Loss 0.084, Train_accy 98.860, Test_accy 83.300
2022-05-25 10:16:06,805 [bic.py] => training => Task 0, Epoch 164/170 => Loss 0.074, Train_accy 98.580, Test_accy 82.400
2022-05-25 10:16:09,794 [bic.py] => training => Task 0, Epoch 165/170 => Loss 0.088, Train_accy 98.420, Test_accy 82.400
2022-05-25 10:16:12,834 [bic.py] => training => Task 0, Epoch 166/170 => Loss 0.075, Train_accy 98.680, Test_accy 83.300
2022-05-25 10:16:15,864 [bic.py] => training => Task 0, Epoch 167/170 => Loss 0.078, Train_accy 98.680, Test_accy 82.800
2022-05-25 10:16:19,004 [bic.py] => training => Task 0, Epoch 168/170 => Loss 0.086, Train_accy 98.500, Test_accy 83.000
2022-05-25 10:16:22,009 [bic.py] => training => Task 0, Epoch 169/170 => Loss 0.089, Train_accy 98.840, Test_accy 83.200
2022-05-25 10:16:25,088 [bic.py] => training => Task 0, Epoch 170/170 => Loss 0.067, Train_accy 98.660, Test_accy 83.000
2022-05-25 10:16:25,089 [base.py] => Reducing exemplars...(200 per classes)
2022-05-25 10:16:25,089 [base.py] => Constructing exemplars...(200 per classes)
2022-05-25 10:16:31,000 [bic.py] => Parameters of bias layer:
2022-05-25 10:16:31,001 [bic.py] => 0 => 1.000, 0.000
2022-05-25 10:16:31,957 [bic.py] => Exemplar size: 2000
2022-05-25 10:16:31,957 [trainer.py] => CNN: {'total': 83.0, '00-09': 83.0, 'old': 0, 'new': 83.0}
2022-05-25 10:16:31,957 [trainer.py] => NME: {'total': 82.8, '00-09': 82.8, 'old': 0, 'new': 82.8}
2022-05-25 10:16:31,957 [trainer.py] => CNN top1 curve: [83.0]
2022-05-25 10:16:31,957 [trainer.py] => CNN top5 curve: [99.1]
2022-05-25 10:16:31,957 [trainer.py] => NME top1 curve: [82.8]
2022-05-25 10:16:31,957 [trainer.py] => NME top5 curve: [99.0]

2022-05-25 10:16:31,958 [trainer.py] => All params: 464806
2022-05-25 10:16:31,958 [trainer.py] => Trainable params: 464806
2022-05-25 10:16:31,959 [bic.py] => Learning on 10-20
2022-05-25 10:16:32,025 [bic.py] => Stage1 dset: 6600, Stage2 dset: 400
2022-05-25 10:16:32,025 [bic.py] => Lambda: 0.500
2022-05-25 10:16:32,029 [bic.py] => Parameters of bias layer:
2022-05-25 10:16:32,029 [bic.py] => 0 => 1.000, 0.000
2022-05-25 10:16:32,029 [bic.py] => 1 => 1.000, 0.000
2022-05-25 10:16:36,077 [bic.py] => training => Task 1, Epoch 1/170 => Loss 1.756, Train_accy 48.790, Test_accy 46.700
2022-05-25 10:16:40,168 [bic.py] => training => Task 1, Epoch 2/170 => Loss 1.272, Train_accy 56.790, Test_accy 51.650
2022-05-25 10:16:44,112 [bic.py] => training => Task 1, Epoch 3/170 => Loss 1.175, Train_accy 59.550, Test_accy 53.650
2022-05-25 10:16:48,085 [bic.py] => training => Task 1, Epoch 4/170 => Loss 1.126, Train_accy 63.240, Test_accy 56.800
2022-05-25 10:16:51,922 [bic.py] => training => Task 1, Epoch 5/170 => Loss 1.086, Train_accy 66.480, Test_accy 58.600
2022-05-25 10:16:55,885 [bic.py] => training => Task 1, Epoch 6/170 => Loss 1.042, Train_accy 68.830, Test_accy 59.500
2022-05-25 10:16:59,804 [bic.py] => training => Task 1, Epoch 7/170 => Loss 1.025, Train_accy 69.320, Test_accy 60.100
2022-05-25 10:17:03,718 [bic.py] => training => Task 1, Epoch 8/170 => Loss 1.003, Train_accy 73.060, Test_accy 63.250
2022-05-25 10:17:07,613 [bic.py] => training => Task 1, Epoch 9/170 => Loss 0.984, Train_accy 74.060, Test_accy 62.100
2022-05-25 10:17:11,601 [bic.py] => training => Task 1, Epoch 10/170 => Loss 0.969, Train_accy 69.710, Test_accy 56.450
2022-05-25 10:17:15,735 [bic.py] => training => Task 1, Epoch 11/170 => Loss 0.953, Train_accy 77.670, Test_accy 63.250
2022-05-25 10:17:19,683 [bic.py] => training => Task 1, Epoch 12/170 => Loss 0.928, Train_accy 76.090, Test_accy 60.800
2022-05-25 10:17:23,519 [bic.py] => training => Task 1, Epoch 13/170 => Loss 0.938, Train_accy 75.790, Test_accy 63.050
2022-05-25 10:17:27,468 [bic.py] => training => Task 1, Epoch 14/170 => Loss 0.915, Train_accy 73.350, Test_accy 62.050
2022-05-25 10:17:31,397 [bic.py] => training => Task 1, Epoch 15/170 => Loss 0.893, Train_accy 79.480, Test_accy 64.450
2022-05-25 10:17:35,288 [bic.py] => training => Task 1, Epoch 16/170 => Loss 0.875, Train_accy 80.700, Test_accy 64.300
2022-05-25 10:17:39,240 [bic.py] => training => Task 1, Epoch 17/170 => Loss 0.863, Train_accy 80.820, Test_accy 64.400
2022-05-25 10:17:43,102 [bic.py] => training => Task 1, Epoch 18/170 => Loss 0.869, Train_accy 81.760, Test_accy 63.950
2022-05-25 10:17:47,044 [bic.py] => training => Task 1, Epoch 19/170 => Loss 0.870, Train_accy 80.830, Test_accy 62.450
2022-05-25 10:17:50,898 [bic.py] => training => Task 1, Epoch 20/170 => Loss 0.845, Train_accy 79.170, Test_accy 62.650
2022-05-25 10:17:54,987 [bic.py] => training => Task 1, Epoch 21/170 => Loss 0.834, Train_accy 84.330, Test_accy 64.500
2022-05-25 10:17:58,835 [bic.py] => training => Task 1, Epoch 22/170 => Loss 0.834, Train_accy 69.450, Test_accy 53.950
2022-05-25 10:18:02,813 [bic.py] => training => Task 1, Epoch 23/170 => Loss 0.833, Train_accy 83.080, Test_accy 64.050
2022-05-25 10:18:06,685 [bic.py] => training => Task 1, Epoch 24/170 => Loss 0.826, Train_accy 82.240, Test_accy 63.550
2022-05-25 10:18:10,588 [bic.py] => training => Task 1, Epoch 25/170 => Loss 0.824, Train_accy 82.940, Test_accy 64.000
2022-05-25 10:18:14,516 [bic.py] => training => Task 1, Epoch 26/170 => Loss 0.809, Train_accy 85.950, Test_accy 66.850
2022-05-25 10:18:18,477 [bic.py] => training => Task 1, Epoch 27/170 => Loss 0.812, Train_accy 83.820, Test_accy 64.400
2022-05-25 10:18:22,453 [bic.py] => training => Task 1, Epoch 28/170 => Loss 0.805, Train_accy 83.030, Test_accy 62.450
2022-05-25 10:18:26,400 [bic.py] => training => Task 1, Epoch 29/170 => Loss 0.795, Train_accy 85.610, Test_accy 63.350
2022-05-25 10:18:30,284 [bic.py] => training => Task 1, Epoch 30/170 => Loss 0.792, Train_accy 80.520, Test_accy 60.800
2022-05-25 10:18:34,194 [bic.py] => training => Task 1, Epoch 31/170 => Loss 0.788, Train_accy 87.700, Test_accy 65.900
2022-05-25 10:18:38,090 [bic.py] => training => Task 1, Epoch 32/170 => Loss 0.771, Train_accy 88.420, Test_accy 66.750
2022-05-25 10:18:41,982 [bic.py] => training => Task 1, Epoch 33/170 => Loss 0.752, Train_accy 85.610, Test_accy 62.300
2022-05-25 10:18:45,899 [bic.py] => training => Task 1, Epoch 34/170 => Loss 0.772, Train_accy 87.670, Test_accy 68.000
2022-05-25 10:18:49,786 [bic.py] => training => Task 1, Epoch 35/170 => Loss 0.763, Train_accy 84.140, Test_accy 62.850
2022-05-25 10:18:53,767 [bic.py] => training => Task 1, Epoch 36/170 => Loss 0.761, Train_accy 89.390, Test_accy 67.400
2022-05-25 10:18:57,715 [bic.py] => training => Task 1, Epoch 37/170 => Loss 0.750, Train_accy 88.390, Test_accy 67.200
2022-05-25 10:19:01,620 [bic.py] => training => Task 1, Epoch 38/170 => Loss 0.746, Train_accy 85.020, Test_accy 62.200
2022-05-25 10:19:05,539 [bic.py] => training => Task 1, Epoch 39/170 => Loss 0.739, Train_accy 88.390, Test_accy 64.300
2022-05-25 10:19:09,447 [bic.py] => training => Task 1, Epoch 40/170 => Loss 0.743, Train_accy 89.240, Test_accy 66.250
2022-05-25 10:19:13,336 [bic.py] => training => Task 1, Epoch 41/170 => Loss 0.741, Train_accy 87.560, Test_accy 63.800
2022-05-25 10:19:17,178 [bic.py] => training => Task 1, Epoch 42/170 => Loss 0.738, Train_accy 85.120, Test_accy 62.200
2022-05-25 10:19:21,200 [bic.py] => training => Task 1, Epoch 43/170 => Loss 0.742, Train_accy 86.020, Test_accy 63.500
2022-05-25 10:19:25,074 [bic.py] => training => Task 1, Epoch 44/170 => Loss 0.741, Train_accy 88.710, Test_accy 66.350
2022-05-25 10:19:29,021 [bic.py] => training => Task 1, Epoch 45/170 => Loss 0.737, Train_accy 90.440, Test_accy 67.800
2022-05-25 10:19:32,859 [bic.py] => training => Task 1, Epoch 46/170 => Loss 0.737, Train_accy 82.680, Test_accy 60.950
2022-05-25 10:19:36,778 [bic.py] => training => Task 1, Epoch 47/170 => Loss 0.740, Train_accy 87.650, Test_accy 64.200
2022-05-25 10:19:40,879 [bic.py] => training => Task 1, Epoch 48/170 => Loss 0.727, Train_accy 85.820, Test_accy 62.750
2022-05-25 10:19:44,821 [bic.py] => training => Task 1, Epoch 49/170 => Loss 0.716, Train_accy 86.670, Test_accy 63.050
2022-05-25 10:19:48,801 [bic.py] => training => Task 1, Epoch 50/170 => Loss 0.699, Train_accy 88.380, Test_accy 65.050
2022-05-25 10:19:52,724 [bic.py] => training => Task 1, Epoch 51/170 => Loss 0.710, Train_accy 87.910, Test_accy 65.550
2022-05-25 10:19:56,698 [bic.py] => training => Task 1, Epoch 52/170 => Loss 0.712, Train_accy 84.710, Test_accy 62.700
2022-05-25 10:20:00,705 [bic.py] => training => Task 1, Epoch 53/170 => Loss 0.713, Train_accy 88.060, Test_accy 64.500
2022-05-25 10:20:04,540 [bic.py] => training => Task 1, Epoch 54/170 => Loss 0.702, Train_accy 89.640, Test_accy 65.350
2022-05-25 10:20:08,351 [bic.py] => training => Task 1, Epoch 55/170 => Loss 0.712, Train_accy 89.830, Test_accy 62.900
2022-05-25 10:20:12,179 [bic.py] => training => Task 1, Epoch 56/170 => Loss 0.717, Train_accy 88.020, Test_accy 66.400
2022-05-25 10:20:16,098 [bic.py] => training => Task 1, Epoch 57/170 => Loss 0.691, Train_accy 92.580, Test_accy 67.750
2022-05-25 10:20:19,969 [bic.py] => training => Task 1, Epoch 58/170 => Loss 0.681, Train_accy 92.880, Test_accy 66.450
2022-05-25 10:20:23,934 [bic.py] => training => Task 1, Epoch 59/170 => Loss 0.686, Train_accy 90.020, Test_accy 65.650
2022-05-25 10:20:27,946 [bic.py] => training => Task 1, Epoch 60/170 => Loss 0.706, Train_accy 89.240, Test_accy 65.800
2022-05-25 10:20:31,922 [bic.py] => training => Task 1, Epoch 61/170 => Loss 0.656, Train_accy 97.800, Test_accy 72.000
2022-05-25 10:20:35,841 [bic.py] => training => Task 1, Epoch 62/170 => Loss 0.618, Train_accy 98.350, Test_accy 72.350
2022-05-25 10:20:39,698 [bic.py] => training => Task 1, Epoch 63/170 => Loss 0.614, Train_accy 98.950, Test_accy 71.900
2022-05-25 10:20:43,561 [bic.py] => training => Task 1, Epoch 64/170 => Loss 0.609, Train_accy 98.950, Test_accy 72.550
2022-05-25 10:20:47,482 [bic.py] => training => Task 1, Epoch 65/170 => Loss 0.597, Train_accy 99.030, Test_accy 72.400
2022-05-25 10:20:51,362 [bic.py] => training => Task 1, Epoch 66/170 => Loss 0.597, Train_accy 99.210, Test_accy 72.700
2022-05-25 10:20:55,203 [bic.py] => training => Task 1, Epoch 67/170 => Loss 0.596, Train_accy 99.260, Test_accy 72.200
2022-05-25 10:20:59,108 [bic.py] => training => Task 1, Epoch 68/170 => Loss 0.597, Train_accy 99.350, Test_accy 73.000
2022-05-25 10:21:02,973 [bic.py] => training => Task 1, Epoch 69/170 => Loss 0.592, Train_accy 99.260, Test_accy 72.650
2022-05-25 10:21:06,877 [bic.py] => training => Task 1, Epoch 70/170 => Loss 0.590, Train_accy 99.380, Test_accy 72.500
2022-05-25 10:21:10,808 [bic.py] => training => Task 1, Epoch 71/170 => Loss 0.589, Train_accy 99.260, Test_accy 72.750
2022-05-25 10:21:14,704 [bic.py] => training => Task 1, Epoch 72/170 => Loss 0.588, Train_accy 99.380, Test_accy 72.500
2022-05-25 10:21:18,545 [bic.py] => training => Task 1, Epoch 73/170 => Loss 0.588, Train_accy 99.380, Test_accy 73.100
2022-05-25 10:21:22,475 [bic.py] => training => Task 1, Epoch 74/170 => Loss 0.583, Train_accy 99.520, Test_accy 73.200
2022-05-25 10:21:26,408 [bic.py] => training => Task 1, Epoch 75/170 => Loss 0.587, Train_accy 99.420, Test_accy 72.750
2022-05-25 10:21:30,318 [bic.py] => training => Task 1, Epoch 76/170 => Loss 0.582, Train_accy 99.520, Test_accy 72.450
2022-05-25 10:21:34,278 [bic.py] => training => Task 1, Epoch 77/170 => Loss 0.580, Train_accy 99.350, Test_accy 72.550
2022-05-25 10:21:38,193 [bic.py] => training => Task 1, Epoch 78/170 => Loss 0.583, Train_accy 99.530, Test_accy 72.700
2022-05-25 10:21:42,124 [bic.py] => training => Task 1, Epoch 79/170 => Loss 0.584, Train_accy 99.410, Test_accy 72.250
2022-05-25 10:21:46,094 [bic.py] => training => Task 1, Epoch 80/170 => Loss 0.583, Train_accy 99.670, Test_accy 72.850
2022-05-25 10:21:50,013 [bic.py] => training => Task 1, Epoch 81/170 => Loss 0.584, Train_accy 99.530, Test_accy 73.150
2022-05-25 10:21:53,966 [bic.py] => training => Task 1, Epoch 82/170 => Loss 0.581, Train_accy 99.610, Test_accy 72.700
2022-05-25 10:21:57,970 [bic.py] => training => Task 1, Epoch 83/170 => Loss 0.576, Train_accy 99.640, Test_accy 72.500
2022-05-25 10:22:01,938 [bic.py] => training => Task 1, Epoch 84/170 => Loss 0.575, Train_accy 99.770, Test_accy 72.950
2022-05-25 10:22:05,945 [bic.py] => training => Task 1, Epoch 85/170 => Loss 0.578, Train_accy 99.790, Test_accy 72.800
2022-05-25 10:22:09,851 [bic.py] => training => Task 1, Epoch 86/170 => Loss 0.576, Train_accy 99.850, Test_accy 72.900
2022-05-25 10:22:13,817 [bic.py] => training => Task 1, Epoch 87/170 => Loss 0.579, Train_accy 99.550, Test_accy 73.350
2022-05-25 10:22:17,702 [bic.py] => training => Task 1, Epoch 88/170 => Loss 0.581, Train_accy 99.620, Test_accy 72.900
2022-05-25 10:22:21,667 [bic.py] => training => Task 1, Epoch 89/170 => Loss 0.579, Train_accy 99.790, Test_accy 72.700
2022-05-25 10:22:25,623 [bic.py] => training => Task 1, Epoch 90/170 => Loss 0.573, Train_accy 99.610, Test_accy 73.000
2022-05-25 10:22:29,602 [bic.py] => training => Task 1, Epoch 91/170 => Loss 0.580, Train_accy 99.680, Test_accy 73.400
2022-05-25 10:22:33,420 [bic.py] => training => Task 1, Epoch 92/170 => Loss 0.576, Train_accy 99.830, Test_accy 73.500
2022-05-25 10:22:37,332 [bic.py] => training => Task 1, Epoch 93/170 => Loss 0.579, Train_accy 99.760, Test_accy 72.800
2022-05-25 10:22:41,221 [bic.py] => training => Task 1, Epoch 94/170 => Loss 0.573, Train_accy 99.700, Test_accy 72.850
2022-05-25 10:22:45,015 [bic.py] => training => Task 1, Epoch 95/170 => Loss 0.575, Train_accy 99.790, Test_accy 72.600
2022-05-25 10:22:48,882 [bic.py] => training => Task 1, Epoch 96/170 => Loss 0.572, Train_accy 99.740, Test_accy 72.950
2022-05-25 10:22:52,812 [bic.py] => training => Task 1, Epoch 97/170 => Loss 0.574, Train_accy 99.730, Test_accy 73.100
2022-05-25 10:22:56,640 [bic.py] => training => Task 1, Epoch 98/170 => Loss 0.572, Train_accy 99.800, Test_accy 72.600
2022-05-25 10:23:00,706 [bic.py] => training => Task 1, Epoch 99/170 => Loss 0.574, Train_accy 99.850, Test_accy 72.750
2022-05-25 10:23:04,592 [bic.py] => training => Task 1, Epoch 100/170 => Loss 0.577, Train_accy 99.820, Test_accy 72.750
2022-05-25 10:23:08,424 [bic.py] => training => Task 1, Epoch 101/170 => Loss 0.569, Train_accy 99.880, Test_accy 72.700
2022-05-25 10:23:12,373 [bic.py] => training => Task 1, Epoch 102/170 => Loss 0.575, Train_accy 99.800, Test_accy 72.700
2022-05-25 10:23:16,228 [bic.py] => training => Task 1, Epoch 103/170 => Loss 0.570, Train_accy 99.830, Test_accy 73.050
2022-05-25 10:23:20,078 [bic.py] => training => Task 1, Epoch 104/170 => Loss 0.573, Train_accy 99.710, Test_accy 73.100
2022-05-25 10:23:24,117 [bic.py] => training => Task 1, Epoch 105/170 => Loss 0.569, Train_accy 99.770, Test_accy 73.100
2022-05-25 10:23:28,046 [bic.py] => training => Task 1, Epoch 106/170 => Loss 0.570, Train_accy 99.790, Test_accy 72.650
2022-05-25 10:23:31,974 [bic.py] => training => Task 1, Epoch 107/170 => Loss 0.570, Train_accy 99.730, Test_accy 73.450
2022-05-25 10:23:35,901 [bic.py] => training => Task 1, Epoch 108/170 => Loss 0.575, Train_accy 99.790, Test_accy 72.900
2022-05-25 10:23:39,877 [bic.py] => training => Task 1, Epoch 109/170 => Loss 0.568, Train_accy 99.800, Test_accy 72.700
2022-05-25 10:23:43,880 [bic.py] => training => Task 1, Epoch 110/170 => Loss 0.572, Train_accy 99.820, Test_accy 73.250
2022-05-25 10:23:47,774 [bic.py] => training => Task 1, Epoch 111/170 => Loss 0.570, Train_accy 99.850, Test_accy 73.200
2022-05-25 10:23:51,759 [bic.py] => training => Task 1, Epoch 112/170 => Loss 0.570, Train_accy 99.920, Test_accy 73.100
2022-05-25 10:23:55,791 [bic.py] => training => Task 1, Epoch 113/170 => Loss 0.567, Train_accy 99.770, Test_accy 73.050
2022-05-25 10:23:59,779 [bic.py] => training => Task 1, Epoch 114/170 => Loss 0.570, Train_accy 99.770, Test_accy 73.300
2022-05-25 10:24:03,831 [bic.py] => training => Task 1, Epoch 115/170 => Loss 0.567, Train_accy 99.820, Test_accy 72.950
2022-05-25 10:24:07,740 [bic.py] => training => Task 1, Epoch 116/170 => Loss 0.574, Train_accy 99.860, Test_accy 73.050
2022-05-25 10:24:11,830 [bic.py] => training => Task 1, Epoch 117/170 => Loss 0.565, Train_accy 99.820, Test_accy 73.050
2022-05-25 10:24:15,716 [bic.py] => training => Task 1, Epoch 118/170 => Loss 0.567, Train_accy 99.740, Test_accy 73.500
2022-05-25 10:24:19,647 [bic.py] => training => Task 1, Epoch 119/170 => Loss 0.573, Train_accy 99.800, Test_accy 72.750
2022-05-25 10:24:23,676 [bic.py] => training => Task 1, Epoch 120/170 => Loss 0.569, Train_accy 99.800, Test_accy 72.600
2022-05-25 10:24:27,678 [bic.py] => training => Task 1, Epoch 121/170 => Loss 0.570, Train_accy 99.890, Test_accy 73.100
2022-05-25 10:24:31,585 [bic.py] => training => Task 1, Epoch 122/170 => Loss 0.570, Train_accy 99.760, Test_accy 73.150
2022-05-25 10:24:35,500 [bic.py] => training => Task 1, Epoch 123/170 => Loss 0.573, Train_accy 99.800, Test_accy 73.350
2022-05-25 10:24:39,471 [bic.py] => training => Task 1, Epoch 124/170 => Loss 0.571, Train_accy 99.740, Test_accy 73.050
2022-05-25 10:24:43,411 [bic.py] => training => Task 1, Epoch 125/170 => Loss 0.570, Train_accy 99.770, Test_accy 73.000
2022-05-25 10:24:47,404 [bic.py] => training => Task 1, Epoch 126/170 => Loss 0.572, Train_accy 99.760, Test_accy 72.950
2022-05-25 10:24:51,328 [bic.py] => training => Task 1, Epoch 127/170 => Loss 0.570, Train_accy 99.800, Test_accy 73.150
2022-05-25 10:24:55,241 [bic.py] => training => Task 1, Epoch 128/170 => Loss 0.569, Train_accy 99.820, Test_accy 73.050
2022-05-25 10:24:59,221 [bic.py] => training => Task 1, Epoch 129/170 => Loss 0.567, Train_accy 99.830, Test_accy 72.900
2022-05-25 10:25:03,120 [bic.py] => training => Task 1, Epoch 130/170 => Loss 0.572, Train_accy 99.700, Test_accy 73.200
2022-05-25 10:25:07,000 [bic.py] => training => Task 1, Epoch 131/170 => Loss 0.566, Train_accy 99.740, Test_accy 73.150
2022-05-25 10:25:10,908 [bic.py] => training => Task 1, Epoch 132/170 => Loss 0.569, Train_accy 99.760, Test_accy 72.850
2022-05-25 10:25:14,876 [bic.py] => training => Task 1, Epoch 133/170 => Loss 0.568, Train_accy 99.850, Test_accy 72.800
2022-05-25 10:25:18,852 [bic.py] => training => Task 1, Epoch 134/170 => Loss 0.570, Train_accy 99.880, Test_accy 72.950
2022-05-25 10:25:22,708 [bic.py] => training => Task 1, Epoch 135/170 => Loss 0.570, Train_accy 99.730, Test_accy 73.000
2022-05-25 10:25:26,708 [bic.py] => training => Task 1, Epoch 136/170 => Loss 0.568, Train_accy 99.790, Test_accy 72.750
2022-05-25 10:25:30,818 [bic.py] => training => Task 1, Epoch 137/170 => Loss 0.571, Train_accy 99.860, Test_accy 72.850
2022-05-25 10:25:34,750 [bic.py] => training => Task 1, Epoch 138/170 => Loss 0.567, Train_accy 99.830, Test_accy 72.700
2022-05-25 10:25:38,661 [bic.py] => training => Task 1, Epoch 139/170 => Loss 0.569, Train_accy 99.910, Test_accy 72.950
2022-05-25 10:25:42,531 [bic.py] => training => Task 1, Epoch 140/170 => Loss 0.566, Train_accy 99.920, Test_accy 72.900
2022-05-25 10:25:46,420 [bic.py] => training => Task 1, Epoch 141/170 => Loss 0.570, Train_accy 99.770, Test_accy 72.950
2022-05-25 10:25:50,369 [bic.py] => training => Task 1, Epoch 142/170 => Loss 0.569, Train_accy 99.830, Test_accy 73.150
2022-05-25 10:25:54,350 [bic.py] => training => Task 1, Epoch 143/170 => Loss 0.570, Train_accy 99.830, Test_accy 72.950
2022-05-25 10:25:58,412 [bic.py] => training => Task 1, Epoch 144/170 => Loss 0.570, Train_accy 99.760, Test_accy 72.950
2022-05-25 10:26:02,361 [bic.py] => training => Task 1, Epoch 145/170 => Loss 0.569, Train_accy 99.800, Test_accy 72.650
2022-05-25 10:26:06,330 [bic.py] => training => Task 1, Epoch 146/170 => Loss 0.568, Train_accy 99.850, Test_accy 73.400
2022-05-25 10:26:10,360 [bic.py] => training => Task 1, Epoch 147/170 => Loss 0.567, Train_accy 99.830, Test_accy 73.050
2022-05-25 10:26:14,317 [bic.py] => training => Task 1, Epoch 148/170 => Loss 0.569, Train_accy 99.800, Test_accy 72.950
2022-05-25 10:26:18,365 [bic.py] => training => Task 1, Epoch 149/170 => Loss 0.572, Train_accy 99.790, Test_accy 73.200
2022-05-25 10:26:22,454 [bic.py] => training => Task 1, Epoch 150/170 => Loss 0.566, Train_accy 99.790, Test_accy 72.700
2022-05-25 10:26:26,351 [bic.py] => training => Task 1, Epoch 151/170 => Loss 0.569, Train_accy 99.880, Test_accy 72.800
2022-05-25 10:26:30,167 [bic.py] => training => Task 1, Epoch 152/170 => Loss 0.566, Train_accy 99.830, Test_accy 72.800
2022-05-25 10:26:34,044 [bic.py] => training => Task 1, Epoch 153/170 => Loss 0.566, Train_accy 99.830, Test_accy 73.350
2022-05-25 10:26:37,873 [bic.py] => training => Task 1, Epoch 154/170 => Loss 0.567, Train_accy 99.770, Test_accy 73.000
2022-05-25 10:26:41,767 [bic.py] => training => Task 1, Epoch 155/170 => Loss 0.570, Train_accy 99.820, Test_accy 72.900
2022-05-25 10:26:45,633 [bic.py] => training => Task 1, Epoch 156/170 => Loss 0.567, Train_accy 99.850, Test_accy 73.100
2022-05-25 10:26:49,526 [bic.py] => training => Task 1, Epoch 157/170 => Loss 0.567, Train_accy 99.860, Test_accy 72.850
2022-05-25 10:26:53,460 [bic.py] => training => Task 1, Epoch 158/170 => Loss 0.570, Train_accy 99.790, Test_accy 73.000
2022-05-25 10:26:57,331 [bic.py] => training => Task 1, Epoch 159/170 => Loss 0.568, Train_accy 99.700, Test_accy 73.200
2022-05-25 10:27:01,282 [bic.py] => training => Task 1, Epoch 160/170 => Loss 0.571, Train_accy 99.790, Test_accy 73.250
2022-05-25 10:27:05,308 [bic.py] => training => Task 1, Epoch 161/170 => Loss 0.569, Train_accy 99.800, Test_accy 73.050
2022-05-25 10:27:09,178 [bic.py] => training => Task 1, Epoch 162/170 => Loss 0.568, Train_accy 99.740, Test_accy 73.000
2022-05-25 10:27:13,134 [bic.py] => training => Task 1, Epoch 163/170 => Loss 0.569, Train_accy 99.850, Test_accy 72.950
2022-05-25 10:27:17,093 [bic.py] => training => Task 1, Epoch 164/170 => Loss 0.571, Train_accy 99.830, Test_accy 73.150
2022-05-25 10:27:20,965 [bic.py] => training => Task 1, Epoch 165/170 => Loss 0.572, Train_accy 99.830, Test_accy 73.250
2022-05-25 10:27:24,935 [bic.py] => training => Task 1, Epoch 166/170 => Loss 0.570, Train_accy 99.860, Test_accy 73.300
2022-05-25 10:27:28,864 [bic.py] => training => Task 1, Epoch 167/170 => Loss 0.569, Train_accy 99.880, Test_accy 73.050
2022-05-25 10:27:32,788 [bic.py] => training => Task 1, Epoch 168/170 => Loss 0.567, Train_accy 99.850, Test_accy 72.750
2022-05-25 10:27:36,725 [bic.py] => training => Task 1, Epoch 169/170 => Loss 0.572, Train_accy 99.800, Test_accy 72.800
2022-05-25 10:27:40,712 [bic.py] => training => Task 1, Epoch 170/170 => Loss 0.568, Train_accy 99.760, Test_accy 73.100
2022-05-25 10:27:42,219 [bic.py] => bias_correction => Task 1, Epoch 1/170 => Loss 2.334, Train_accy 78.750, Test_accy 74.200
2022-05-25 10:27:43,725 [bic.py] => bias_correction => Task 1, Epoch 2/170 => Loss 2.355, Train_accy 76.250, Test_accy 74.200
2022-05-25 10:27:45,248 [bic.py] => bias_correction => Task 1, Epoch 3/170 => Loss 2.330, Train_accy 75.750, Test_accy 73.900
2022-05-25 10:27:46,761 [bic.py] => bias_correction => Task 1, Epoch 4/170 => Loss 2.340, Train_accy 78.000, Test_accy 74.400
2022-05-25 10:27:48,304 [bic.py] => bias_correction => Task 1, Epoch 5/170 => Loss 2.373, Train_accy 75.750, Test_accy 73.700
2022-05-25 10:27:49,823 [bic.py] => bias_correction => Task 1, Epoch 6/170 => Loss 2.389, Train_accy 77.750, Test_accy 73.450
2022-05-25 10:27:51,362 [bic.py] => bias_correction => Task 1, Epoch 7/170 => Loss 2.330, Train_accy 80.750, Test_accy 73.950
2022-05-25 10:27:52,859 [bic.py] => bias_correction => Task 1, Epoch 8/170 => Loss 2.335, Train_accy 79.000, Test_accy 73.800
2022-05-25 10:27:54,329 [bic.py] => bias_correction => Task 1, Epoch 9/170 => Loss 2.390, Train_accy 80.500, Test_accy 74.300
2022-05-25 10:27:55,798 [bic.py] => bias_correction => Task 1, Epoch 10/170 => Loss 2.365, Train_accy 77.500, Test_accy 74.050
2022-05-25 10:27:57,325 [bic.py] => bias_correction => Task 1, Epoch 11/170 => Loss 2.332, Train_accy 80.750, Test_accy 73.950
2022-05-25 10:27:58,841 [bic.py] => bias_correction => Task 1, Epoch 12/170 => Loss 2.356, Train_accy 78.500, Test_accy 73.700
2022-05-25 10:28:00,350 [bic.py] => bias_correction => Task 1, Epoch 13/170 => Loss 2.380, Train_accy 79.250, Test_accy 74.100
2022-05-25 10:28:01,905 [bic.py] => bias_correction => Task 1, Epoch 14/170 => Loss 2.366, Train_accy 77.250, Test_accy 74.250
2022-05-25 10:28:03,422 [bic.py] => bias_correction => Task 1, Epoch 15/170 => Loss 2.353, Train_accy 80.500, Test_accy 73.750
2022-05-25 10:28:04,900 [bic.py] => bias_correction => Task 1, Epoch 16/170 => Loss 2.340, Train_accy 77.750, Test_accy 74.350
2022-05-25 10:28:06,420 [bic.py] => bias_correction => Task 1, Epoch 17/170 => Loss 2.372, Train_accy 77.500, Test_accy 73.700
2022-05-25 10:28:07,885 [bic.py] => bias_correction => Task 1, Epoch 18/170 => Loss 2.371, Train_accy 75.500, Test_accy 72.900
2022-05-25 10:28:09,434 [bic.py] => bias_correction => Task 1, Epoch 19/170 => Loss 2.336, Train_accy 80.750, Test_accy 73.850
2022-05-25 10:28:10,929 [bic.py] => bias_correction => Task 1, Epoch 20/170 => Loss 2.355, Train_accy 78.000, Test_accy 73.450
2022-05-25 10:28:12,369 [bic.py] => bias_correction => Task 1, Epoch 21/170 => Loss 2.358, Train_accy 77.750, Test_accy 73.950
2022-05-25 10:28:13,841 [bic.py] => bias_correction => Task 1, Epoch 22/170 => Loss 2.396, Train_accy 79.000, Test_accy 74.250
2022-05-25 10:28:15,244 [bic.py] => bias_correction => Task 1, Epoch 23/170 => Loss 2.340, Train_accy 78.000, Test_accy 74.200
2022-05-25 10:28:16,726 [bic.py] => bias_correction => Task 1, Epoch 24/170 => Loss 2.339, Train_accy 80.000, Test_accy 73.950
2022-05-25 10:28:18,231 [bic.py] => bias_correction => Task 1, Epoch 25/170 => Loss 2.334, Train_accy 77.250, Test_accy 73.200
2022-05-25 10:28:19,742 [bic.py] => bias_correction => Task 1, Epoch 26/170 => Loss 2.365, Train_accy 75.250, Test_accy 73.200
2022-05-25 10:28:21,157 [bic.py] => bias_correction => Task 1, Epoch 27/170 => Loss 2.407, Train_accy 77.750, Test_accy 73.500
2022-05-25 10:28:22,606 [bic.py] => bias_correction => Task 1, Epoch 28/170 => Loss 2.392, Train_accy 79.500, Test_accy 73.900
2022-05-25 10:28:24,069 [bic.py] => bias_correction => Task 1, Epoch 29/170 => Loss 2.358, Train_accy 77.750, Test_accy 73.350
2022-05-25 10:28:25,581 [bic.py] => bias_correction => Task 1, Epoch 30/170 => Loss 2.362, Train_accy 77.750, Test_accy 73.850
2022-05-25 10:28:27,113 [bic.py] => bias_correction => Task 1, Epoch 31/170 => Loss 2.370, Train_accy 76.500, Test_accy 73.400
2022-05-25 10:28:28,643 [bic.py] => bias_correction => Task 1, Epoch 32/170 => Loss 2.371, Train_accy 77.000, Test_accy 73.900
2022-05-25 10:28:30,177 [bic.py] => bias_correction => Task 1, Epoch 33/170 => Loss 2.319, Train_accy 76.750, Test_accy 74.250
2022-05-25 10:28:31,693 [bic.py] => bias_correction => Task 1, Epoch 34/170 => Loss 2.334, Train_accy 77.750, Test_accy 73.900
2022-05-25 10:28:33,227 [bic.py] => bias_correction => Task 1, Epoch 35/170 => Loss 2.360, Train_accy 77.500, Test_accy 74.150
2022-05-25 10:28:34,752 [bic.py] => bias_correction => Task 1, Epoch 36/170 => Loss 2.368, Train_accy 78.500, Test_accy 73.750
2022-05-25 10:28:36,274 [bic.py] => bias_correction => Task 1, Epoch 37/170 => Loss 2.366, Train_accy 76.500, Test_accy 73.950
2022-05-25 10:28:37,806 [bic.py] => bias_correction => Task 1, Epoch 38/170 => Loss 2.323, Train_accy 76.250, Test_accy 73.600
2022-05-25 10:28:39,302 [bic.py] => bias_correction => Task 1, Epoch 39/170 => Loss 2.369, Train_accy 79.750, Test_accy 74.150
2022-05-25 10:28:40,792 [bic.py] => bias_correction => Task 1, Epoch 40/170 => Loss 2.349, Train_accy 81.250, Test_accy 74.250
2022-05-25 10:28:42,342 [bic.py] => bias_correction => Task 1, Epoch 41/170 => Loss 2.379, Train_accy 77.000, Test_accy 73.600
2022-05-25 10:28:43,864 [bic.py] => bias_correction => Task 1, Epoch 42/170 => Loss 2.345, Train_accy 78.500, Test_accy 73.350
2022-05-25 10:28:45,436 [bic.py] => bias_correction => Task 1, Epoch 43/170 => Loss 2.394, Train_accy 78.500, Test_accy 74.300
2022-05-25 10:28:46,855 [bic.py] => bias_correction => Task 1, Epoch 44/170 => Loss 2.343, Train_accy 76.750, Test_accy 73.700
2022-05-25 10:28:48,348 [bic.py] => bias_correction => Task 1, Epoch 45/170 => Loss 2.388, Train_accy 78.250, Test_accy 73.550
2022-05-25 10:28:49,820 [bic.py] => bias_correction => Task 1, Epoch 46/170 => Loss 2.322, Train_accy 77.250, Test_accy 74.650
2022-05-25 10:28:51,347 [bic.py] => bias_correction => Task 1, Epoch 47/170 => Loss 2.341, Train_accy 78.000, Test_accy 73.900
2022-05-25 10:28:52,849 [bic.py] => bias_correction => Task 1, Epoch 48/170 => Loss 2.326, Train_accy 75.000, Test_accy 74.350
2022-05-25 10:28:54,363 [bic.py] => bias_correction => Task 1, Epoch 49/170 => Loss 2.306, Train_accy 76.750, Test_accy 73.350
2022-05-25 10:28:55,911 [bic.py] => bias_correction => Task 1, Epoch 50/170 => Loss 2.344, Train_accy 77.250, Test_accy 73.050
2022-05-25 10:28:57,459 [bic.py] => bias_correction => Task 1, Epoch 51/170 => Loss 2.367, Train_accy 75.500, Test_accy 73.500
2022-05-25 10:28:58,951 [bic.py] => bias_correction => Task 1, Epoch 52/170 => Loss 2.331, Train_accy 76.500, Test_accy 74.150
2022-05-25 10:29:00,510 [bic.py] => bias_correction => Task 1, Epoch 53/170 => Loss 2.333, Train_accy 77.000, Test_accy 73.600
2022-05-25 10:29:02,043 [bic.py] => bias_correction => Task 1, Epoch 54/170 => Loss 2.354, Train_accy 77.250, Test_accy 74.000
2022-05-25 10:29:03,570 [bic.py] => bias_correction => Task 1, Epoch 55/170 => Loss 2.324, Train_accy 78.500, Test_accy 74.050
2022-05-25 10:29:05,068 [bic.py] => bias_correction => Task 1, Epoch 56/170 => Loss 2.330, Train_accy 78.000, Test_accy 73.350
2022-05-25 10:29:06,575 [bic.py] => bias_correction => Task 1, Epoch 57/170 => Loss 2.395, Train_accy 79.000, Test_accy 74.100
2022-05-25 10:29:08,078 [bic.py] => bias_correction => Task 1, Epoch 58/170 => Loss 2.362, Train_accy 77.500, Test_accy 74.300
2022-05-25 10:29:09,566 [bic.py] => bias_correction => Task 1, Epoch 59/170 => Loss 2.374, Train_accy 77.000, Test_accy 73.650
2022-05-25 10:29:11,109 [bic.py] => bias_correction => Task 1, Epoch 60/170 => Loss 2.378, Train_accy 77.500, Test_accy 73.750
2022-05-25 10:29:12,625 [bic.py] => bias_correction => Task 1, Epoch 61/170 => Loss 2.380, Train_accy 78.000, Test_accy 73.750
2022-05-25 10:29:14,140 [bic.py] => bias_correction => Task 1, Epoch 62/170 => Loss 2.337, Train_accy 79.500, Test_accy 73.850
2022-05-25 10:29:15,632 [bic.py] => bias_correction => Task 1, Epoch 63/170 => Loss 2.386, Train_accy 78.000, Test_accy 74.200
2022-05-25 10:29:17,109 [bic.py] => bias_correction => Task 1, Epoch 64/170 => Loss 2.345, Train_accy 78.750, Test_accy 73.800
2022-05-25 10:29:18,667 [bic.py] => bias_correction => Task 1, Epoch 65/170 => Loss 2.332, Train_accy 78.750, Test_accy 73.850
2022-05-25 10:29:20,147 [bic.py] => bias_correction => Task 1, Epoch 66/170 => Loss 2.343, Train_accy 78.000, Test_accy 73.650
2022-05-25 10:29:21,686 [bic.py] => bias_correction => Task 1, Epoch 67/170 => Loss 2.369, Train_accy 79.000, Test_accy 73.950
2022-05-25 10:29:23,241 [bic.py] => bias_correction => Task 1, Epoch 68/170 => Loss 2.341, Train_accy 78.500, Test_accy 73.550
2022-05-25 10:29:24,767 [bic.py] => bias_correction => Task 1, Epoch 69/170 => Loss 2.377, Train_accy 77.500, Test_accy 74.100
2022-05-25 10:29:26,279 [bic.py] => bias_correction => Task 1, Epoch 70/170 => Loss 2.365, Train_accy 77.500, Test_accy 74.050
2022-05-25 10:29:27,776 [bic.py] => bias_correction => Task 1, Epoch 71/170 => Loss 2.316, Train_accy 76.000, Test_accy 73.900
2022-05-25 10:29:29,260 [bic.py] => bias_correction => Task 1, Epoch 72/170 => Loss 2.348, Train_accy 77.500, Test_accy 73.900
2022-05-25 10:29:30,793 [bic.py] => bias_correction => Task 1, Epoch 73/170 => Loss 2.369, Train_accy 77.750, Test_accy 73.650
2022-05-25 10:29:32,300 [bic.py] => bias_correction => Task 1, Epoch 74/170 => Loss 2.351, Train_accy 77.500, Test_accy 73.900
2022-05-25 10:29:33,813 [bic.py] => bias_correction => Task 1, Epoch 75/170 => Loss 2.346, Train_accy 77.750, Test_accy 73.800
2022-05-25 10:29:35,333 [bic.py] => bias_correction => Task 1, Epoch 76/170 => Loss 2.364, Train_accy 76.750, Test_accy 74.300
2022-05-25 10:29:36,854 [bic.py] => bias_correction => Task 1, Epoch 77/170 => Loss 2.336, Train_accy 76.000, Test_accy 74.000
2022-05-25 10:29:38,388 [bic.py] => bias_correction => Task 1, Epoch 78/170 => Loss 2.321, Train_accy 75.750, Test_accy 73.550
2022-05-25 10:29:39,870 [bic.py] => bias_correction => Task 1, Epoch 79/170 => Loss 2.328, Train_accy 78.750, Test_accy 74.100
2022-05-25 10:29:41,443 [bic.py] => bias_correction => Task 1, Epoch 80/170 => Loss 2.373, Train_accy 75.500, Test_accy 74.300
2022-05-25 10:29:43,019 [bic.py] => bias_correction => Task 1, Epoch 81/170 => Loss 2.358, Train_accy 77.750, Test_accy 73.850
2022-05-25 10:29:44,528 [bic.py] => bias_correction => Task 1, Epoch 82/170 => Loss 2.348, Train_accy 77.000, Test_accy 74.100
2022-05-25 10:29:46,047 [bic.py] => bias_correction => Task 1, Epoch 83/170 => Loss 2.314, Train_accy 77.000, Test_accy 74.100
2022-05-25 10:29:47,550 [bic.py] => bias_correction => Task 1, Epoch 84/170 => Loss 2.340, Train_accy 78.750, Test_accy 74.000
2022-05-25 10:29:49,079 [bic.py] => bias_correction => Task 1, Epoch 85/170 => Loss 2.327, Train_accy 75.750, Test_accy 73.600
2022-05-25 10:29:50,639 [bic.py] => bias_correction => Task 1, Epoch 86/170 => Loss 2.367, Train_accy 78.500, Test_accy 74.050
2022-05-25 10:29:52,121 [bic.py] => bias_correction => Task 1, Epoch 87/170 => Loss 2.369, Train_accy 76.500, Test_accy 73.700
2022-05-25 10:29:53,656 [bic.py] => bias_correction => Task 1, Epoch 88/170 => Loss 2.331, Train_accy 79.500, Test_accy 74.200
2022-05-25 10:29:55,142 [bic.py] => bias_correction => Task 1, Epoch 89/170 => Loss 2.343, Train_accy 77.250, Test_accy 73.950
2022-05-25 10:29:56,668 [bic.py] => bias_correction => Task 1, Epoch 90/170 => Loss 2.345, Train_accy 78.500, Test_accy 74.050
2022-05-25 10:29:58,200 [bic.py] => bias_correction => Task 1, Epoch 91/170 => Loss 2.319, Train_accy 80.500, Test_accy 73.900
2022-05-25 10:29:59,673 [bic.py] => bias_correction => Task 1, Epoch 92/170 => Loss 2.356, Train_accy 78.250, Test_accy 74.000
2022-05-25 10:30:01,182 [bic.py] => bias_correction => Task 1, Epoch 93/170 => Loss 2.350, Train_accy 79.000, Test_accy 74.350
2022-05-25 10:30:02,663 [bic.py] => bias_correction => Task 1, Epoch 94/170 => Loss 2.337, Train_accy 78.250, Test_accy 74.000
2022-05-25 10:30:04,164 [bic.py] => bias_correction => Task 1, Epoch 95/170 => Loss 2.358, Train_accy 79.500, Test_accy 73.750
2022-05-25 10:30:05,691 [bic.py] => bias_correction => Task 1, Epoch 96/170 => Loss 2.386, Train_accy 78.500, Test_accy 74.000
2022-05-25 10:30:07,262 [bic.py] => bias_correction => Task 1, Epoch 97/170 => Loss 2.407, Train_accy 77.750, Test_accy 74.100
2022-05-25 10:30:08,728 [bic.py] => bias_correction => Task 1, Epoch 98/170 => Loss 2.340, Train_accy 79.250, Test_accy 73.850
2022-05-25 10:30:10,225 [bic.py] => bias_correction => Task 1, Epoch 99/170 => Loss 2.348, Train_accy 77.250, Test_accy 73.700
2022-05-25 10:30:11,756 [bic.py] => bias_correction => Task 1, Epoch 100/170 => Loss 2.331, Train_accy 78.250, Test_accy 74.000
2022-05-25 10:30:13,193 [bic.py] => bias_correction => Task 1, Epoch 101/170 => Loss 2.370, Train_accy 77.500, Test_accy 73.700
2022-05-25 10:30:14,672 [bic.py] => bias_correction => Task 1, Epoch 102/170 => Loss 2.345, Train_accy 79.750, Test_accy 73.850
2022-05-25 10:30:16,198 [bic.py] => bias_correction => Task 1, Epoch 103/170 => Loss 2.346, Train_accy 76.750, Test_accy 73.550
2022-05-25 10:30:17,711 [bic.py] => bias_correction => Task 1, Epoch 104/170 => Loss 2.390, Train_accy 78.000, Test_accy 73.650
2022-05-25 10:30:19,375 [bic.py] => bias_correction => Task 1, Epoch 105/170 => Loss 2.370, Train_accy 76.750, Test_accy 73.550
2022-05-25 10:30:20,839 [bic.py] => bias_correction => Task 1, Epoch 106/170 => Loss 2.324, Train_accy 79.000, Test_accy 74.000
2022-05-25 10:30:22,318 [bic.py] => bias_correction => Task 1, Epoch 107/170 => Loss 2.414, Train_accy 77.000, Test_accy 73.850
2022-05-25 10:30:23,829 [bic.py] => bias_correction => Task 1, Epoch 108/170 => Loss 2.373, Train_accy 78.750, Test_accy 73.950
2022-05-25 10:30:25,393 [bic.py] => bias_correction => Task 1, Epoch 109/170 => Loss 2.347, Train_accy 78.750, Test_accy 74.000
2022-05-25 10:30:26,950 [bic.py] => bias_correction => Task 1, Epoch 110/170 => Loss 2.350, Train_accy 77.250, Test_accy 74.000
2022-05-25 10:30:28,561 [bic.py] => bias_correction => Task 1, Epoch 111/170 => Loss 2.335, Train_accy 78.500, Test_accy 74.200
2022-05-25 10:30:30,103 [bic.py] => bias_correction => Task 1, Epoch 112/170 => Loss 2.341, Train_accy 78.750, Test_accy 74.000
2022-05-25 10:30:31,575 [bic.py] => bias_correction => Task 1, Epoch 113/170 => Loss 2.359, Train_accy 77.750, Test_accy 74.250
2022-05-25 10:30:32,998 [bic.py] => bias_correction => Task 1, Epoch 114/170 => Loss 2.374, Train_accy 76.750, Test_accy 74.450
2022-05-25 10:30:34,427 [bic.py] => bias_correction => Task 1, Epoch 115/170 => Loss 2.357, Train_accy 77.000, Test_accy 74.250
2022-05-25 10:30:35,861 [bic.py] => bias_correction => Task 1, Epoch 116/170 => Loss 2.331, Train_accy 78.500, Test_accy 74.350
2022-05-25 10:30:37,355 [bic.py] => bias_correction => Task 1, Epoch 117/170 => Loss 2.352, Train_accy 78.750, Test_accy 74.400
2022-05-25 10:30:38,847 [bic.py] => bias_correction => Task 1, Epoch 118/170 => Loss 2.350, Train_accy 77.250, Test_accy 73.750
2022-05-25 10:30:40,320 [bic.py] => bias_correction => Task 1, Epoch 119/170 => Loss 2.333, Train_accy 76.250, Test_accy 73.900
2022-05-25 10:30:41,769 [bic.py] => bias_correction => Task 1, Epoch 120/170 => Loss 2.330, Train_accy 79.250, Test_accy 74.150
2022-05-25 10:30:43,277 [bic.py] => bias_correction => Task 1, Epoch 121/170 => Loss 2.322, Train_accy 77.750, Test_accy 73.800
2022-05-25 10:30:44,833 [bic.py] => bias_correction => Task 1, Epoch 122/170 => Loss 2.380, Train_accy 78.000, Test_accy 74.050
2022-05-25 10:30:46,373 [bic.py] => bias_correction => Task 1, Epoch 123/170 => Loss 2.359, Train_accy 76.250, Test_accy 74.100
2022-05-25 10:30:47,898 [bic.py] => bias_correction => Task 1, Epoch 124/170 => Loss 2.352, Train_accy 78.250, Test_accy 73.950
2022-05-25 10:30:49,461 [bic.py] => bias_correction => Task 1, Epoch 125/170 => Loss 2.336, Train_accy 79.750, Test_accy 73.950
2022-05-25 10:30:51,027 [bic.py] => bias_correction => Task 1, Epoch 126/170 => Loss 2.345, Train_accy 78.250, Test_accy 73.650
2022-05-25 10:30:52,590 [bic.py] => bias_correction => Task 1, Epoch 127/170 => Loss 2.398, Train_accy 76.250, Test_accy 74.050
2022-05-25 10:30:54,151 [bic.py] => bias_correction => Task 1, Epoch 128/170 => Loss 2.327, Train_accy 78.000, Test_accy 74.200
2022-05-25 10:30:55,707 [bic.py] => bias_correction => Task 1, Epoch 129/170 => Loss 2.351, Train_accy 77.750, Test_accy 74.500
2022-05-25 10:30:57,201 [bic.py] => bias_correction => Task 1, Epoch 130/170 => Loss 2.320, Train_accy 78.500, Test_accy 74.050
2022-05-25 10:30:58,696 [bic.py] => bias_correction => Task 1, Epoch 131/170 => Loss 2.359, Train_accy 77.250, Test_accy 74.200
2022-05-25 10:31:00,249 [bic.py] => bias_correction => Task 1, Epoch 132/170 => Loss 2.372, Train_accy 78.750, Test_accy 73.850
2022-05-25 10:31:01,800 [bic.py] => bias_correction => Task 1, Epoch 133/170 => Loss 2.355, Train_accy 79.000, Test_accy 73.800
2022-05-25 10:31:03,317 [bic.py] => bias_correction => Task 1, Epoch 134/170 => Loss 2.357, Train_accy 78.750, Test_accy 74.200
2022-05-25 10:31:04,951 [bic.py] => bias_correction => Task 1, Epoch 135/170 => Loss 2.328, Train_accy 78.750, Test_accy 73.750
2022-05-25 10:31:06,602 [bic.py] => bias_correction => Task 1, Epoch 136/170 => Loss 2.329, Train_accy 78.000, Test_accy 73.800
2022-05-25 10:31:08,030 [bic.py] => bias_correction => Task 1, Epoch 137/170 => Loss 2.335, Train_accy 76.250, Test_accy 74.050
2022-05-25 10:31:09,510 [bic.py] => bias_correction => Task 1, Epoch 138/170 => Loss 2.352, Train_accy 78.250, Test_accy 73.950
2022-05-25 10:31:11,036 [bic.py] => bias_correction => Task 1, Epoch 139/170 => Loss 2.298, Train_accy 77.000, Test_accy 73.700
2022-05-25 10:31:12,532 [bic.py] => bias_correction => Task 1, Epoch 140/170 => Loss 2.362, Train_accy 78.250, Test_accy 74.000
2022-05-25 10:31:14,002 [bic.py] => bias_correction => Task 1, Epoch 141/170 => Loss 2.341, Train_accy 77.000, Test_accy 73.650
2022-05-25 10:31:15,555 [bic.py] => bias_correction => Task 1, Epoch 142/170 => Loss 2.341, Train_accy 78.750, Test_accy 73.700
2022-05-25 10:31:17,159 [bic.py] => bias_correction => Task 1, Epoch 143/170 => Loss 2.370, Train_accy 78.250, Test_accy 73.750
2022-05-25 10:31:18,695 [bic.py] => bias_correction => Task 1, Epoch 144/170 => Loss 2.355, Train_accy 79.000, Test_accy 73.750
2022-05-25 10:31:20,207 [bic.py] => bias_correction => Task 1, Epoch 145/170 => Loss 2.325, Train_accy 76.750, Test_accy 73.350
2022-05-25 10:31:21,769 [bic.py] => bias_correction => Task 1, Epoch 146/170 => Loss 2.374, Train_accy 79.000, Test_accy 73.700
2022-05-25 10:31:23,345 [bic.py] => bias_correction => Task 1, Epoch 147/170 => Loss 2.387, Train_accy 77.500, Test_accy 73.800
2022-05-25 10:31:24,941 [bic.py] => bias_correction => Task 1, Epoch 148/170 => Loss 2.381, Train_accy 77.250, Test_accy 73.900
2022-05-25 10:31:26,542 [bic.py] => bias_correction => Task 1, Epoch 149/170 => Loss 2.355, Train_accy 79.750, Test_accy 73.650
2022-05-25 10:31:28,086 [bic.py] => bias_correction => Task 1, Epoch 150/170 => Loss 2.391, Train_accy 77.250, Test_accy 74.050
2022-05-25 10:31:29,741 [bic.py] => bias_correction => Task 1, Epoch 151/170 => Loss 2.342, Train_accy 81.250, Test_accy 74.050
2022-05-25 10:31:31,329 [bic.py] => bias_correction => Task 1, Epoch 152/170 => Loss 2.343, Train_accy 78.500, Test_accy 74.300
2022-05-25 10:31:32,886 [bic.py] => bias_correction => Task 1, Epoch 153/170 => Loss 2.335, Train_accy 79.750, Test_accy 74.250
2022-05-25 10:31:34,407 [bic.py] => bias_correction => Task 1, Epoch 154/170 => Loss 2.326, Train_accy 79.500, Test_accy 74.400
2022-05-25 10:31:36,000 [bic.py] => bias_correction => Task 1, Epoch 155/170 => Loss 2.345, Train_accy 77.250, Test_accy 74.400
2022-05-25 10:31:37,615 [bic.py] => bias_correction => Task 1, Epoch 156/170 => Loss 2.362, Train_accy 76.750, Test_accy 74.550
2022-05-25 10:31:39,156 [bic.py] => bias_correction => Task 1, Epoch 157/170 => Loss 2.339, Train_accy 77.000, Test_accy 74.350
2022-05-25 10:31:40,704 [bic.py] => bias_correction => Task 1, Epoch 158/170 => Loss 2.353, Train_accy 79.000, Test_accy 74.000
2022-05-25 10:31:42,189 [bic.py] => bias_correction => Task 1, Epoch 159/170 => Loss 2.347, Train_accy 79.500, Test_accy 74.200
2022-05-25 10:31:43,665 [bic.py] => bias_correction => Task 1, Epoch 160/170 => Loss 2.347, Train_accy 77.500, Test_accy 74.050
2022-05-25 10:31:45,201 [bic.py] => bias_correction => Task 1, Epoch 161/170 => Loss 2.332, Train_accy 78.750, Test_accy 74.100
2022-05-25 10:31:46,697 [bic.py] => bias_correction => Task 1, Epoch 162/170 => Loss 2.359, Train_accy 77.000, Test_accy 73.950
2022-05-25 10:31:48,236 [bic.py] => bias_correction => Task 1, Epoch 163/170 => Loss 2.343, Train_accy 79.500, Test_accy 73.800
2022-05-25 10:31:49,869 [bic.py] => bias_correction => Task 1, Epoch 164/170 => Loss 2.319, Train_accy 78.250, Test_accy 73.300
2022-05-25 10:31:51,485 [bic.py] => bias_correction => Task 1, Epoch 165/170 => Loss 2.332, Train_accy 79.000, Test_accy 73.850
2022-05-25 10:31:53,070 [bic.py] => bias_correction => Task 1, Epoch 166/170 => Loss 2.340, Train_accy 78.750, Test_accy 73.600
2022-05-25 10:31:54,688 [bic.py] => bias_correction => Task 1, Epoch 167/170 => Loss 2.354, Train_accy 77.250, Test_accy 73.700
2022-05-25 10:31:56,237 [bic.py] => bias_correction => Task 1, Epoch 168/170 => Loss 2.350, Train_accy 80.250, Test_accy 73.800
2022-05-25 10:31:57,779 [bic.py] => bias_correction => Task 1, Epoch 169/170 => Loss 2.347, Train_accy 78.750, Test_accy 74.150
2022-05-25 10:31:59,323 [bic.py] => bias_correction => Task 1, Epoch 170/170 => Loss 2.320, Train_accy 77.500, Test_accy 73.700
2022-05-25 10:31:59,324 [base.py] => Reducing exemplars...(100 per classes)
2022-05-25 10:32:01,680 [base.py] => Constructing exemplars...(100 per classes)
2022-05-25 10:32:07,366 [bic.py] => Parameters of bias layer:
2022-05-25 10:32:07,367 [bic.py] => 0 => 1.000, 0.000
2022-05-25 10:32:07,367 [bic.py] => 1 => 0.904, -1.125
2022-05-25 10:32:08,499 [bic.py] => Exemplar size: 2000
2022-05-25 10:32:08,500 [trainer.py] => CNN: {'total': 73.7, '00-09': 74.5, '10-19': 72.9, 'old': 74.5, 'new': 72.9}
2022-05-25 10:32:08,500 [trainer.py] => NME: {'total': 74.15, '00-09': 74.7, '10-19': 73.6, 'old': 74.7, 'new': 73.6}
2022-05-25 10:32:08,500 [trainer.py] => CNN top1 curve: [83.0, 73.7]
2022-05-25 10:32:08,500 [trainer.py] => CNN top5 curve: [99.1, 95.65]
2022-05-25 10:32:08,500 [trainer.py] => NME top1 curve: [82.8, 74.15]
2022-05-25 10:32:08,500 [trainer.py] => NME top5 curve: [99.0, 95.75]

2022-05-25 10:32:08,501 [trainer.py] => All params: 465458
2022-05-25 10:32:08,501 [trainer.py] => Trainable params: 465458
2022-05-25 10:32:08,502 [bic.py] => Learning on 20-30
2022-05-25 10:32:08,565 [bic.py] => Stage1 dset: 6700, Stage2 dset: 300
2022-05-25 10:32:08,565 [bic.py] => Lambda: 0.667
2022-05-25 10:32:08,572 [bic.py] => Parameters of bias layer:
2022-05-25 10:32:08,572 [bic.py] => 0 => 1.000, 0.000
2022-05-25 10:32:08,572 [bic.py] => 1 => 0.904, -1.125
2022-05-25 10:32:08,572 [bic.py] => 2 => 1.000, 0.000
2022-05-25 10:32:12,987 [bic.py] => training => Task 2, Epoch 1/170 => Loss 1.789, Train_accy 60.600, Test_accy 49.070
2022-05-25 10:32:17,251 [bic.py] => training => Task 2, Epoch 2/170 => Loss 1.480, Train_accy 66.150, Test_accy 48.800
2022-05-25 10:32:21,465 [bic.py] => training => Task 2, Epoch 3/170 => Loss 1.423, Train_accy 71.220, Test_accy 54.130
2022-05-25 10:32:25,710 [bic.py] => training => Task 2, Epoch 4/170 => Loss 1.391, Train_accy 73.060, Test_accy 55.000
2022-05-25 10:32:29,805 [bic.py] => training => Task 2, Epoch 5/170 => Loss 1.363, Train_accy 77.010, Test_accy 57.230
2022-05-25 10:32:33,947 [bic.py] => training => Task 2, Epoch 6/170 => Loss 1.353, Train_accy 75.340, Test_accy 57.100
2022-05-25 10:32:38,095 [bic.py] => training => Task 2, Epoch 7/170 => Loss 1.347, Train_accy 78.840, Test_accy 57.600
2022-05-25 10:32:42,284 [bic.py] => training => Task 2, Epoch 8/170 => Loss 1.330, Train_accy 77.220, Test_accy 56.900
2022-05-25 10:32:46,510 [bic.py] => training => Task 2, Epoch 9/170 => Loss 1.316, Train_accy 82.780, Test_accy 59.700
2022-05-25 10:32:50,692 [bic.py] => training => Task 2, Epoch 10/170 => Loss 1.299, Train_accy 81.300, Test_accy 56.830
2022-05-25 10:32:54,840 [bic.py] => training => Task 2, Epoch 11/170 => Loss 1.298, Train_accy 80.810, Test_accy 57.330
2022-05-25 10:32:59,039 [bic.py] => training => Task 2, Epoch 12/170 => Loss 1.292, Train_accy 82.630, Test_accy 58.300
2022-05-25 10:33:03,180 [bic.py] => training => Task 2, Epoch 13/170 => Loss 1.269, Train_accy 83.870, Test_accy 55.870
2022-05-25 10:33:07,377 [bic.py] => training => Task 2, Epoch 14/170 => Loss 1.275, Train_accy 82.190, Test_accy 56.700
2022-05-25 10:33:11,568 [bic.py] => training => Task 2, Epoch 15/170 => Loss 1.264, Train_accy 85.400, Test_accy 58.970
2022-05-25 10:33:15,746 [bic.py] => training => Task 2, Epoch 16/170 => Loss 1.263, Train_accy 83.670, Test_accy 57.070
2022-05-25 10:33:20,090 [bic.py] => training => Task 2, Epoch 17/170 => Loss 1.260, Train_accy 84.480, Test_accy 57.100
2022-05-25 10:33:24,199 [bic.py] => training => Task 2, Epoch 18/170 => Loss 1.251, Train_accy 86.070, Test_accy 59.670
2022-05-25 10:33:28,361 [bic.py] => training => Task 2, Epoch 19/170 => Loss 1.246, Train_accy 86.820, Test_accy 57.300
2022-05-25 10:33:32,535 [bic.py] => training => Task 2, Epoch 20/170 => Loss 1.250, Train_accy 84.280, Test_accy 54.530
2022-05-25 10:33:36,718 [bic.py] => training => Task 2, Epoch 21/170 => Loss 1.248, Train_accy 88.160, Test_accy 58.500
2022-05-25 10:33:41,039 [bic.py] => training => Task 2, Epoch 22/170 => Loss 1.240, Train_accy 89.310, Test_accy 60.300
2022-05-25 10:33:45,238 [bic.py] => training => Task 2, Epoch 23/170 => Loss 1.235, Train_accy 88.520, Test_accy 59.270
2022-05-25 10:33:49,339 [bic.py] => training => Task 2, Epoch 24/170 => Loss 1.236, Train_accy 87.000, Test_accy 58.900
2022-05-25 10:33:53,589 [bic.py] => training => Task 2, Epoch 25/170 => Loss 1.242, Train_accy 86.750, Test_accy 56.670
2022-05-25 10:33:57,741 [bic.py] => training => Task 2, Epoch 26/170 => Loss 1.248, Train_accy 87.900, Test_accy 59.030
2022-05-25 10:34:01,807 [bic.py] => training => Task 2, Epoch 27/170 => Loss 1.233, Train_accy 87.880, Test_accy 60.530
2022-05-25 10:34:06,015 [bic.py] => training => Task 2, Epoch 28/170 => Loss 1.232, Train_accy 88.130, Test_accy 58.530
2022-05-25 10:34:10,204 [bic.py] => training => Task 2, Epoch 29/170 => Loss 1.217, Train_accy 87.210, Test_accy 55.630
2022-05-25 10:34:14,560 [bic.py] => training => Task 2, Epoch 30/170 => Loss 1.216, Train_accy 88.840, Test_accy 57.770
2022-05-25 10:34:18,588 [bic.py] => training => Task 2, Epoch 31/170 => Loss 1.209, Train_accy 89.420, Test_accy 58.500
2022-05-25 10:34:22,690 [bic.py] => training => Task 2, Epoch 32/170 => Loss 1.209, Train_accy 87.820, Test_accy 54.630
2022-05-25 10:34:26,792 [bic.py] => training => Task 2, Epoch 33/170 => Loss 1.225, Train_accy 91.970, Test_accy 57.570
2022-05-25 10:34:30,997 [bic.py] => training => Task 2, Epoch 34/170 => Loss 1.209, Train_accy 89.520, Test_accy 59.970
2022-05-25 10:34:35,075 [bic.py] => training => Task 2, Epoch 35/170 => Loss 1.207, Train_accy 90.540, Test_accy 58.730
2022-05-25 10:34:39,137 [bic.py] => training => Task 2, Epoch 36/170 => Loss 1.217, Train_accy 89.850, Test_accy 58.830
2022-05-25 10:34:43,283 [bic.py] => training => Task 2, Epoch 37/170 => Loss 1.199, Train_accy 90.210, Test_accy 58.800
2022-05-25 10:34:47,379 [bic.py] => training => Task 2, Epoch 38/170 => Loss 1.210, Train_accy 88.700, Test_accy 58.270
2022-05-25 10:34:51,507 [bic.py] => training => Task 2, Epoch 39/170 => Loss 1.210, Train_accy 91.310, Test_accy 57.900
2022-05-25 10:34:55,637 [bic.py] => training => Task 2, Epoch 40/170 => Loss 1.207, Train_accy 90.610, Test_accy 59.170
2022-05-25 10:34:59,658 [bic.py] => training => Task 2, Epoch 41/170 => Loss 1.194, Train_accy 88.940, Test_accy 59.800
2022-05-25 10:35:03,730 [bic.py] => training => Task 2, Epoch 42/170 => Loss 1.186, Train_accy 90.960, Test_accy 56.070
2022-05-25 10:35:07,806 [bic.py] => training => Task 2, Epoch 43/170 => Loss 1.197, Train_accy 90.880, Test_accy 57.400
2022-05-25 10:35:11,932 [bic.py] => training => Task 2, Epoch 44/170 => Loss 1.197, Train_accy 90.570, Test_accy 55.770
2022-05-25 10:35:16,158 [bic.py] => training => Task 2, Epoch 45/170 => Loss 1.197, Train_accy 87.490, Test_accy 53.600
2022-05-25 10:35:20,229 [bic.py] => training => Task 2, Epoch 46/170 => Loss 1.196, Train_accy 88.870, Test_accy 56.100
2022-05-25 10:35:24,363 [bic.py] => training => Task 2, Epoch 47/170 => Loss 1.196, Train_accy 91.810, Test_accy 58.870
2022-05-25 10:35:28,397 [bic.py] => training => Task 2, Epoch 48/170 => Loss 1.196, Train_accy 91.180, Test_accy 59.670
2022-05-25 10:35:32,405 [bic.py] => training => Task 2, Epoch 49/170 => Loss 1.190, Train_accy 90.510, Test_accy 58.730
2022-05-25 10:35:36,637 [bic.py] => training => Task 2, Epoch 50/170 => Loss 1.180, Train_accy 90.670, Test_accy 57.500
2022-05-25 10:35:40,667 [bic.py] => training => Task 2, Epoch 51/170 => Loss 1.189, Train_accy 92.130, Test_accy 57.800
2022-05-25 10:35:44,868 [bic.py] => training => Task 2, Epoch 52/170 => Loss 1.184, Train_accy 92.550, Test_accy 56.900
2022-05-25 10:35:49,127 [bic.py] => training => Task 2, Epoch 53/170 => Loss 1.183, Train_accy 92.390, Test_accy 60.500
2022-05-25 10:35:53,251 [bic.py] => training => Task 2, Epoch 54/170 => Loss 1.185, Train_accy 88.550, Test_accy 57.030
2022-05-25 10:35:57,400 [bic.py] => training => Task 2, Epoch 55/170 => Loss 1.190, Train_accy 92.580, Test_accy 58.700
2022-05-25 10:36:01,587 [bic.py] => training => Task 2, Epoch 56/170 => Loss 1.192, Train_accy 93.780, Test_accy 59.400
2022-05-25 10:36:05,613 [bic.py] => training => Task 2, Epoch 57/170 => Loss 1.199, Train_accy 94.510, Test_accy 61.500
2022-05-25 10:36:09,741 [bic.py] => training => Task 2, Epoch 58/170 => Loss 1.192, Train_accy 91.180, Test_accy 57.730
2022-05-25 10:36:13,894 [bic.py] => training => Task 2, Epoch 59/170 => Loss 1.182, Train_accy 90.240, Test_accy 56.000
2022-05-25 10:36:18,053 [bic.py] => training => Task 2, Epoch 60/170 => Loss 1.196, Train_accy 90.910, Test_accy 58.470
2022-05-25 10:36:22,298 [bic.py] => training => Task 2, Epoch 61/170 => Loss 1.144, Train_accy 98.420, Test_accy 64.970
2022-05-25 10:36:26,445 [bic.py] => training => Task 2, Epoch 62/170 => Loss 1.115, Train_accy 99.120, Test_accy 64.600
2022-05-25 10:36:30,588 [bic.py] => training => Task 2, Epoch 63/170 => Loss 1.109, Train_accy 99.010, Test_accy 64.370
2022-05-25 10:36:34,761 [bic.py] => training => Task 2, Epoch 64/170 => Loss 1.103, Train_accy 99.190, Test_accy 64.300
2022-05-25 10:36:38,808 [bic.py] => training => Task 2, Epoch 65/170 => Loss 1.104, Train_accy 99.270, Test_accy 64.500
2022-05-25 10:36:42,775 [bic.py] => training => Task 2, Epoch 66/170 => Loss 1.103, Train_accy 99.240, Test_accy 64.570
2022-05-25 10:36:46,969 [bic.py] => training => Task 2, Epoch 67/170 => Loss 1.097, Train_accy 99.360, Test_accy 64.530
2022-05-25 10:36:50,990 [bic.py] => training => Task 2, Epoch 68/170 => Loss 1.101, Train_accy 99.430, Test_accy 64.400
2022-05-25 10:36:55,172 [bic.py] => training => Task 2, Epoch 69/170 => Loss 1.103, Train_accy 99.550, Test_accy 64.400
2022-05-25 10:36:59,321 [bic.py] => training => Task 2, Epoch 70/170 => Loss 1.094, Train_accy 99.510, Test_accy 64.200
2022-05-25 10:37:03,399 [bic.py] => training => Task 2, Epoch 71/170 => Loss 1.098, Train_accy 99.580, Test_accy 64.030
2022-05-25 10:37:07,473 [bic.py] => training => Task 2, Epoch 72/170 => Loss 1.092, Train_accy 99.430, Test_accy 64.470
2022-05-25 10:37:11,572 [bic.py] => training => Task 2, Epoch 73/170 => Loss 1.090, Train_accy 99.610, Test_accy 64.800
2022-05-25 10:37:15,786 [bic.py] => training => Task 2, Epoch 74/170 => Loss 1.085, Train_accy 99.420, Test_accy 64.370
2022-05-25 10:37:20,027 [bic.py] => training => Task 2, Epoch 75/170 => Loss 1.093, Train_accy 99.610, Test_accy 64.700
2022-05-25 10:37:24,104 [bic.py] => training => Task 2, Epoch 76/170 => Loss 1.094, Train_accy 99.660, Test_accy 64.400
2022-05-25 10:37:28,224 [bic.py] => training => Task 2, Epoch 77/170 => Loss 1.093, Train_accy 99.520, Test_accy 64.330
2022-05-25 10:37:32,410 [bic.py] => training => Task 2, Epoch 78/170 => Loss 1.090, Train_accy 99.330, Test_accy 64.670
2022-05-25 10:37:36,635 [bic.py] => training => Task 2, Epoch 79/170 => Loss 1.093, Train_accy 99.520, Test_accy 64.700
2022-05-25 10:37:40,746 [bic.py] => training => Task 2, Epoch 80/170 => Loss 1.085, Train_accy 99.640, Test_accy 64.430
2022-05-25 10:37:44,859 [bic.py] => training => Task 2, Epoch 81/170 => Loss 1.089, Train_accy 99.730, Test_accy 64.730
2022-05-25 10:37:49,047 [bic.py] => training => Task 2, Epoch 82/170 => Loss 1.083, Train_accy 99.660, Test_accy 64.400
2022-05-25 10:37:53,187 [bic.py] => training => Task 2, Epoch 83/170 => Loss 1.089, Train_accy 99.600, Test_accy 64.470
2022-05-25 10:37:57,357 [bic.py] => training => Task 2, Epoch 84/170 => Loss 1.086, Train_accy 99.640, Test_accy 64.500
2022-05-25 10:38:01,497 [bic.py] => training => Task 2, Epoch 85/170 => Loss 1.084, Train_accy 99.720, Test_accy 64.100
2022-05-25 10:38:05,658 [bic.py] => training => Task 2, Epoch 86/170 => Loss 1.085, Train_accy 99.810, Test_accy 64.400
2022-05-25 10:38:09,855 [bic.py] => training => Task 2, Epoch 87/170 => Loss 1.086, Train_accy 99.660, Test_accy 64.500
2022-05-25 10:38:14,050 [bic.py] => training => Task 2, Epoch 88/170 => Loss 1.086, Train_accy 99.790, Test_accy 64.070
