2022-05-24 22:00:43,262 [trainer.py] => config: exps/bic.json
2022-05-24 22:00:43,262 [trainer.py] => prefix: reproduce
2022-05-24 22:00:43,262 [trainer.py] => dataset: cifar100
2022-05-24 22:00:43,262 [trainer.py] => memory_size: 2000
2022-05-24 22:00:43,262 [trainer.py] => memory_per_class: 20
2022-05-24 22:00:43,262 [trainer.py] => fixed_memory: False
2022-05-24 22:00:43,262 [trainer.py] => shuffle: True
2022-05-24 22:00:43,262 [trainer.py] => init_cls: 10
2022-05-24 22:00:43,262 [trainer.py] => increment: 10
2022-05-24 22:00:43,263 [trainer.py] => model_name: bic
2022-05-24 22:00:43,263 [trainer.py] => convnet_type: resnet32
2022-05-24 22:00:43,263 [trainer.py] => device: [device(type='cuda', index=0)]
2022-05-24 22:00:43,263 [trainer.py] => seed: 1993
2022-05-24 22:00:44,998 [data_manager.py] => class order: [68, 56, 78, 8, 23, 84, 90, 65, 74, 76, 40, 89, 3, 92, 55, 9, 26, 80, 43, 38, 58, 70, 77, 1, 85, 19, 17, 50, 28, 53, 13, 81, 45, 82, 6, 59, 83, 16, 15, 44, 91, 41, 72, 60, 79, 52, 20, 10, 31, 54, 37, 95, 14, 71, 96, 98, 97, 2, 64, 66, 42, 22, 35, 86, 24, 34, 87, 21, 99, 0, 88, 27, 18, 94, 11, 12, 47, 25, 30, 46, 62, 69, 36, 61, 7, 63, 75, 5, 32, 4, 51, 48, 73, 93, 39, 67, 29, 49, 57, 33]
2022-05-24 22:00:45,347 [trainer.py] => All params: 464154
2022-05-24 22:00:45,347 [trainer.py] => Trainable params: 464154
2022-05-24 22:00:45,347 [bic.py] => Learning on 0-10
2022-05-24 22:00:45,359 [bic.py] => Parameters of bias layer:
2022-05-24 22:00:45,359 [bic.py] => 0 => 1.000, 0.000
2022-05-24 22:00:51,071 [bic.py] => training => Task 0, Epoch 1/170 => Loss 2.702, Train_accy 14.200, Test_accy 12.600
2022-05-24 22:00:54,052 [bic.py] => training => Task 0, Epoch 2/170 => Loss 2.002, Train_accy 24.680, Test_accy 24.800
2022-05-24 22:00:56,969 [bic.py] => training => Task 0, Epoch 3/170 => Loss 1.797, Train_accy 33.140, Test_accy 35.100
2022-05-24 22:01:00,030 [bic.py] => training => Task 0, Epoch 4/170 => Loss 1.675, Train_accy 40.920, Test_accy 40.900
2022-05-24 22:01:02,902 [bic.py] => training => Task 0, Epoch 5/170 => Loss 1.567, Train_accy 30.180, Test_accy 29.400
2022-05-24 22:01:05,912 [bic.py] => training => Task 0, Epoch 6/170 => Loss 1.517, Train_accy 48.740, Test_accy 48.400
2022-05-24 22:01:08,837 [bic.py] => training => Task 0, Epoch 7/170 => Loss 1.437, Train_accy 49.320, Test_accy 48.900
2022-05-24 22:01:11,798 [bic.py] => training => Task 0, Epoch 8/170 => Loss 1.372, Train_accy 47.500, Test_accy 48.600
2022-05-24 22:01:14,751 [bic.py] => training => Task 0, Epoch 9/170 => Loss 1.345, Train_accy 52.660, Test_accy 53.600
2022-05-24 22:01:17,715 [bic.py] => training => Task 0, Epoch 10/170 => Loss 1.220, Train_accy 50.000, Test_accy 49.700
2022-05-24 22:01:20,676 [bic.py] => training => Task 0, Epoch 11/170 => Loss 1.173, Train_accy 53.920, Test_accy 51.900
2022-05-24 22:01:24,371 [bic.py] => training => Task 0, Epoch 12/170 => Loss 1.113, Train_accy 59.640, Test_accy 60.400
2022-05-24 22:01:28,254 [bic.py] => training => Task 0, Epoch 13/170 => Loss 1.063, Train_accy 64.200, Test_accy 63.700
2022-05-24 22:01:31,895 [bic.py] => training => Task 0, Epoch 14/170 => Loss 0.989, Train_accy 62.540, Test_accy 61.200
2022-05-24 22:01:35,993 [bic.py] => training => Task 0, Epoch 15/170 => Loss 0.950, Train_accy 60.600, Test_accy 57.900
2022-05-24 22:01:39,878 [bic.py] => training => Task 0, Epoch 16/170 => Loss 0.935, Train_accy 68.480, Test_accy 68.000
2022-05-24 22:01:44,022 [bic.py] => training => Task 0, Epoch 17/170 => Loss 0.846, Train_accy 67.960, Test_accy 65.700
2022-05-24 22:01:47,683 [bic.py] => training => Task 0, Epoch 18/170 => Loss 0.833, Train_accy 69.380, Test_accy 66.200
2022-05-24 22:01:51,675 [bic.py] => training => Task 0, Epoch 19/170 => Loss 0.768, Train_accy 73.040, Test_accy 71.600
2022-05-24 22:01:55,358 [bic.py] => training => Task 0, Epoch 20/170 => Loss 0.763, Train_accy 71.480, Test_accy 69.900
2022-05-24 22:01:59,238 [bic.py] => training => Task 0, Epoch 21/170 => Loss 0.770, Train_accy 69.340, Test_accy 67.600
2022-05-24 22:02:03,113 [bic.py] => training => Task 0, Epoch 22/170 => Loss 0.765, Train_accy 73.340, Test_accy 69.900
2022-05-24 22:02:06,951 [bic.py] => training => Task 0, Epoch 23/170 => Loss 0.659, Train_accy 77.420, Test_accy 74.300
2022-05-24 22:02:10,993 [bic.py] => training => Task 0, Epoch 24/170 => Loss 0.653, Train_accy 72.580, Test_accy 70.300
2022-05-24 22:02:15,198 [bic.py] => training => Task 0, Epoch 25/170 => Loss 0.701, Train_accy 74.900, Test_accy 70.800
2022-05-24 22:02:19,666 [bic.py] => training => Task 0, Epoch 26/170 => Loss 0.771, Train_accy 76.520, Test_accy 74.400
2022-05-24 22:02:23,828 [bic.py] => training => Task 0, Epoch 27/170 => Loss 0.620, Train_accy 79.100, Test_accy 75.700
2022-05-24 22:02:28,427 [bic.py] => training => Task 0, Epoch 28/170 => Loss 0.532, Train_accy 77.260, Test_accy 74.400
2022-05-24 22:02:32,689 [bic.py] => training => Task 0, Epoch 29/170 => Loss 0.523, Train_accy 76.280, Test_accy 71.700
2022-05-24 22:02:37,189 [bic.py] => training => Task 0, Epoch 30/170 => Loss 0.583, Train_accy 79.860, Test_accy 76.900
2022-05-24 22:02:41,275 [bic.py] => training => Task 0, Epoch 31/170 => Loss 0.497, Train_accy 79.360, Test_accy 74.900
2022-05-24 22:02:45,483 [bic.py] => training => Task 0, Epoch 32/170 => Loss 0.578, Train_accy 79.680, Test_accy 76.200
2022-05-24 22:02:49,888 [bic.py] => training => Task 0, Epoch 33/170 => Loss 0.456, Train_accy 83.740, Test_accy 77.300
2022-05-24 22:02:54,165 [bic.py] => training => Task 0, Epoch 34/170 => Loss 0.423, Train_accy 80.360, Test_accy 75.800
2022-05-24 22:02:58,323 [bic.py] => training => Task 0, Epoch 35/170 => Loss 0.485, Train_accy 78.020, Test_accy 73.900
2022-05-24 22:03:02,314 [bic.py] => training => Task 0, Epoch 36/170 => Loss 0.429, Train_accy 83.120, Test_accy 77.100
2022-05-24 22:03:06,747 [bic.py] => training => Task 0, Epoch 37/170 => Loss 0.421, Train_accy 75.320, Test_accy 72.600
2022-05-24 22:03:10,775 [bic.py] => training => Task 0, Epoch 38/170 => Loss 0.544, Train_accy 80.900, Test_accy 77.300
2022-05-24 22:03:14,947 [bic.py] => training => Task 0, Epoch 39/170 => Loss 0.405, Train_accy 81.980, Test_accy 77.700
2022-05-24 22:03:19,479 [bic.py] => training => Task 0, Epoch 40/170 => Loss 0.358, Train_accy 87.340, Test_accy 81.500
2022-05-24 22:03:23,466 [bic.py] => training => Task 0, Epoch 41/170 => Loss 0.468, Train_accy 80.900, Test_accy 73.200
2022-05-24 22:03:27,859 [bic.py] => training => Task 0, Epoch 42/170 => Loss 0.470, Train_accy 83.340, Test_accy 78.300
2022-05-24 22:03:32,237 [bic.py] => training => Task 0, Epoch 43/170 => Loss 0.359, Train_accy 85.560, Test_accy 79.800
2022-05-24 22:03:36,512 [bic.py] => training => Task 0, Epoch 44/170 => Loss 0.385, Train_accy 85.620, Test_accy 79.300
2022-05-24 22:03:40,741 [bic.py] => training => Task 0, Epoch 45/170 => Loss 0.323, Train_accy 88.020, Test_accy 82.500
2022-05-24 22:03:44,787 [bic.py] => training => Task 0, Epoch 46/170 => Loss 0.308, Train_accy 86.840, Test_accy 79.400
2022-05-24 22:03:49,139 [bic.py] => training => Task 0, Epoch 47/170 => Loss 0.372, Train_accy 83.380, Test_accy 78.000
2022-05-24 22:03:53,114 [bic.py] => training => Task 0, Epoch 48/170 => Loss 0.483, Train_accy 72.540, Test_accy 65.400
2022-05-24 22:03:56,955 [bic.py] => training => Task 0, Epoch 49/170 => Loss 0.480, Train_accy 87.880, Test_accy 80.700
2022-05-24 22:04:01,078 [bic.py] => training => Task 0, Epoch 50/170 => Loss 0.332, Train_accy 86.640, Test_accy 79.800
2022-05-24 22:04:05,011 [bic.py] => training => Task 0, Epoch 51/170 => Loss 0.301, Train_accy 89.020, Test_accy 80.600
2022-05-24 22:04:09,088 [bic.py] => training => Task 0, Epoch 52/170 => Loss 0.253, Train_accy 90.700, Test_accy 82.800
2022-05-24 22:04:12,905 [bic.py] => training => Task 0, Epoch 53/170 => Loss 0.304, Train_accy 86.360, Test_accy 76.800
2022-05-24 22:04:16,577 [bic.py] => training => Task 0, Epoch 54/170 => Loss 0.429, Train_accy 85.760, Test_accy 81.200
2022-05-24 22:04:20,614 [bic.py] => training => Task 0, Epoch 55/170 => Loss 0.359, Train_accy 89.160, Test_accy 81.900
2022-05-24 22:04:24,380 [bic.py] => training => Task 0, Epoch 56/170 => Loss 0.312, Train_accy 85.460, Test_accy 77.700
2022-05-24 22:04:28,445 [bic.py] => training => Task 0, Epoch 57/170 => Loss 0.277, Train_accy 86.580, Test_accy 78.500
2022-05-24 22:04:32,435 [bic.py] => training => Task 0, Epoch 58/170 => Loss 0.217, Train_accy 92.200, Test_accy 84.800
2022-05-24 22:04:36,401 [bic.py] => training => Task 0, Epoch 59/170 => Loss 0.220, Train_accy 90.400, Test_accy 81.800
2022-05-24 22:04:40,218 [bic.py] => training => Task 0, Epoch 60/170 => Loss 0.211, Train_accy 86.280, Test_accy 78.200
2022-05-24 22:04:43,987 [bic.py] => training => Task 0, Epoch 61/170 => Loss 0.160, Train_accy 96.760, Test_accy 86.500
2022-05-24 22:04:48,170 [bic.py] => training => Task 0, Epoch 62/170 => Loss 0.135, Train_accy 97.160, Test_accy 86.900
2022-05-24 22:04:52,032 [bic.py] => training => Task 0, Epoch 63/170 => Loss 0.112, Train_accy 96.980, Test_accy 87.000
2022-05-24 22:04:56,253 [bic.py] => training => Task 0, Epoch 64/170 => Loss 0.105, Train_accy 97.560, Test_accy 87.000
2022-05-24 22:05:00,410 [bic.py] => training => Task 0, Epoch 65/170 => Loss 0.106, Train_accy 97.660, Test_accy 86.900
2022-05-24 22:05:04,679 [bic.py] => training => Task 0, Epoch 66/170 => Loss 0.094, Train_accy 97.960, Test_accy 87.000
2022-05-24 22:05:08,652 [bic.py] => training => Task 0, Epoch 67/170 => Loss 0.089, Train_accy 97.640, Test_accy 87.500
2022-05-24 22:05:12,911 [bic.py] => training => Task 0, Epoch 68/170 => Loss 0.092, Train_accy 97.940, Test_accy 86.600
2022-05-24 22:05:16,719 [bic.py] => training => Task 0, Epoch 69/170 => Loss 0.082, Train_accy 98.260, Test_accy 86.600
2022-05-24 22:05:20,822 [bic.py] => training => Task 0, Epoch 70/170 => Loss 0.091, Train_accy 98.040, Test_accy 86.900
2022-05-24 22:05:24,662 [bic.py] => training => Task 0, Epoch 71/170 => Loss 0.082, Train_accy 98.060, Test_accy 86.200
2022-05-24 22:05:28,662 [bic.py] => training => Task 0, Epoch 72/170 => Loss 0.090, Train_accy 98.320, Test_accy 87.200
2022-05-24 22:05:32,647 [bic.py] => training => Task 0, Epoch 73/170 => Loss 0.094, Train_accy 97.780, Test_accy 86.700
2022-05-24 22:05:36,548 [bic.py] => training => Task 0, Epoch 74/170 => Loss 0.097, Train_accy 98.280, Test_accy 86.900
2022-05-24 22:05:40,685 [bic.py] => training => Task 0, Epoch 75/170 => Loss 0.090, Train_accy 98.120, Test_accy 86.800
2022-05-24 22:05:44,579 [bic.py] => training => Task 0, Epoch 76/170 => Loss 0.076, Train_accy 98.560, Test_accy 86.900
2022-05-24 22:05:48,678 [bic.py] => training => Task 0, Epoch 77/170 => Loss 0.068, Train_accy 98.560, Test_accy 86.700
2022-05-24 22:05:52,568 [bic.py] => training => Task 0, Epoch 78/170 => Loss 0.061, Train_accy 98.800, Test_accy 86.700
2022-05-24 22:05:56,749 [bic.py] => training => Task 0, Epoch 79/170 => Loss 0.066, Train_accy 98.780, Test_accy 86.700
2022-05-24 22:06:00,539 [bic.py] => training => Task 0, Epoch 80/170 => Loss 0.066, Train_accy 98.800, Test_accy 87.300
2022-05-24 22:06:04,546 [bic.py] => training => Task 0, Epoch 81/170 => Loss 0.079, Train_accy 98.500, Test_accy 87.600
2022-05-24 22:06:08,678 [bic.py] => training => Task 0, Epoch 82/170 => Loss 0.073, Train_accy 98.680, Test_accy 87.000
2022-05-24 22:06:12,790 [bic.py] => training => Task 0, Epoch 83/170 => Loss 0.067, Train_accy 98.580, Test_accy 87.200
2022-05-24 22:06:16,769 [bic.py] => training => Task 0, Epoch 84/170 => Loss 0.056, Train_accy 98.900, Test_accy 86.800
2022-05-24 22:06:20,739 [bic.py] => training => Task 0, Epoch 85/170 => Loss 0.055, Train_accy 98.980, Test_accy 87.600
2022-05-24 22:06:24,720 [bic.py] => training => Task 0, Epoch 86/170 => Loss 0.047, Train_accy 98.960, Test_accy 87.300
2022-05-24 22:06:28,685 [bic.py] => training => Task 0, Epoch 87/170 => Loss 0.067, Train_accy 99.140, Test_accy 87.200
2022-05-24 22:06:32,748 [bic.py] => training => Task 0, Epoch 88/170 => Loss 0.060, Train_accy 98.780, Test_accy 87.100
2022-05-24 22:06:36,812 [bic.py] => training => Task 0, Epoch 89/170 => Loss 0.060, Train_accy 98.840, Test_accy 87.100
2022-05-24 22:06:41,131 [bic.py] => training => Task 0, Epoch 90/170 => Loss 0.073, Train_accy 98.780, Test_accy 87.000
2022-05-24 22:06:45,035 [bic.py] => training => Task 0, Epoch 91/170 => Loss 0.055, Train_accy 98.980, Test_accy 86.700
2022-05-24 22:06:49,127 [bic.py] => training => Task 0, Epoch 92/170 => Loss 0.054, Train_accy 99.060, Test_accy 87.200
2022-05-24 22:06:52,906 [bic.py] => training => Task 0, Epoch 93/170 => Loss 0.066, Train_accy 99.120, Test_accy 87.400
2022-05-24 22:06:56,935 [bic.py] => training => Task 0, Epoch 94/170 => Loss 0.069, Train_accy 99.100, Test_accy 87.200
2022-05-24 22:07:00,868 [bic.py] => training => Task 0, Epoch 95/170 => Loss 0.068, Train_accy 99.220, Test_accy 87.100
2022-05-24 22:07:05,057 [bic.py] => training => Task 0, Epoch 96/170 => Loss 0.055, Train_accy 99.060, Test_accy 87.400
2022-05-24 22:07:08,942 [bic.py] => training => Task 0, Epoch 97/170 => Loss 0.050, Train_accy 99.140, Test_accy 87.300
2022-05-24 22:07:13,037 [bic.py] => training => Task 0, Epoch 98/170 => Loss 0.049, Train_accy 99.360, Test_accy 87.600
2022-05-24 22:07:17,313 [bic.py] => training => Task 0, Epoch 99/170 => Loss 0.045, Train_accy 99.360, Test_accy 87.000
2022-05-24 22:07:21,363 [bic.py] => training => Task 0, Epoch 100/170 => Loss 0.052, Train_accy 99.060, Test_accy 87.100
2022-05-24 22:07:25,232 [bic.py] => training => Task 0, Epoch 101/170 => Loss 0.037, Train_accy 99.360, Test_accy 87.300
2022-05-24 22:07:29,150 [bic.py] => training => Task 0, Epoch 102/170 => Loss 0.071, Train_accy 99.300, Test_accy 87.000
2022-05-24 22:07:33,131 [bic.py] => training => Task 0, Epoch 103/170 => Loss 0.042, Train_accy 99.140, Test_accy 88.100
2022-05-24 22:07:36,942 [bic.py] => training => Task 0, Epoch 104/170 => Loss 0.036, Train_accy 99.280, Test_accy 86.800
2022-05-24 22:07:41,128 [bic.py] => training => Task 0, Epoch 105/170 => Loss 0.037, Train_accy 99.300, Test_accy 87.200
2022-05-24 22:07:45,292 [bic.py] => training => Task 0, Epoch 106/170 => Loss 0.036, Train_accy 99.500, Test_accy 87.400
2022-05-24 22:07:49,571 [bic.py] => training => Task 0, Epoch 107/170 => Loss 0.036, Train_accy 99.420, Test_accy 87.100
2022-05-24 22:07:53,354 [bic.py] => training => Task 0, Epoch 108/170 => Loss 0.035, Train_accy 99.320, Test_accy 86.900
2022-05-24 22:07:57,286 [bic.py] => training => Task 0, Epoch 109/170 => Loss 0.044, Train_accy 99.360, Test_accy 87.000
2022-05-24 22:08:01,060 [bic.py] => training => Task 0, Epoch 110/170 => Loss 0.034, Train_accy 99.340, Test_accy 87.100
2022-05-24 22:08:05,120 [bic.py] => training => Task 0, Epoch 111/170 => Loss 0.043, Train_accy 99.400, Test_accy 87.200
2022-05-24 22:08:09,163 [bic.py] => training => Task 0, Epoch 112/170 => Loss 0.045, Train_accy 99.360, Test_accy 86.800
2022-05-24 22:08:13,114 [bic.py] => training => Task 0, Epoch 113/170 => Loss 0.033, Train_accy 99.460, Test_accy 87.500
2022-05-24 22:08:17,205 [bic.py] => training => Task 0, Epoch 114/170 => Loss 0.042, Train_accy 99.420, Test_accy 87.500
2022-05-24 22:08:20,999 [bic.py] => training => Task 0, Epoch 115/170 => Loss 0.049, Train_accy 99.540, Test_accy 87.600
2022-05-24 22:08:25,226 [bic.py] => training => Task 0, Epoch 116/170 => Loss 0.045, Train_accy 99.420, Test_accy 87.100
2022-05-24 22:08:29,098 [bic.py] => training => Task 0, Epoch 117/170 => Loss 0.036, Train_accy 99.400, Test_accy 87.400
2022-05-24 22:08:33,455 [bic.py] => training => Task 0, Epoch 118/170 => Loss 0.036, Train_accy 99.460, Test_accy 87.500
2022-05-24 22:08:37,357 [bic.py] => training => Task 0, Epoch 119/170 => Loss 0.045, Train_accy 99.440, Test_accy 87.100
2022-05-24 22:08:41,499 [bic.py] => training => Task 0, Epoch 120/170 => Loss 0.036, Train_accy 99.280, Test_accy 86.900
2022-05-24 22:08:45,383 [bic.py] => training => Task 0, Epoch 121/170 => Loss 0.041, Train_accy 99.380, Test_accy 88.000
2022-05-24 22:08:49,654 [bic.py] => training => Task 0, Epoch 122/170 => Loss 0.038, Train_accy 99.380, Test_accy 87.400
2022-05-24 22:08:53,747 [bic.py] => training => Task 0, Epoch 123/170 => Loss 0.029, Train_accy 99.260, Test_accy 87.500
2022-05-24 22:08:57,960 [bic.py] => training => Task 0, Epoch 124/170 => Loss 0.034, Train_accy 99.500, Test_accy 87.300
2022-05-24 22:09:01,774 [bic.py] => training => Task 0, Epoch 125/170 => Loss 0.040, Train_accy 99.320, Test_accy 87.200
2022-05-24 22:09:05,754 [bic.py] => training => Task 0, Epoch 126/170 => Loss 0.046, Train_accy 99.400, Test_accy 87.300
2022-05-24 22:09:09,646 [bic.py] => training => Task 0, Epoch 127/170 => Loss 0.042, Train_accy 99.260, Test_accy 86.700
2022-05-24 22:09:13,560 [bic.py] => training => Task 0, Epoch 128/170 => Loss 0.039, Train_accy 99.480, Test_accy 88.000
2022-05-24 22:09:17,647 [bic.py] => training => Task 0, Epoch 129/170 => Loss 0.036, Train_accy 99.360, Test_accy 88.000
2022-05-24 22:09:21,621 [bic.py] => training => Task 0, Epoch 130/170 => Loss 0.048, Train_accy 99.500, Test_accy 87.200
2022-05-24 22:09:25,689 [bic.py] => training => Task 0, Epoch 131/170 => Loss 0.036, Train_accy 99.480, Test_accy 87.900
2022-05-24 22:09:29,635 [bic.py] => training => Task 0, Epoch 132/170 => Loss 0.034, Train_accy 99.500, Test_accy 87.400
2022-05-24 22:09:34,044 [bic.py] => training => Task 0, Epoch 133/170 => Loss 0.053, Train_accy 99.540, Test_accy 87.400
2022-05-24 22:09:37,917 [bic.py] => training => Task 0, Epoch 134/170 => Loss 0.034, Train_accy 99.560, Test_accy 87.200
2022-05-24 22:09:42,018 [bic.py] => training => Task 0, Epoch 135/170 => Loss 0.033, Train_accy 99.660, Test_accy 87.300
2022-05-24 22:09:45,864 [bic.py] => training => Task 0, Epoch 136/170 => Loss 0.045, Train_accy 99.440, Test_accy 88.200
2022-05-24 22:09:50,069 [bic.py] => training => Task 0, Epoch 137/170 => Loss 0.031, Train_accy 99.620, Test_accy 87.800
2022-05-24 22:09:53,964 [bic.py] => training => Task 0, Epoch 138/170 => Loss 0.028, Train_accy 99.440, Test_accy 87.700
2022-05-24 22:09:58,284 [bic.py] => training => Task 0, Epoch 139/170 => Loss 0.033, Train_accy 99.480, Test_accy 87.200
2022-05-24 22:10:02,353 [bic.py] => training => Task 0, Epoch 140/170 => Loss 0.042, Train_accy 99.780, Test_accy 87.900
2022-05-24 22:10:06,541 [bic.py] => training => Task 0, Epoch 141/170 => Loss 0.056, Train_accy 99.420, Test_accy 87.400
2022-05-24 22:10:10,519 [bic.py] => training => Task 0, Epoch 142/170 => Loss 0.029, Train_accy 99.560, Test_accy 87.500
2022-05-24 22:10:14,414 [bic.py] => training => Task 0, Epoch 143/170 => Loss 0.049, Train_accy 99.520, Test_accy 87.700
2022-05-24 22:10:18,238 [bic.py] => training => Task 0, Epoch 144/170 => Loss 0.033, Train_accy 99.520, Test_accy 88.000
2022-05-24 22:10:22,138 [bic.py] => training => Task 0, Epoch 145/170 => Loss 0.034, Train_accy 99.480, Test_accy 87.300
2022-05-24 22:10:26,261 [bic.py] => training => Task 0, Epoch 146/170 => Loss 0.034, Train_accy 99.400, Test_accy 87.400
2022-05-24 22:10:30,364 [bic.py] => training => Task 0, Epoch 147/170 => Loss 0.033, Train_accy 99.480, Test_accy 87.000
2022-05-24 22:10:34,523 [bic.py] => training => Task 0, Epoch 148/170 => Loss 0.035, Train_accy 99.520, Test_accy 87.500
2022-05-24 22:10:38,271 [bic.py] => training => Task 0, Epoch 149/170 => Loss 0.040, Train_accy 99.560, Test_accy 87.500
2022-05-24 22:10:42,523 [bic.py] => training => Task 0, Epoch 150/170 => Loss 0.033, Train_accy 99.260, Test_accy 88.100
2022-05-24 22:10:46,415 [bic.py] => training => Task 0, Epoch 151/170 => Loss 0.034, Train_accy 99.700, Test_accy 88.000
2022-05-24 22:10:50,519 [bic.py] => training => Task 0, Epoch 152/170 => Loss 0.036, Train_accy 99.520, Test_accy 88.000
2022-05-24 22:10:54,326 [bic.py] => training => Task 0, Epoch 153/170 => Loss 0.048, Train_accy 99.620, Test_accy 87.800
2022-05-24 22:10:58,152 [bic.py] => training => Task 0, Epoch 154/170 => Loss 0.030, Train_accy 99.600, Test_accy 87.900
2022-05-24 22:11:02,093 [bic.py] => training => Task 0, Epoch 155/170 => Loss 0.031, Train_accy 99.500, Test_accy 88.000
2022-05-24 22:11:05,892 [bic.py] => training => Task 0, Epoch 156/170 => Loss 0.031, Train_accy 99.540, Test_accy 87.400
2022-05-24 22:11:09,663 [bic.py] => training => Task 0, Epoch 157/170 => Loss 0.030, Train_accy 99.600, Test_accy 87.700
2022-05-24 22:11:13,582 [bic.py] => training => Task 0, Epoch 158/170 => Loss 0.030, Train_accy 99.300, Test_accy 87.600
2022-05-24 22:11:17,451 [bic.py] => training => Task 0, Epoch 159/170 => Loss 0.028, Train_accy 99.520, Test_accy 87.300
2022-05-24 22:11:21,281 [bic.py] => training => Task 0, Epoch 160/170 => Loss 0.058, Train_accy 99.540, Test_accy 88.100
2022-05-24 22:11:25,173 [bic.py] => training => Task 0, Epoch 161/170 => Loss 0.049, Train_accy 99.560, Test_accy 87.700
2022-05-24 22:11:29,043 [bic.py] => training => Task 0, Epoch 162/170 => Loss 0.032, Train_accy 99.600, Test_accy 88.000
2022-05-24 22:11:32,899 [bic.py] => training => Task 0, Epoch 163/170 => Loss 0.058, Train_accy 99.460, Test_accy 87.500
2022-05-24 22:11:36,657 [bic.py] => training => Task 0, Epoch 164/170 => Loss 0.057, Train_accy 99.560, Test_accy 87.000
2022-05-24 22:11:40,528 [bic.py] => training => Task 0, Epoch 165/170 => Loss 0.064, Train_accy 99.420, Test_accy 87.000
2022-05-24 22:11:44,188 [bic.py] => training => Task 0, Epoch 166/170 => Loss 0.030, Train_accy 99.520, Test_accy 87.300
2022-05-24 22:11:48,102 [bic.py] => training => Task 0, Epoch 167/170 => Loss 0.034, Train_accy 99.660, Test_accy 87.000
2022-05-24 22:11:51,861 [bic.py] => training => Task 0, Epoch 168/170 => Loss 0.042, Train_accy 99.360, Test_accy 88.000
2022-05-24 22:11:55,662 [bic.py] => training => Task 0, Epoch 169/170 => Loss 0.048, Train_accy 99.700, Test_accy 87.500
2022-05-24 22:11:59,482 [bic.py] => training => Task 0, Epoch 170/170 => Loss 0.031, Train_accy 99.600, Test_accy 87.500
2022-05-24 22:11:59,483 [base.py] => Reducing exemplars...(200 per classes)
2022-05-24 22:11:59,483 [base.py] => Constructing exemplars...(200 per classes)
2022-05-24 22:12:05,968 [bic.py] => Parameters of bias layer:
2022-05-24 22:12:05,968 [bic.py] => 0 => 1.000, 0.000
2022-05-24 22:12:07,000 [bic.py] => Exemplar size: 2000
2022-05-24 22:12:07,000 [trainer.py] => CNN: {'total': 87.5, '00-09': 87.5, 'old': 0, 'new': 87.5}
2022-05-24 22:12:07,000 [trainer.py] => NME: {'total': 88.1, '00-09': 88.1, 'old': 0, 'new': 88.1}
2022-05-24 22:12:07,001 [trainer.py] => CNN top1 curve: [87.5]
2022-05-24 22:12:07,001 [trainer.py] => CNN top5 curve: [99.3]
2022-05-24 22:12:07,001 [trainer.py] => NME top1 curve: [88.1]
2022-05-24 22:12:07,001 [trainer.py] => NME top5 curve: [99.4]

2022-05-24 22:12:07,001 [trainer.py] => All params: 464806
2022-05-24 22:12:07,002 [trainer.py] => Trainable params: 464806
2022-05-24 22:12:07,003 [bic.py] => Learning on 10-20
2022-05-24 22:12:07,067 [bic.py] => Stage1 dset: 6600, Stage2 dset: 400
2022-05-24 22:12:07,067 [bic.py] => Lambda: 0.500
2022-05-24 22:12:07,071 [bic.py] => Parameters of bias layer:
2022-05-24 22:12:07,072 [bic.py] => 0 => 1.000, 0.000
2022-05-24 22:12:07,072 [bic.py] => 1 => 1.000, 0.000
2022-05-24 22:12:12,355 [bic.py] => training => Task 1, Epoch 1/170 => Loss 1.643, Train_accy 49.170, Test_accy 50.450
2022-05-24 22:12:17,518 [bic.py] => training => Task 1, Epoch 2/170 => Loss 1.186, Train_accy 57.020, Test_accy 56.650
2022-05-24 22:12:22,601 [bic.py] => training => Task 1, Epoch 3/170 => Loss 1.109, Train_accy 62.390, Test_accy 58.250
2022-05-24 22:12:28,038 [bic.py] => training => Task 1, Epoch 4/170 => Loss 1.055, Train_accy 64.880, Test_accy 60.450
2022-05-24 22:12:33,364 [bic.py] => training => Task 1, Epoch 5/170 => Loss 1.020, Train_accy 65.080, Test_accy 60.000
2022-05-24 22:12:38,435 [bic.py] => training => Task 1, Epoch 6/170 => Loss 0.989, Train_accy 68.480, Test_accy 62.000
2022-05-24 22:12:43,588 [bic.py] => training => Task 1, Epoch 7/170 => Loss 0.973, Train_accy 70.350, Test_accy 63.250
2022-05-24 22:12:48,915 [bic.py] => training => Task 1, Epoch 8/170 => Loss 0.947, Train_accy 71.060, Test_accy 63.800
2022-05-24 22:12:54,173 [bic.py] => training => Task 1, Epoch 9/170 => Loss 0.928, Train_accy 71.560, Test_accy 63.400
2022-05-24 22:12:59,542 [bic.py] => training => Task 1, Epoch 10/170 => Loss 0.906, Train_accy 74.390, Test_accy 64.650
2022-05-24 22:13:04,848 [bic.py] => training => Task 1, Epoch 11/170 => Loss 0.897, Train_accy 70.740, Test_accy 61.850
2022-05-24 22:13:10,156 [bic.py] => training => Task 1, Epoch 12/170 => Loss 0.877, Train_accy 70.700, Test_accy 61.800
2022-05-24 22:13:15,402 [bic.py] => training => Task 1, Epoch 13/170 => Loss 0.879, Train_accy 73.320, Test_accy 63.400
2022-05-24 22:13:20,653 [bic.py] => training => Task 1, Epoch 14/170 => Loss 0.856, Train_accy 75.300, Test_accy 64.600
2022-05-24 22:13:26,181 [bic.py] => training => Task 1, Epoch 15/170 => Loss 0.842, Train_accy 72.410, Test_accy 60.550
2022-05-24 22:13:31,415 [bic.py] => training => Task 1, Epoch 16/170 => Loss 0.820, Train_accy 74.650, Test_accy 63.400
2022-05-24 22:13:36,940 [bic.py] => training => Task 1, Epoch 17/170 => Loss 0.829, Train_accy 77.640, Test_accy 61.800
2022-05-24 22:13:42,034 [bic.py] => training => Task 1, Epoch 18/170 => Loss 0.811, Train_accy 79.080, Test_accy 64.800
2022-05-24 22:13:47,249 [bic.py] => training => Task 1, Epoch 19/170 => Loss 0.813, Train_accy 79.470, Test_accy 66.000
2022-05-24 22:13:52,826 [bic.py] => training => Task 1, Epoch 20/170 => Loss 0.788, Train_accy 81.090, Test_accy 67.200
2022-05-24 22:13:58,104 [bic.py] => training => Task 1, Epoch 21/170 => Loss 0.777, Train_accy 80.180, Test_accy 64.750
2022-05-24 22:14:03,221 [bic.py] => training => Task 1, Epoch 22/170 => Loss 0.787, Train_accy 80.000, Test_accy 65.800
2022-05-24 22:14:08,733 [bic.py] => training => Task 1, Epoch 23/170 => Loss 0.762, Train_accy 78.620, Test_accy 64.500
2022-05-24 22:14:13,882 [bic.py] => training => Task 1, Epoch 24/170 => Loss 0.780, Train_accy 83.110, Test_accy 65.700
2022-05-24 22:14:18,970 [bic.py] => training => Task 1, Epoch 25/170 => Loss 0.760, Train_accy 77.800, Test_accy 63.150
2022-05-24 22:14:24,563 [bic.py] => training => Task 1, Epoch 26/170 => Loss 0.738, Train_accy 84.500, Test_accy 68.800
2022-05-24 22:14:29,695 [bic.py] => training => Task 1, Epoch 27/170 => Loss 0.736, Train_accy 82.980, Test_accy 66.200
2022-05-24 22:14:34,918 [bic.py] => training => Task 1, Epoch 28/170 => Loss 0.738, Train_accy 77.560, Test_accy 62.500
2022-05-24 22:14:40,137 [bic.py] => training => Task 1, Epoch 29/170 => Loss 0.737, Train_accy 80.710, Test_accy 64.200
2022-05-24 22:14:45,583 [bic.py] => training => Task 1, Epoch 30/170 => Loss 0.734, Train_accy 84.650, Test_accy 67.900
2022-05-24 22:14:50,785 [bic.py] => training => Task 1, Epoch 31/170 => Loss 0.730, Train_accy 79.920, Test_accy 60.950
2022-05-24 22:14:56,109 [bic.py] => training => Task 1, Epoch 32/170 => Loss 0.706, Train_accy 84.050, Test_accy 66.850
2022-05-24 22:15:01,380 [bic.py] => training => Task 1, Epoch 33/170 => Loss 0.713, Train_accy 87.170, Test_accy 68.900
2022-05-24 22:15:06,564 [bic.py] => training => Task 1, Epoch 34/170 => Loss 0.710, Train_accy 84.590, Test_accy 66.950
2022-05-24 22:15:11,837 [bic.py] => training => Task 1, Epoch 35/170 => Loss 0.692, Train_accy 87.700, Test_accy 68.950
2022-05-24 22:15:17,349 [bic.py] => training => Task 1, Epoch 36/170 => Loss 0.700, Train_accy 84.640, Test_accy 67.700
2022-05-24 22:15:22,551 [bic.py] => training => Task 1, Epoch 37/170 => Loss 0.695, Train_accy 88.180, Test_accy 68.200
2022-05-24 22:15:27,786 [bic.py] => training => Task 1, Epoch 38/170 => Loss 0.677, Train_accy 85.200, Test_accy 66.900
2022-05-24 22:15:32,962 [bic.py] => training => Task 1, Epoch 39/170 => Loss 0.689, Train_accy 80.140, Test_accy 62.400
2022-05-24 22:15:38,456 [bic.py] => training => Task 1, Epoch 40/170 => Loss 0.691, Train_accy 88.790, Test_accy 67.800
2022-05-24 22:15:43,589 [bic.py] => training => Task 1, Epoch 41/170 => Loss 0.681, Train_accy 85.440, Test_accy 64.950
2022-05-24 22:15:48,844 [bic.py] => training => Task 1, Epoch 42/170 => Loss 0.667, Train_accy 86.470, Test_accy 66.200
2022-05-24 22:15:54,226 [bic.py] => training => Task 1, Epoch 43/170 => Loss 0.678, Train_accy 86.680, Test_accy 64.650
2022-05-24 22:15:59,462 [bic.py] => training => Task 1, Epoch 44/170 => Loss 0.674, Train_accy 84.180, Test_accy 65.050
2022-05-24 22:16:04,533 [bic.py] => training => Task 1, Epoch 45/170 => Loss 0.673, Train_accy 83.200, Test_accy 66.150
2022-05-24 22:16:09,865 [bic.py] => training => Task 1, Epoch 46/170 => Loss 0.662, Train_accy 88.230, Test_accy 68.300
2022-05-24 22:16:15,116 [bic.py] => training => Task 1, Epoch 47/170 => Loss 0.643, Train_accy 86.200, Test_accy 67.850
2022-05-24 22:16:20,411 [bic.py] => training => Task 1, Epoch 48/170 => Loss 0.646, Train_accy 88.330, Test_accy 66.500
2022-05-24 22:16:25,699 [bic.py] => training => Task 1, Epoch 49/170 => Loss 0.650, Train_accy 84.620, Test_accy 64.750
2022-05-24 22:16:31,101 [bic.py] => training => Task 1, Epoch 50/170 => Loss 0.636, Train_accy 85.060, Test_accy 66.300
2022-05-24 22:16:36,491 [bic.py] => training => Task 1, Epoch 51/170 => Loss 0.635, Train_accy 90.210, Test_accy 69.700
2022-05-24 22:16:41,726 [bic.py] => training => Task 1, Epoch 52/170 => Loss 0.643, Train_accy 84.560, Test_accy 66.700
2022-05-24 22:16:47,134 [bic.py] => training => Task 1, Epoch 53/170 => Loss 0.645, Train_accy 81.650, Test_accy 63.300
2022-05-24 22:16:52,397 [bic.py] => training => Task 1, Epoch 54/170 => Loss 0.632, Train_accy 91.860, Test_accy 67.750
2022-05-24 22:16:57,690 [bic.py] => training => Task 1, Epoch 55/170 => Loss 0.631, Train_accy 91.260, Test_accy 69.750
2022-05-24 22:17:03,071 [bic.py] => training => Task 1, Epoch 56/170 => Loss 0.627, Train_accy 89.230, Test_accy 68.000
2022-05-24 22:17:08,338 [bic.py] => training => Task 1, Epoch 57/170 => Loss 0.627, Train_accy 88.820, Test_accy 67.750
2022-05-24 22:17:13,705 [bic.py] => training => Task 1, Epoch 58/170 => Loss 0.630, Train_accy 87.620, Test_accy 68.100
2022-05-24 22:17:19,042 [bic.py] => training => Task 1, Epoch 59/170 => Loss 0.641, Train_accy 87.560, Test_accy 66.200
2022-05-24 22:17:24,338 [bic.py] => training => Task 1, Epoch 60/170 => Loss 0.637, Train_accy 87.730, Test_accy 65.000
2022-05-24 22:17:29,602 [bic.py] => training => Task 1, Epoch 61/170 => Loss 0.581, Train_accy 98.210, Test_accy 73.800
2022-05-24 22:17:34,922 [bic.py] => training => Task 1, Epoch 62/170 => Loss 0.547, Train_accy 98.860, Test_accy 74.300
2022-05-24 22:17:40,225 [bic.py] => training => Task 1, Epoch 63/170 => Loss 0.538, Train_accy 99.030, Test_accy 74.200
2022-05-24 22:17:45,520 [bic.py] => training => Task 1, Epoch 64/170 => Loss 0.535, Train_accy 99.150, Test_accy 74.600
2022-05-24 22:17:50,940 [bic.py] => training => Task 1, Epoch 65/170 => Loss 0.526, Train_accy 99.270, Test_accy 74.600
2022-05-24 22:17:56,207 [bic.py] => training => Task 1, Epoch 66/170 => Loss 0.525, Train_accy 99.350, Test_accy 74.900
2022-05-24 22:18:01,480 [bic.py] => training => Task 1, Epoch 67/170 => Loss 0.527, Train_accy 99.380, Test_accy 74.100
2022-05-24 22:18:06,934 [bic.py] => training => Task 1, Epoch 68/170 => Loss 0.522, Train_accy 99.580, Test_accy 74.600
2022-05-24 22:18:12,304 [bic.py] => training => Task 1, Epoch 69/170 => Loss 0.517, Train_accy 99.560, Test_accy 74.750
2022-05-24 22:18:17,540 [bic.py] => training => Task 1, Epoch 70/170 => Loss 0.520, Train_accy 99.550, Test_accy 74.850
2022-05-24 22:18:22,951 [bic.py] => training => Task 1, Epoch 71/170 => Loss 0.516, Train_accy 99.670, Test_accy 75.250
2022-05-24 22:18:28,153 [bic.py] => training => Task 1, Epoch 72/170 => Loss 0.519, Train_accy 99.530, Test_accy 74.700
2022-05-24 22:18:33,265 [bic.py] => training => Task 1, Epoch 73/170 => Loss 0.517, Train_accy 99.700, Test_accy 75.300
2022-05-24 22:18:38,668 [bic.py] => training => Task 1, Epoch 74/170 => Loss 0.515, Train_accy 99.710, Test_accy 74.900
2022-05-24 22:18:43,746 [bic.py] => training => Task 1, Epoch 75/170 => Loss 0.512, Train_accy 99.610, Test_accy 75.250
2022-05-24 22:18:49,198 [bic.py] => training => Task 1, Epoch 76/170 => Loss 0.511, Train_accy 99.740, Test_accy 75.600
2022-05-24 22:18:54,639 [bic.py] => training => Task 1, Epoch 77/170 => Loss 0.515, Train_accy 99.710, Test_accy 75.250
2022-05-24 22:18:59,783 [bic.py] => training => Task 1, Epoch 78/170 => Loss 0.515, Train_accy 99.670, Test_accy 75.450
2022-05-24 22:19:05,114 [bic.py] => training => Task 1, Epoch 79/170 => Loss 0.509, Train_accy 99.730, Test_accy 75.450
2022-05-24 22:19:10,562 [bic.py] => training => Task 1, Epoch 80/170 => Loss 0.514, Train_accy 99.790, Test_accy 75.650
2022-05-24 22:19:15,915 [bic.py] => training => Task 1, Epoch 81/170 => Loss 0.509, Train_accy 99.680, Test_accy 75.850
2022-05-24 22:19:21,185 [bic.py] => training => Task 1, Epoch 82/170 => Loss 0.509, Train_accy 99.680, Test_accy 75.100
2022-05-24 22:19:26,534 [bic.py] => training => Task 1, Epoch 83/170 => Loss 0.508, Train_accy 99.730, Test_accy 75.300
2022-05-24 22:19:31,721 [bic.py] => training => Task 1, Epoch 84/170 => Loss 0.511, Train_accy 99.800, Test_accy 75.200
2022-05-24 22:19:36,931 [bic.py] => training => Task 1, Epoch 85/170 => Loss 0.509, Train_accy 99.770, Test_accy 75.500
2022-05-24 22:19:42,047 [bic.py] => training => Task 1, Epoch 86/170 => Loss 0.509, Train_accy 99.700, Test_accy 75.500
2022-05-24 22:19:47,515 [bic.py] => training => Task 1, Epoch 87/170 => Loss 0.504, Train_accy 99.830, Test_accy 75.650
2022-05-24 22:19:52,766 [bic.py] => training => Task 1, Epoch 88/170 => Loss 0.506, Train_accy 99.740, Test_accy 75.950
2022-05-24 22:19:58,071 [bic.py] => training => Task 1, Epoch 89/170 => Loss 0.505, Train_accy 99.800, Test_accy 75.750
2022-05-24 22:20:03,349 [bic.py] => training => Task 1, Epoch 90/170 => Loss 0.505, Train_accy 99.770, Test_accy 75.850
2022-05-24 22:20:08,684 [bic.py] => training => Task 1, Epoch 91/170 => Loss 0.503, Train_accy 99.760, Test_accy 75.050
2022-05-24 22:20:14,017 [bic.py] => training => Task 1, Epoch 92/170 => Loss 0.505, Train_accy 99.770, Test_accy 75.250
2022-05-24 22:20:19,368 [bic.py] => training => Task 1, Epoch 93/170 => Loss 0.504, Train_accy 99.800, Test_accy 75.200
2022-05-24 22:20:24,459 [bic.py] => training => Task 1, Epoch 94/170 => Loss 0.503, Train_accy 99.850, Test_accy 75.300
2022-05-24 22:20:29,954 [bic.py] => training => Task 1, Epoch 95/170 => Loss 0.503, Train_accy 99.800, Test_accy 75.950
2022-05-24 22:20:35,425 [bic.py] => training => Task 1, Epoch 96/170 => Loss 0.502, Train_accy 99.860, Test_accy 75.450
2022-05-24 22:20:40,555 [bic.py] => training => Task 1, Epoch 97/170 => Loss 0.500, Train_accy 99.890, Test_accy 76.100
2022-05-24 22:20:45,851 [bic.py] => training => Task 1, Epoch 98/170 => Loss 0.503, Train_accy 99.770, Test_accy 75.800
2022-05-24 22:20:51,370 [bic.py] => training => Task 1, Epoch 99/170 => Loss 0.500, Train_accy 99.850, Test_accy 75.650
2022-05-24 22:20:56,617 [bic.py] => training => Task 1, Epoch 100/170 => Loss 0.499, Train_accy 99.820, Test_accy 75.400
2022-05-24 22:21:01,970 [bic.py] => training => Task 1, Epoch 101/170 => Loss 0.496, Train_accy 99.920, Test_accy 75.250
2022-05-24 22:21:07,386 [bic.py] => training => Task 1, Epoch 102/170 => Loss 0.500, Train_accy 99.850, Test_accy 75.550
2022-05-24 22:21:12,800 [bic.py] => training => Task 1, Epoch 103/170 => Loss 0.497, Train_accy 99.850, Test_accy 75.150
2022-05-24 22:21:17,911 [bic.py] => training => Task 1, Epoch 104/170 => Loss 0.500, Train_accy 99.820, Test_accy 75.450
2022-05-24 22:21:23,228 [bic.py] => training => Task 1, Epoch 105/170 => Loss 0.501, Train_accy 99.890, Test_accy 75.700
2022-05-24 22:21:28,542 [bic.py] => training => Task 1, Epoch 106/170 => Loss 0.499, Train_accy 99.820, Test_accy 75.350
2022-05-24 22:21:33,775 [bic.py] => training => Task 1, Epoch 107/170 => Loss 0.497, Train_accy 99.760, Test_accy 75.500
2022-05-24 22:21:39,208 [bic.py] => training => Task 1, Epoch 108/170 => Loss 0.497, Train_accy 99.910, Test_accy 75.700
2022-05-24 22:21:44,237 [bic.py] => training => Task 1, Epoch 109/170 => Loss 0.500, Train_accy 99.860, Test_accy 75.600
2022-05-24 22:21:49,368 [bic.py] => training => Task 1, Epoch 110/170 => Loss 0.499, Train_accy 99.800, Test_accy 75.700
2022-05-24 22:21:54,697 [bic.py] => training => Task 1, Epoch 111/170 => Loss 0.501, Train_accy 99.910, Test_accy 75.800
2022-05-24 22:21:59,975 [bic.py] => training => Task 1, Epoch 112/170 => Loss 0.501, Train_accy 99.880, Test_accy 75.750
2022-05-24 22:22:05,046 [bic.py] => training => Task 1, Epoch 113/170 => Loss 0.499, Train_accy 99.860, Test_accy 75.850
2022-05-24 22:22:10,257 [bic.py] => training => Task 1, Epoch 114/170 => Loss 0.497, Train_accy 99.850, Test_accy 75.700
2022-05-24 22:22:15,568 [bic.py] => training => Task 1, Epoch 115/170 => Loss 0.499, Train_accy 99.880, Test_accy 75.750
2022-05-24 22:22:20,797 [bic.py] => training => Task 1, Epoch 116/170 => Loss 0.497, Train_accy 99.820, Test_accy 75.550
2022-05-24 22:22:25,991 [bic.py] => training => Task 1, Epoch 117/170 => Loss 0.498, Train_accy 99.860, Test_accy 75.700
2022-05-24 22:22:31,528 [bic.py] => training => Task 1, Epoch 118/170 => Loss 0.498, Train_accy 99.770, Test_accy 75.700
2022-05-24 22:22:36,793 [bic.py] => training => Task 1, Epoch 119/170 => Loss 0.498, Train_accy 99.760, Test_accy 75.950
2022-05-24 22:22:42,393 [bic.py] => training => Task 1, Epoch 120/170 => Loss 0.499, Train_accy 99.880, Test_accy 75.650
2022-05-24 22:22:47,709 [bic.py] => training => Task 1, Epoch 121/170 => Loss 0.500, Train_accy 99.920, Test_accy 75.300
2022-05-24 22:22:52,927 [bic.py] => training => Task 1, Epoch 122/170 => Loss 0.498, Train_accy 99.890, Test_accy 75.650
2022-05-24 22:22:58,167 [bic.py] => training => Task 1, Epoch 123/170 => Loss 0.499, Train_accy 99.800, Test_accy 75.600
2022-05-24 22:23:03,346 [bic.py] => training => Task 1, Epoch 124/170 => Loss 0.499, Train_accy 99.850, Test_accy 75.750
2022-05-24 22:23:08,425 [bic.py] => training => Task 1, Epoch 125/170 => Loss 0.496, Train_accy 99.820, Test_accy 75.900
2022-05-24 22:23:13,701 [bic.py] => training => Task 1, Epoch 126/170 => Loss 0.502, Train_accy 99.920, Test_accy 75.650
2022-05-24 22:23:19,163 [bic.py] => training => Task 1, Epoch 127/170 => Loss 0.500, Train_accy 99.790, Test_accy 75.700
2022-05-24 22:23:24,494 [bic.py] => training => Task 1, Epoch 128/170 => Loss 0.498, Train_accy 99.880, Test_accy 75.650
2022-05-24 22:23:29,794 [bic.py] => training => Task 1, Epoch 129/170 => Loss 0.497, Train_accy 99.920, Test_accy 75.650
2022-05-24 22:23:35,085 [bic.py] => training => Task 1, Epoch 130/170 => Loss 0.498, Train_accy 99.820, Test_accy 75.950
2022-05-24 22:23:40,265 [bic.py] => training => Task 1, Epoch 131/170 => Loss 0.497, Train_accy 99.850, Test_accy 75.350
2022-05-24 22:23:45,566 [bic.py] => training => Task 1, Epoch 132/170 => Loss 0.500, Train_accy 99.880, Test_accy 75.850
2022-05-24 22:23:50,985 [bic.py] => training => Task 1, Epoch 133/170 => Loss 0.496, Train_accy 99.940, Test_accy 75.700
2022-05-24 22:23:56,235 [bic.py] => training => Task 1, Epoch 134/170 => Loss 0.498, Train_accy 99.950, Test_accy 75.600
2022-05-24 22:24:01,369 [bic.py] => training => Task 1, Epoch 135/170 => Loss 0.498, Train_accy 99.920, Test_accy 75.700
2022-05-24 22:24:06,818 [bic.py] => training => Task 1, Epoch 136/170 => Loss 0.498, Train_accy 99.920, Test_accy 75.700
2022-05-24 22:24:11,903 [bic.py] => training => Task 1, Epoch 137/170 => Loss 0.500, Train_accy 99.910, Test_accy 75.500
2022-05-24 22:24:17,095 [bic.py] => training => Task 1, Epoch 138/170 => Loss 0.495, Train_accy 99.850, Test_accy 75.700
2022-05-24 22:24:22,429 [bic.py] => training => Task 1, Epoch 139/170 => Loss 0.500, Train_accy 99.880, Test_accy 75.700
2022-05-24 22:24:27,774 [bic.py] => training => Task 1, Epoch 140/170 => Loss 0.498, Train_accy 99.910, Test_accy 75.650
2022-05-24 22:24:33,006 [bic.py] => training => Task 1, Epoch 141/170 => Loss 0.498, Train_accy 99.800, Test_accy 75.700
2022-05-24 22:24:38,465 [bic.py] => training => Task 1, Epoch 142/170 => Loss 0.497, Train_accy 99.910, Test_accy 75.550
2022-05-24 22:24:43,622 [bic.py] => training => Task 1, Epoch 143/170 => Loss 0.499, Train_accy 99.910, Test_accy 75.850
2022-05-24 22:24:48,754 [bic.py] => training => Task 1, Epoch 144/170 => Loss 0.498, Train_accy 99.830, Test_accy 75.700
2022-05-24 22:24:53,955 [bic.py] => training => Task 1, Epoch 145/170 => Loss 0.498, Train_accy 99.890, Test_accy 75.950
2022-05-24 22:24:59,517 [bic.py] => training => Task 1, Epoch 146/170 => Loss 0.497, Train_accy 99.860, Test_accy 75.800
2022-05-24 22:25:04,737 [bic.py] => training => Task 1, Epoch 147/170 => Loss 0.499, Train_accy 99.950, Test_accy 76.050
2022-05-24 22:25:09,919 [bic.py] => training => Task 1, Epoch 148/170 => Loss 0.500, Train_accy 99.890, Test_accy 75.850
2022-05-24 22:25:15,287 [bic.py] => training => Task 1, Epoch 149/170 => Loss 0.497, Train_accy 99.770, Test_accy 75.650
2022-05-24 22:25:20,424 [bic.py] => training => Task 1, Epoch 150/170 => Loss 0.493, Train_accy 99.790, Test_accy 75.900
2022-05-24 22:25:25,634 [bic.py] => training => Task 1, Epoch 151/170 => Loss 0.496, Train_accy 99.940, Test_accy 75.700
2022-05-24 22:25:30,963 [bic.py] => training => Task 1, Epoch 152/170 => Loss 0.495, Train_accy 99.920, Test_accy 75.400
2022-05-24 22:25:36,273 [bic.py] => training => Task 1, Epoch 153/170 => Loss 0.495, Train_accy 99.910, Test_accy 75.650
2022-05-24 22:25:41,440 [bic.py] => training => Task 1, Epoch 154/170 => Loss 0.495, Train_accy 99.890, Test_accy 75.750
2022-05-24 22:25:47,050 [bic.py] => training => Task 1, Epoch 155/170 => Loss 0.498, Train_accy 99.860, Test_accy 75.550
2022-05-24 22:25:52,255 [bic.py] => training => Task 1, Epoch 156/170 => Loss 0.496, Train_accy 99.970, Test_accy 75.950
2022-05-24 22:25:57,482 [bic.py] => training => Task 1, Epoch 157/170 => Loss 0.501, Train_accy 99.830, Test_accy 75.950
2022-05-24 22:26:02,796 [bic.py] => training => Task 1, Epoch 158/170 => Loss 0.497, Train_accy 99.890, Test_accy 75.450
2022-05-24 22:26:08,119 [bic.py] => training => Task 1, Epoch 159/170 => Loss 0.496, Train_accy 99.850, Test_accy 75.900
2022-05-24 22:26:13,311 [bic.py] => training => Task 1, Epoch 160/170 => Loss 0.497, Train_accy 99.830, Test_accy 75.900
2022-05-24 22:26:18,498 [bic.py] => training => Task 1, Epoch 161/170 => Loss 0.495, Train_accy 99.860, Test_accy 75.700
2022-05-24 22:26:23,884 [bic.py] => training => Task 1, Epoch 162/170 => Loss 0.501, Train_accy 99.880, Test_accy 75.750
2022-05-24 22:26:29,084 [bic.py] => training => Task 1, Epoch 163/170 => Loss 0.495, Train_accy 99.860, Test_accy 75.600
2022-05-24 22:26:34,333 [bic.py] => training => Task 1, Epoch 164/170 => Loss 0.499, Train_accy 99.860, Test_accy 75.600
2022-05-24 22:26:39,824 [bic.py] => training => Task 1, Epoch 165/170 => Loss 0.499, Train_accy 99.890, Test_accy 76.000
2022-05-24 22:26:45,213 [bic.py] => training => Task 1, Epoch 166/170 => Loss 0.501, Train_accy 99.920, Test_accy 75.800
2022-05-24 22:26:50,356 [bic.py] => training => Task 1, Epoch 167/170 => Loss 0.500, Train_accy 99.910, Test_accy 75.950
2022-05-24 22:26:55,748 [bic.py] => training => Task 1, Epoch 168/170 => Loss 0.500, Train_accy 99.820, Test_accy 75.650
2022-05-24 22:27:01,045 [bic.py] => training => Task 1, Epoch 169/170 => Loss 0.498, Train_accy 99.920, Test_accy 75.900
2022-05-24 22:27:06,212 [bic.py] => training => Task 1, Epoch 170/170 => Loss 0.497, Train_accy 99.940, Test_accy 75.700
2022-05-24 22:27:07,819 [bic.py] => bias_correction => Task 1, Epoch 1/170 => Loss 2.311, Train_accy 81.000, Test_accy 76.050
2022-05-24 22:27:09,539 [bic.py] => bias_correction => Task 1, Epoch 2/170 => Loss 2.344, Train_accy 78.750, Test_accy 76.700
2022-05-24 22:27:11,232 [bic.py] => bias_correction => Task 1, Epoch 3/170 => Loss 2.336, Train_accy 80.500, Test_accy 76.600
2022-05-24 22:27:12,922 [bic.py] => bias_correction => Task 1, Epoch 4/170 => Loss 2.317, Train_accy 78.750, Test_accy 76.150
2022-05-24 22:27:14,591 [bic.py] => bias_correction => Task 1, Epoch 5/170 => Loss 2.332, Train_accy 77.750, Test_accy 74.600
2022-05-24 22:27:16,218 [bic.py] => bias_correction => Task 1, Epoch 6/170 => Loss 2.382, Train_accy 78.500, Test_accy 74.950
2022-05-24 22:27:17,816 [bic.py] => bias_correction => Task 1, Epoch 7/170 => Loss 2.323, Train_accy 82.000, Test_accy 76.150
2022-05-24 22:27:19,518 [bic.py] => bias_correction => Task 1, Epoch 8/170 => Loss 2.336, Train_accy 78.750, Test_accy 75.950
2022-05-24 22:27:21,268 [bic.py] => bias_correction => Task 1, Epoch 9/170 => Loss 2.315, Train_accy 79.750, Test_accy 75.900
2022-05-24 22:27:22,948 [bic.py] => bias_correction => Task 1, Epoch 10/170 => Loss 2.316, Train_accy 81.000, Test_accy 75.350
2022-05-24 22:27:24,544 [bic.py] => bias_correction => Task 1, Epoch 11/170 => Loss 2.334, Train_accy 79.250, Test_accy 75.350
2022-05-24 22:27:26,094 [bic.py] => bias_correction => Task 1, Epoch 12/170 => Loss 2.334, Train_accy 79.500, Test_accy 76.250
2022-05-24 22:27:27,740 [bic.py] => bias_correction => Task 1, Epoch 13/170 => Loss 2.357, Train_accy 79.000, Test_accy 76.150
2022-05-24 22:27:29,342 [bic.py] => bias_correction => Task 1, Epoch 14/170 => Loss 2.322, Train_accy 80.000, Test_accy 75.400
2022-05-24 22:27:30,949 [bic.py] => bias_correction => Task 1, Epoch 15/170 => Loss 2.323, Train_accy 79.750, Test_accy 74.650
2022-05-24 22:27:32,534 [bic.py] => bias_correction => Task 1, Epoch 16/170 => Loss 2.326, Train_accy 79.250, Test_accy 75.000
2022-05-24 22:27:34,229 [bic.py] => bias_correction => Task 1, Epoch 17/170 => Loss 2.307, Train_accy 78.750, Test_accy 75.700
2022-05-24 22:27:35,957 [bic.py] => bias_correction => Task 1, Epoch 18/170 => Loss 2.311, Train_accy 78.000, Test_accy 76.100
2022-05-24 22:27:37,622 [bic.py] => bias_correction => Task 1, Epoch 19/170 => Loss 2.293, Train_accy 79.500, Test_accy 76.500
2022-05-24 22:27:39,246 [bic.py] => bias_correction => Task 1, Epoch 20/170 => Loss 2.348, Train_accy 80.000, Test_accy 75.900
2022-05-24 22:27:40,893 [bic.py] => bias_correction => Task 1, Epoch 21/170 => Loss 2.335, Train_accy 78.750, Test_accy 74.950
2022-05-24 22:27:42,452 [bic.py] => bias_correction => Task 1, Epoch 22/170 => Loss 2.324, Train_accy 79.750, Test_accy 74.900
2022-05-24 22:27:44,096 [bic.py] => bias_correction => Task 1, Epoch 23/170 => Loss 2.328, Train_accy 79.750, Test_accy 76.050
2022-05-24 22:27:45,657 [bic.py] => bias_correction => Task 1, Epoch 24/170 => Loss 2.328, Train_accy 78.750, Test_accy 75.900
2022-05-24 22:27:47,272 [bic.py] => bias_correction => Task 1, Epoch 25/170 => Loss 2.330, Train_accy 79.500, Test_accy 75.900
2022-05-24 22:27:48,950 [bic.py] => bias_correction => Task 1, Epoch 26/170 => Loss 2.328, Train_accy 79.750, Test_accy 75.400
2022-05-24 22:27:50,576 [bic.py] => bias_correction => Task 1, Epoch 27/170 => Loss 2.323, Train_accy 78.500, Test_accy 75.000
2022-05-24 22:27:52,226 [bic.py] => bias_correction => Task 1, Epoch 28/170 => Loss 2.328, Train_accy 80.500, Test_accy 75.300
2022-05-24 22:27:53,826 [bic.py] => bias_correction => Task 1, Epoch 29/170 => Loss 2.337, Train_accy 79.750, Test_accy 75.650
2022-05-24 22:27:55,449 [bic.py] => bias_correction => Task 1, Epoch 30/170 => Loss 2.312, Train_accy 79.500, Test_accy 75.750
2022-05-24 22:27:57,112 [bic.py] => bias_correction => Task 1, Epoch 31/170 => Loss 2.293, Train_accy 79.000, Test_accy 75.800
2022-05-24 22:27:58,656 [bic.py] => bias_correction => Task 1, Epoch 32/170 => Loss 2.288, Train_accy 81.500, Test_accy 75.900
2022-05-24 22:28:00,268 [bic.py] => bias_correction => Task 1, Epoch 33/170 => Loss 2.330, Train_accy 78.500, Test_accy 76.000
2022-05-24 22:28:01,873 [bic.py] => bias_correction => Task 1, Epoch 34/170 => Loss 2.328, Train_accy 79.000, Test_accy 75.900
2022-05-24 22:28:03,623 [bic.py] => bias_correction => Task 1, Epoch 35/170 => Loss 2.322, Train_accy 79.250, Test_accy 75.650
2022-05-24 22:28:05,219 [bic.py] => bias_correction => Task 1, Epoch 36/170 => Loss 2.330, Train_accy 82.250, Test_accy 75.600
2022-05-24 22:28:06,835 [bic.py] => bias_correction => Task 1, Epoch 37/170 => Loss 2.306, Train_accy 80.250, Test_accy 74.300
2022-05-24 22:28:08,386 [bic.py] => bias_correction => Task 1, Epoch 38/170 => Loss 2.347, Train_accy 78.500, Test_accy 75.150
2022-05-24 22:28:10,037 [bic.py] => bias_correction => Task 1, Epoch 39/170 => Loss 2.293, Train_accy 80.250, Test_accy 76.050
2022-05-24 22:28:11,647 [bic.py] => bias_correction => Task 1, Epoch 40/170 => Loss 2.309, Train_accy 79.250, Test_accy 76.050
2022-05-24 22:28:13,300 [bic.py] => bias_correction => Task 1, Epoch 41/170 => Loss 2.315, Train_accy 78.500, Test_accy 75.950
2022-05-24 22:28:14,931 [bic.py] => bias_correction => Task 1, Epoch 42/170 => Loss 2.304, Train_accy 78.000, Test_accy 76.400
2022-05-24 22:28:16,530 [bic.py] => bias_correction => Task 1, Epoch 43/170 => Loss 2.341, Train_accy 78.750, Test_accy 75.950
2022-05-24 22:28:18,174 [bic.py] => bias_correction => Task 1, Epoch 44/170 => Loss 2.337, Train_accy 77.500, Test_accy 75.000
2022-05-24 22:28:19,791 [bic.py] => bias_correction => Task 1, Epoch 45/170 => Loss 2.337, Train_accy 78.000, Test_accy 74.850
2022-05-24 22:28:21,447 [bic.py] => bias_correction => Task 1, Epoch 46/170 => Loss 2.303, Train_accy 80.500, Test_accy 75.600
2022-05-24 22:28:23,034 [bic.py] => bias_correction => Task 1, Epoch 47/170 => Loss 2.289, Train_accy 80.750, Test_accy 76.350
2022-05-24 22:28:24,684 [bic.py] => bias_correction => Task 1, Epoch 48/170 => Loss 2.343, Train_accy 80.750, Test_accy 76.150
2022-05-24 22:28:26,295 [bic.py] => bias_correction => Task 1, Epoch 49/170 => Loss 2.310, Train_accy 78.250, Test_accy 75.750
2022-05-24 22:28:27,951 [bic.py] => bias_correction => Task 1, Epoch 50/170 => Loss 2.298, Train_accy 77.250, Test_accy 73.550
2022-05-24 22:28:29,590 [bic.py] => bias_correction => Task 1, Epoch 51/170 => Loss 2.339, Train_accy 76.000, Test_accy 72.850
2022-05-24 22:28:31,289 [bic.py] => bias_correction => Task 1, Epoch 52/170 => Loss 2.285, Train_accy 77.750, Test_accy 75.000
2022-05-24 22:28:33,010 [bic.py] => bias_correction => Task 1, Epoch 53/170 => Loss 2.347, Train_accy 78.750, Test_accy 75.900
2022-05-24 22:28:34,662 [bic.py] => bias_correction => Task 1, Epoch 54/170 => Loss 2.307, Train_accy 80.000, Test_accy 76.100
2022-05-24 22:28:36,263 [bic.py] => bias_correction => Task 1, Epoch 55/170 => Loss 2.311, Train_accy 81.750, Test_accy 75.850
2022-05-24 22:28:37,873 [bic.py] => bias_correction => Task 1, Epoch 56/170 => Loss 2.275, Train_accy 78.000, Test_accy 75.650
2022-05-24 22:28:39,456 [bic.py] => bias_correction => Task 1, Epoch 57/170 => Loss 2.299, Train_accy 79.750, Test_accy 76.200
2022-05-24 22:28:41,064 [bic.py] => bias_correction => Task 1, Epoch 58/170 => Loss 2.352, Train_accy 78.250, Test_accy 75.900
2022-05-24 22:28:42,595 [bic.py] => bias_correction => Task 1, Epoch 59/170 => Loss 2.305, Train_accy 80.750, Test_accy 76.300
2022-05-24 22:28:44,278 [bic.py] => bias_correction => Task 1, Epoch 60/170 => Loss 2.314, Train_accy 80.750, Test_accy 76.400
2022-05-24 22:28:46,025 [bic.py] => bias_correction => Task 1, Epoch 61/170 => Loss 2.329, Train_accy 80.250, Test_accy 76.250
2022-05-24 22:28:47,700 [bic.py] => bias_correction => Task 1, Epoch 62/170 => Loss 2.311, Train_accy 80.750, Test_accy 76.450
2022-05-24 22:28:49,348 [bic.py] => bias_correction => Task 1, Epoch 63/170 => Loss 2.330, Train_accy 79.500, Test_accy 76.150
2022-05-24 22:28:50,938 [bic.py] => bias_correction => Task 1, Epoch 64/170 => Loss 2.340, Train_accy 81.750, Test_accy 76.150
2022-05-24 22:28:52,594 [bic.py] => bias_correction => Task 1, Epoch 65/170 => Loss 2.293, Train_accy 79.250, Test_accy 76.100
2022-05-24 22:28:54,193 [bic.py] => bias_correction => Task 1, Epoch 66/170 => Loss 2.311, Train_accy 77.250, Test_accy 76.100
2022-05-24 22:28:55,849 [bic.py] => bias_correction => Task 1, Epoch 67/170 => Loss 2.340, Train_accy 79.250, Test_accy 75.950
2022-05-24 22:28:57,369 [bic.py] => bias_correction => Task 1, Epoch 68/170 => Loss 2.335, Train_accy 80.250, Test_accy 75.750
2022-05-24 22:28:58,993 [bic.py] => bias_correction => Task 1, Epoch 69/170 => Loss 2.309, Train_accy 78.750, Test_accy 75.350
2022-05-24 22:29:00,584 [bic.py] => bias_correction => Task 1, Epoch 70/170 => Loss 2.305, Train_accy 79.250, Test_accy 75.550
2022-05-24 22:29:02,281 [bic.py] => bias_correction => Task 1, Epoch 71/170 => Loss 2.347, Train_accy 79.250, Test_accy 75.700
2022-05-24 22:29:03,857 [bic.py] => bias_correction => Task 1, Epoch 72/170 => Loss 2.308, Train_accy 78.250, Test_accy 75.550
2022-05-24 22:29:05,485 [bic.py] => bias_correction => Task 1, Epoch 73/170 => Loss 2.332, Train_accy 79.000, Test_accy 76.100
2022-05-24 22:29:07,159 [bic.py] => bias_correction => Task 1, Epoch 74/170 => Loss 2.321, Train_accy 79.000, Test_accy 76.200
2022-05-24 22:29:08,717 [bic.py] => bias_correction => Task 1, Epoch 75/170 => Loss 2.319, Train_accy 78.250, Test_accy 75.800
2022-05-24 22:29:10,290 [bic.py] => bias_correction => Task 1, Epoch 76/170 => Loss 2.293, Train_accy 80.750, Test_accy 75.950
2022-05-24 22:29:11,944 [bic.py] => bias_correction => Task 1, Epoch 77/170 => Loss 2.313, Train_accy 79.000, Test_accy 75.700
2022-05-24 22:29:13,593 [bic.py] => bias_correction => Task 1, Epoch 78/170 => Loss 2.332, Train_accy 78.750, Test_accy 75.600
2022-05-24 22:29:15,272 [bic.py] => bias_correction => Task 1, Epoch 79/170 => Loss 2.364, Train_accy 81.500, Test_accy 75.700
2022-05-24 22:29:16,902 [bic.py] => bias_correction => Task 1, Epoch 80/170 => Loss 2.317, Train_accy 80.750, Test_accy 75.850
2022-05-24 22:29:18,572 [bic.py] => bias_correction => Task 1, Epoch 81/170 => Loss 2.304, Train_accy 78.500, Test_accy 75.500
2022-05-24 22:29:20,217 [bic.py] => bias_correction => Task 1, Epoch 82/170 => Loss 2.328, Train_accy 79.000, Test_accy 75.900
2022-05-24 22:29:21,905 [bic.py] => bias_correction => Task 1, Epoch 83/170 => Loss 2.289, Train_accy 79.750, Test_accy 75.500
2022-05-24 22:29:23,509 [bic.py] => bias_correction => Task 1, Epoch 84/170 => Loss 2.299, Train_accy 78.500, Test_accy 75.950
2022-05-24 22:29:25,077 [bic.py] => bias_correction => Task 1, Epoch 85/170 => Loss 2.318, Train_accy 78.750, Test_accy 76.250
2022-05-24 22:29:26,685 [bic.py] => bias_correction => Task 1, Epoch 86/170 => Loss 2.370, Train_accy 80.250, Test_accy 76.150
2022-05-24 22:29:28,223 [bic.py] => bias_correction => Task 1, Epoch 87/170 => Loss 2.322, Train_accy 80.250, Test_accy 76.100
2022-05-24 22:29:29,904 [bic.py] => bias_correction => Task 1, Epoch 88/170 => Loss 2.333, Train_accy 80.750, Test_accy 76.150
2022-05-24 22:29:31,482 [bic.py] => bias_correction => Task 1, Epoch 89/170 => Loss 2.308, Train_accy 80.500, Test_accy 76.300
2022-05-24 22:29:33,079 [bic.py] => bias_correction => Task 1, Epoch 90/170 => Loss 2.320, Train_accy 80.750, Test_accy 75.350
2022-05-24 22:29:34,602 [bic.py] => bias_correction => Task 1, Epoch 91/170 => Loss 2.303, Train_accy 79.000, Test_accy 75.600
2022-05-24 22:29:36,218 [bic.py] => bias_correction => Task 1, Epoch 92/170 => Loss 2.304, Train_accy 79.500, Test_accy 75.600
2022-05-24 22:29:37,870 [bic.py] => bias_correction => Task 1, Epoch 93/170 => Loss 2.315, Train_accy 79.250, Test_accy 75.800
2022-05-24 22:29:39,496 [bic.py] => bias_correction => Task 1, Epoch 94/170 => Loss 2.345, Train_accy 80.000, Test_accy 75.550
2022-05-24 22:29:41,124 [bic.py] => bias_correction => Task 1, Epoch 95/170 => Loss 2.321, Train_accy 78.500, Test_accy 75.500
2022-05-24 22:29:42,712 [bic.py] => bias_correction => Task 1, Epoch 96/170 => Loss 2.323, Train_accy 79.500, Test_accy 75.750
2022-05-24 22:29:44,373 [bic.py] => bias_correction => Task 1, Epoch 97/170 => Loss 2.331, Train_accy 80.500, Test_accy 75.800
2022-05-24 22:29:46,035 [bic.py] => bias_correction => Task 1, Epoch 98/170 => Loss 2.334, Train_accy 80.750, Test_accy 75.550
2022-05-24 22:29:47,608 [bic.py] => bias_correction => Task 1, Epoch 99/170 => Loss 2.313, Train_accy 80.000, Test_accy 75.700
2022-05-24 22:29:49,221 [bic.py] => bias_correction => Task 1, Epoch 100/170 => Loss 2.346, Train_accy 78.000, Test_accy 76.200
2022-05-24 22:29:50,833 [bic.py] => bias_correction => Task 1, Epoch 101/170 => Loss 2.390, Train_accy 78.000, Test_accy 76.200
2022-05-24 22:29:52,502 [bic.py] => bias_correction => Task 1, Epoch 102/170 => Loss 2.322, Train_accy 80.250, Test_accy 76.300
2022-05-24 22:29:54,088 [bic.py] => bias_correction => Task 1, Epoch 103/170 => Loss 2.309, Train_accy 78.250, Test_accy 76.050
2022-05-24 22:29:55,668 [bic.py] => bias_correction => Task 1, Epoch 104/170 => Loss 2.291, Train_accy 78.250, Test_accy 76.000
2022-05-24 22:29:57,194 [bic.py] => bias_correction => Task 1, Epoch 105/170 => Loss 2.307, Train_accy 80.500, Test_accy 76.200
2022-05-24 22:29:58,788 [bic.py] => bias_correction => Task 1, Epoch 106/170 => Loss 2.307, Train_accy 78.500, Test_accy 75.950
2022-05-24 22:30:00,463 [bic.py] => bias_correction => Task 1, Epoch 107/170 => Loss 2.344, Train_accy 77.250, Test_accy 76.050
2022-05-24 22:30:02,039 [bic.py] => bias_correction => Task 1, Epoch 108/170 => Loss 2.324, Train_accy 77.250, Test_accy 75.850
2022-05-24 22:30:03,654 [bic.py] => bias_correction => Task 1, Epoch 109/170 => Loss 2.317, Train_accy 79.500, Test_accy 76.000
2022-05-24 22:30:05,308 [bic.py] => bias_correction => Task 1, Epoch 110/170 => Loss 2.362, Train_accy 81.750, Test_accy 76.500
2022-05-24 22:30:07,020 [bic.py] => bias_correction => Task 1, Epoch 111/170 => Loss 2.332, Train_accy 81.500, Test_accy 76.100
2022-05-24 22:30:08,670 [bic.py] => bias_correction => Task 1, Epoch 112/170 => Loss 2.292, Train_accy 78.000, Test_accy 76.300
2022-05-24 22:30:10,285 [bic.py] => bias_correction => Task 1, Epoch 113/170 => Loss 2.313, Train_accy 78.750, Test_accy 76.050
2022-05-24 22:30:11,948 [bic.py] => bias_correction => Task 1, Epoch 114/170 => Loss 2.317, Train_accy 81.750, Test_accy 76.300
2022-05-24 22:30:13,658 [bic.py] => bias_correction => Task 1, Epoch 115/170 => Loss 2.334, Train_accy 79.250, Test_accy 76.100
2022-05-24 22:30:15,400 [bic.py] => bias_correction => Task 1, Epoch 116/170 => Loss 2.326, Train_accy 79.250, Test_accy 75.900
2022-05-24 22:30:16,991 [bic.py] => bias_correction => Task 1, Epoch 117/170 => Loss 2.345, Train_accy 81.500, Test_accy 76.100
2022-05-24 22:30:18,540 [bic.py] => bias_correction => Task 1, Epoch 118/170 => Loss 2.299, Train_accy 79.500, Test_accy 76.150
2022-05-24 22:30:20,155 [bic.py] => bias_correction => Task 1, Epoch 119/170 => Loss 2.326, Train_accy 79.750, Test_accy 76.400
2022-05-24 22:30:21,743 [bic.py] => bias_correction => Task 1, Epoch 120/170 => Loss 2.373, Train_accy 80.750, Test_accy 76.200
2022-05-24 22:30:23,391 [bic.py] => bias_correction => Task 1, Epoch 121/170 => Loss 2.328, Train_accy 79.500, Test_accy 75.900
2022-05-24 22:30:25,047 [bic.py] => bias_correction => Task 1, Epoch 122/170 => Loss 2.291, Train_accy 80.000, Test_accy 75.900
2022-05-24 22:30:26,609 [bic.py] => bias_correction => Task 1, Epoch 123/170 => Loss 2.301, Train_accy 80.250, Test_accy 75.950
2022-05-24 22:30:28,210 [bic.py] => bias_correction => Task 1, Epoch 124/170 => Loss 2.328, Train_accy 81.000, Test_accy 75.950
2022-05-24 22:30:29,801 [bic.py] => bias_correction => Task 1, Epoch 125/170 => Loss 2.322, Train_accy 79.750, Test_accy 76.250
2022-05-24 22:30:31,484 [bic.py] => bias_correction => Task 1, Epoch 126/170 => Loss 2.334, Train_accy 79.500, Test_accy 76.400
2022-05-24 22:30:33,034 [bic.py] => bias_correction => Task 1, Epoch 127/170 => Loss 2.347, Train_accy 81.750, Test_accy 76.150
2022-05-24 22:30:34,707 [bic.py] => bias_correction => Task 1, Epoch 128/170 => Loss 2.310, Train_accy 78.500, Test_accy 76.300
2022-05-24 22:30:36,290 [bic.py] => bias_correction => Task 1, Epoch 129/170 => Loss 2.381, Train_accy 78.500, Test_accy 76.250
2022-05-24 22:30:37,914 [bic.py] => bias_correction => Task 1, Epoch 130/170 => Loss 2.272, Train_accy 81.750, Test_accy 76.700
2022-05-24 22:30:39,519 [bic.py] => bias_correction => Task 1, Epoch 131/170 => Loss 2.363, Train_accy 80.250, Test_accy 76.550
2022-05-24 22:30:41,107 [bic.py] => bias_correction => Task 1, Epoch 132/170 => Loss 2.309, Train_accy 80.500, Test_accy 76.250
2022-05-24 22:30:42,730 [bic.py] => bias_correction => Task 1, Epoch 133/170 => Loss 2.320, Train_accy 79.500, Test_accy 75.950
2022-05-24 22:30:44,386 [bic.py] => bias_correction => Task 1, Epoch 134/170 => Loss 2.298, Train_accy 79.750, Test_accy 76.050
2022-05-24 22:30:46,034 [bic.py] => bias_correction => Task 1, Epoch 135/170 => Loss 2.304, Train_accy 79.750, Test_accy 76.350
2022-05-24 22:30:47,608 [bic.py] => bias_correction => Task 1, Epoch 136/170 => Loss 2.319, Train_accy 81.000, Test_accy 75.750
2022-05-24 22:30:49,194 [bic.py] => bias_correction => Task 1, Epoch 137/170 => Loss 2.280, Train_accy 79.750, Test_accy 76.050
2022-05-24 22:30:50,698 [bic.py] => bias_correction => Task 1, Epoch 138/170 => Loss 2.330, Train_accy 81.750, Test_accy 76.000
2022-05-24 22:30:52,340 [bic.py] => bias_correction => Task 1, Epoch 139/170 => Loss 2.327, Train_accy 80.500, Test_accy 76.200
2022-05-24 22:30:54,129 [bic.py] => bias_correction => Task 1, Epoch 140/170 => Loss 2.345, Train_accy 81.750, Test_accy 76.150
2022-05-24 22:30:55,736 [bic.py] => bias_correction => Task 1, Epoch 141/170 => Loss 2.333, Train_accy 79.500, Test_accy 75.900
2022-05-24 22:30:57,437 [bic.py] => bias_correction => Task 1, Epoch 142/170 => Loss 2.349, Train_accy 81.500, Test_accy 76.050
2022-05-24 22:30:59,009 [bic.py] => bias_correction => Task 1, Epoch 143/170 => Loss 2.330, Train_accy 78.750, Test_accy 75.900
2022-05-24 22:31:00,671 [bic.py] => bias_correction => Task 1, Epoch 144/170 => Loss 2.307, Train_accy 79.750, Test_accy 76.000
2022-05-24 22:31:02,270 [bic.py] => bias_correction => Task 1, Epoch 145/170 => Loss 2.268, Train_accy 80.000, Test_accy 76.100
2022-05-24 22:31:03,864 [bic.py] => bias_correction => Task 1, Epoch 146/170 => Loss 2.297, Train_accy 81.250, Test_accy 75.800
2022-05-24 22:31:05,471 [bic.py] => bias_correction => Task 1, Epoch 147/170 => Loss 2.291, Train_accy 79.250, Test_accy 75.750
2022-05-24 22:31:06,994 [bic.py] => bias_correction => Task 1, Epoch 148/170 => Loss 2.316, Train_accy 77.500, Test_accy 75.800
2022-05-24 22:31:08,695 [bic.py] => bias_correction => Task 1, Epoch 149/170 => Loss 2.313, Train_accy 79.000, Test_accy 75.850
2022-05-24 22:31:10,268 [bic.py] => bias_correction => Task 1, Epoch 150/170 => Loss 2.340, Train_accy 79.000, Test_accy 75.600
2022-05-24 22:31:11,876 [bic.py] => bias_correction => Task 1, Epoch 151/170 => Loss 2.308, Train_accy 81.000, Test_accy 76.350
2022-05-24 22:31:13,490 [bic.py] => bias_correction => Task 1, Epoch 152/170 => Loss 2.316, Train_accy 78.250, Test_accy 76.100
2022-05-24 22:31:15,179 [bic.py] => bias_correction => Task 1, Epoch 153/170 => Loss 2.301, Train_accy 78.250, Test_accy 75.950
2022-05-24 22:31:16,853 [bic.py] => bias_correction => Task 1, Epoch 154/170 => Loss 2.266, Train_accy 79.250, Test_accy 76.100
2022-05-24 22:31:18,474 [bic.py] => bias_correction => Task 1, Epoch 155/170 => Loss 2.339, Train_accy 79.750, Test_accy 76.050
2022-05-24 22:31:20,033 [bic.py] => bias_correction => Task 1, Epoch 156/170 => Loss 2.355, Train_accy 80.500, Test_accy 76.450
2022-05-24 22:31:21,666 [bic.py] => bias_correction => Task 1, Epoch 157/170 => Loss 2.335, Train_accy 80.250, Test_accy 76.000
2022-05-24 22:31:23,213 [bic.py] => bias_correction => Task 1, Epoch 158/170 => Loss 2.343, Train_accy 80.500, Test_accy 76.200
2022-05-24 22:31:24,796 [bic.py] => bias_correction => Task 1, Epoch 159/170 => Loss 2.303, Train_accy 81.250, Test_accy 75.900
2022-05-24 22:31:26,466 [bic.py] => bias_correction => Task 1, Epoch 160/170 => Loss 2.324, Train_accy 80.000, Test_accy 76.050
2022-05-24 22:31:28,078 [bic.py] => bias_correction => Task 1, Epoch 161/170 => Loss 2.308, Train_accy 79.000, Test_accy 76.400
2022-05-24 22:31:29,667 [bic.py] => bias_correction => Task 1, Epoch 162/170 => Loss 2.303, Train_accy 79.750, Test_accy 75.850
2022-05-24 22:31:31,282 [bic.py] => bias_correction => Task 1, Epoch 163/170 => Loss 2.306, Train_accy 79.250, Test_accy 76.400
2022-05-24 22:31:32,973 [bic.py] => bias_correction => Task 1, Epoch 164/170 => Loss 2.358, Train_accy 80.000, Test_accy 76.400
2022-05-24 22:31:34,577 [bic.py] => bias_correction => Task 1, Epoch 165/170 => Loss 2.357, Train_accy 82.000, Test_accy 76.050
2022-05-24 22:31:36,255 [bic.py] => bias_correction => Task 1, Epoch 166/170 => Loss 2.328, Train_accy 80.750, Test_accy 76.200
2022-05-24 22:31:37,746 [bic.py] => bias_correction => Task 1, Epoch 167/170 => Loss 2.300, Train_accy 78.500, Test_accy 76.300
2022-05-24 22:31:39,293 [bic.py] => bias_correction => Task 1, Epoch 168/170 => Loss 2.328, Train_accy 79.750, Test_accy 76.300
2022-05-24 22:31:40,927 [bic.py] => bias_correction => Task 1, Epoch 169/170 => Loss 2.332, Train_accy 80.000, Test_accy 76.050
2022-05-24 22:31:42,543 [bic.py] => bias_correction => Task 1, Epoch 170/170 => Loss 2.307, Train_accy 80.000, Test_accy 75.950
2022-05-24 22:31:42,544 [base.py] => Reducing exemplars...(100 per classes)
2022-05-24 22:31:44,922 [base.py] => Constructing exemplars...(100 per classes)
2022-05-24 22:31:51,223 [bic.py] => Parameters of bias layer:
2022-05-24 22:31:51,224 [bic.py] => 0 => 1.000, 0.000
2022-05-24 22:31:51,224 [bic.py] => 1 => 0.981, -1.523
2022-05-24 22:31:52,402 [bic.py] => Exemplar size: 2000
2022-05-24 22:31:52,403 [trainer.py] => CNN: {'total': 75.95, '00-09': 79.2, '10-19': 72.7, 'old': 79.2, 'new': 72.7}
2022-05-24 22:31:52,403 [trainer.py] => NME: {'total': 75.6, '00-09': 79.5, '10-19': 71.7, 'old': 79.5, 'new': 71.7}
2022-05-24 22:31:52,403 [trainer.py] => CNN top1 curve: [87.5, 75.95]
2022-05-24 22:31:52,403 [trainer.py] => CNN top5 curve: [99.3, 95.5]
2022-05-24 22:31:52,403 [trainer.py] => NME top1 curve: [88.1, 75.6]
2022-05-24 22:31:52,403 [trainer.py] => NME top5 curve: [99.4, 95.4]

2022-05-24 22:31:52,403 [trainer.py] => All params: 465458
2022-05-24 22:31:52,404 [trainer.py] => Trainable params: 465458
2022-05-24 22:31:52,405 [bic.py] => Learning on 20-30
2022-05-24 22:31:52,469 [bic.py] => Stage1 dset: 6700, Stage2 dset: 300
2022-05-24 22:31:52,469 [bic.py] => Lambda: 0.667
2022-05-24 22:31:52,476 [bic.py] => Parameters of bias layer:
2022-05-24 22:31:52,477 [bic.py] => 0 => 1.000, 0.000
2022-05-24 22:31:52,477 [bic.py] => 1 => 0.981, -1.523
2022-05-24 22:31:52,477 [bic.py] => 2 => 1.000, 0.000
2022-05-24 22:31:57,684 [bic.py] => training => Task 2, Epoch 1/170 => Loss 1.598, Train_accy 55.880, Test_accy 49.230
2022-05-24 22:32:03,164 [bic.py] => training => Task 2, Epoch 2/170 => Loss 1.249, Train_accy 64.540, Test_accy 51.000
2022-05-24 22:32:08,471 [bic.py] => training => Task 2, Epoch 3/170 => Loss 1.188, Train_accy 70.990, Test_accy 55.000
2022-05-24 22:32:13,856 [bic.py] => training => Task 2, Epoch 4/170 => Loss 1.158, Train_accy 73.250, Test_accy 55.830
2022-05-24 22:32:19,143 [bic.py] => training => Task 2, Epoch 5/170 => Loss 1.116, Train_accy 76.090, Test_accy 56.370
2022-05-24 22:32:24,590 [bic.py] => training => Task 2, Epoch 6/170 => Loss 1.102, Train_accy 79.880, Test_accy 58.030
2022-05-24 22:32:30,142 [bic.py] => training => Task 2, Epoch 7/170 => Loss 1.101, Train_accy 78.000, Test_accy 56.870
2022-05-24 22:32:35,505 [bic.py] => training => Task 2, Epoch 8/170 => Loss 1.077, Train_accy 77.820, Test_accy 56.770
2022-05-24 22:32:40,866 [bic.py] => training => Task 2, Epoch 9/170 => Loss 1.069, Train_accy 81.300, Test_accy 59.030
2022-05-24 22:32:46,362 [bic.py] => training => Task 2, Epoch 10/170 => Loss 1.060, Train_accy 81.360, Test_accy 59.300
2022-05-24 22:32:51,819 [bic.py] => training => Task 2, Epoch 11/170 => Loss 1.050, Train_accy 84.600, Test_accy 60.570
2022-05-24 22:32:57,295 [bic.py] => training => Task 2, Epoch 12/170 => Loss 1.043, Train_accy 84.420, Test_accy 61.430
2022-05-24 22:33:02,841 [bic.py] => training => Task 2, Epoch 13/170 => Loss 1.044, Train_accy 85.370, Test_accy 59.900
2022-05-24 22:33:08,329 [bic.py] => training => Task 2, Epoch 14/170 => Loss 1.039, Train_accy 80.370, Test_accy 55.900
2022-05-24 22:33:13,914 [bic.py] => training => Task 2, Epoch 15/170 => Loss 1.031, Train_accy 80.690, Test_accy 56.200
2022-05-24 22:33:19,270 [bic.py] => training => Task 2, Epoch 16/170 => Loss 1.011, Train_accy 87.120, Test_accy 62.530
2022-05-24 22:33:24,598 [bic.py] => training => Task 2, Epoch 17/170 => Loss 1.013, Train_accy 86.220, Test_accy 60.830
2022-05-24 22:33:30,271 [bic.py] => training => Task 2, Epoch 18/170 => Loss 1.007, Train_accy 87.700, Test_accy 60.000
2022-05-24 22:33:35,748 [bic.py] => training => Task 2, Epoch 19/170 => Loss 1.009, Train_accy 85.150, Test_accy 59.900
2022-05-24 22:33:41,042 [bic.py] => training => Task 2, Epoch 20/170 => Loss 0.994, Train_accy 87.510, Test_accy 60.100
2022-05-24 22:33:46,538 [bic.py] => training => Task 2, Epoch 21/170 => Loss 0.994, Train_accy 89.850, Test_accy 62.870
2022-05-24 22:33:51,917 [bic.py] => training => Task 2, Epoch 22/170 => Loss 1.004, Train_accy 87.370, Test_accy 60.870
2022-05-24 22:33:57,590 [bic.py] => training => Task 2, Epoch 23/170 => Loss 0.991, Train_accy 87.820, Test_accy 62.070
2022-05-24 22:34:02,978 [bic.py] => training => Task 2, Epoch 24/170 => Loss 0.996, Train_accy 88.520, Test_accy 63.130
2022-05-24 22:34:08,334 [bic.py] => training => Task 2, Epoch 25/170 => Loss 0.982, Train_accy 87.130, Test_accy 59.070
2022-05-24 22:34:14,011 [bic.py] => training => Task 2, Epoch 26/170 => Loss 0.976, Train_accy 90.450, Test_accy 62.570
2022-05-24 22:34:19,422 [bic.py] => training => Task 2, Epoch 27/170 => Loss 0.977, Train_accy 88.520, Test_accy 62.630
2022-05-24 22:34:24,754 [bic.py] => training => Task 2, Epoch 28/170 => Loss 0.977, Train_accy 89.400, Test_accy 60.570
2022-05-24 22:34:30,363 [bic.py] => training => Task 2, Epoch 29/170 => Loss 0.979, Train_accy 88.640, Test_accy 60.230
2022-05-24 22:34:35,882 [bic.py] => training => Task 2, Epoch 30/170 => Loss 0.983, Train_accy 87.870, Test_accy 61.030
2022-05-24 22:34:41,468 [bic.py] => training => Task 2, Epoch 31/170 => Loss 0.983, Train_accy 86.010, Test_accy 58.900
2022-05-24 22:34:47,017 [bic.py] => training => Task 2, Epoch 32/170 => Loss 0.958, Train_accy 92.600, Test_accy 61.800
2022-05-24 22:34:52,363 [bic.py] => training => Task 2, Epoch 33/170 => Loss 0.967, Train_accy 91.330, Test_accy 62.400
2022-05-24 22:34:57,750 [bic.py] => training => Task 2, Epoch 34/170 => Loss 0.966, Train_accy 88.970, Test_accy 58.730
2022-05-24 22:35:03,084 [bic.py] => training => Task 2, Epoch 35/170 => Loss 0.963, Train_accy 90.790, Test_accy 63.400
2022-05-24 22:35:08,579 [bic.py] => training => Task 2, Epoch 36/170 => Loss 0.980, Train_accy 88.250, Test_accy 59.170
2022-05-24 22:35:13,977 [bic.py] => training => Task 2, Epoch 37/170 => Loss 0.952, Train_accy 91.850, Test_accy 61.600
2022-05-24 22:35:19,274 [bic.py] => training => Task 2, Epoch 38/170 => Loss 0.969, Train_accy 90.510, Test_accy 62.530
2022-05-24 22:35:24,621 [bic.py] => training => Task 2, Epoch 39/170 => Loss 0.970, Train_accy 89.940, Test_accy 61.270
2022-05-24 22:35:30,033 [bic.py] => training => Task 2, Epoch 40/170 => Loss 0.972, Train_accy 85.820, Test_accy 60.970
2022-05-24 22:35:35,697 [bic.py] => training => Task 2, Epoch 41/170 => Loss 0.962, Train_accy 89.850, Test_accy 60.400
2022-05-24 22:35:41,157 [bic.py] => training => Task 2, Epoch 42/170 => Loss 0.962, Train_accy 92.160, Test_accy 63.230
2022-05-24 22:35:46,548 [bic.py] => training => Task 2, Epoch 43/170 => Loss 0.950, Train_accy 89.720, Test_accy 63.030
2022-05-24 22:35:52,000 [bic.py] => training => Task 2, Epoch 44/170 => Loss 0.975, Train_accy 91.690, Test_accy 63.170
2022-05-24 22:35:57,289 [bic.py] => training => Task 2, Epoch 45/170 => Loss 0.946, Train_accy 90.160, Test_accy 63.070
2022-05-24 22:36:02,917 [bic.py] => training => Task 2, Epoch 46/170 => Loss 0.946, Train_accy 93.510, Test_accy 63.070
2022-05-24 22:36:08,341 [bic.py] => training => Task 2, Epoch 47/170 => Loss 0.955, Train_accy 91.220, Test_accy 60.530
2022-05-24 22:36:13,701 [bic.py] => training => Task 2, Epoch 48/170 => Loss 0.942, Train_accy 93.460, Test_accy 65.100
2022-05-24 22:36:19,282 [bic.py] => training => Task 2, Epoch 49/170 => Loss 0.942, Train_accy 89.180, Test_accy 57.700
2022-05-24 22:36:24,745 [bic.py] => training => Task 2, Epoch 50/170 => Loss 0.959, Train_accy 90.420, Test_accy 61.600
2022-05-24 22:36:29,997 [bic.py] => training => Task 2, Epoch 51/170 => Loss 0.955, Train_accy 91.610, Test_accy 61.770
2022-05-24 22:36:35,556 [bic.py] => training => Task 2, Epoch 52/170 => Loss 0.942, Train_accy 93.630, Test_accy 62.930
2022-05-24 22:36:40,988 [bic.py] => training => Task 2, Epoch 53/170 => Loss 0.927, Train_accy 92.810, Test_accy 61.470
2022-05-24 22:36:46,309 [bic.py] => training => Task 2, Epoch 54/170 => Loss 0.942, Train_accy 93.160, Test_accy 63.670
2022-05-24 22:36:51,720 [bic.py] => training => Task 2, Epoch 55/170 => Loss 0.942, Train_accy 93.580, Test_accy 62.770
2022-05-24 22:36:57,286 [bic.py] => training => Task 2, Epoch 56/170 => Loss 0.932, Train_accy 93.300, Test_accy 61.930
2022-05-24 22:37:02,890 [bic.py] => training => Task 2, Epoch 57/170 => Loss 0.920, Train_accy 94.960, Test_accy 64.200
2022-05-24 22:37:08,620 [bic.py] => training => Task 2, Epoch 58/170 => Loss 0.927, Train_accy 93.630, Test_accy 62.000
2022-05-24 22:37:14,017 [bic.py] => training => Task 2, Epoch 59/170 => Loss 0.939, Train_accy 93.010, Test_accy 61.230
2022-05-24 22:37:19,370 [bic.py] => training => Task 2, Epoch 60/170 => Loss 0.947, Train_accy 94.900, Test_accy 64.130
2022-05-24 22:37:24,899 [bic.py] => training => Task 2, Epoch 61/170 => Loss 0.892, Train_accy 98.940, Test_accy 66.630
2022-05-24 22:37:30,187 [bic.py] => training => Task 2, Epoch 62/170 => Loss 0.869, Train_accy 99.160, Test_accy 67.530
2022-05-24 22:37:35,666 [bic.py] => training => Task 2, Epoch 63/170 => Loss 0.867, Train_accy 99.280, Test_accy 67.130
2022-05-24 22:37:41,018 [bic.py] => training => Task 2, Epoch 64/170 => Loss 0.858, Train_accy 99.330, Test_accy 67.800
2022-05-24 22:37:46,465 [bic.py] => training => Task 2, Epoch 65/170 => Loss 0.860, Train_accy 99.330, Test_accy 67.200
2022-05-24 22:37:51,958 [bic.py] => training => Task 2, Epoch 66/170 => Loss 0.857, Train_accy 99.400, Test_accy 67.900
2022-05-24 22:37:57,265 [bic.py] => training => Task 2, Epoch 67/170 => Loss 0.850, Train_accy 99.400, Test_accy 67.500
2022-05-24 22:38:02,508 [bic.py] => training => Task 2, Epoch 68/170 => Loss 0.852, Train_accy 99.670, Test_accy 67.570
2022-05-24 22:38:07,912 [bic.py] => training => Task 2, Epoch 69/170 => Loss 0.856, Train_accy 99.520, Test_accy 67.430
2022-05-24 22:38:13,297 [bic.py] => training => Task 2, Epoch 70/170 => Loss 0.848, Train_accy 99.550, Test_accy 67.200
2022-05-24 22:38:18,780 [bic.py] => training => Task 2, Epoch 71/170 => Loss 0.849, Train_accy 99.540, Test_accy 68.000
2022-05-24 22:38:24,100 [bic.py] => training => Task 2, Epoch 72/170 => Loss 0.845, Train_accy 99.600, Test_accy 67.730
2022-05-24 22:38:29,693 [bic.py] => training => Task 2, Epoch 73/170 => Loss 0.847, Train_accy 99.580, Test_accy 67.770
2022-05-24 22:38:35,253 [bic.py] => training => Task 2, Epoch 74/170 => Loss 0.842, Train_accy 99.510, Test_accy 68.070
2022-05-24 22:38:40,536 [bic.py] => training => Task 2, Epoch 75/170 => Loss 0.847, Train_accy 99.600, Test_accy 67.930
2022-05-24 22:38:45,985 [bic.py] => training => Task 2, Epoch 76/170 => Loss 0.842, Train_accy 99.640, Test_accy 67.630
2022-05-24 22:38:51,320 [bic.py] => training => Task 2, Epoch 77/170 => Loss 0.840, Train_accy 99.660, Test_accy 67.900
2022-05-24 22:38:56,747 [bic.py] => training => Task 2, Epoch 78/170 => Loss 0.843, Train_accy 99.670, Test_accy 67.970
2022-05-24 22:39:02,178 [bic.py] => training => Task 2, Epoch 79/170 => Loss 0.845, Train_accy 99.670, Test_accy 67.800
2022-05-24 22:39:07,555 [bic.py] => training => Task 2, Epoch 80/170 => Loss 0.849, Train_accy 99.540, Test_accy 67.630
2022-05-24 22:39:12,976 [bic.py] => training => Task 2, Epoch 81/170 => Loss 0.840, Train_accy 99.760, Test_accy 67.730
2022-05-24 22:39:18,533 [bic.py] => training => Task 2, Epoch 82/170 => Loss 0.838, Train_accy 99.660, Test_accy 67.470
2022-05-24 22:39:23,767 [bic.py] => training => Task 2, Epoch 83/170 => Loss 0.842, Train_accy 99.700, Test_accy 68.330
2022-05-24 22:39:29,187 [bic.py] => training => Task 2, Epoch 84/170 => Loss 0.840, Train_accy 99.570, Test_accy 67.670
2022-05-24 22:39:34,656 [bic.py] => training => Task 2, Epoch 85/170 => Loss 0.839, Train_accy 99.700, Test_accy 67.670
2022-05-24 22:39:40,019 [bic.py] => training => Task 2, Epoch 86/170 => Loss 0.838, Train_accy 99.760, Test_accy 67.430
2022-05-24 22:39:45,654 [bic.py] => training => Task 2, Epoch 87/170 => Loss 0.841, Train_accy 99.700, Test_accy 67.630
2022-05-24 22:39:51,074 [bic.py] => training => Task 2, Epoch 88/170 => Loss 0.832, Train_accy 99.750, Test_accy 67.370
2022-05-24 22:39:56,433 [bic.py] => training => Task 2, Epoch 89/170 => Loss 0.839, Train_accy 99.700, Test_accy 67.500
2022-05-24 22:40:01,899 [bic.py] => training => Task 2, Epoch 90/170 => Loss 0.841, Train_accy 99.730, Test_accy 67.930
2022-05-24 22:40:07,349 [bic.py] => training => Task 2, Epoch 91/170 => Loss 0.841, Train_accy 99.570, Test_accy 67.530
2022-05-24 22:40:12,817 [bic.py] => training => Task 2, Epoch 92/170 => Loss 0.842, Train_accy 99.660, Test_accy 67.670
2022-05-24 22:40:18,439 [bic.py] => training => Task 2, Epoch 93/170 => Loss 0.838, Train_accy 99.730, Test_accy 67.430
2022-05-24 22:40:24,006 [bic.py] => training => Task 2, Epoch 94/170 => Loss 0.839, Train_accy 99.760, Test_accy 67.770
2022-05-24 22:40:29,377 [bic.py] => training => Task 2, Epoch 95/170 => Loss 0.835, Train_accy 99.730, Test_accy 67.570
2022-05-24 22:40:34,893 [bic.py] => training => Task 2, Epoch 96/170 => Loss 0.838, Train_accy 99.810, Test_accy 67.500
2022-05-24 22:40:40,315 [bic.py] => training => Task 2, Epoch 97/170 => Loss 0.836, Train_accy 99.690, Test_accy 67.800
2022-05-24 22:40:45,635 [bic.py] => training => Task 2, Epoch 98/170 => Loss 0.832, Train_accy 99.850, Test_accy 67.230
2022-05-24 22:40:51,270 [bic.py] => training => Task 2, Epoch 99/170 => Loss 0.833, Train_accy 99.690, Test_accy 67.700
2022-05-24 22:40:56,656 [bic.py] => training => Task 2, Epoch 100/170 => Loss 0.832, Train_accy 99.720, Test_accy 67.370
2022-05-24 22:41:02,016 [bic.py] => training => Task 2, Epoch 101/170 => Loss 0.831, Train_accy 99.850, Test_accy 67.470
2022-05-24 22:41:07,474 [bic.py] => training => Task 2, Epoch 102/170 => Loss 0.837, Train_accy 99.640, Test_accy 67.700
2022-05-24 22:41:12,887 [bic.py] => training => Task 2, Epoch 103/170 => Loss 0.838, Train_accy 99.810, Test_accy 67.900
2022-05-24 22:41:18,345 [bic.py] => training => Task 2, Epoch 104/170 => Loss 0.835, Train_accy 99.690, Test_accy 67.570
2022-05-24 22:41:23,825 [bic.py] => training => Task 2, Epoch 105/170 => Loss 0.837, Train_accy 99.750, Test_accy 67.430
2022-05-24 22:41:29,177 [bic.py] => training => Task 2, Epoch 106/170 => Loss 0.833, Train_accy 99.700, Test_accy 67.500
2022-05-24 22:41:34,466 [bic.py] => training => Task 2, Epoch 107/170 => Loss 0.827, Train_accy 99.730, Test_accy 67.670
2022-05-24 22:41:40,040 [bic.py] => training => Task 2, Epoch 108/170 => Loss 0.830, Train_accy 99.790, Test_accy 67.700
2022-05-24 22:41:45,479 [bic.py] => training => Task 2, Epoch 109/170 => Loss 0.832, Train_accy 99.790, Test_accy 67.400
2022-05-24 22:41:51,029 [bic.py] => training => Task 2, Epoch 110/170 => Loss 0.827, Train_accy 99.730, Test_accy 67.500
2022-05-24 22:41:56,471 [bic.py] => training => Task 2, Epoch 111/170 => Loss 0.830, Train_accy 99.670, Test_accy 67.600
2022-05-24 22:42:02,069 [bic.py] => training => Task 2, Epoch 112/170 => Loss 0.826, Train_accy 99.750, Test_accy 67.830
2022-05-24 22:42:07,714 [bic.py] => training => Task 2, Epoch 113/170 => Loss 0.832, Train_accy 99.790, Test_accy 67.430
2022-05-24 22:42:13,182 [bic.py] => training => Task 2, Epoch 114/170 => Loss 0.829, Train_accy 99.760, Test_accy 67.870
2022-05-24 22:42:18,423 [bic.py] => training => Task 2, Epoch 115/170 => Loss 0.827, Train_accy 99.780, Test_accy 67.370
2022-05-24 22:42:24,037 [bic.py] => training => Task 2, Epoch 116/170 => Loss 0.831, Train_accy 99.750, Test_accy 67.600
2022-05-24 22:42:29,389 [bic.py] => training => Task 2, Epoch 117/170 => Loss 0.829, Train_accy 99.820, Test_accy 67.500
2022-05-24 22:42:34,808 [bic.py] => training => Task 2, Epoch 118/170 => Loss 0.830, Train_accy 99.790, Test_accy 67.400
2022-05-24 22:42:40,443 [bic.py] => training => Task 2, Epoch 119/170 => Loss 0.836, Train_accy 99.720, Test_accy 67.500
2022-05-24 22:42:45,957 [bic.py] => training => Task 2, Epoch 120/170 => Loss 0.833, Train_accy 99.790, Test_accy 67.800
2022-05-24 22:42:51,442 [bic.py] => training => Task 2, Epoch 121/170 => Loss 0.826, Train_accy 99.760, Test_accy 67.070
2022-05-24 22:42:56,974 [bic.py] => training => Task 2, Epoch 122/170 => Loss 0.826, Train_accy 99.820, Test_accy 67.370
2022-05-24 22:43:02,405 [bic.py] => training => Task 2, Epoch 123/170 => Loss 0.829, Train_accy 99.730, Test_accy 67.600
2022-05-24 22:43:07,791 [bic.py] => training => Task 2, Epoch 124/170 => Loss 0.830, Train_accy 99.900, Test_accy 67.500
2022-05-24 22:43:13,520 [bic.py] => training => Task 2, Epoch 125/170 => Loss 0.829, Train_accy 99.750, Test_accy 67.830
2022-05-24 22:43:18,963 [bic.py] => training => Task 2, Epoch 126/170 => Loss 0.825, Train_accy 99.720, Test_accy 67.500
2022-05-24 22:43:24,234 [bic.py] => training => Task 2, Epoch 127/170 => Loss 0.827, Train_accy 99.760, Test_accy 67.270
2022-05-24 22:43:29,539 [bic.py] => training => Task 2, Epoch 128/170 => Loss 0.831, Train_accy 99.730, Test_accy 67.470
2022-05-24 22:43:34,858 [bic.py] => training => Task 2, Epoch 129/170 => Loss 0.834, Train_accy 99.820, Test_accy 67.430
2022-05-24 22:43:40,198 [bic.py] => training => Task 2, Epoch 130/170 => Loss 0.834, Train_accy 99.810, Test_accy 67.570
2022-05-24 22:43:45,710 [bic.py] => training => Task 2, Epoch 131/170 => Loss 0.834, Train_accy 99.790, Test_accy 67.430
2022-05-24 22:43:51,062 [bic.py] => training => Task 2, Epoch 132/170 => Loss 0.832, Train_accy 99.810, Test_accy 67.600
2022-05-24 22:43:56,519 [bic.py] => training => Task 2, Epoch 133/170 => Loss 0.835, Train_accy 99.870, Test_accy 67.570
2022-05-24 22:44:01,833 [bic.py] => training => Task 2, Epoch 134/170 => Loss 0.832, Train_accy 99.810, Test_accy 67.700
2022-05-24 22:44:07,406 [bic.py] => training => Task 2, Epoch 135/170 => Loss 0.828, Train_accy 99.820, Test_accy 67.570
2022-05-24 22:44:12,849 [bic.py] => training => Task 2, Epoch 136/170 => Loss 0.825, Train_accy 99.840, Test_accy 67.500
2022-05-24 22:44:18,370 [bic.py] => training => Task 2, Epoch 137/170 => Loss 0.830, Train_accy 99.810, Test_accy 67.530
2022-05-24 22:44:23,775 [bic.py] => training => Task 2, Epoch 138/170 => Loss 0.836, Train_accy 99.760, Test_accy 67.170
2022-05-24 22:44:29,195 [bic.py] => training => Task 2, Epoch 139/170 => Loss 0.824, Train_accy 99.880, Test_accy 67.500
2022-05-24 22:44:34,594 [bic.py] => training => Task 2, Epoch 140/170 => Loss 0.832, Train_accy 99.870, Test_accy 67.930
2022-05-24 22:44:40,192 [bic.py] => training => Task 2, Epoch 141/170 => Loss 0.832, Train_accy 99.790, Test_accy 67.530
2022-05-24 22:44:45,521 [bic.py] => training => Task 2, Epoch 142/170 => Loss 0.830, Train_accy 99.720, Test_accy 67.430
2022-05-24 22:44:51,203 [bic.py] => training => Task 2, Epoch 143/170 => Loss 0.826, Train_accy 99.840, Test_accy 67.730
2022-05-24 22:44:56,759 [bic.py] => training => Task 2, Epoch 144/170 => Loss 0.828, Train_accy 99.760, Test_accy 67.570
2022-05-24 22:45:02,198 [bic.py] => training => Task 2, Epoch 145/170 => Loss 0.827, Train_accy 99.750, Test_accy 67.470
2022-05-24 22:45:07,782 [bic.py] => training => Task 2, Epoch 146/170 => Loss 0.830, Train_accy 99.730, Test_accy 67.430
2022-05-24 22:45:13,121 [bic.py] => training => Task 2, Epoch 147/170 => Loss 0.834, Train_accy 99.760, Test_accy 67.500
2022-05-24 22:45:18,818 [bic.py] => training => Task 2, Epoch 148/170 => Loss 0.831, Train_accy 99.790, Test_accy 67.530
2022-05-24 22:45:24,301 [bic.py] => training => Task 2, Epoch 149/170 => Loss 0.828, Train_accy 99.720, Test_accy 67.730
2022-05-24 22:45:29,753 [bic.py] => training => Task 2, Epoch 150/170 => Loss 0.832, Train_accy 99.730, Test_accy 67.770
2022-05-24 22:45:35,076 [bic.py] => training => Task 2, Epoch 151/170 => Loss 0.836, Train_accy 99.760, Test_accy 67.400
2022-05-24 22:45:40,727 [bic.py] => training => Task 2, Epoch 152/170 => Loss 0.826, Train_accy 99.780, Test_accy 67.330
2022-05-24 22:45:46,086 [bic.py] => training => Task 2, Epoch 153/170 => Loss 0.825, Train_accy 99.760, Test_accy 67.470
2022-05-24 22:45:51,505 [bic.py] => training => Task 2, Epoch 154/170 => Loss 0.828, Train_accy 99.810, Test_accy 67.470
2022-05-24 22:45:57,074 [bic.py] => training => Task 2, Epoch 155/170 => Loss 0.830, Train_accy 99.810, Test_accy 67.370
2022-05-24 22:46:02,506 [bic.py] => training => Task 2, Epoch 156/170 => Loss 0.833, Train_accy 99.780, Test_accy 67.730
2022-05-24 22:46:07,789 [bic.py] => training => Task 2, Epoch 157/170 => Loss 0.834, Train_accy 99.810, Test_accy 67.400
2022-05-24 22:46:13,313 [bic.py] => training => Task 2, Epoch 158/170 => Loss 0.831, Train_accy 99.810, Test_accy 67.500
2022-05-24 22:46:18,581 [bic.py] => training => Task 2, Epoch 159/170 => Loss 0.832, Train_accy 99.820, Test_accy 67.330
2022-05-24 22:46:24,165 [bic.py] => training => Task 2, Epoch 160/170 => Loss 0.828, Train_accy 99.850, Test_accy 67.270
2022-05-24 22:46:29,387 [bic.py] => training => Task 2, Epoch 161/170 => Loss 0.831, Train_accy 99.810, Test_accy 67.400
2022-05-24 22:46:34,624 [bic.py] => training => Task 2, Epoch 162/170 => Loss 0.822, Train_accy 99.730, Test_accy 67.530
2022-05-24 22:46:40,029 [bic.py] => training => Task 2, Epoch 163/170 => Loss 0.827, Train_accy 99.820, Test_accy 67.530
2022-05-24 22:46:45,314 [bic.py] => training => Task 2, Epoch 164/170 => Loss 0.828, Train_accy 99.840, Test_accy 67.830
2022-05-24 22:46:50,584 [bic.py] => training => Task 2, Epoch 165/170 => Loss 0.829, Train_accy 99.840, Test_accy 67.570
2022-05-24 22:46:55,789 [bic.py] => training => Task 2, Epoch 166/170 => Loss 0.830, Train_accy 99.810, Test_accy 67.670
2022-05-24 22:47:01,003 [bic.py] => training => Task 2, Epoch 167/170 => Loss 0.836, Train_accy 99.780, Test_accy 67.900
2022-05-24 22:47:06,250 [bic.py] => training => Task 2, Epoch 168/170 => Loss 0.829, Train_accy 99.790, Test_accy 67.230
2022-05-24 22:47:11,395 [bic.py] => training => Task 2, Epoch 169/170 => Loss 0.826, Train_accy 99.760, Test_accy 67.500
2022-05-24 22:47:16,748 [bic.py] => training => Task 2, Epoch 170/170 => Loss 0.834, Train_accy 99.790, Test_accy 67.630
2022-05-24 22:47:18,393 [bic.py] => bias_correction => Task 2, Epoch 1/170 => Loss 2.754, Train_accy 82.330, Test_accy 70.430
2022-05-24 22:47:19,917 [bic.py] => bias_correction => Task 2, Epoch 2/170 => Loss 2.733, Train_accy 76.000, Test_accy 65.670
2022-05-24 22:47:21,498 [bic.py] => bias_correction => Task 2, Epoch 3/170 => Loss 2.746, Train_accy 79.670, Test_accy 67.570
2022-05-24 22:47:23,037 [bic.py] => bias_correction => Task 2, Epoch 4/170 => Loss 2.711, Train_accy 79.670, Test_accy 70.170
2022-05-24 22:47:24,718 [bic.py] => bias_correction => Task 2, Epoch 5/170 => Loss 2.727, Train_accy 79.000, Test_accy 69.600
2022-05-24 22:47:26,307 [bic.py] => bias_correction => Task 2, Epoch 6/170 => Loss 2.708, Train_accy 80.330, Test_accy 70.800
2022-05-24 22:47:27,854 [bic.py] => bias_correction => Task 2, Epoch 7/170 => Loss 2.698, Train_accy 78.330, Test_accy 67.530
2022-05-24 22:47:29,416 [bic.py] => bias_correction => Task 2, Epoch 8/170 => Loss 2.720, Train_accy 82.670, Test_accy 69.830
2022-05-24 22:47:31,051 [bic.py] => bias_correction => Task 2, Epoch 9/170 => Loss 2.733, Train_accy 81.670, Test_accy 70.330
2022-05-24 22:47:32,659 [bic.py] => bias_correction => Task 2, Epoch 10/170 => Loss 2.698, Train_accy 81.330, Test_accy 70.530
2022-05-24 22:47:34,280 [bic.py] => bias_correction => Task 2, Epoch 11/170 => Loss 2.689, Train_accy 81.000, Test_accy 69.730
2022-05-24 22:47:35,824 [bic.py] => bias_correction => Task 2, Epoch 12/170 => Loss 2.723, Train_accy 81.670, Test_accy 70.130
2022-05-24 22:47:37,393 [bic.py] => bias_correction => Task 2, Epoch 13/170 => Loss 2.716, Train_accy 82.330, Test_accy 70.500
2022-05-24 22:47:38,986 [bic.py] => bias_correction => Task 2, Epoch 14/170 => Loss 2.689, Train_accy 82.670, Test_accy 70.700
2022-05-24 22:47:40,562 [bic.py] => bias_correction => Task 2, Epoch 15/170 => Loss 2.727, Train_accy 83.000, Test_accy 70.630
2022-05-24 22:47:42,199 [bic.py] => bias_correction => Task 2, Epoch 16/170 => Loss 2.697, Train_accy 80.000, Test_accy 70.600
2022-05-24 22:47:43,697 [bic.py] => bias_correction => Task 2, Epoch 17/170 => Loss 2.724, Train_accy 79.670, Test_accy 70.630
2022-05-24 22:47:45,298 [bic.py] => bias_correction => Task 2, Epoch 18/170 => Loss 2.704, Train_accy 82.330, Test_accy 70.600
2022-05-24 22:47:46,862 [bic.py] => bias_correction => Task 2, Epoch 19/170 => Loss 2.691, Train_accy 79.670, Test_accy 70.830
2022-05-24 22:47:48,448 [bic.py] => bias_correction => Task 2, Epoch 20/170 => Loss 2.686, Train_accy 79.670, Test_accy 70.700
2022-05-24 22:47:50,020 [bic.py] => bias_correction => Task 2, Epoch 21/170 => Loss 2.693, Train_accy 82.330, Test_accy 70.330
2022-05-24 22:47:51,633 [bic.py] => bias_correction => Task 2, Epoch 22/170 => Loss 2.707, Train_accy 82.000, Test_accy 70.730
2022-05-24 22:47:53,329 [bic.py] => bias_correction => Task 2, Epoch 23/170 => Loss 2.707, Train_accy 83.330, Test_accy 70.630
2022-05-24 22:47:54,983 [bic.py] => bias_correction => Task 2, Epoch 24/170 => Loss 2.704, Train_accy 83.670, Test_accy 70.330
2022-05-24 22:47:56,610 [bic.py] => bias_correction => Task 2, Epoch 25/170 => Loss 2.706, Train_accy 83.000, Test_accy 70.200
2022-05-24 22:47:58,174 [bic.py] => bias_correction => Task 2, Epoch 26/170 => Loss 2.685, Train_accy 81.330, Test_accy 70.700
2022-05-24 22:47:59,771 [bic.py] => bias_correction => Task 2, Epoch 27/170 => Loss 2.701, Train_accy 80.000, Test_accy 70.830
2022-05-24 22:48:01,267 [bic.py] => bias_correction => Task 2, Epoch 28/170 => Loss 2.694, Train_accy 81.000, Test_accy 70.970
2022-05-24 22:48:02,871 [bic.py] => bias_correction => Task 2, Epoch 29/170 => Loss 2.709, Train_accy 80.000, Test_accy 70.470
2022-05-24 22:48:04,494 [bic.py] => bias_correction => Task 2, Epoch 30/170 => Loss 2.705, Train_accy 81.670, Test_accy 70.500
2022-05-24 22:48:06,118 [bic.py] => bias_correction => Task 2, Epoch 31/170 => Loss 2.697, Train_accy 81.000, Test_accy 70.030
2022-05-24 22:48:07,631 [bic.py] => bias_correction => Task 2, Epoch 32/170 => Loss 2.711, Train_accy 80.670, Test_accy 69.930
2022-05-24 22:48:09,211 [bic.py] => bias_correction => Task 2, Epoch 33/170 => Loss 2.700, Train_accy 81.670, Test_accy 70.600
2022-05-24 22:48:10,859 [bic.py] => bias_correction => Task 2, Epoch 34/170 => Loss 2.699, Train_accy 80.330, Test_accy 70.730
2022-05-24 22:48:12,500 [bic.py] => bias_correction => Task 2, Epoch 35/170 => Loss 2.695, Train_accy 80.670, Test_accy 70.430
2022-05-24 22:48:14,231 [bic.py] => bias_correction => Task 2, Epoch 36/170 => Loss 2.695, Train_accy 83.000, Test_accy 70.130
2022-05-24 22:48:15,806 [bic.py] => bias_correction => Task 2, Epoch 37/170 => Loss 2.711, Train_accy 81.000, Test_accy 70.530
2022-05-24 22:48:17,347 [bic.py] => bias_correction => Task 2, Epoch 38/170 => Loss 2.691, Train_accy 81.670, Test_accy 70.770
2022-05-24 22:48:18,987 [bic.py] => bias_correction => Task 2, Epoch 39/170 => Loss 2.706, Train_accy 81.330, Test_accy 70.200
2022-05-24 22:48:20,703 [bic.py] => bias_correction => Task 2, Epoch 40/170 => Loss 2.705, Train_accy 83.330, Test_accy 70.270
2022-05-24 22:48:22,368 [bic.py] => bias_correction => Task 2, Epoch 41/170 => Loss 2.699, Train_accy 81.000, Test_accy 70.670
2022-05-24 22:48:23,941 [bic.py] => bias_correction => Task 2, Epoch 42/170 => Loss 2.689, Train_accy 82.670, Test_accy 70.570
2022-05-24 22:48:25,558 [bic.py] => bias_correction => Task 2, Epoch 43/170 => Loss 2.689, Train_accy 81.330, Test_accy 70.370
2022-05-24 22:48:27,114 [bic.py] => bias_correction => Task 2, Epoch 44/170 => Loss 2.695, Train_accy 82.000, Test_accy 70.200
2022-05-24 22:48:28,639 [bic.py] => bias_correction => Task 2, Epoch 45/170 => Loss 2.684, Train_accy 83.000, Test_accy 70.530
2022-05-24 22:48:30,183 [bic.py] => bias_correction => Task 2, Epoch 46/170 => Loss 2.703, Train_accy 83.000, Test_accy 70.730
2022-05-24 22:48:31,744 [bic.py] => bias_correction => Task 2, Epoch 47/170 => Loss 2.689, Train_accy 81.330, Test_accy 70.630
2022-05-24 22:48:33,391 [bic.py] => bias_correction => Task 2, Epoch 48/170 => Loss 2.712, Train_accy 81.000, Test_accy 70.670
2022-05-24 22:48:35,009 [bic.py] => bias_correction => Task 2, Epoch 49/170 => Loss 2.692, Train_accy 79.330, Test_accy 70.100
2022-05-24 22:48:36,599 [bic.py] => bias_correction => Task 2, Epoch 50/170 => Loss 2.684, Train_accy 83.670, Test_accy 70.900
2022-05-24 22:48:38,185 [bic.py] => bias_correction => Task 2, Epoch 51/170 => Loss 2.701, Train_accy 81.670, Test_accy 71.130
2022-05-24 22:48:39,765 [bic.py] => bias_correction => Task 2, Epoch 52/170 => Loss 2.690, Train_accy 82.000, Test_accy 70.730
2022-05-24 22:48:41,332 [bic.py] => bias_correction => Task 2, Epoch 53/170 => Loss 2.705, Train_accy 81.000, Test_accy 70.430
2022-05-24 22:48:42,926 [bic.py] => bias_correction => Task 2, Epoch 54/170 => Loss 2.684, Train_accy 83.000, Test_accy 70.770
2022-05-24 22:48:44,514 [bic.py] => bias_correction => Task 2, Epoch 55/170 => Loss 2.723, Train_accy 80.670, Test_accy 70.530
2022-05-24 22:48:46,140 [bic.py] => bias_correction => Task 2, Epoch 56/170 => Loss 2.709, Train_accy 82.000, Test_accy 70.600
2022-05-24 22:48:47,734 [bic.py] => bias_correction => Task 2, Epoch 57/170 => Loss 2.702, Train_accy 84.330, Test_accy 70.870
2022-05-24 22:48:49,312 [bic.py] => bias_correction => Task 2, Epoch 58/170 => Loss 2.705, Train_accy 81.330, Test_accy 70.870
2022-05-24 22:48:50,841 [bic.py] => bias_correction => Task 2, Epoch 59/170 => Loss 2.698, Train_accy 80.000, Test_accy 69.930
2022-05-24 22:48:52,445 [bic.py] => bias_correction => Task 2, Epoch 60/170 => Loss 2.727, Train_accy 82.670, Test_accy 70.000
2022-05-24 22:48:54,043 [bic.py] => bias_correction => Task 2, Epoch 61/170 => Loss 2.706, Train_accy 80.330, Test_accy 70.530
2022-05-24 22:48:55,675 [bic.py] => bias_correction => Task 2, Epoch 62/170 => Loss 2.698, Train_accy 80.670, Test_accy 70.630
2022-05-24 22:48:57,271 [bic.py] => bias_correction => Task 2, Epoch 63/170 => Loss 2.710, Train_accy 84.330, Test_accy 70.700
2022-05-24 22:48:58,840 [bic.py] => bias_correction => Task 2, Epoch 64/170 => Loss 2.684, Train_accy 82.670, Test_accy 70.730
2022-05-24 22:49:00,413 [bic.py] => bias_correction => Task 2, Epoch 65/170 => Loss 2.709, Train_accy 80.670, Test_accy 70.830
2022-05-24 22:49:01,982 [bic.py] => bias_correction => Task 2, Epoch 66/170 => Loss 2.718, Train_accy 80.670, Test_accy 70.800
2022-05-24 22:49:03,577 [bic.py] => bias_correction => Task 2, Epoch 67/170 => Loss 2.702, Train_accy 80.330, Test_accy 70.930
2022-05-24 22:49:05,158 [bic.py] => bias_correction => Task 2, Epoch 68/170 => Loss 2.697, Train_accy 85.000, Test_accy 70.830
2022-05-24 22:49:06,755 [bic.py] => bias_correction => Task 2, Epoch 69/170 => Loss 2.699, Train_accy 79.330, Test_accy 70.730
2022-05-24 22:49:08,410 [bic.py] => bias_correction => Task 2, Epoch 70/170 => Loss 2.703, Train_accy 80.000, Test_accy 70.670
2022-05-24 22:49:10,068 [bic.py] => bias_correction => Task 2, Epoch 71/170 => Loss 2.682, Train_accy 84.000, Test_accy 70.670
2022-05-24 22:49:11,732 [bic.py] => bias_correction => Task 2, Epoch 72/170 => Loss 2.689, Train_accy 80.000, Test_accy 70.670
2022-05-24 22:49:13,327 [bic.py] => bias_correction => Task 2, Epoch 73/170 => Loss 2.683, Train_accy 82.670, Test_accy 70.630
2022-05-24 22:49:14,881 [bic.py] => bias_correction => Task 2, Epoch 74/170 => Loss 2.681, Train_accy 82.670, Test_accy 70.570
2022-05-24 22:49:16,544 [bic.py] => bias_correction => Task 2, Epoch 75/170 => Loss 2.689, Train_accy 82.670, Test_accy 70.730
2022-05-24 22:49:18,236 [bic.py] => bias_correction => Task 2, Epoch 76/170 => Loss 2.708, Train_accy 81.670, Test_accy 70.700
2022-05-24 22:49:19,791 [bic.py] => bias_correction => Task 2, Epoch 77/170 => Loss 2.710, Train_accy 82.670, Test_accy 70.670
2022-05-24 22:49:21,369 [bic.py] => bias_correction => Task 2, Epoch 78/170 => Loss 2.706, Train_accy 81.000, Test_accy 70.700
2022-05-24 22:49:22,933 [bic.py] => bias_correction => Task 2, Epoch 79/170 => Loss 2.697, Train_accy 82.000, Test_accy 70.800
2022-05-24 22:49:24,482 [bic.py] => bias_correction => Task 2, Epoch 80/170 => Loss 2.696, Train_accy 83.670, Test_accy 70.770
2022-05-24 22:49:26,063 [bic.py] => bias_correction => Task 2, Epoch 81/170 => Loss 2.699, Train_accy 80.330, Test_accy 70.770
2022-05-24 22:49:27,688 [bic.py] => bias_correction => Task 2, Epoch 82/170 => Loss 2.695, Train_accy 82.000, Test_accy 70.800
2022-05-24 22:49:29,276 [bic.py] => bias_correction => Task 2, Epoch 83/170 => Loss 2.660, Train_accy 81.330, Test_accy 71.000
2022-05-24 22:49:30,818 [bic.py] => bias_correction => Task 2, Epoch 84/170 => Loss 2.710, Train_accy 81.330, Test_accy 70.870
2022-05-24 22:49:32,431 [bic.py] => bias_correction => Task 2, Epoch 85/170 => Loss 2.676, Train_accy 82.330, Test_accy 70.970
2022-05-24 22:49:34,011 [bic.py] => bias_correction => Task 2, Epoch 86/170 => Loss 2.707, Train_accy 82.670, Test_accy 70.770
2022-05-24 22:49:35,639 [bic.py] => bias_correction => Task 2, Epoch 87/170 => Loss 2.689, Train_accy 82.000, Test_accy 70.870
2022-05-24 22:49:37,236 [bic.py] => bias_correction => Task 2, Epoch 88/170 => Loss 2.705, Train_accy 82.670, Test_accy 70.930
2022-05-24 22:49:38,813 [bic.py] => bias_correction => Task 2, Epoch 89/170 => Loss 2.692, Train_accy 84.000, Test_accy 70.770
2022-05-24 22:49:40,318 [bic.py] => bias_correction => Task 2, Epoch 90/170 => Loss 2.671, Train_accy 81.670, Test_accy 70.930
2022-05-24 22:49:41,863 [bic.py] => bias_correction => Task 2, Epoch 91/170 => Loss 2.699, Train_accy 82.670, Test_accy 70.830
2022-05-24 22:49:43,456 [bic.py] => bias_correction => Task 2, Epoch 92/170 => Loss 2.709, Train_accy 79.670, Test_accy 70.800
2022-05-24 22:49:45,076 [bic.py] => bias_correction => Task 2, Epoch 93/170 => Loss 2.698, Train_accy 80.330, Test_accy 70.630
2022-05-24 22:49:46,646 [bic.py] => bias_correction => Task 2, Epoch 94/170 => Loss 2.688, Train_accy 81.330, Test_accy 70.900
2022-05-24 22:49:48,271 [bic.py] => bias_correction => Task 2, Epoch 95/170 => Loss 2.699, Train_accy 83.330, Test_accy 70.770
2022-05-24 22:49:49,881 [bic.py] => bias_correction => Task 2, Epoch 96/170 => Loss 2.696, Train_accy 82.670, Test_accy 70.830
2022-05-24 22:49:51,478 [bic.py] => bias_correction => Task 2, Epoch 97/170 => Loss 2.689, Train_accy 80.330, Test_accy 70.670
2022-05-24 22:49:53,059 [bic.py] => bias_correction => Task 2, Epoch 98/170 => Loss 2.696, Train_accy 80.000, Test_accy 70.630
2022-05-24 22:49:54,696 [bic.py] => bias_correction => Task 2, Epoch 99/170 => Loss 2.717, Train_accy 80.670, Test_accy 70.470
2022-05-24 22:49:56,305 [bic.py] => bias_correction => Task 2, Epoch 100/170 => Loss 2.721, Train_accy 81.000, Test_accy 70.330
2022-05-24 22:49:57,952 [bic.py] => bias_correction => Task 2, Epoch 101/170 => Loss 2.706, Train_accy 81.670, Test_accy 70.330
2022-05-24 22:49:59,676 [bic.py] => bias_correction => Task 2, Epoch 102/170 => Loss 2.678, Train_accy 80.330, Test_accy 70.430
2022-05-24 22:50:01,310 [bic.py] => bias_correction => Task 2, Epoch 103/170 => Loss 2.713, Train_accy 82.000, Test_accy 70.570
2022-05-24 22:50:02,867 [bic.py] => bias_correction => Task 2, Epoch 104/170 => Loss 2.685, Train_accy 80.670, Test_accy 70.570
2022-05-24 22:50:04,440 [bic.py] => bias_correction => Task 2, Epoch 105/170 => Loss 2.676, Train_accy 77.000, Test_accy 70.500
2022-05-24 22:50:06,060 [bic.py] => bias_correction => Task 2, Epoch 106/170 => Loss 2.675, Train_accy 81.670, Test_accy 70.500
2022-05-24 22:50:07,639 [bic.py] => bias_correction => Task 2, Epoch 107/170 => Loss 2.702, Train_accy 83.000, Test_accy 70.570
2022-05-24 22:50:09,240 [bic.py] => bias_correction => Task 2, Epoch 108/170 => Loss 2.700, Train_accy 82.000, Test_accy 70.600
2022-05-24 22:50:10,784 [bic.py] => bias_correction => Task 2, Epoch 109/170 => Loss 2.710, Train_accy 81.000, Test_accy 70.800
2022-05-24 22:50:12,393 [bic.py] => bias_correction => Task 2, Epoch 110/170 => Loss 2.712, Train_accy 81.330, Test_accy 70.870
2022-05-24 22:50:13,945 [bic.py] => bias_correction => Task 2, Epoch 111/170 => Loss 2.691, Train_accy 80.330, Test_accy 70.900
2022-05-24 22:50:15,568 [bic.py] => bias_correction => Task 2, Epoch 112/170 => Loss 2.699, Train_accy 80.670, Test_accy 70.700
2022-05-24 22:50:17,094 [bic.py] => bias_correction => Task 2, Epoch 113/170 => Loss 2.704, Train_accy 80.670, Test_accy 70.830
2022-05-24 22:50:18,635 [bic.py] => bias_correction => Task 2, Epoch 114/170 => Loss 2.672, Train_accy 83.330, Test_accy 70.670
2022-05-24 22:50:20,165 [bic.py] => bias_correction => Task 2, Epoch 115/170 => Loss 2.689, Train_accy 81.330, Test_accy 70.530
2022-05-24 22:50:21,721 [bic.py] => bias_correction => Task 2, Epoch 116/170 => Loss 2.660, Train_accy 83.000, Test_accy 70.600
2022-05-24 22:50:23,290 [bic.py] => bias_correction => Task 2, Epoch 117/170 => Loss 2.692, Train_accy 82.670, Test_accy 70.930
2022-05-24 22:50:24,884 [bic.py] => bias_correction => Task 2, Epoch 118/170 => Loss 2.705, Train_accy 82.670, Test_accy 70.770
2022-05-24 22:50:26,475 [bic.py] => bias_correction => Task 2, Epoch 119/170 => Loss 2.707, Train_accy 80.670, Test_accy 70.630
2022-05-24 22:50:27,980 [bic.py] => bias_correction => Task 2, Epoch 120/170 => Loss 2.674, Train_accy 84.330, Test_accy 70.670
2022-05-24 22:50:29,640 [bic.py] => bias_correction => Task 2, Epoch 121/170 => Loss 2.661, Train_accy 80.670, Test_accy 70.770
2022-05-24 22:50:31,316 [bic.py] => bias_correction => Task 2, Epoch 122/170 => Loss 2.675, Train_accy 82.000, Test_accy 70.770
2022-05-24 22:50:32,846 [bic.py] => bias_correction => Task 2, Epoch 123/170 => Loss 2.691, Train_accy 82.330, Test_accy 70.730
2022-05-24 22:50:34,358 [bic.py] => bias_correction => Task 2, Epoch 124/170 => Loss 2.706, Train_accy 79.670, Test_accy 70.700
2022-05-24 22:50:35,939 [bic.py] => bias_correction => Task 2, Epoch 125/170 => Loss 2.699, Train_accy 80.670, Test_accy 70.670
2022-05-24 22:50:37,428 [bic.py] => bias_correction => Task 2, Epoch 126/170 => Loss 2.707, Train_accy 83.000, Test_accy 70.770
2022-05-24 22:50:39,022 [bic.py] => bias_correction => Task 2, Epoch 127/170 => Loss 2.688, Train_accy 82.670, Test_accy 70.630
2022-05-24 22:50:40,604 [bic.py] => bias_correction => Task 2, Epoch 128/170 => Loss 2.684, Train_accy 81.000, Test_accy 70.900
2022-05-24 22:50:42,242 [bic.py] => bias_correction => Task 2, Epoch 129/170 => Loss 2.685, Train_accy 82.670, Test_accy 70.770
2022-05-24 22:50:43,827 [bic.py] => bias_correction => Task 2, Epoch 130/170 => Loss 2.682, Train_accy 82.670, Test_accy 70.700
2022-05-24 22:50:45,465 [bic.py] => bias_correction => Task 2, Epoch 131/170 => Loss 2.730, Train_accy 83.000, Test_accy 70.500
2022-05-24 22:50:47,091 [bic.py] => bias_correction => Task 2, Epoch 132/170 => Loss 2.695, Train_accy 80.330, Test_accy 70.630
2022-05-24 22:50:48,686 [bic.py] => bias_correction => Task 2, Epoch 133/170 => Loss 2.689, Train_accy 85.670, Test_accy 70.530
2022-05-24 22:50:50,316 [bic.py] => bias_correction => Task 2, Epoch 134/170 => Loss 2.702, Train_accy 79.330, Test_accy 70.570
2022-05-24 22:50:51,901 [bic.py] => bias_correction => Task 2, Epoch 135/170 => Loss 2.700, Train_accy 83.330, Test_accy 70.600
2022-05-24 22:50:53,515 [bic.py] => bias_correction => Task 2, Epoch 136/170 => Loss 2.704, Train_accy 79.330, Test_accy 70.600
2022-05-24 22:50:55,154 [bic.py] => bias_correction => Task 2, Epoch 137/170 => Loss 2.691, Train_accy 81.000, Test_accy 70.400
2022-05-24 22:50:56,771 [bic.py] => bias_correction => Task 2, Epoch 138/170 => Loss 2.702, Train_accy 82.330, Test_accy 70.530
2022-05-24 22:50:58,351 [bic.py] => bias_correction => Task 2, Epoch 139/170 => Loss 2.686, Train_accy 82.670, Test_accy 70.500
2022-05-24 22:50:59,907 [bic.py] => bias_correction => Task 2, Epoch 140/170 => Loss 2.690, Train_accy 79.000, Test_accy 70.570
2022-05-24 22:51:01,506 [bic.py] => bias_correction => Task 2, Epoch 141/170 => Loss 2.696, Train_accy 81.670, Test_accy 70.570
2022-05-24 22:51:03,035 [bic.py] => bias_correction => Task 2, Epoch 142/170 => Loss 2.698, Train_accy 81.330, Test_accy 70.700
2022-05-24 22:51:04,598 [bic.py] => bias_correction => Task 2, Epoch 143/170 => Loss 2.687, Train_accy 78.670, Test_accy 70.770
2022-05-24 22:51:06,245 [bic.py] => bias_correction => Task 2, Epoch 144/170 => Loss 2.699, Train_accy 80.670, Test_accy 70.700
2022-05-24 22:51:07,850 [bic.py] => bias_correction => Task 2, Epoch 145/170 => Loss 2.680, Train_accy 81.000, Test_accy 70.770
2022-05-24 22:51:09,428 [bic.py] => bias_correction => Task 2, Epoch 146/170 => Loss 2.697, Train_accy 81.330, Test_accy 70.770
2022-05-24 22:51:10,993 [bic.py] => bias_correction => Task 2, Epoch 147/170 => Loss 2.712, Train_accy 81.000, Test_accy 70.830
2022-05-24 22:51:12,550 [bic.py] => bias_correction => Task 2, Epoch 148/170 => Loss 2.715, Train_accy 82.670, Test_accy 70.770
2022-05-24 22:51:14,113 [bic.py] => bias_correction => Task 2, Epoch 149/170 => Loss 2.696, Train_accy 84.000, Test_accy 70.630
2022-05-24 22:51:15,771 [bic.py] => bias_correction => Task 2, Epoch 150/170 => Loss 2.687, Train_accy 79.330, Test_accy 70.700
2022-05-24 22:51:17,408 [bic.py] => bias_correction => Task 2, Epoch 151/170 => Loss 2.691, Train_accy 83.330, Test_accy 70.770
2022-05-24 22:51:19,029 [bic.py] => bias_correction => Task 2, Epoch 152/170 => Loss 2.684, Train_accy 79.670, Test_accy 70.600
2022-05-24 22:51:20,697 [bic.py] => bias_correction => Task 2, Epoch 153/170 => Loss 2.683, Train_accy 82.000, Test_accy 70.770
2022-05-24 22:51:22,296 [bic.py] => bias_correction => Task 2, Epoch 154/170 => Loss 2.706, Train_accy 82.330, Test_accy 70.630
2022-05-24 22:51:23,935 [bic.py] => bias_correction => Task 2, Epoch 155/170 => Loss 2.710, Train_accy 79.670, Test_accy 70.530
2022-05-24 22:51:25,670 [bic.py] => bias_correction => Task 2, Epoch 156/170 => Loss 2.677, Train_accy 82.670, Test_accy 70.530
2022-05-24 22:51:27,272 [bic.py] => bias_correction => Task 2, Epoch 157/170 => Loss 2.667, Train_accy 82.670, Test_accy 70.630
2022-05-24 22:51:28,861 [bic.py] => bias_correction => Task 2, Epoch 158/170 => Loss 2.695, Train_accy 81.000, Test_accy 70.730
2022-05-24 22:51:30,434 [bic.py] => bias_correction => Task 2, Epoch 159/170 => Loss 2.681, Train_accy 83.330, Test_accy 70.630
2022-05-24 22:51:32,093 [bic.py] => bias_correction => Task 2, Epoch 160/170 => Loss 2.670, Train_accy 82.330, Test_accy 70.630
2022-05-24 22:51:33,670 [bic.py] => bias_correction => Task 2, Epoch 161/170 => Loss 2.702, Train_accy 80.330, Test_accy 70.530
2022-05-24 22:51:35,415 [bic.py] => bias_correction => Task 2, Epoch 162/170 => Loss 2.692, Train_accy 80.330, Test_accy 70.670
2022-05-24 22:51:37,033 [bic.py] => bias_correction => Task 2, Epoch 163/170 => Loss 2.692, Train_accy 81.330, Test_accy 70.470
2022-05-24 22:51:38,686 [bic.py] => bias_correction => Task 2, Epoch 164/170 => Loss 2.652, Train_accy 80.670, Test_accy 70.470
2022-05-24 22:51:40,342 [bic.py] => bias_correction => Task 2, Epoch 165/170 => Loss 2.709, Train_accy 81.670, Test_accy 70.470
2022-05-24 22:51:41,990 [bic.py] => bias_correction => Task 2, Epoch 166/170 => Loss 2.685, Train_accy 83.670, Test_accy 70.570
2022-05-24 22:51:43,665 [bic.py] => bias_correction => Task 2, Epoch 167/170 => Loss 2.685, Train_accy 80.670, Test_accy 70.630
2022-05-24 22:51:45,323 [bic.py] => bias_correction => Task 2, Epoch 168/170 => Loss 2.682, Train_accy 83.330, Test_accy 70.770
2022-05-24 22:51:46,989 [bic.py] => bias_correction => Task 2, Epoch 169/170 => Loss 2.685, Train_accy 81.330, Test_accy 70.600
2022-05-24 22:51:48,649 [bic.py] => bias_correction => Task 2, Epoch 170/170 => Loss 2.674, Train_accy 82.330, Test_accy 70.600
2022-05-24 22:51:48,650 [base.py] => Reducing exemplars...(66 per classes)
2022-05-24 22:51:53,303 [base.py] => Constructing exemplars...(66 per classes)
2022-05-24 22:51:59,227 [bic.py] => Parameters of bias layer:
2022-05-24 22:51:59,228 [bic.py] => 0 => 1.000, 0.000
2022-05-24 22:51:59,228 [bic.py] => 1 => 0.981, -1.523
2022-05-24 22:51:59,228 [bic.py] => 2 => 0.816, -1.587
2022-05-24 22:52:00,622 [bic.py] => Exemplar size: 1980
2022-05-24 22:52:00,622 [trainer.py] => CNN: {'total': 70.6, '00-09': 74.8, '10-19': 65.3, '20-29': 71.7, 'old': 70.05, 'new': 71.7}
2022-05-24 22:52:00,622 [trainer.py] => NME: {'total': 71.27, '00-09': 74.0, '10-19': 62.5, '20-29': 77.3, 'old': 68.25, 'new': 77.3}
2022-05-24 22:52:00,623 [trainer.py] => CNN top1 curve: [87.5, 75.95, 70.6]
2022-05-24 22:52:00,623 [trainer.py] => CNN top5 curve: [99.3, 95.5, 93.17]
2022-05-24 22:52:00,623 [trainer.py] => NME top1 curve: [88.1, 75.6, 71.27]
2022-05-24 22:52:00,623 [trainer.py] => NME top5 curve: [99.4, 95.4, 93.2]

2022-05-24 22:52:00,623 [trainer.py] => All params: 466110
2022-05-24 22:52:00,624 [trainer.py] => Trainable params: 466110
2022-05-24 22:52:00,625 [bic.py] => Learning on 30-40
2022-05-24 22:52:00,688 [bic.py] => Stage1 dset: 6740, Stage2 dset: 240
2022-05-24 22:52:00,688 [bic.py] => Lambda: 0.750
2022-05-24 22:52:00,698 [bic.py] => Parameters of bias layer:
2022-05-24 22:52:00,699 [bic.py] => 0 => 1.000, 0.000
2022-05-24 22:52:00,699 [bic.py] => 1 => 0.981, -1.523
2022-05-24 22:52:00,699 [bic.py] => 2 => 0.816, -1.587
2022-05-24 22:52:00,699 [bic.py] => 3 => 1.000, 0.000
2022-05-24 22:52:06,070 [bic.py] => training => Task 3, Epoch 1/170 => Loss 1.874, Train_accy 58.070, Test_accy 43.700
2022-05-24 22:52:11,688 [bic.py] => training => Task 3, Epoch 2/170 => Loss 1.615, Train_accy 61.510, Test_accy 45.150
2022-05-24 22:52:17,100 [bic.py] => training => Task 3, Epoch 3/170 => Loss 1.579, Train_accy 73.130, Test_accy 49.800
2022-05-24 22:52:22,414 [bic.py] => training => Task 3, Epoch 4/170 => Loss 1.553, Train_accy 73.280, Test_accy 50.720
2022-05-24 22:52:27,811 [bic.py] => training => Task 3, Epoch 5/170 => Loss 1.530, Train_accy 74.850, Test_accy 50.980
2022-05-24 22:52:33,318 [bic.py] => training => Task 3, Epoch 6/170 => Loss 1.520, Train_accy 79.330, Test_accy 53.400
2022-05-24 22:52:38,644 [bic.py] => training => Task 3, Epoch 7/170 => Loss 1.511, Train_accy 77.670, Test_accy 52.000
2022-05-24 22:52:44,163 [bic.py] => training => Task 3, Epoch 8/170 => Loss 1.511, Train_accy 80.730, Test_accy 53.950
2022-05-24 22:52:49,611 [bic.py] => training => Task 3, Epoch 9/170 => Loss 1.495, Train_accy 78.180, Test_accy 50.780
2022-05-24 22:52:54,940 [bic.py] => training => Task 3, Epoch 10/170 => Loss 1.498, Train_accy 79.450, Test_accy 50.880
2022-05-24 22:53:00,513 [bic.py] => training => Task 3, Epoch 11/170 => Loss 1.490, Train_accy 80.730, Test_accy 52.450
2022-05-24 22:53:05,918 [bic.py] => training => Task 3, Epoch 12/170 => Loss 1.481, Train_accy 75.580, Test_accy 49.120
2022-05-24 22:53:11,382 [bic.py] => training => Task 3, Epoch 13/170 => Loss 1.468, Train_accy 82.090, Test_accy 50.620
2022-05-24 22:53:17,005 [bic.py] => training => Task 3, Epoch 14/170 => Loss 1.478, Train_accy 82.860, Test_accy 57.020
2022-05-24 22:53:22,545 [bic.py] => training => Task 3, Epoch 15/170 => Loss 1.477, Train_accy 83.740, Test_accy 53.900
2022-05-24 22:53:28,155 [bic.py] => training => Task 3, Epoch 16/170 => Loss 1.468, Train_accy 85.240, Test_accy 53.620
2022-05-24 22:53:33,774 [bic.py] => training => Task 3, Epoch 17/170 => Loss 1.467, Train_accy 83.800, Test_accy 53.480
2022-05-24 22:53:39,264 [bic.py] => training => Task 3, Epoch 18/170 => Loss 1.453, Train_accy 85.150, Test_accy 52.050
2022-05-24 22:53:44,855 [bic.py] => training => Task 3, Epoch 19/170 => Loss 1.458, Train_accy 87.610, Test_accy 55.020
2022-05-24 22:53:50,384 [bic.py] => training => Task 3, Epoch 20/170 => Loss 1.452, Train_accy 83.870, Test_accy 54.150
2022-05-24 22:53:55,835 [bic.py] => training => Task 3, Epoch 21/170 => Loss 1.462, Train_accy 86.070, Test_accy 52.350
2022-05-24 22:54:01,463 [bic.py] => training => Task 3, Epoch 22/170 => Loss 1.462, Train_accy 86.510, Test_accy 56.120
2022-05-24 22:54:06,896 [bic.py] => training => Task 3, Epoch 23/170 => Loss 1.454, Train_accy 88.530, Test_accy 54.480
2022-05-24 22:54:12,590 [bic.py] => training => Task 3, Epoch 24/170 => Loss 1.446, Train_accy 86.200, Test_accy 53.280
2022-05-24 22:54:17,974 [bic.py] => training => Task 3, Epoch 25/170 => Loss 1.441, Train_accy 82.760, Test_accy 51.450
2022-05-24 22:54:23,535 [bic.py] => training => Task 3, Epoch 26/170 => Loss 1.452, Train_accy 89.450, Test_accy 57.300
2022-05-24 22:54:29,299 [bic.py] => training => Task 3, Epoch 27/170 => Loss 1.438, Train_accy 88.030, Test_accy 56.380
2022-05-24 22:54:34,794 [bic.py] => training => Task 3, Epoch 28/170 => Loss 1.434, Train_accy 89.080, Test_accy 53.980
2022-05-24 22:54:40,152 [bic.py] => training => Task 3, Epoch 29/170 => Loss 1.444, Train_accy 85.520, Test_accy 50.380
2022-05-24 22:54:45,679 [bic.py] => training => Task 3, Epoch 30/170 => Loss 1.441, Train_accy 84.730, Test_accy 51.780
2022-05-24 22:54:51,164 [bic.py] => training => Task 3, Epoch 31/170 => Loss 1.441, Train_accy 89.300, Test_accy 54.600
2022-05-24 22:54:56,754 [bic.py] => training => Task 3, Epoch 32/170 => Loss 1.437, Train_accy 89.910, Test_accy 53.080
2022-05-24 22:55:02,240 [bic.py] => training => Task 3, Epoch 33/170 => Loss 1.429, Train_accy 89.910, Test_accy 55.050
2022-05-24 22:55:07,719 [bic.py] => training => Task 3, Epoch 34/170 => Loss 1.437, Train_accy 82.180, Test_accy 49.650
2022-05-24 22:55:13,497 [bic.py] => training => Task 3, Epoch 35/170 => Loss 1.439, Train_accy 87.020, Test_accy 56.900
2022-05-24 22:55:18,828 [bic.py] => training => Task 3, Epoch 36/170 => Loss 1.434, Train_accy 84.930, Test_accy 51.520
2022-05-24 22:55:24,277 [bic.py] => training => Task 3, Epoch 37/170 => Loss 1.428, Train_accy 88.280, Test_accy 51.480
2022-05-24 22:55:30,049 [bic.py] => training => Task 3, Epoch 38/170 => Loss 1.430, Train_accy 87.740, Test_accy 53.800
2022-05-24 22:55:35,533 [bic.py] => training => Task 3, Epoch 39/170 => Loss 1.421, Train_accy 91.100, Test_accy 54.300
2022-05-24 22:55:40,840 [bic.py] => training => Task 3, Epoch 40/170 => Loss 1.413, Train_accy 86.010, Test_accy 50.100
2022-05-24 22:55:46,489 [bic.py] => training => Task 3, Epoch 41/170 => Loss 1.432, Train_accy 89.780, Test_accy 53.020
2022-05-24 22:55:52,008 [bic.py] => training => Task 3, Epoch 42/170 => Loss 1.434, Train_accy 87.420, Test_accy 52.800
2022-05-24 22:55:57,497 [bic.py] => training => Task 3, Epoch 43/170 => Loss 1.428, Train_accy 85.920, Test_accy 49.980
2022-05-24 22:56:03,076 [bic.py] => training => Task 3, Epoch 44/170 => Loss 1.424, Train_accy 90.550, Test_accy 54.900
2022-05-24 22:56:08,509 [bic.py] => training => Task 3, Epoch 45/170 => Loss 1.427, Train_accy 91.160, Test_accy 54.050
2022-05-24 22:56:14,340 [bic.py] => training => Task 3, Epoch 46/170 => Loss 1.431, Train_accy 87.240, Test_accy 49.850
2022-05-24 22:56:19,762 [bic.py] => training => Task 3, Epoch 47/170 => Loss 1.420, Train_accy 91.900, Test_accy 54.950
2022-05-24 22:56:25,107 [bic.py] => training => Task 3, Epoch 48/170 => Loss 1.426, Train_accy 89.290, Test_accy 53.080
2022-05-24 22:56:30,694 [bic.py] => training => Task 3, Epoch 49/170 => Loss 1.428, Train_accy 87.580, Test_accy 51.480
2022-05-24 22:56:36,105 [bic.py] => training => Task 3, Epoch 50/170 => Loss 1.433, Train_accy 90.330, Test_accy 53.720
2022-05-24 22:56:41,476 [bic.py] => training => Task 3, Epoch 51/170 => Loss 1.425, Train_accy 86.940, Test_accy 49.980
2022-05-24 22:56:46,992 [bic.py] => training => Task 3, Epoch 52/170 => Loss 1.417, Train_accy 92.400, Test_accy 55.700
2022-05-24 22:56:52,639 [bic.py] => training => Task 3, Epoch 53/170 => Loss 1.420, Train_accy 91.970, Test_accy 55.650
2022-05-24 22:56:58,207 [bic.py] => training => Task 3, Epoch 54/170 => Loss 1.418, Train_accy 88.400, Test_accy 49.250
2022-05-24 22:57:03,610 [bic.py] => training => Task 3, Epoch 55/170 => Loss 1.427, Train_accy 91.320, Test_accy 55.200
2022-05-24 22:57:08,951 [bic.py] => training => Task 3, Epoch 56/170 => Loss 1.403, Train_accy 93.960, Test_accy 55.080
2022-05-24 22:57:14,634 [bic.py] => training => Task 3, Epoch 57/170 => Loss 1.415, Train_accy 91.500, Test_accy 54.400
2022-05-24 22:57:20,010 [bic.py] => training => Task 3, Epoch 58/170 => Loss 1.410, Train_accy 92.450, Test_accy 51.480
2022-05-24 22:57:25,477 [bic.py] => training => Task 3, Epoch 59/170 => Loss 1.417, Train_accy 90.700, Test_accy 55.520
2022-05-24 22:57:31,195 [bic.py] => training => Task 3, Epoch 60/170 => Loss 1.416, Train_accy 92.600, Test_accy 55.880
2022-05-24 22:57:36,573 [bic.py] => training => Task 3, Epoch 61/170 => Loss 1.378, Train_accy 98.280, Test_accy 58.980
2022-05-24 22:57:42,058 [bic.py] => training => Task 3, Epoch 62/170 => Loss 1.348, Train_accy 98.690, Test_accy 59.520
2022-05-24 22:57:47,740 [bic.py] => training => Task 3, Epoch 63/170 => Loss 1.349, Train_accy 98.860, Test_accy 59.150
2022-05-24 22:57:53,213 [bic.py] => training => Task 3, Epoch 64/170 => Loss 1.346, Train_accy 98.890, Test_accy 58.980
2022-05-24 22:57:58,766 [bic.py] => training => Task 3, Epoch 65/170 => Loss 1.339, Train_accy 99.180, Test_accy 59.380
2022-05-24 22:58:04,494 [bic.py] => training => Task 3, Epoch 66/170 => Loss 1.336, Train_accy 99.210, Test_accy 59.050
2022-05-24 22:58:10,010 [bic.py] => training => Task 3, Epoch 67/170 => Loss 1.339, Train_accy 99.240, Test_accy 59.420
2022-05-24 22:58:15,663 [bic.py] => training => Task 3, Epoch 68/170 => Loss 1.332, Train_accy 99.420, Test_accy 59.250
2022-05-24 22:58:21,063 [bic.py] => training => Task 3, Epoch 69/170 => Loss 1.329, Train_accy 99.320, Test_accy 59.100
2022-05-24 22:58:26,553 [bic.py] => training => Task 3, Epoch 70/170 => Loss 1.330, Train_accy 99.230, Test_accy 59.350
2022-05-24 22:58:32,099 [bic.py] => training => Task 3, Epoch 71/170 => Loss 1.332, Train_accy 99.390, Test_accy 59.700
2022-05-24 22:58:37,517 [bic.py] => training => Task 3, Epoch 72/170 => Loss 1.333, Train_accy 99.320, Test_accy 59.350
2022-05-24 22:58:42,990 [bic.py] => training => Task 3, Epoch 73/170 => Loss 1.330, Train_accy 99.410, Test_accy 59.320
2022-05-24 22:58:48,581 [bic.py] => training => Task 3, Epoch 74/170 => Loss 1.331, Train_accy 99.390, Test_accy 59.320
2022-05-24 22:58:53,930 [bic.py] => training => Task 3, Epoch 75/170 => Loss 1.325, Train_accy 99.390, Test_accy 59.320
2022-05-24 22:58:59,315 [bic.py] => training => Task 3, Epoch 76/170 => Loss 1.319, Train_accy 99.480, Test_accy 59.050
2022-05-24 22:59:04,935 [bic.py] => training => Task 3, Epoch 77/170 => Loss 1.328, Train_accy 99.440, Test_accy 59.620
2022-05-24 22:59:10,437 [bic.py] => training => Task 3, Epoch 78/170 => Loss 1.324, Train_accy 99.420, Test_accy 59.420
2022-05-24 22:59:15,884 [bic.py] => training => Task 3, Epoch 79/170 => Loss 1.329, Train_accy 99.550, Test_accy 59.320
2022-05-24 22:59:21,453 [bic.py] => training => Task 3, Epoch 80/170 => Loss 1.326, Train_accy 99.440, Test_accy 59.900
2022-05-24 22:59:26,904 [bic.py] => training => Task 3, Epoch 81/170 => Loss 1.322, Train_accy 99.550, Test_accy 59.550
2022-05-24 22:59:32,361 [bic.py] => training => Task 3, Epoch 82/170 => Loss 1.324, Train_accy 99.570, Test_accy 58.920
2022-05-24 22:59:37,886 [bic.py] => training => Task 3, Epoch 83/170 => Loss 1.325, Train_accy 99.570, Test_accy 59.480
2022-05-24 22:59:43,298 [bic.py] => training => Task 3, Epoch 84/170 => Loss 1.328, Train_accy 99.440, Test_accy 59.600
2022-05-24 22:59:48,823 [bic.py] => training => Task 3, Epoch 85/170 => Loss 1.326, Train_accy 99.540, Test_accy 59.600
2022-05-24 22:59:54,254 [bic.py] => training => Task 3, Epoch 86/170 => Loss 1.322, Train_accy 99.530, Test_accy 59.200
2022-05-24 22:59:59,679 [bic.py] => training => Task 3, Epoch 87/170 => Loss 1.325, Train_accy 99.670, Test_accy 59.650
2022-05-24 23:00:05,058 [bic.py] => training => Task 3, Epoch 88/170 => Loss 1.319, Train_accy 99.450, Test_accy 59.500
2022-05-24 23:00:10,711 [bic.py] => training => Task 3, Epoch 89/170 => Loss 1.314, Train_accy 99.630, Test_accy 59.320
2022-05-24 23:00:16,085 [bic.py] => training => Task 3, Epoch 90/170 => Loss 1.322, Train_accy 99.470, Test_accy 59.920
2022-05-24 23:00:21,697 [bic.py] => training => Task 3, Epoch 91/170 => Loss 1.324, Train_accy 99.570, Test_accy 59.780
2022-05-24 23:00:27,142 [bic.py] => training => Task 3, Epoch 92/170 => Loss 1.325, Train_accy 99.540, Test_accy 59.600
2022-05-24 23:00:32,435 [bic.py] => training => Task 3, Epoch 93/170 => Loss 1.318, Train_accy 99.610, Test_accy 59.280
2022-05-24 23:00:38,020 [bic.py] => training => Task 3, Epoch 94/170 => Loss 1.316, Train_accy 99.660, Test_accy 59.280
2022-05-24 23:00:43,626 [bic.py] => training => Task 3, Epoch 95/170 => Loss 1.317, Train_accy 99.550, Test_accy 59.220
2022-05-24 23:00:49,077 [bic.py] => training => Task 3, Epoch 96/170 => Loss 1.319, Train_accy 99.610, Test_accy 59.320
2022-05-24 23:00:54,427 [bic.py] => training => Task 3, Epoch 97/170 => Loss 1.322, Train_accy 99.480, Test_accy 59.520
2022-05-24 23:00:59,838 [bic.py] => training => Task 3, Epoch 98/170 => Loss 1.320, Train_accy 99.510, Test_accy 59.400
2022-05-24 23:01:05,459 [bic.py] => training => Task 3, Epoch 99/170 => Loss 1.317, Train_accy 99.700, Test_accy 60.220
2022-05-24 23:01:10,937 [bic.py] => training => Task 3, Epoch 100/170 => Loss 1.317, Train_accy 99.580, Test_accy 59.350
2022-05-24 23:01:16,464 [bic.py] => training => Task 3, Epoch 101/170 => Loss 1.316, Train_accy 99.610, Test_accy 59.600
2022-05-24 23:01:22,188 [bic.py] => training => Task 3, Epoch 102/170 => Loss 1.314, Train_accy 99.540, Test_accy 59.300
2022-05-24 23:01:27,641 [bic.py] => training => Task 3, Epoch 103/170 => Loss 1.316, Train_accy 99.530, Test_accy 60.050
2022-05-24 23:01:33,077 [bic.py] => training => Task 3, Epoch 104/170 => Loss 1.316, Train_accy 99.600, Test_accy 59.950
2022-05-24 23:01:38,904 [bic.py] => training => Task 3, Epoch 105/170 => Loss 1.314, Train_accy 99.610, Test_accy 59.580
2022-05-24 23:01:44,486 [bic.py] => training => Task 3, Epoch 106/170 => Loss 1.318, Train_accy 99.660, Test_accy 59.800
2022-05-24 23:01:49,814 [bic.py] => training => Task 3, Epoch 107/170 => Loss 1.307, Train_accy 99.640, Test_accy 59.780
2022-05-24 23:01:55,403 [bic.py] => training => Task 3, Epoch 108/170 => Loss 1.313, Train_accy 99.760, Test_accy 59.600
2022-05-24 23:02:00,824 [bic.py] => training => Task 3, Epoch 109/170 => Loss 1.319, Train_accy 99.720, Test_accy 59.520
2022-05-24 23:02:06,336 [bic.py] => training => Task 3, Epoch 110/170 => Loss 1.319, Train_accy 99.690, Test_accy 59.700
2022-05-24 23:02:11,892 [bic.py] => training => Task 3, Epoch 111/170 => Loss 1.314, Train_accy 99.630, Test_accy 59.850
2022-05-24 23:02:17,232 [bic.py] => training => Task 3, Epoch 112/170 => Loss 1.318, Train_accy 99.630, Test_accy 59.750
2022-05-24 23:02:22,716 [bic.py] => training => Task 3, Epoch 113/170 => Loss 1.311, Train_accy 99.500, Test_accy 59.880
2022-05-24 23:02:28,519 [bic.py] => training => Task 3, Epoch 114/170 => Loss 1.317, Train_accy 99.600, Test_accy 59.580
2022-05-24 23:02:33,880 [bic.py] => training => Task 3, Epoch 115/170 => Loss 1.318, Train_accy 99.720, Test_accy 59.600
2022-05-24 23:02:39,294 [bic.py] => training => Task 3, Epoch 116/170 => Loss 1.312, Train_accy 99.810, Test_accy 59.280
2022-05-24 23:02:44,667 [bic.py] => training => Task 3, Epoch 117/170 => Loss 1.317, Train_accy 99.630, Test_accy 59.750
2022-05-24 23:02:50,106 [bic.py] => training => Task 3, Epoch 118/170 => Loss 1.318, Train_accy 99.690, Test_accy 59.850
2022-05-24 23:02:55,369 [bic.py] => training => Task 3, Epoch 119/170 => Loss 1.315, Train_accy 99.630, Test_accy 59.650
2022-05-24 23:03:00,869 [bic.py] => training => Task 3, Epoch 120/170 => Loss 1.316, Train_accy 99.600, Test_accy 59.880
2022-05-24 23:03:06,281 [bic.py] => training => Task 3, Epoch 121/170 => Loss 1.321, Train_accy 99.730, Test_accy 59.700
2022-05-24 23:03:11,761 [bic.py] => training => Task 3, Epoch 122/170 => Loss 1.319, Train_accy 99.690, Test_accy 59.700
2022-05-24 23:03:17,139 [bic.py] => training => Task 3, Epoch 123/170 => Loss 1.316, Train_accy 99.550, Test_accy 59.650
2022-05-24 23:03:22,466 [bic.py] => training => Task 3, Epoch 124/170 => Loss 1.318, Train_accy 99.610, Test_accy 59.880
2022-05-24 23:03:27,820 [bic.py] => training => Task 3, Epoch 125/170 => Loss 1.313, Train_accy 99.580, Test_accy 59.600
2022-05-24 23:03:33,266 [bic.py] => training => Task 3, Epoch 126/170 => Loss 1.314, Train_accy 99.750, Test_accy 59.750
2022-05-24 23:03:38,793 [bic.py] => training => Task 3, Epoch 127/170 => Loss 1.318, Train_accy 99.690, Test_accy 59.580
2022-05-24 23:03:44,140 [bic.py] => training => Task 3, Epoch 128/170 => Loss 1.311, Train_accy 99.580, Test_accy 59.350
2022-05-24 23:03:49,454 [bic.py] => training => Task 3, Epoch 129/170 => Loss 1.314, Train_accy 99.690, Test_accy 59.680
2022-05-24 23:03:55,048 [bic.py] => training => Task 3, Epoch 130/170 => Loss 1.314, Train_accy 99.690, Test_accy 59.450
2022-05-24 23:04:00,423 [bic.py] => training => Task 3, Epoch 131/170 => Loss 1.314, Train_accy 99.660, Test_accy 59.850
2022-05-24 23:04:05,800 [bic.py] => training => Task 3, Epoch 132/170 => Loss 1.309, Train_accy 99.700, Test_accy 59.650
2022-05-24 23:04:11,139 [bic.py] => training => Task 3, Epoch 133/170 => Loss 1.315, Train_accy 99.550, Test_accy 59.380
2022-05-24 23:04:16,600 [bic.py] => training => Task 3, Epoch 134/170 => Loss 1.317, Train_accy 99.660, Test_accy 59.520
2022-05-24 23:04:21,909 [bic.py] => training => Task 3, Epoch 135/170 => Loss 1.315, Train_accy 99.630, Test_accy 59.850
2022-05-24 23:04:27,416 [bic.py] => training => Task 3, Epoch 136/170 => Loss 1.319, Train_accy 99.700, Test_accy 59.820
2022-05-24 23:04:32,772 [bic.py] => training => Task 3, Epoch 137/170 => Loss 1.315, Train_accy 99.840, Test_accy 59.820
2022-05-24 23:04:37,982 [bic.py] => training => Task 3, Epoch 138/170 => Loss 1.314, Train_accy 99.550, Test_accy 59.520
2022-05-24 23:04:43,523 [bic.py] => training => Task 3, Epoch 139/170 => Loss 1.311, Train_accy 99.550, Test_accy 59.800
2022-05-24 23:04:48,894 [bic.py] => training => Task 3, Epoch 140/170 => Loss 1.314, Train_accy 99.690, Test_accy 59.820
2022-05-24 23:04:54,215 [bic.py] => training => Task 3, Epoch 141/170 => Loss 1.314, Train_accy 99.700, Test_accy 59.880
2022-05-24 23:04:59,742 [bic.py] => training => Task 3, Epoch 142/170 => Loss 1.311, Train_accy 99.690, Test_accy 59.650
2022-05-24 23:05:05,206 [bic.py] => training => Task 3, Epoch 143/170 => Loss 1.313, Train_accy 99.640, Test_accy 59.780
2022-05-24 23:05:10,639 [bic.py] => training => Task 3, Epoch 144/170 => Loss 1.313, Train_accy 99.600, Test_accy 59.780
2022-05-24 23:05:16,202 [bic.py] => training => Task 3, Epoch 145/170 => Loss 1.318, Train_accy 99.640, Test_accy 59.820
2022-05-24 23:05:21,510 [bic.py] => training => Task 3, Epoch 146/170 => Loss 1.312, Train_accy 99.810, Test_accy 59.580
2022-05-24 23:05:26,891 [bic.py] => training => Task 3, Epoch 147/170 => Loss 1.314, Train_accy 99.750, Test_accy 59.600
2022-05-24 23:05:32,367 [bic.py] => training => Task 3, Epoch 148/170 => Loss 1.312, Train_accy 99.760, Test_accy 59.700
2022-05-24 23:05:37,803 [bic.py] => training => Task 3, Epoch 149/170 => Loss 1.310, Train_accy 99.720, Test_accy 59.800
2022-05-24 23:05:43,179 [bic.py] => training => Task 3, Epoch 150/170 => Loss 1.321, Train_accy 99.500, Test_accy 60.200
2022-05-24 23:05:48,602 [bic.py] => training => Task 3, Epoch 151/170 => Loss 1.313, Train_accy 99.720, Test_accy 59.700
2022-05-24 23:05:53,984 [bic.py] => training => Task 3, Epoch 152/170 => Loss 1.318, Train_accy 99.760, Test_accy 59.480
2022-05-24 23:05:59,388 [bic.py] => training => Task 3, Epoch 153/170 => Loss 1.318, Train_accy 99.720, Test_accy 59.980
2022-05-24 23:06:04,883 [bic.py] => training => Task 3, Epoch 154/170 => Loss 1.315, Train_accy 99.730, Test_accy 60.150
2022-05-24 23:06:10,393 [bic.py] => training => Task 3, Epoch 155/170 => Loss 1.321, Train_accy 99.660, Test_accy 59.620
2022-05-24 23:06:15,822 [bic.py] => training => Task 3, Epoch 156/170 => Loss 1.314, Train_accy 99.790, Test_accy 59.900
2022-05-24 23:06:21,357 [bic.py] => training => Task 3, Epoch 157/170 => Loss 1.316, Train_accy 99.690, Test_accy 60.000
2022-05-24 23:06:26,731 [bic.py] => training => Task 3, Epoch 158/170 => Loss 1.316, Train_accy 99.530, Test_accy 59.850
2022-05-24 23:06:32,084 [bic.py] => training => Task 3, Epoch 159/170 => Loss 1.312, Train_accy 99.690, Test_accy 60.000
2022-05-24 23:06:37,632 [bic.py] => training => Task 3, Epoch 160/170 => Loss 1.316, Train_accy 99.600, Test_accy 59.750
2022-05-24 23:06:43,155 [bic.py] => training => Task 3, Epoch 161/170 => Loss 1.317, Train_accy 99.580, Test_accy 59.620
2022-05-24 23:06:48,760 [bic.py] => training => Task 3, Epoch 162/170 => Loss 1.313, Train_accy 99.540, Test_accy 59.750
2022-05-24 23:06:54,168 [bic.py] => training => Task 3, Epoch 163/170 => Loss 1.310, Train_accy 99.670, Test_accy 59.280
2022-05-24 23:06:59,587 [bic.py] => training => Task 3, Epoch 164/170 => Loss 1.322, Train_accy 99.760, Test_accy 59.820
2022-05-24 23:07:04,980 [bic.py] => training => Task 3, Epoch 165/170 => Loss 1.315, Train_accy 99.670, Test_accy 59.780
2022-05-24 23:07:10,602 [bic.py] => training => Task 3, Epoch 166/170 => Loss 1.314, Train_accy 99.550, Test_accy 59.550
2022-05-24 23:07:16,094 [bic.py] => training => Task 3, Epoch 167/170 => Loss 1.316, Train_accy 99.720, Test_accy 59.800
2022-05-24 23:07:21,925 [bic.py] => training => Task 3, Epoch 168/170 => Loss 1.315, Train_accy 99.610, Test_accy 59.580
2022-05-24 23:07:27,395 [bic.py] => training => Task 3, Epoch 169/170 => Loss 1.314, Train_accy 99.670, Test_accy 60.000
2022-05-24 23:07:32,748 [bic.py] => training => Task 3, Epoch 170/170 => Loss 1.313, Train_accy 99.610, Test_accy 59.800
2022-05-24 23:07:34,405 [bic.py] => bias_correction => Task 3, Epoch 1/170 => Loss 3.133, Train_accy 68.750, Test_accy 62.480
2022-05-24 23:07:36,095 [bic.py] => bias_correction => Task 3, Epoch 2/170 => Loss 3.065, Train_accy 79.170, Test_accy 64.880
2022-05-24 23:07:37,794 [bic.py] => bias_correction => Task 3, Epoch 3/170 => Loss 3.027, Train_accy 73.750, Test_accy 60.650
2022-05-24 23:07:39,430 [bic.py] => bias_correction => Task 3, Epoch 4/170 => Loss 3.080, Train_accy 70.420, Test_accy 58.300
2022-05-24 23:07:41,091 [bic.py] => bias_correction => Task 3, Epoch 5/170 => Loss 3.072, Train_accy 77.500, Test_accy 61.380
2022-05-24 23:07:42,718 [bic.py] => bias_correction => Task 3, Epoch 6/170 => Loss 3.051, Train_accy 77.920, Test_accy 64.720
2022-05-24 23:07:44,403 [bic.py] => bias_correction => Task 3, Epoch 7/170 => Loss 3.042, Train_accy 75.000, Test_accy 63.520
2022-05-24 23:07:46,190 [bic.py] => bias_correction => Task 3, Epoch 8/170 => Loss 3.065, Train_accy 78.330, Test_accy 63.580
2022-05-24 23:07:47,917 [bic.py] => bias_correction => Task 3, Epoch 9/170 => Loss 3.047, Train_accy 77.500, Test_accy 64.530
2022-05-24 23:07:49,559 [bic.py] => bias_correction => Task 3, Epoch 10/170 => Loss 3.029, Train_accy 80.830, Test_accy 62.980
2022-05-24 23:07:51,272 [bic.py] => bias_correction => Task 3, Epoch 11/170 => Loss 3.038, Train_accy 82.920, Test_accy 62.420
2022-05-24 23:07:52,850 [bic.py] => bias_correction => Task 3, Epoch 12/170 => Loss 3.041, Train_accy 78.750, Test_accy 63.680
2022-05-24 23:07:54,571 [bic.py] => bias_correction => Task 3, Epoch 13/170 => Loss 3.047, Train_accy 77.080, Test_accy 64.380
2022-05-24 23:07:56,203 [bic.py] => bias_correction => Task 3, Epoch 14/170 => Loss 3.048, Train_accy 75.420, Test_accy 64.300
2022-05-24 23:07:57,883 [bic.py] => bias_correction => Task 3, Epoch 15/170 => Loss 3.017, Train_accy 78.330, Test_accy 64.400
2022-05-24 23:07:59,508 [bic.py] => bias_correction => Task 3, Epoch 16/170 => Loss 3.029, Train_accy 78.750, Test_accy 64.150
2022-05-24 23:08:01,192 [bic.py] => bias_correction => Task 3, Epoch 17/170 => Loss 3.026, Train_accy 83.330, Test_accy 63.380
2022-05-24 23:08:02,982 [bic.py] => bias_correction => Task 3, Epoch 18/170 => Loss 3.033, Train_accy 76.250, Test_accy 63.300
2022-05-24 23:08:04,656 [bic.py] => bias_correction => Task 3, Epoch 19/170 => Loss 3.051, Train_accy 78.330, Test_accy 63.780
2022-05-24 23:08:06,381 [bic.py] => bias_correction => Task 3, Epoch 20/170 => Loss 3.022, Train_accy 80.830, Test_accy 64.350
2022-05-24 23:08:08,160 [bic.py] => bias_correction => Task 3, Epoch 21/170 => Loss 3.030, Train_accy 77.080, Test_accy 64.320
2022-05-24 23:08:09,740 [bic.py] => bias_correction => Task 3, Epoch 22/170 => Loss 3.048, Train_accy 77.920, Test_accy 64.300
2022-05-24 23:08:11,423 [bic.py] => bias_correction => Task 3, Epoch 23/170 => Loss 3.030, Train_accy 80.830, Test_accy 64.100
2022-05-24 23:08:13,071 [bic.py] => bias_correction => Task 3, Epoch 24/170 => Loss 3.023, Train_accy 79.580, Test_accy 63.150
2022-05-24 23:08:14,761 [bic.py] => bias_correction => Task 3, Epoch 25/170 => Loss 3.024, Train_accy 80.420, Test_accy 63.480
2022-05-24 23:08:16,400 [bic.py] => bias_correction => Task 3, Epoch 26/170 => Loss 3.058, Train_accy 80.830, Test_accy 64.180
2022-05-24 23:08:18,070 [bic.py] => bias_correction => Task 3, Epoch 27/170 => Loss 3.016, Train_accy 78.330, Test_accy 64.550
2022-05-24 23:08:19,740 [bic.py] => bias_correction => Task 3, Epoch 28/170 => Loss 3.034, Train_accy 80.000, Test_accy 64.320
2022-05-24 23:08:21,452 [bic.py] => bias_correction => Task 3, Epoch 29/170 => Loss 3.025, Train_accy 79.170, Test_accy 64.580
2022-05-24 23:08:23,098 [bic.py] => bias_correction => Task 3, Epoch 30/170 => Loss 3.030, Train_accy 79.170, Test_accy 64.400
2022-05-24 23:08:24,749 [bic.py] => bias_correction => Task 3, Epoch 31/170 => Loss 3.031, Train_accy 76.670, Test_accy 63.650
2022-05-24 23:08:26,494 [bic.py] => bias_correction => Task 3, Epoch 32/170 => Loss 3.050, Train_accy 79.170, Test_accy 63.680
2022-05-24 23:08:28,210 [bic.py] => bias_correction => Task 3, Epoch 33/170 => Loss 3.029, Train_accy 78.330, Test_accy 64.180
2022-05-24 23:08:29,908 [bic.py] => bias_correction => Task 3, Epoch 34/170 => Loss 3.033, Train_accy 80.000, Test_accy 64.680
2022-05-24 23:08:31,588 [bic.py] => bias_correction => Task 3, Epoch 35/170 => Loss 3.020, Train_accy 79.170, Test_accy 64.400
2022-05-24 23:08:33,412 [bic.py] => bias_correction => Task 3, Epoch 36/170 => Loss 3.028, Train_accy 78.750, Test_accy 64.500
2022-05-24 23:08:35,119 [bic.py] => bias_correction => Task 3, Epoch 37/170 => Loss 3.039, Train_accy 77.920, Test_accy 64.180
2022-05-24 23:08:36,752 [bic.py] => bias_correction => Task 3, Epoch 38/170 => Loss 3.035, Train_accy 80.830, Test_accy 63.800
2022-05-24 23:08:38,407 [bic.py] => bias_correction => Task 3, Epoch 39/170 => Loss 3.019, Train_accy 77.920, Test_accy 64.000
2022-05-24 23:08:40,106 [bic.py] => bias_correction => Task 3, Epoch 40/170 => Loss 3.014, Train_accy 79.170, Test_accy 64.530
2022-05-24 23:08:41,807 [bic.py] => bias_correction => Task 3, Epoch 41/170 => Loss 3.025, Train_accy 77.080, Test_accy 64.680
2022-05-24 23:08:43,481 [bic.py] => bias_correction => Task 3, Epoch 42/170 => Loss 3.049, Train_accy 77.080, Test_accy 64.680
2022-05-24 23:08:45,157 [bic.py] => bias_correction => Task 3, Epoch 43/170 => Loss 3.012, Train_accy 79.580, Test_accy 64.530
2022-05-24 23:08:46,869 [bic.py] => bias_correction => Task 3, Epoch 44/170 => Loss 3.024, Train_accy 78.750, Test_accy 64.200
2022-05-24 23:08:48,558 [bic.py] => bias_correction => Task 3, Epoch 45/170 => Loss 3.011, Train_accy 75.830, Test_accy 64.200
2022-05-24 23:08:50,293 [bic.py] => bias_correction => Task 3, Epoch 46/170 => Loss 3.024, Train_accy 80.830, Test_accy 64.420
2022-05-24 23:08:52,122 [bic.py] => bias_correction => Task 3, Epoch 47/170 => Loss 3.024, Train_accy 77.920, Test_accy 64.650
2022-05-24 23:08:53,861 [bic.py] => bias_correction => Task 3, Epoch 48/170 => Loss 3.019, Train_accy 76.250, Test_accy 64.700
2022-05-24 23:08:55,451 [bic.py] => bias_correction => Task 3, Epoch 49/170 => Loss 3.006, Train_accy 80.420, Test_accy 64.530
2022-05-24 23:08:57,176 [bic.py] => bias_correction => Task 3, Epoch 50/170 => Loss 3.016, Train_accy 77.080, Test_accy 64.200
2022-05-24 23:08:58,861 [bic.py] => bias_correction => Task 3, Epoch 51/170 => Loss 3.022, Train_accy 75.000, Test_accy 64.250
2022-05-24 23:09:00,504 [bic.py] => bias_correction => Task 3, Epoch 52/170 => Loss 3.029, Train_accy 75.830, Test_accy 64.580
2022-05-24 23:09:02,229 [bic.py] => bias_correction => Task 3, Epoch 53/170 => Loss 3.037, Train_accy 81.670, Test_accy 64.720
2022-05-24 23:09:03,955 [bic.py] => bias_correction => Task 3, Epoch 54/170 => Loss 3.031, Train_accy 76.670, Test_accy 64.750
2022-05-24 23:09:05,624 [bic.py] => bias_correction => Task 3, Epoch 55/170 => Loss 3.030, Train_accy 77.500, Test_accy 64.720
2022-05-24 23:09:07,262 [bic.py] => bias_correction => Task 3, Epoch 56/170 => Loss 3.034, Train_accy 81.250, Test_accy 64.320
2022-05-24 23:09:08,896 [bic.py] => bias_correction => Task 3, Epoch 57/170 => Loss 3.015, Train_accy 78.330, Test_accy 64.150
2022-05-24 23:09:10,558 [bic.py] => bias_correction => Task 3, Epoch 58/170 => Loss 3.029, Train_accy 79.170, Test_accy 64.300
2022-05-24 23:09:12,251 [bic.py] => bias_correction => Task 3, Epoch 59/170 => Loss 3.020, Train_accy 80.000, Test_accy 64.380
2022-05-24 23:09:13,904 [bic.py] => bias_correction => Task 3, Epoch 60/170 => Loss 3.035, Train_accy 79.580, Test_accy 64.580
2022-05-24 23:09:15,630 [bic.py] => bias_correction => Task 3, Epoch 61/170 => Loss 3.015, Train_accy 80.830, Test_accy 64.500
2022-05-24 23:09:17,388 [bic.py] => bias_correction => Task 3, Epoch 62/170 => Loss 3.039, Train_accy 80.000, Test_accy 64.650
2022-05-24 23:09:19,056 [bic.py] => bias_correction => Task 3, Epoch 63/170 => Loss 3.019, Train_accy 79.580, Test_accy 64.620
2022-05-24 23:09:20,738 [bic.py] => bias_correction => Task 3, Epoch 64/170 => Loss 3.009, Train_accy 77.920, Test_accy 64.650
2022-05-24 23:09:22,394 [bic.py] => bias_correction => Task 3, Epoch 65/170 => Loss 3.047, Train_accy 77.920, Test_accy 64.600
2022-05-24 23:09:24,158 [bic.py] => bias_correction => Task 3, Epoch 66/170 => Loss 3.032, Train_accy 79.170, Test_accy 64.530
2022-05-24 23:09:25,698 [bic.py] => bias_correction => Task 3, Epoch 67/170 => Loss 3.017, Train_accy 78.330, Test_accy 64.550
2022-05-24 23:09:27,409 [bic.py] => bias_correction => Task 3, Epoch 68/170 => Loss 3.023, Train_accy 80.000, Test_accy 64.500
2022-05-24 23:09:29,050 [bic.py] => bias_correction => Task 3, Epoch 69/170 => Loss 3.025, Train_accy 77.080, Test_accy 64.450
2022-05-24 23:09:30,802 [bic.py] => bias_correction => Task 3, Epoch 70/170 => Loss 3.010, Train_accy 78.750, Test_accy 64.380
2022-05-24 23:09:32,573 [bic.py] => bias_correction => Task 3, Epoch 71/170 => Loss 3.041, Train_accy 79.170, Test_accy 64.400
2022-05-24 23:09:34,219 [bic.py] => bias_correction => Task 3, Epoch 72/170 => Loss 3.028, Train_accy 81.250, Test_accy 64.400
2022-05-24 23:09:35,909 [bic.py] => bias_correction => Task 3, Epoch 73/170 => Loss 3.031, Train_accy 80.830, Test_accy 64.350
2022-05-24 23:09:37,595 [bic.py] => bias_correction => Task 3, Epoch 74/170 => Loss 3.020, Train_accy 78.330, Test_accy 64.380
2022-05-24 23:09:39,184 [bic.py] => bias_correction => Task 3, Epoch 75/170 => Loss 3.019, Train_accy 77.920, Test_accy 64.580
2022-05-24 23:09:40,929 [bic.py] => bias_correction => Task 3, Epoch 76/170 => Loss 3.016, Train_accy 78.750, Test_accy 64.650
2022-05-24 23:09:42,596 [bic.py] => bias_correction => Task 3, Epoch 77/170 => Loss 3.006, Train_accy 79.170, Test_accy 64.380
2022-05-24 23:09:44,238 [bic.py] => bias_correction => Task 3, Epoch 78/170 => Loss 3.017, Train_accy 78.330, Test_accy 64.550
2022-05-24 23:09:45,930 [bic.py] => bias_correction => Task 3, Epoch 79/170 => Loss 3.022, Train_accy 79.170, Test_accy 64.530
2022-05-24 23:09:47,604 [bic.py] => bias_correction => Task 3, Epoch 80/170 => Loss 3.027, Train_accy 77.080, Test_accy 64.620
2022-05-24 23:09:49,478 [bic.py] => bias_correction => Task 3, Epoch 81/170 => Loss 3.026, Train_accy 82.080, Test_accy 64.650
2022-05-24 23:09:51,164 [bic.py] => bias_correction => Task 3, Epoch 82/170 => Loss 3.004, Train_accy 77.500, Test_accy 64.700
2022-05-24 23:09:52,831 [bic.py] => bias_correction => Task 3, Epoch 83/170 => Loss 3.013, Train_accy 79.170, Test_accy 64.720
2022-05-24 23:09:54,537 [bic.py] => bias_correction => Task 3, Epoch 84/170 => Loss 3.036, Train_accy 80.420, Test_accy 64.700
2022-05-24 23:09:56,199 [bic.py] => bias_correction => Task 3, Epoch 85/170 => Loss 3.014, Train_accy 79.580, Test_accy 64.700
2022-05-24 23:09:57,843 [bic.py] => bias_correction => Task 3, Epoch 86/170 => Loss 3.023, Train_accy 80.000, Test_accy 64.650
2022-05-24 23:09:59,548 [bic.py] => bias_correction => Task 3, Epoch 87/170 => Loss 3.022, Train_accy 76.250, Test_accy 64.750
2022-05-24 23:10:01,325 [bic.py] => bias_correction => Task 3, Epoch 88/170 => Loss 3.014, Train_accy 82.080, Test_accy 64.680
2022-05-24 23:10:02,960 [bic.py] => bias_correction => Task 3, Epoch 89/170 => Loss 3.015, Train_accy 81.670, Test_accy 64.680
2022-05-24 23:10:04,690 [bic.py] => bias_correction => Task 3, Epoch 90/170 => Loss 3.031, Train_accy 77.080, Test_accy 64.800
2022-05-24 23:10:06,400 [bic.py] => bias_correction => Task 3, Epoch 91/170 => Loss 3.022, Train_accy 78.330, Test_accy 64.700
2022-05-24 23:10:08,124 [bic.py] => bias_correction => Task 3, Epoch 92/170 => Loss 3.016, Train_accy 80.000, Test_accy 64.620
2022-05-24 23:10:09,792 [bic.py] => bias_correction => Task 3, Epoch 93/170 => Loss 3.014, Train_accy 80.420, Test_accy 64.780
2022-05-24 23:10:11,497 [bic.py] => bias_correction => Task 3, Epoch 94/170 => Loss 3.015, Train_accy 80.420, Test_accy 64.680
2022-05-24 23:10:13,093 [bic.py] => bias_correction => Task 3, Epoch 95/170 => Loss 3.017, Train_accy 81.250, Test_accy 64.580
2022-05-24 23:10:14,846 [bic.py] => bias_correction => Task 3, Epoch 96/170 => Loss 3.026, Train_accy 80.420, Test_accy 64.620
2022-05-24 23:10:16,507 [bic.py] => bias_correction => Task 3, Epoch 97/170 => Loss 3.016, Train_accy 77.920, Test_accy 64.580
2022-05-24 23:10:18,127 [bic.py] => bias_correction => Task 3, Epoch 98/170 => Loss 3.026, Train_accy 81.250, Test_accy 64.550
2022-05-24 23:10:19,807 [bic.py] => bias_correction => Task 3, Epoch 99/170 => Loss 3.014, Train_accy 77.920, Test_accy 64.580
2022-05-24 23:10:21,523 [bic.py] => bias_correction => Task 3, Epoch 100/170 => Loss 3.018, Train_accy 76.250, Test_accy 64.600
2022-05-24 23:10:23,322 [bic.py] => bias_correction => Task 3, Epoch 101/170 => Loss 3.025, Train_accy 80.000, Test_accy 64.650
2022-05-24 23:10:24,934 [bic.py] => bias_correction => Task 3, Epoch 102/170 => Loss 3.022, Train_accy 78.330, Test_accy 64.700
2022-05-24 23:10:26,570 [bic.py] => bias_correction => Task 3, Epoch 103/170 => Loss 3.027, Train_accy 78.750, Test_accy 64.680
2022-05-24 23:10:28,211 [bic.py] => bias_correction => Task 3, Epoch 104/170 => Loss 3.023, Train_accy 81.250, Test_accy 64.650
2022-05-24 23:10:29,842 [bic.py] => bias_correction => Task 3, Epoch 105/170 => Loss 3.003, Train_accy 77.920, Test_accy 64.550
2022-05-24 23:10:31,459 [bic.py] => bias_correction => Task 3, Epoch 106/170 => Loss 3.018, Train_accy 78.330, Test_accy 64.620
2022-05-24 23:10:33,177 [bic.py] => bias_correction => Task 3, Epoch 107/170 => Loss 3.020, Train_accy 77.500, Test_accy 64.500
2022-05-24 23:10:34,914 [bic.py] => bias_correction => Task 3, Epoch 108/170 => Loss 3.013, Train_accy 77.500, Test_accy 64.580
2022-05-24 23:10:36,537 [bic.py] => bias_correction => Task 3, Epoch 109/170 => Loss 3.033, Train_accy 77.920, Test_accy 64.600
2022-05-24 23:10:38,170 [bic.py] => bias_correction => Task 3, Epoch 110/170 => Loss 3.021, Train_accy 77.920, Test_accy 64.720
2022-05-24 23:10:39,838 [bic.py] => bias_correction => Task 3, Epoch 111/170 => Loss 3.009, Train_accy 80.830, Test_accy 64.680
2022-05-24 23:10:41,479 [bic.py] => bias_correction => Task 3, Epoch 112/170 => Loss 3.032, Train_accy 80.830, Test_accy 64.620
2022-05-24 23:10:43,159 [bic.py] => bias_correction => Task 3, Epoch 113/170 => Loss 3.029, Train_accy 76.670, Test_accy 64.650
2022-05-24 23:10:44,925 [bic.py] => bias_correction => Task 3, Epoch 114/170 => Loss 3.023, Train_accy 79.170, Test_accy 64.600
2022-05-24 23:10:46,595 [bic.py] => bias_correction => Task 3, Epoch 115/170 => Loss 3.010, Train_accy 77.920, Test_accy 64.600
2022-05-24 23:10:48,231 [bic.py] => bias_correction => Task 3, Epoch 116/170 => Loss 3.008, Train_accy 79.170, Test_accy 64.680
2022-05-24 23:10:49,937 [bic.py] => bias_correction => Task 3, Epoch 117/170 => Loss 3.031, Train_accy 82.080, Test_accy 64.700
2022-05-24 23:10:51,599 [bic.py] => bias_correction => Task 3, Epoch 118/170 => Loss 3.019, Train_accy 76.670, Test_accy 64.680
2022-05-24 23:10:53,236 [bic.py] => bias_correction => Task 3, Epoch 119/170 => Loss 3.017, Train_accy 78.750, Test_accy 64.650
2022-05-24 23:10:54,906 [bic.py] => bias_correction => Task 3, Epoch 120/170 => Loss 3.019, Train_accy 77.080, Test_accy 64.680
2022-05-24 23:10:56,599 [bic.py] => bias_correction => Task 3, Epoch 121/170 => Loss 3.014, Train_accy 78.750, Test_accy 64.680
2022-05-24 23:10:58,371 [bic.py] => bias_correction => Task 3, Epoch 122/170 => Loss 3.023, Train_accy 81.250, Test_accy 64.720
2022-05-24 23:11:00,066 [bic.py] => bias_correction => Task 3, Epoch 123/170 => Loss 3.019, Train_accy 79.580, Test_accy 64.620
2022-05-24 23:11:01,683 [bic.py] => bias_correction => Task 3, Epoch 124/170 => Loss 3.024, Train_accy 77.920, Test_accy 64.600
2022-05-24 23:11:03,357 [bic.py] => bias_correction => Task 3, Epoch 125/170 => Loss 3.017, Train_accy 76.250, Test_accy 64.530
2022-05-24 23:11:04,929 [bic.py] => bias_correction => Task 3, Epoch 126/170 => Loss 3.025, Train_accy 80.000, Test_accy 64.620
2022-05-24 23:11:06,613 [bic.py] => bias_correction => Task 3, Epoch 127/170 => Loss 3.026, Train_accy 76.670, Test_accy 64.400
2022-05-24 23:11:08,219 [bic.py] => bias_correction => Task 3, Epoch 128/170 => Loss 3.025, Train_accy 79.580, Test_accy 64.400
2022-05-24 23:11:09,957 [bic.py] => bias_correction => Task 3, Epoch 129/170 => Loss 3.036, Train_accy 78.750, Test_accy 64.400
2022-05-24 23:11:11,643 [bic.py] => bias_correction => Task 3, Epoch 130/170 => Loss 3.038, Train_accy 76.670, Test_accy 64.450
2022-05-24 23:11:13,357 [bic.py] => bias_correction => Task 3, Epoch 131/170 => Loss 3.026, Train_accy 80.000, Test_accy 64.450
2022-05-24 23:11:15,154 [bic.py] => bias_correction => Task 3, Epoch 132/170 => Loss 3.031, Train_accy 81.250, Test_accy 64.420
2022-05-24 23:11:16,759 [bic.py] => bias_correction => Task 3, Epoch 133/170 => Loss 3.019, Train_accy 79.170, Test_accy 64.580
2022-05-24 23:11:18,439 [bic.py] => bias_correction => Task 3, Epoch 134/170 => Loss 3.028, Train_accy 79.170, Test_accy 64.380
2022-05-24 23:11:20,112 [bic.py] => bias_correction => Task 3, Epoch 135/170 => Loss 3.035, Train_accy 82.080, Test_accy 64.380
2022-05-24 23:11:21,831 [bic.py] => bias_correction => Task 3, Epoch 136/170 => Loss 3.026, Train_accy 77.920, Test_accy 64.420
2022-05-24 23:11:23,614 [bic.py] => bias_correction => Task 3, Epoch 137/170 => Loss 3.010, Train_accy 79.170, Test_accy 64.350
2022-05-24 23:11:25,251 [bic.py] => bias_correction => Task 3, Epoch 138/170 => Loss 3.014, Train_accy 80.000, Test_accy 64.380
2022-05-24 23:11:26,987 [bic.py] => bias_correction => Task 3, Epoch 139/170 => Loss 3.033, Train_accy 79.580, Test_accy 64.470
2022-05-24 23:11:28,630 [bic.py] => bias_correction => Task 3, Epoch 140/170 => Loss 3.037, Train_accy 79.170, Test_accy 64.600
2022-05-24 23:11:30,352 [bic.py] => bias_correction => Task 3, Epoch 141/170 => Loss 3.032, Train_accy 77.920, Test_accy 64.600
2022-05-24 23:11:31,942 [bic.py] => bias_correction => Task 3, Epoch 142/170 => Loss 3.011, Train_accy 78.330, Test_accy 64.530
2022-05-24 23:11:33,616 [bic.py] => bias_correction => Task 3, Epoch 143/170 => Loss 3.021, Train_accy 78.330, Test_accy 64.470
2022-05-24 23:11:35,247 [bic.py] => bias_correction => Task 3, Epoch 144/170 => Loss 3.031, Train_accy 80.830, Test_accy 64.620
2022-05-24 23:11:36,906 [bic.py] => bias_correction => Task 3, Epoch 145/170 => Loss 3.033, Train_accy 80.000, Test_accy 64.580
2022-05-24 23:11:38,573 [bic.py] => bias_correction => Task 3, Epoch 146/170 => Loss 3.027, Train_accy 79.580, Test_accy 64.500
2022-05-24 23:11:40,164 [bic.py] => bias_correction => Task 3, Epoch 147/170 => Loss 3.019, Train_accy 79.170, Test_accy 64.470
2022-05-24 23:11:41,868 [bic.py] => bias_correction => Task 3, Epoch 148/170 => Loss 3.034, Train_accy 77.920, Test_accy 64.530
2022-05-24 23:11:43,547 [bic.py] => bias_correction => Task 3, Epoch 149/170 => Loss 3.035, Train_accy 74.580, Test_accy 64.650
2022-05-24 23:11:45,198 [bic.py] => bias_correction => Task 3, Epoch 150/170 => Loss 3.024, Train_accy 77.500, Test_accy 64.650
2022-05-24 23:11:46,889 [bic.py] => bias_correction => Task 3, Epoch 151/170 => Loss 3.029, Train_accy 80.830, Test_accy 64.680
2022-05-24 23:11:48,541 [bic.py] => bias_correction => Task 3, Epoch 152/170 => Loss 3.012, Train_accy 78.330, Test_accy 64.700
2022-05-24 23:11:50,207 [bic.py] => bias_correction => Task 3, Epoch 153/170 => Loss 3.019, Train_accy 80.000, Test_accy 64.550
2022-05-24 23:11:51,857 [bic.py] => bias_correction => Task 3, Epoch 154/170 => Loss 3.029, Train_accy 76.670, Test_accy 64.470
2022-05-24 23:11:53,426 [bic.py] => bias_correction => Task 3, Epoch 155/170 => Loss 3.007, Train_accy 75.830, Test_accy 64.470
2022-05-24 23:11:55,085 [bic.py] => bias_correction => Task 3, Epoch 156/170 => Loss 3.007, Train_accy 77.920, Test_accy 64.420
2022-05-24 23:11:56,722 [bic.py] => bias_correction => Task 3, Epoch 157/170 => Loss 3.041, Train_accy 80.420, Test_accy 64.420
2022-05-24 23:11:58,384 [bic.py] => bias_correction => Task 3, Epoch 158/170 => Loss 3.033, Train_accy 79.580, Test_accy 64.530
2022-05-24 23:12:00,121 [bic.py] => bias_correction => Task 3, Epoch 159/170 => Loss 3.025, Train_accy 78.330, Test_accy 64.620
2022-05-24 23:12:01,846 [bic.py] => bias_correction => Task 3, Epoch 160/170 => Loss 3.017, Train_accy 77.920, Test_accy 64.580
2022-05-24 23:12:03,555 [bic.py] => bias_correction => Task 3, Epoch 161/170 => Loss 3.019, Train_accy 79.170, Test_accy 64.680
2022-05-24 23:12:05,256 [bic.py] => bias_correction => Task 3, Epoch 162/170 => Loss 3.025, Train_accy 79.170, Test_accy 64.650
2022-05-24 23:12:06,994 [bic.py] => bias_correction => Task 3, Epoch 163/170 => Loss 3.014, Train_accy 80.420, Test_accy 64.650
2022-05-24 23:12:08,680 [bic.py] => bias_correction => Task 3, Epoch 164/170 => Loss 3.025, Train_accy 79.580, Test_accy 64.680
2022-05-24 23:12:10,347 [bic.py] => bias_correction => Task 3, Epoch 165/170 => Loss 3.041, Train_accy 80.830, Test_accy 64.680
2022-05-24 23:12:12,028 [bic.py] => bias_correction => Task 3, Epoch 166/170 => Loss 3.036, Train_accy 82.920, Test_accy 64.650
2022-05-24 23:12:13,689 [bic.py] => bias_correction => Task 3, Epoch 167/170 => Loss 3.036, Train_accy 77.080, Test_accy 64.600
2022-05-24 23:12:15,339 [bic.py] => bias_correction => Task 3, Epoch 168/170 => Loss 3.021, Train_accy 77.920, Test_accy 64.500
2022-05-24 23:12:16,912 [bic.py] => bias_correction => Task 3, Epoch 169/170 => Loss 3.012, Train_accy 79.170, Test_accy 64.530
2022-05-24 23:12:18,563 [bic.py] => bias_correction => Task 3, Epoch 170/170 => Loss 3.025, Train_accy 78.330, Test_accy 64.530
2022-05-24 23:12:18,564 [base.py] => Reducing exemplars...(50 per classes)
2022-05-24 23:12:25,041 [base.py] => Constructing exemplars...(50 per classes)
2022-05-24 23:12:30,624 [bic.py] => Parameters of bias layer:
2022-05-24 23:12:30,624 [bic.py] => 0 => 1.000, 0.000
2022-05-24 23:12:30,625 [bic.py] => 1 => 0.981, -1.523
2022-05-24 23:12:30,625 [bic.py] => 2 => 0.816, -1.587
2022-05-24 23:12:30,625 [bic.py] => 3 => 0.723, -1.178
2022-05-24 23:12:32,243 [bic.py] => Exemplar size: 2000
2022-05-24 23:12:32,243 [trainer.py] => CNN: {'total': 64.53, '00-09': 70.1, '10-19': 59.8, '20-29': 66.3, '30-39': 61.9, 'old': 65.4, 'new': 61.9}
2022-05-24 23:12:32,244 [trainer.py] => NME: {'total': 64.97, '00-09': 68.6, '10-19': 55.3, '20-29': 68.4, '30-39': 67.6, 'old': 64.1, 'new': 67.6}
2022-05-24 23:12:32,244 [trainer.py] => CNN top1 curve: [87.5, 75.95, 70.6, 64.53]
2022-05-24 23:12:32,244 [trainer.py] => CNN top5 curve: [99.3, 95.5, 93.17, 90.3]
2022-05-24 23:12:32,244 [trainer.py] => NME top1 curve: [88.1, 75.6, 71.27, 64.97]
2022-05-24 23:12:32,244 [trainer.py] => NME top5 curve: [99.4, 95.4, 93.2, 90.05]

2022-05-24 23:12:32,244 [trainer.py] => All params: 466762
2022-05-24 23:12:32,245 [trainer.py] => Trainable params: 466762
2022-05-24 23:12:32,246 [bic.py] => Learning on 40-50
2022-05-24 23:12:32,305 [bic.py] => Stage1 dset: 6750, Stage2 dset: 250
2022-05-24 23:12:32,305 [bic.py] => Lambda: 0.800
2022-05-24 23:12:32,324 [bic.py] => Parameters of bias layer:
2022-05-24 23:12:32,325 [bic.py] => 0 => 1.000, 0.000
2022-05-24 23:12:32,325 [bic.py] => 1 => 0.981, -1.523
2022-05-24 23:12:32,325 [bic.py] => 2 => 0.816, -1.587
2022-05-24 23:12:32,325 [bic.py] => 3 => 0.723, -1.178
2022-05-24 23:12:32,325 [bic.py] => 4 => 1.000, 0.000
2022-05-24 23:12:37,810 [bic.py] => training => Task 4, Epoch 1/170 => Loss 2.100, Train_accy 73.270, Test_accy 44.780
2022-05-24 23:12:43,448 [bic.py] => training => Task 4, Epoch 2/170 => Loss 1.886, Train_accy 79.070, Test_accy 48.160
2022-05-24 23:12:48,858 [bic.py] => training => Task 4, Epoch 3/170 => Loss 1.854, Train_accy 80.310, Test_accy 49.500
2022-05-24 23:12:54,498 [bic.py] => training => Task 4, Epoch 4/170 => Loss 1.838, Train_accy 82.390, Test_accy 48.920
2022-05-24 23:12:59,996 [bic.py] => training => Task 4, Epoch 5/170 => Loss 1.827, Train_accy 82.800, Test_accy 49.060
2022-05-24 23:13:05,666 [bic.py] => training => Task 4, Epoch 6/170 => Loss 1.829, Train_accy 84.670, Test_accy 49.900
2022-05-24 23:13:11,346 [bic.py] => training => Task 4, Epoch 7/170 => Loss 1.825, Train_accy 85.070, Test_accy 49.000
2022-05-24 23:13:16,793 [bic.py] => training => Task 4, Epoch 8/170 => Loss 1.814, Train_accy 86.370, Test_accy 51.480
2022-05-24 23:13:22,665 [bic.py] => training => Task 4, Epoch 9/170 => Loss 1.813, Train_accy 87.780, Test_accy 50.440
2022-05-24 23:13:28,313 [bic.py] => training => Task 4, Epoch 10/170 => Loss 1.809, Train_accy 86.710, Test_accy 50.160
2022-05-24 23:13:33,972 [bic.py] => training => Task 4, Epoch 11/170 => Loss 1.804, Train_accy 87.690, Test_accy 50.560
2022-05-24 23:13:39,719 [bic.py] => training => Task 4, Epoch 12/170 => Loss 1.791, Train_accy 88.620, Test_accy 50.740
2022-05-24 23:13:45,328 [bic.py] => training => Task 4, Epoch 13/170 => Loss 1.797, Train_accy 88.100, Test_accy 51.100
2022-05-24 23:13:50,844 [bic.py] => training => Task 4, Epoch 14/170 => Loss 1.796, Train_accy 90.090, Test_accy 51.780
2022-05-24 23:13:56,497 [bic.py] => training => Task 4, Epoch 15/170 => Loss 1.788, Train_accy 89.230, Test_accy 48.480
2022-05-24 23:14:02,388 [bic.py] => training => Task 4, Epoch 16/170 => Loss 1.790, Train_accy 88.500, Test_accy 49.800
2022-05-24 23:14:08,278 [bic.py] => training => Task 4, Epoch 17/170 => Loss 1.792, Train_accy 85.290, Test_accy 48.440
2022-05-24 23:14:13,860 [bic.py] => training => Task 4, Epoch 18/170 => Loss 1.787, Train_accy 89.790, Test_accy 52.480
2022-05-24 23:14:19,328 [bic.py] => training => Task 4, Epoch 19/170 => Loss 1.790, Train_accy 89.380, Test_accy 49.660
2022-05-24 23:14:25,015 [bic.py] => training => Task 4, Epoch 20/170 => Loss 1.789, Train_accy 90.930, Test_accy 51.700
2022-05-24 23:14:30,463 [bic.py] => training => Task 4, Epoch 21/170 => Loss 1.784, Train_accy 91.010, Test_accy 51.600
2022-05-24 23:14:35,970 [bic.py] => training => Task 4, Epoch 22/170 => Loss 1.788, Train_accy 91.110, Test_accy 51.360
2022-05-24 23:14:41,615 [bic.py] => training => Task 4, Epoch 23/170 => Loss 1.784, Train_accy 89.850, Test_accy 49.340
2022-05-24 23:14:47,337 [bic.py] => training => Task 4, Epoch 24/170 => Loss 1.787, Train_accy 88.830, Test_accy 51.620
2022-05-24 23:14:53,042 [bic.py] => training => Task 4, Epoch 25/170 => Loss 1.788, Train_accy 91.530, Test_accy 49.740
2022-05-24 23:14:58,777 [bic.py] => training => Task 4, Epoch 26/170 => Loss 1.785, Train_accy 92.120, Test_accy 53.100
2022-05-24 23:15:04,459 [bic.py] => training => Task 4, Epoch 27/170 => Loss 1.788, Train_accy 91.200, Test_accy 49.920
2022-05-24 23:15:10,017 [bic.py] => training => Task 4, Epoch 28/170 => Loss 1.780, Train_accy 92.640, Test_accy 50.660
2022-05-24 23:15:15,481 [bic.py] => training => Task 4, Epoch 29/170 => Loss 1.778, Train_accy 92.810, Test_accy 52.460
2022-05-24 23:15:21,223 [bic.py] => training => Task 4, Epoch 30/170 => Loss 1.778, Train_accy 92.440, Test_accy 51.900
2022-05-24 23:15:26,819 [bic.py] => training => Task 4, Epoch 31/170 => Loss 1.771, Train_accy 92.370, Test_accy 51.180
2022-05-24 23:15:32,332 [bic.py] => training => Task 4, Epoch 32/170 => Loss 1.775, Train_accy 92.370, Test_accy 50.920
2022-05-24 23:15:37,861 [bic.py] => training => Task 4, Epoch 33/170 => Loss 1.776, Train_accy 91.240, Test_accy 50.480
2022-05-24 23:15:43,403 [bic.py] => training => Task 4, Epoch 34/170 => Loss 1.774, Train_accy 92.410, Test_accy 52.840
2022-05-24 23:15:49,168 [bic.py] => training => Task 4, Epoch 35/170 => Loss 1.777, Train_accy 92.250, Test_accy 50.520
2022-05-24 23:15:54,675 [bic.py] => training => Task 4, Epoch 36/170 => Loss 1.776, Train_accy 93.290, Test_accy 50.260
2022-05-24 23:16:00,221 [bic.py] => training => Task 4, Epoch 37/170 => Loss 1.777, Train_accy 91.110, Test_accy 47.760
2022-05-24 23:16:06,163 [bic.py] => training => Task 4, Epoch 38/170 => Loss 1.771, Train_accy 93.410, Test_accy 49.860
2022-05-24 23:16:11,763 [bic.py] => training => Task 4, Epoch 39/170 => Loss 1.763, Train_accy 92.520, Test_accy 49.720
2022-05-24 23:16:17,112 [bic.py] => training => Task 4, Epoch 40/170 => Loss 1.780, Train_accy 90.440, Test_accy 52.420
2022-05-24 23:16:22,946 [bic.py] => training => Task 4, Epoch 41/170 => Loss 1.777, Train_accy 92.920, Test_accy 51.980
2022-05-24 23:16:28,417 [bic.py] => training => Task 4, Epoch 42/170 => Loss 1.778, Train_accy 93.660, Test_accy 51.560
2022-05-24 23:16:33,970 [bic.py] => training => Task 4, Epoch 43/170 => Loss 1.776, Train_accy 93.590, Test_accy 51.680
2022-05-24 23:16:39,676 [bic.py] => training => Task 4, Epoch 44/170 => Loss 1.772, Train_accy 90.680, Test_accy 49.580
2022-05-24 23:16:45,234 [bic.py] => training => Task 4, Epoch 45/170 => Loss 1.774, Train_accy 90.960, Test_accy 50.940
2022-05-24 23:16:50,932 [bic.py] => training => Task 4, Epoch 46/170 => Loss 1.774, Train_accy 91.050, Test_accy 49.960
2022-05-24 23:16:56,503 [bic.py] => training => Task 4, Epoch 47/170 => Loss 1.781, Train_accy 91.390, Test_accy 52.620
2022-05-24 23:17:02,011 [bic.py] => training => Task 4, Epoch 48/170 => Loss 1.782, Train_accy 92.610, Test_accy 52.160
2022-05-24 23:17:07,839 [bic.py] => training => Task 4, Epoch 49/170 => Loss 1.776, Train_accy 90.950, Test_accy 50.880
2022-05-24 23:17:13,480 [bic.py] => training => Task 4, Epoch 50/170 => Loss 1.778, Train_accy 92.270, Test_accy 50.480
2022-05-24 23:17:19,009 [bic.py] => training => Task 4, Epoch 51/170 => Loss 1.772, Train_accy 93.670, Test_accy 49.560
2022-05-24 23:17:24,595 [bic.py] => training => Task 4, Epoch 52/170 => Loss 1.768, Train_accy 90.300, Test_accy 51.600
2022-05-24 23:17:30,163 [bic.py] => training => Task 4, Epoch 53/170 => Loss 1.779, Train_accy 89.020, Test_accy 50.360
2022-05-24 23:17:35,812 [bic.py] => training => Task 4, Epoch 54/170 => Loss 1.774, Train_accy 90.490, Test_accy 50.620
2022-05-24 23:17:41,490 [bic.py] => training => Task 4, Epoch 55/170 => Loss 1.768, Train_accy 93.320, Test_accy 52.560
2022-05-24 23:17:47,065 [bic.py] => training => Task 4, Epoch 56/170 => Loss 1.769, Train_accy 92.130, Test_accy 51.020
2022-05-24 23:17:52,622 [bic.py] => training => Task 4, Epoch 57/170 => Loss 1.773, Train_accy 92.700, Test_accy 50.220
2022-05-24 23:17:58,110 [bic.py] => training => Task 4, Epoch 58/170 => Loss 1.775, Train_accy 92.960, Test_accy 51.580
2022-05-24 23:18:03,538 [bic.py] => training => Task 4, Epoch 59/170 => Loss 1.771, Train_accy 91.940, Test_accy 51.900
2022-05-24 23:18:09,328 [bic.py] => training => Task 4, Epoch 60/170 => Loss 1.770, Train_accy 92.030, Test_accy 51.200
2022-05-24 23:18:14,878 [bic.py] => training => Task 4, Epoch 61/170 => Loss 1.746, Train_accy 98.360, Test_accy 55.540
2022-05-24 23:18:20,255 [bic.py] => training => Task 4, Epoch 62/170 => Loss 1.719, Train_accy 98.680, Test_accy 55.600
2022-05-24 23:18:25,946 [bic.py] => training => Task 4, Epoch 63/170 => Loss 1.723, Train_accy 98.840, Test_accy 55.840
2022-05-24 23:18:31,617 [bic.py] => training => Task 4, Epoch 64/170 => Loss 1.723, Train_accy 98.840, Test_accy 55.180
2022-05-24 23:18:37,234 [bic.py] => training => Task 4, Epoch 65/170 => Loss 1.709, Train_accy 98.960, Test_accy 55.920
2022-05-24 23:18:42,890 [bic.py] => training => Task 4, Epoch 66/170 => Loss 1.713, Train_accy 99.130, Test_accy 55.960
2022-05-24 23:18:48,320 [bic.py] => training => Task 4, Epoch 67/170 => Loss 1.716, Train_accy 99.100, Test_accy 55.960
2022-05-24 23:18:53,906 [bic.py] => training => Task 4, Epoch 68/170 => Loss 1.719, Train_accy 99.270, Test_accy 55.800
2022-05-24 23:18:59,500 [bic.py] => training => Task 4, Epoch 69/170 => Loss 1.716, Train_accy 99.050, Test_accy 55.860
2022-05-24 23:19:05,160 [bic.py] => training => Task 4, Epoch 70/170 => Loss 1.708, Train_accy 99.160, Test_accy 55.760
2022-05-24 23:19:11,079 [bic.py] => training => Task 4, Epoch 71/170 => Loss 1.713, Train_accy 99.410, Test_accy 55.960
2022-05-24 23:19:16,715 [bic.py] => training => Task 4, Epoch 72/170 => Loss 1.715, Train_accy 99.080, Test_accy 55.760
2022-05-24 23:19:22,265 [bic.py] => training => Task 4, Epoch 73/170 => Loss 1.710, Train_accy 99.210, Test_accy 55.700
2022-05-24 23:19:28,031 [bic.py] => training => Task 4, Epoch 74/170 => Loss 1.713, Train_accy 99.350, Test_accy 55.600
2022-05-24 23:19:33,704 [bic.py] => training => Task 4, Epoch 75/170 => Loss 1.710, Train_accy 99.290, Test_accy 55.880
2022-05-24 23:19:39,275 [bic.py] => training => Task 4, Epoch 76/170 => Loss 1.708, Train_accy 99.190, Test_accy 55.940
2022-05-24 23:19:44,725 [bic.py] => training => Task 4, Epoch 77/170 => Loss 1.707, Train_accy 99.380, Test_accy 55.840
2022-05-24 23:19:50,355 [bic.py] => training => Task 4, Epoch 78/170 => Loss 1.707, Train_accy 99.200, Test_accy 55.640
2022-05-24 23:19:56,001 [bic.py] => training => Task 4, Epoch 79/170 => Loss 1.700, Train_accy 99.410, Test_accy 55.720
2022-05-24 23:20:01,582 [bic.py] => training => Task 4, Epoch 80/170 => Loss 1.704, Train_accy 99.300, Test_accy 55.580
2022-05-24 23:20:07,078 [bic.py] => training => Task 4, Epoch 81/170 => Loss 1.701, Train_accy 99.380, Test_accy 55.940
2022-05-24 23:20:12,642 [bic.py] => training => Task 4, Epoch 82/170 => Loss 1.708, Train_accy 99.290, Test_accy 55.640
2022-05-24 23:20:18,180 [bic.py] => training => Task 4, Epoch 83/170 => Loss 1.706, Train_accy 99.470, Test_accy 56.000
2022-05-24 23:20:23,538 [bic.py] => training => Task 4, Epoch 84/170 => Loss 1.705, Train_accy 99.390, Test_accy 55.240
2022-05-24 23:20:29,328 [bic.py] => training => Task 4, Epoch 85/170 => Loss 1.708, Train_accy 99.380, Test_accy 55.280
2022-05-24 23:20:34,914 [bic.py] => training => Task 4, Epoch 86/170 => Loss 1.707, Train_accy 99.570, Test_accy 55.480
2022-05-24 23:20:40,412 [bic.py] => training => Task 4, Epoch 87/170 => Loss 1.704, Train_accy 99.390, Test_accy 55.740
2022-05-24 23:20:45,976 [bic.py] => training => Task 4, Epoch 88/170 => Loss 1.705, Train_accy 99.500, Test_accy 55.760
2022-05-24 23:20:51,651 [bic.py] => training => Task 4, Epoch 89/170 => Loss 1.704, Train_accy 99.440, Test_accy 55.440
2022-05-24 23:20:57,382 [bic.py] => training => Task 4, Epoch 90/170 => Loss 1.704, Train_accy 99.600, Test_accy 55.520
2022-05-24 23:21:02,926 [bic.py] => training => Task 4, Epoch 91/170 => Loss 1.702, Train_accy 99.470, Test_accy 55.960
2022-05-24 23:21:08,613 [bic.py] => training => Task 4, Epoch 92/170 => Loss 1.702, Train_accy 99.440, Test_accy 55.540
2022-05-24 23:21:14,676 [bic.py] => training => Task 4, Epoch 93/170 => Loss 1.708, Train_accy 99.510, Test_accy 55.740
2022-05-24 23:21:20,332 [bic.py] => training => Task 4, Epoch 94/170 => Loss 1.708, Train_accy 99.420, Test_accy 55.720
2022-05-24 23:21:25,778 [bic.py] => training => Task 4, Epoch 95/170 => Loss 1.704, Train_accy 99.480, Test_accy 55.580
2022-05-24 23:21:31,511 [bic.py] => training => Task 4, Epoch 96/170 => Loss 1.705, Train_accy 99.450, Test_accy 55.640
2022-05-24 23:21:36,930 [bic.py] => training => Task 4, Epoch 97/170 => Loss 1.704, Train_accy 99.600, Test_accy 55.880
2022-05-24 23:21:42,455 [bic.py] => training => Task 4, Epoch 98/170 => Loss 1.704, Train_accy 99.540, Test_accy 55.620
2022-05-24 23:21:48,091 [bic.py] => training => Task 4, Epoch 99/170 => Loss 1.709, Train_accy 99.410, Test_accy 55.460
2022-05-24 23:21:53,646 [bic.py] => training => Task 4, Epoch 100/170 => Loss 1.704, Train_accy 99.420, Test_accy 55.960
2022-05-24 23:21:59,234 [bic.py] => training => Task 4, Epoch 101/170 => Loss 1.702, Train_accy 99.610, Test_accy 55.820
2022-05-24 23:22:04,989 [bic.py] => training => Task 4, Epoch 102/170 => Loss 1.703, Train_accy 99.570, Test_accy 55.760
2022-05-24 23:22:10,515 [bic.py] => training => Task 4, Epoch 103/170 => Loss 1.703, Train_accy 99.530, Test_accy 55.700
2022-05-24 23:22:16,054 [bic.py] => training => Task 4, Epoch 104/170 => Loss 1.697, Train_accy 99.530, Test_accy 55.700
2022-05-24 23:22:21,843 [bic.py] => training => Task 4, Epoch 105/170 => Loss 1.699, Train_accy 99.530, Test_accy 55.860
2022-05-24 23:22:27,364 [bic.py] => training => Task 4, Epoch 106/170 => Loss 1.698, Train_accy 99.440, Test_accy 55.720
2022-05-24 23:22:33,043 [bic.py] => training => Task 4, Epoch 107/170 => Loss 1.703, Train_accy 99.470, Test_accy 55.860
2022-05-24 23:22:38,485 [bic.py] => training => Task 4, Epoch 108/170 => Loss 1.699, Train_accy 99.660, Test_accy 55.780
2022-05-24 23:22:44,007 [bic.py] => training => Task 4, Epoch 109/170 => Loss 1.698, Train_accy 99.480, Test_accy 55.760
2022-05-24 23:22:49,685 [bic.py] => training => Task 4, Epoch 110/170 => Loss 1.705, Train_accy 99.590, Test_accy 55.700
2022-05-24 23:22:55,317 [bic.py] => training => Task 4, Epoch 111/170 => Loss 1.703, Train_accy 99.480, Test_accy 55.620
2022-05-24 23:23:00,865 [bic.py] => training => Task 4, Epoch 112/170 => Loss 1.691, Train_accy 99.630, Test_accy 55.780
2022-05-24 23:23:06,579 [bic.py] => training => Task 4, Epoch 113/170 => Loss 1.709, Train_accy 99.470, Test_accy 55.640
2022-05-24 23:23:12,068 [bic.py] => training => Task 4, Epoch 114/170 => Loss 1.701, Train_accy 99.450, Test_accy 55.760
2022-05-24 23:23:17,525 [bic.py] => training => Task 4, Epoch 115/170 => Loss 1.700, Train_accy 99.540, Test_accy 55.720
2022-05-24 23:23:23,186 [bic.py] => training => Task 4, Epoch 116/170 => Loss 1.698, Train_accy 99.510, Test_accy 55.660
2022-05-24 23:23:28,796 [bic.py] => training => Task 4, Epoch 117/170 => Loss 1.700, Train_accy 99.630, Test_accy 55.860
2022-05-24 23:23:34,222 [bic.py] => training => Task 4, Epoch 118/170 => Loss 1.701, Train_accy 99.610, Test_accy 55.580
2022-05-24 23:23:39,765 [bic.py] => training => Task 4, Epoch 119/170 => Loss 1.698, Train_accy 99.590, Test_accy 55.860
2022-05-24 23:23:45,382 [bic.py] => training => Task 4, Epoch 120/170 => Loss 1.703, Train_accy 99.610, Test_accy 55.780
2022-05-24 23:23:50,967 [bic.py] => training => Task 4, Epoch 121/170 => Loss 1.695, Train_accy 99.540, Test_accy 55.620
2022-05-24 23:23:56,591 [bic.py] => training => Task 4, Epoch 122/170 => Loss 1.698, Train_accy 99.570, Test_accy 55.740
2022-05-24 23:24:02,147 [bic.py] => training => Task 4, Epoch 123/170 => Loss 1.700, Train_accy 99.630, Test_accy 55.620
2022-05-24 23:24:08,086 [bic.py] => training => Task 4, Epoch 124/170 => Loss 1.700, Train_accy 99.630, Test_accy 55.660
2022-05-24 23:24:13,640 [bic.py] => training => Task 4, Epoch 125/170 => Loss 1.705, Train_accy 99.560, Test_accy 55.740
2022-05-24 23:24:19,311 [bic.py] => training => Task 4, Epoch 126/170 => Loss 1.698, Train_accy 99.670, Test_accy 56.020
2022-05-24 23:24:25,076 [bic.py] => training => Task 4, Epoch 127/170 => Loss 1.702, Train_accy 99.560, Test_accy 55.520
2022-05-24 23:24:30,531 [bic.py] => training => Task 4, Epoch 128/170 => Loss 1.703, Train_accy 99.530, Test_accy 55.760
2022-05-24 23:24:36,260 [bic.py] => training => Task 4, Epoch 129/170 => Loss 1.700, Train_accy 99.720, Test_accy 55.700
2022-05-24 23:24:41,815 [bic.py] => training => Task 4, Epoch 130/170 => Loss 1.702, Train_accy 99.560, Test_accy 55.620
2022-05-24 23:24:47,554 [bic.py] => training => Task 4, Epoch 131/170 => Loss 1.701, Train_accy 99.530, Test_accy 55.740
2022-05-24 23:24:53,048 [bic.py] => training => Task 4, Epoch 132/170 => Loss 1.705, Train_accy 99.700, Test_accy 55.720
2022-05-24 23:24:58,584 [bic.py] => training => Task 4, Epoch 133/170 => Loss 1.701, Train_accy 99.530, Test_accy 55.860
2022-05-24 23:25:04,480 [bic.py] => training => Task 4, Epoch 134/170 => Loss 1.695, Train_accy 99.560, Test_accy 55.480
2022-05-24 23:25:10,174 [bic.py] => training => Task 4, Epoch 135/170 => Loss 1.700, Train_accy 99.570, Test_accy 55.880
2022-05-24 23:25:15,698 [bic.py] => training => Task 4, Epoch 136/170 => Loss 1.699, Train_accy 99.540, Test_accy 55.820
2022-05-24 23:25:21,353 [bic.py] => training => Task 4, Epoch 137/170 => Loss 1.700, Train_accy 99.560, Test_accy 55.620
2022-05-24 23:25:27,082 [bic.py] => training => Task 4, Epoch 138/170 => Loss 1.702, Train_accy 99.590, Test_accy 55.980
2022-05-24 23:25:32,747 [bic.py] => training => Task 4, Epoch 139/170 => Loss 1.699, Train_accy 99.420, Test_accy 55.780
2022-05-24 23:25:38,484 [bic.py] => training => Task 4, Epoch 140/170 => Loss 1.700, Train_accy 99.630, Test_accy 55.920
2022-05-24 23:25:44,016 [bic.py] => training => Task 4, Epoch 141/170 => Loss 1.693, Train_accy 99.560, Test_accy 55.720
2022-05-24 23:25:49,963 [bic.py] => training => Task 4, Epoch 142/170 => Loss 1.696, Train_accy 99.590, Test_accy 55.960
2022-05-24 23:25:55,608 [bic.py] => training => Task 4, Epoch 143/170 => Loss 1.699, Train_accy 99.670, Test_accy 55.460
2022-05-24 23:26:01,463 [bic.py] => training => Task 4, Epoch 144/170 => Loss 1.704, Train_accy 99.470, Test_accy 55.640
2022-05-24 23:26:07,010 [bic.py] => training => Task 4, Epoch 145/170 => Loss 1.697, Train_accy 99.420, Test_accy 55.580
2022-05-24 23:26:12,446 [bic.py] => training => Task 4, Epoch 146/170 => Loss 1.704, Train_accy 99.610, Test_accy 55.880
2022-05-24 23:26:18,036 [bic.py] => training => Task 4, Epoch 147/170 => Loss 1.702, Train_accy 99.590, Test_accy 55.440
2022-05-24 23:26:23,699 [bic.py] => training => Task 4, Epoch 148/170 => Loss 1.701, Train_accy 99.470, Test_accy 55.840
2022-05-24 23:26:29,368 [bic.py] => training => Task 4, Epoch 149/170 => Loss 1.701, Train_accy 99.560, Test_accy 55.400
2022-05-24 23:26:35,066 [bic.py] => training => Task 4, Epoch 150/170 => Loss 1.696, Train_accy 99.570, Test_accy 55.880
2022-05-24 23:26:40,540 [bic.py] => training => Task 4, Epoch 151/170 => Loss 1.698, Train_accy 99.500, Test_accy 55.740
2022-05-24 23:26:46,586 [bic.py] => training => Task 4, Epoch 152/170 => Loss 1.703, Train_accy 99.690, Test_accy 55.700
2022-05-24 23:26:52,061 [bic.py] => training => Task 4, Epoch 153/170 => Loss 1.700, Train_accy 99.510, Test_accy 55.760
2022-05-24 23:26:57,843 [bic.py] => training => Task 4, Epoch 154/170 => Loss 1.696, Train_accy 99.560, Test_accy 55.860
2022-05-24 23:27:03,389 [bic.py] => training => Task 4, Epoch 155/170 => Loss 1.704, Train_accy 99.660, Test_accy 55.880
2022-05-24 23:27:08,995 [bic.py] => training => Task 4, Epoch 156/170 => Loss 1.697, Train_accy 99.480, Test_accy 55.620
2022-05-24 23:27:14,587 [bic.py] => training => Task 4, Epoch 157/170 => Loss 1.703, Train_accy 99.600, Test_accy 55.900
2022-05-24 23:27:20,367 [bic.py] => training => Task 4, Epoch 158/170 => Loss 1.702, Train_accy 99.610, Test_accy 55.680
2022-05-24 23:27:25,814 [bic.py] => training => Task 4, Epoch 159/170 => Loss 1.704, Train_accy 99.660, Test_accy 55.500
2022-05-24 23:27:31,486 [bic.py] => training => Task 4, Epoch 160/170 => Loss 1.702, Train_accy 99.560, Test_accy 55.780
2022-05-24 23:27:37,017 [bic.py] => training => Task 4, Epoch 161/170 => Loss 1.701, Train_accy 99.500, Test_accy 55.880
2022-05-24 23:27:42,613 [bic.py] => training => Task 4, Epoch 162/170 => Loss 1.698, Train_accy 99.450, Test_accy 55.660
2022-05-24 23:27:48,402 [bic.py] => training => Task 4, Epoch 163/170 => Loss 1.698, Train_accy 99.500, Test_accy 55.420
2022-05-24 23:27:53,927 [bic.py] => training => Task 4, Epoch 164/170 => Loss 1.701, Train_accy 99.600, Test_accy 55.660
2022-05-24 23:27:59,544 [bic.py] => training => Task 4, Epoch 165/170 => Loss 1.702, Train_accy 99.600, Test_accy 55.960
2022-05-24 23:28:05,242 [bic.py] => training => Task 4, Epoch 166/170 => Loss 1.694, Train_accy 99.640, Test_accy 55.600
2022-05-24 23:28:10,960 [bic.py] => training => Task 4, Epoch 167/170 => Loss 1.707, Train_accy 99.570, Test_accy 55.660
2022-05-24 23:28:16,640 [bic.py] => training => Task 4, Epoch 168/170 => Loss 1.700, Train_accy 99.640, Test_accy 55.820
2022-05-24 23:28:22,180 [bic.py] => training => Task 4, Epoch 169/170 => Loss 1.702, Train_accy 99.450, Test_accy 55.600
2022-05-24 23:28:27,710 [bic.py] => training => Task 4, Epoch 170/170 => Loss 1.696, Train_accy 99.700, Test_accy 55.980
2022-05-24 23:28:29,400 [bic.py] => bias_correction => Task 4, Epoch 1/170 => Loss 3.375, Train_accy 71.200, Test_accy 58.840
2022-05-24 23:28:31,243 [bic.py] => bias_correction => Task 4, Epoch 2/170 => Loss 3.332, Train_accy 76.000, Test_accy 62.320
2022-05-24 23:28:33,038 [bic.py] => bias_correction => Task 4, Epoch 3/170 => Loss 3.284, Train_accy 75.200, Test_accy 59.460
2022-05-24 23:28:34,827 [bic.py] => bias_correction => Task 4, Epoch 4/170 => Loss 3.308, Train_accy 72.800, Test_accy 56.460
2022-05-24 23:28:36,600 [bic.py] => bias_correction => Task 4, Epoch 5/170 => Loss 3.313, Train_accy 72.800, Test_accy 56.080
2022-05-24 23:28:38,386 [bic.py] => bias_correction => Task 4, Epoch 6/170 => Loss 3.316, Train_accy 74.800, Test_accy 58.280
2022-05-24 23:28:40,090 [bic.py] => bias_correction => Task 4, Epoch 7/170 => Loss 3.287, Train_accy 77.600, Test_accy 60.920
2022-05-24 23:28:41,876 [bic.py] => bias_correction => Task 4, Epoch 8/170 => Loss 3.290, Train_accy 74.000, Test_accy 61.900
2022-05-24 23:28:43,760 [bic.py] => bias_correction => Task 4, Epoch 9/170 => Loss 3.280, Train_accy 74.800, Test_accy 61.160
2022-05-24 23:28:45,531 [bic.py] => bias_correction => Task 4, Epoch 10/170 => Loss 3.298, Train_accy 78.000, Test_accy 61.380
2022-05-24 23:28:47,334 [bic.py] => bias_correction => Task 4, Epoch 11/170 => Loss 3.310, Train_accy 77.200, Test_accy 61.660
2022-05-24 23:28:49,043 [bic.py] => bias_correction => Task 4, Epoch 12/170 => Loss 3.277, Train_accy 77.200, Test_accy 60.220
2022-05-24 23:28:50,843 [bic.py] => bias_correction => Task 4, Epoch 13/170 => Loss 3.289, Train_accy 77.200, Test_accy 59.560
2022-05-24 23:28:52,684 [bic.py] => bias_correction => Task 4, Epoch 14/170 => Loss 3.302, Train_accy 74.400, Test_accy 59.940
2022-05-24 23:28:54,302 [bic.py] => bias_correction => Task 4, Epoch 15/170 => Loss 3.280, Train_accy 77.200, Test_accy 61.600
2022-05-24 23:28:56,048 [bic.py] => bias_correction => Task 4, Epoch 16/170 => Loss 3.281, Train_accy 76.400, Test_accy 62.020
2022-05-24 23:28:57,861 [bic.py] => bias_correction => Task 4, Epoch 17/170 => Loss 3.267, Train_accy 74.800, Test_accy 61.960
2022-05-24 23:28:59,608 [bic.py] => bias_correction => Task 4, Epoch 18/170 => Loss 3.275, Train_accy 75.600, Test_accy 61.920
2022-05-24 23:29:01,429 [bic.py] => bias_correction => Task 4, Epoch 19/170 => Loss 3.286, Train_accy 76.800, Test_accy 61.820
2022-05-24 23:29:03,222 [bic.py] => bias_correction => Task 4, Epoch 20/170 => Loss 3.273, Train_accy 78.000, Test_accy 61.680
2022-05-24 23:29:05,060 [bic.py] => bias_correction => Task 4, Epoch 21/170 => Loss 3.291, Train_accy 74.800, Test_accy 61.280
2022-05-24 23:29:06,894 [bic.py] => bias_correction => Task 4, Epoch 22/170 => Loss 3.272, Train_accy 76.800, Test_accy 61.620
2022-05-24 23:29:08,621 [bic.py] => bias_correction => Task 4, Epoch 23/170 => Loss 3.269, Train_accy 79.200, Test_accy 61.620
2022-05-24 23:29:10,419 [bic.py] => bias_correction => Task 4, Epoch 24/170 => Loss 3.276, Train_accy 76.800, Test_accy 61.920
2022-05-24 23:29:12,191 [bic.py] => bias_correction => Task 4, Epoch 25/170 => Loss 3.276, Train_accy 79.200, Test_accy 62.100
2022-05-24 23:29:13,992 [bic.py] => bias_correction => Task 4, Epoch 26/170 => Loss 3.269, Train_accy 77.600, Test_accy 62.000
2022-05-24 23:29:15,792 [bic.py] => bias_correction => Task 4, Epoch 27/170 => Loss 3.279, Train_accy 78.400, Test_accy 61.980
2022-05-24 23:29:17,604 [bic.py] => bias_correction => Task 4, Epoch 28/170 => Loss 3.278, Train_accy 76.400, Test_accy 61.940
2022-05-24 23:29:19,461 [bic.py] => bias_correction => Task 4, Epoch 29/170 => Loss 3.297, Train_accy 77.200, Test_accy 61.740
2022-05-24 23:29:21,280 [bic.py] => bias_correction => Task 4, Epoch 30/170 => Loss 3.276, Train_accy 79.200, Test_accy 61.620
2022-05-24 23:29:22,998 [bic.py] => bias_correction => Task 4, Epoch 31/170 => Loss 3.273, Train_accy 78.000, Test_accy 62.020
2022-05-24 23:29:24,757 [bic.py] => bias_correction => Task 4, Epoch 32/170 => Loss 3.288, Train_accy 77.600, Test_accy 62.080
2022-05-24 23:29:26,521 [bic.py] => bias_correction => Task 4, Epoch 33/170 => Loss 3.288, Train_accy 77.600, Test_accy 62.140
2022-05-24 23:29:28,367 [bic.py] => bias_correction => Task 4, Epoch 34/170 => Loss 3.269, Train_accy 76.000, Test_accy 62.260
2022-05-24 23:29:30,113 [bic.py] => bias_correction => Task 4, Epoch 35/170 => Loss 3.271, Train_accy 78.400, Test_accy 62.300
2022-05-24 23:29:31,876 [bic.py] => bias_correction => Task 4, Epoch 36/170 => Loss 3.276, Train_accy 77.200, Test_accy 62.100
2022-05-24 23:29:33,697 [bic.py] => bias_correction => Task 4, Epoch 37/170 => Loss 3.283, Train_accy 79.600, Test_accy 62.060
2022-05-24 23:29:35,535 [bic.py] => bias_correction => Task 4, Epoch 38/170 => Loss 3.280, Train_accy 79.200, Test_accy 62.080
2022-05-24 23:29:37,251 [bic.py] => bias_correction => Task 4, Epoch 39/170 => Loss 3.266, Train_accy 78.000, Test_accy 62.320
2022-05-24 23:29:38,986 [bic.py] => bias_correction => Task 4, Epoch 40/170 => Loss 3.280, Train_accy 78.400, Test_accy 62.400
2022-05-24 23:29:40,747 [bic.py] => bias_correction => Task 4, Epoch 41/170 => Loss 3.293, Train_accy 78.000, Test_accy 62.280
2022-05-24 23:29:42,549 [bic.py] => bias_correction => Task 4, Epoch 42/170 => Loss 3.277, Train_accy 78.800, Test_accy 62.160
2022-05-24 23:29:44,305 [bic.py] => bias_correction => Task 4, Epoch 43/170 => Loss 3.273, Train_accy 79.600, Test_accy 62.040
2022-05-24 23:29:46,037 [bic.py] => bias_correction => Task 4, Epoch 44/170 => Loss 3.272, Train_accy 76.000, Test_accy 62.160
2022-05-24 23:29:47,817 [bic.py] => bias_correction => Task 4, Epoch 45/170 => Loss 3.311, Train_accy 77.600, Test_accy 62.220
2022-05-24 23:29:49,635 [bic.py] => bias_correction => Task 4, Epoch 46/170 => Loss 3.278, Train_accy 77.200, Test_accy 62.320
2022-05-24 23:29:51,380 [bic.py] => bias_correction => Task 4, Epoch 47/170 => Loss 3.270, Train_accy 79.600, Test_accy 62.320
2022-05-24 23:29:53,155 [bic.py] => bias_correction => Task 4, Epoch 48/170 => Loss 3.278, Train_accy 75.600, Test_accy 62.280
2022-05-24 23:29:54,909 [bic.py] => bias_correction => Task 4, Epoch 49/170 => Loss 3.275, Train_accy 78.400, Test_accy 62.200
2022-05-24 23:29:56,746 [bic.py] => bias_correction => Task 4, Epoch 50/170 => Loss 3.281, Train_accy 78.800, Test_accy 62.040
2022-05-24 23:29:58,524 [bic.py] => bias_correction => Task 4, Epoch 51/170 => Loss 3.259, Train_accy 77.200, Test_accy 62.100
2022-05-24 23:30:00,314 [bic.py] => bias_correction => Task 4, Epoch 52/170 => Loss 3.285, Train_accy 77.600, Test_accy 62.300
2022-05-24 23:30:02,126 [bic.py] => bias_correction => Task 4, Epoch 53/170 => Loss 3.283, Train_accy 76.800, Test_accy 62.380
2022-05-24 23:30:04,006 [bic.py] => bias_correction => Task 4, Epoch 54/170 => Loss 3.274, Train_accy 77.600, Test_accy 62.440
2022-05-24 23:30:05,813 [bic.py] => bias_correction => Task 4, Epoch 55/170 => Loss 3.267, Train_accy 75.200, Test_accy 62.280
2022-05-24 23:30:07,586 [bic.py] => bias_correction => Task 4, Epoch 56/170 => Loss 3.270, Train_accy 75.600, Test_accy 62.100
2022-05-24 23:30:09,463 [bic.py] => bias_correction => Task 4, Epoch 57/170 => Loss 3.269, Train_accy 78.400, Test_accy 62.060
2022-05-24 23:30:11,209 [bic.py] => bias_correction => Task 4, Epoch 58/170 => Loss 3.271, Train_accy 78.800, Test_accy 62.020
2022-05-24 23:30:12,990 [bic.py] => bias_correction => Task 4, Epoch 59/170 => Loss 3.273, Train_accy 78.800, Test_accy 62.260
2022-05-24 23:30:14,867 [bic.py] => bias_correction => Task 4, Epoch 60/170 => Loss 3.287, Train_accy 78.000, Test_accy 62.480
2022-05-24 23:30:16,661 [bic.py] => bias_correction => Task 4, Epoch 61/170 => Loss 3.295, Train_accy 74.800, Test_accy 62.400
2022-05-24 23:30:18,540 [bic.py] => bias_correction => Task 4, Epoch 62/170 => Loss 3.272, Train_accy 80.000, Test_accy 62.360
2022-05-24 23:30:20,319 [bic.py] => bias_correction => Task 4, Epoch 63/170 => Loss 3.271, Train_accy 76.400, Test_accy 62.380
2022-05-24 23:30:22,101 [bic.py] => bias_correction => Task 4, Epoch 64/170 => Loss 3.270, Train_accy 76.800, Test_accy 62.300
2022-05-24 23:30:23,923 [bic.py] => bias_correction => Task 4, Epoch 65/170 => Loss 3.286, Train_accy 78.000, Test_accy 62.300
2022-05-24 23:30:25,716 [bic.py] => bias_correction => Task 4, Epoch 66/170 => Loss 3.281, Train_accy 75.600, Test_accy 62.440
2022-05-24 23:30:27,548 [bic.py] => bias_correction => Task 4, Epoch 67/170 => Loss 3.268, Train_accy 78.400, Test_accy 62.420
2022-05-24 23:30:29,245 [bic.py] => bias_correction => Task 4, Epoch 68/170 => Loss 3.283, Train_accy 78.000, Test_accy 62.460
2022-05-24 23:30:31,008 [bic.py] => bias_correction => Task 4, Epoch 69/170 => Loss 3.266, Train_accy 78.400, Test_accy 62.420
2022-05-24 23:30:32,859 [bic.py] => bias_correction => Task 4, Epoch 70/170 => Loss 3.258, Train_accy 77.200, Test_accy 62.440
2022-05-24 23:30:34,612 [bic.py] => bias_correction => Task 4, Epoch 71/170 => Loss 3.279, Train_accy 74.400, Test_accy 62.340
2022-05-24 23:30:36,339 [bic.py] => bias_correction => Task 4, Epoch 72/170 => Loss 3.271, Train_accy 76.800, Test_accy 62.360
2022-05-24 23:30:38,075 [bic.py] => bias_correction => Task 4, Epoch 73/170 => Loss 3.259, Train_accy 76.800, Test_accy 62.420
2022-05-24 23:30:39,921 [bic.py] => bias_correction => Task 4, Epoch 74/170 => Loss 3.282, Train_accy 78.000, Test_accy 62.440
2022-05-24 23:30:41,638 [bic.py] => bias_correction => Task 4, Epoch 75/170 => Loss 3.291, Train_accy 75.200, Test_accy 62.460
2022-05-24 23:30:43,317 [bic.py] => bias_correction => Task 4, Epoch 76/170 => Loss 3.279, Train_accy 77.600, Test_accy 62.460
2022-05-24 23:30:45,039 [bic.py] => bias_correction => Task 4, Epoch 77/170 => Loss 3.269, Train_accy 77.200, Test_accy 62.400
2022-05-24 23:30:46,832 [bic.py] => bias_correction => Task 4, Epoch 78/170 => Loss 3.283, Train_accy 78.800, Test_accy 62.500
2022-05-24 23:30:48,599 [bic.py] => bias_correction => Task 4, Epoch 79/170 => Loss 3.273, Train_accy 78.800, Test_accy 62.520
2022-05-24 23:30:50,403 [bic.py] => bias_correction => Task 4, Epoch 80/170 => Loss 3.270, Train_accy 78.800, Test_accy 62.440
2022-05-24 23:30:52,207 [bic.py] => bias_correction => Task 4, Epoch 81/170 => Loss 3.281, Train_accy 75.600, Test_accy 62.360
2022-05-24 23:30:54,023 [bic.py] => bias_correction => Task 4, Epoch 82/170 => Loss 3.271, Train_accy 75.600, Test_accy 62.480
2022-05-24 23:30:55,749 [bic.py] => bias_correction => Task 4, Epoch 83/170 => Loss 3.268, Train_accy 78.800, Test_accy 62.380
2022-05-24 23:30:57,480 [bic.py] => bias_correction => Task 4, Epoch 84/170 => Loss 3.271, Train_accy 77.200, Test_accy 62.360
2022-05-24 23:30:59,250 [bic.py] => bias_correction => Task 4, Epoch 85/170 => Loss 3.280, Train_accy 79.200, Test_accy 62.320
2022-05-24 23:31:01,045 [bic.py] => bias_correction => Task 4, Epoch 86/170 => Loss 3.288, Train_accy 78.000, Test_accy 62.460
2022-05-24 23:31:02,772 [bic.py] => bias_correction => Task 4, Epoch 87/170 => Loss 3.274, Train_accy 77.600, Test_accy 62.500
2022-05-24 23:31:04,556 [bic.py] => bias_correction => Task 4, Epoch 88/170 => Loss 3.270, Train_accy 78.000, Test_accy 62.460
2022-05-24 23:31:06,386 [bic.py] => bias_correction => Task 4, Epoch 89/170 => Loss 3.279, Train_accy 80.400, Test_accy 62.400
2022-05-24 23:31:08,197 [bic.py] => bias_correction => Task 4, Epoch 90/170 => Loss 3.268, Train_accy 80.800, Test_accy 62.480
2022-05-24 23:31:09,943 [bic.py] => bias_correction => Task 4, Epoch 91/170 => Loss 3.261, Train_accy 79.200, Test_accy 62.560
2022-05-24 23:31:11,729 [bic.py] => bias_correction => Task 4, Epoch 92/170 => Loss 3.267, Train_accy 77.600, Test_accy 62.440
2022-05-24 23:31:13,530 [bic.py] => bias_correction => Task 4, Epoch 93/170 => Loss 3.276, Train_accy 78.800, Test_accy 62.460
2022-05-24 23:31:15,265 [bic.py] => bias_correction => Task 4, Epoch 94/170 => Loss 3.273, Train_accy 78.800, Test_accy 62.520
2022-05-24 23:31:17,016 [bic.py] => bias_correction => Task 4, Epoch 95/170 => Loss 3.272, Train_accy 76.000, Test_accy 62.420
2022-05-24 23:31:18,807 [bic.py] => bias_correction => Task 4, Epoch 96/170 => Loss 3.257, Train_accy 76.000, Test_accy 62.520
2022-05-24 23:31:20,630 [bic.py] => bias_correction => Task 4, Epoch 97/170 => Loss 3.270, Train_accy 77.600, Test_accy 62.540
2022-05-24 23:31:22,323 [bic.py] => bias_correction => Task 4, Epoch 98/170 => Loss 3.267, Train_accy 79.600, Test_accy 62.480
2022-05-24 23:31:24,117 [bic.py] => bias_correction => Task 4, Epoch 99/170 => Loss 3.278, Train_accy 78.000, Test_accy 62.380
2022-05-24 23:31:25,956 [bic.py] => bias_correction => Task 4, Epoch 100/170 => Loss 3.273, Train_accy 77.200, Test_accy 62.420
2022-05-24 23:31:27,633 [bic.py] => bias_correction => Task 4, Epoch 101/170 => Loss 3.275, Train_accy 75.200, Test_accy 62.480
2022-05-24 23:31:29,454 [bic.py] => bias_correction => Task 4, Epoch 102/170 => Loss 3.275, Train_accy 78.400, Test_accy 62.380
2022-05-24 23:31:31,169 [bic.py] => bias_correction => Task 4, Epoch 103/170 => Loss 3.265, Train_accy 78.000, Test_accy 62.420
2022-05-24 23:31:33,052 [bic.py] => bias_correction => Task 4, Epoch 104/170 => Loss 3.258, Train_accy 77.600, Test_accy 62.440
2022-05-24 23:31:34,768 [bic.py] => bias_correction => Task 4, Epoch 105/170 => Loss 3.292, Train_accy 79.600, Test_accy 62.380
2022-05-24 23:31:36,517 [bic.py] => bias_correction => Task 4, Epoch 106/170 => Loss 3.261, Train_accy 78.400, Test_accy 62.300
2022-05-24 23:31:38,355 [bic.py] => bias_correction => Task 4, Epoch 107/170 => Loss 3.279, Train_accy 78.400, Test_accy 62.380
2022-05-24 23:31:40,052 [bic.py] => bias_correction => Task 4, Epoch 108/170 => Loss 3.263, Train_accy 77.600, Test_accy 62.460
2022-05-24 23:31:41,802 [bic.py] => bias_correction => Task 4, Epoch 109/170 => Loss 3.258, Train_accy 78.400, Test_accy 62.480
2022-05-24 23:31:43,571 [bic.py] => bias_correction => Task 4, Epoch 110/170 => Loss 3.276, Train_accy 79.200, Test_accy 62.500
2022-05-24 23:31:45,363 [bic.py] => bias_correction => Task 4, Epoch 111/170 => Loss 3.277, Train_accy 76.400, Test_accy 62.560
2022-05-24 23:31:47,181 [bic.py] => bias_correction => Task 4, Epoch 112/170 => Loss 3.271, Train_accy 77.200, Test_accy 62.480
2022-05-24 23:31:49,084 [bic.py] => bias_correction => Task 4, Epoch 113/170 => Loss 3.261, Train_accy 77.600, Test_accy 62.580
2022-05-24 23:31:50,864 [bic.py] => bias_correction => Task 4, Epoch 114/170 => Loss 3.261, Train_accy 77.600, Test_accy 62.540
2022-05-24 23:31:52,765 [bic.py] => bias_correction => Task 4, Epoch 115/170 => Loss 3.267, Train_accy 76.000, Test_accy 62.460
2022-05-24 23:31:54,566 [bic.py] => bias_correction => Task 4, Epoch 116/170 => Loss 3.279, Train_accy 75.600, Test_accy 62.440
2022-05-24 23:31:56,375 [bic.py] => bias_correction => Task 4, Epoch 117/170 => Loss 3.276, Train_accy 77.600, Test_accy 62.500
2022-05-24 23:31:58,314 [bic.py] => bias_correction => Task 4, Epoch 118/170 => Loss 3.277, Train_accy 76.800, Test_accy 62.500
2022-05-24 23:32:00,061 [bic.py] => bias_correction => Task 4, Epoch 119/170 => Loss 3.281, Train_accy 77.200, Test_accy 62.560
2022-05-24 23:32:01,740 [bic.py] => bias_correction => Task 4, Epoch 120/170 => Loss 3.272, Train_accy 75.600, Test_accy 62.440
2022-05-24 23:32:03,512 [bic.py] => bias_correction => Task 4, Epoch 121/170 => Loss 3.270, Train_accy 76.800, Test_accy 62.480
2022-05-24 23:32:05,284 [bic.py] => bias_correction => Task 4, Epoch 122/170 => Loss 3.268, Train_accy 77.200, Test_accy 62.440
2022-05-24 23:32:07,074 [bic.py] => bias_correction => Task 4, Epoch 123/170 => Loss 3.272, Train_accy 77.200, Test_accy 62.340
2022-05-24 23:32:08,816 [bic.py] => bias_correction => Task 4, Epoch 124/170 => Loss 3.280, Train_accy 80.000, Test_accy 62.340
2022-05-24 23:32:10,581 [bic.py] => bias_correction => Task 4, Epoch 125/170 => Loss 3.295, Train_accy 78.400, Test_accy 62.300
2022-05-24 23:32:12,436 [bic.py] => bias_correction => Task 4, Epoch 126/170 => Loss 3.265, Train_accy 76.400, Test_accy 62.320
2022-05-24 23:32:14,118 [bic.py] => bias_correction => Task 4, Epoch 127/170 => Loss 3.269, Train_accy 78.800, Test_accy 62.460
2022-05-24 23:32:15,964 [bic.py] => bias_correction => Task 4, Epoch 128/170 => Loss 3.277, Train_accy 76.800, Test_accy 62.400
2022-05-24 23:32:17,721 [bic.py] => bias_correction => Task 4, Epoch 129/170 => Loss 3.277, Train_accy 75.600, Test_accy 62.280
2022-05-24 23:32:19,422 [bic.py] => bias_correction => Task 4, Epoch 130/170 => Loss 3.268, Train_accy 78.000, Test_accy 62.320
2022-05-24 23:32:21,214 [bic.py] => bias_correction => Task 4, Epoch 131/170 => Loss 3.275, Train_accy 78.000, Test_accy 62.400
2022-05-24 23:32:23,024 [bic.py] => bias_correction => Task 4, Epoch 132/170 => Loss 3.268, Train_accy 76.400, Test_accy 62.360
2022-05-24 23:32:24,866 [bic.py] => bias_correction => Task 4, Epoch 133/170 => Loss 3.271, Train_accy 78.400, Test_accy 62.340
2022-05-24 23:32:26,679 [bic.py] => bias_correction => Task 4, Epoch 134/170 => Loss 3.277, Train_accy 78.800, Test_accy 62.400
2022-05-24 23:32:28,427 [bic.py] => bias_correction => Task 4, Epoch 135/170 => Loss 3.270, Train_accy 78.400, Test_accy 62.340
2022-05-24 23:32:30,157 [bic.py] => bias_correction => Task 4, Epoch 136/170 => Loss 3.275, Train_accy 77.200, Test_accy 62.420
2022-05-24 23:32:31,943 [bic.py] => bias_correction => Task 4, Epoch 137/170 => Loss 3.278, Train_accy 78.000, Test_accy 62.440
2022-05-24 23:32:33,748 [bic.py] => bias_correction => Task 4, Epoch 138/170 => Loss 3.267, Train_accy 76.800, Test_accy 62.360
2022-05-24 23:32:35,482 [bic.py] => bias_correction => Task 4, Epoch 139/170 => Loss 3.274, Train_accy 78.400, Test_accy 62.400
2022-05-24 23:32:37,272 [bic.py] => bias_correction => Task 4, Epoch 140/170 => Loss 3.273, Train_accy 78.000, Test_accy 62.480
2022-05-24 23:32:38,979 [bic.py] => bias_correction => Task 4, Epoch 141/170 => Loss 3.264, Train_accy 79.600, Test_accy 62.400
2022-05-24 23:32:40,696 [bic.py] => bias_correction => Task 4, Epoch 142/170 => Loss 3.268, Train_accy 77.200, Test_accy 62.360
2022-05-24 23:32:42,483 [bic.py] => bias_correction => Task 4, Epoch 143/170 => Loss 3.298, Train_accy 80.000, Test_accy 62.380
2022-05-24 23:32:44,317 [bic.py] => bias_correction => Task 4, Epoch 144/170 => Loss 3.283, Train_accy 76.400, Test_accy 62.400
2022-05-24 23:32:46,097 [bic.py] => bias_correction => Task 4, Epoch 145/170 => Loss 3.277, Train_accy 78.800, Test_accy 62.440
2022-05-24 23:32:47,909 [bic.py] => bias_correction => Task 4, Epoch 146/170 => Loss 3.262, Train_accy 76.000, Test_accy 62.360
2022-05-24 23:32:49,753 [bic.py] => bias_correction => Task 4, Epoch 147/170 => Loss 3.283, Train_accy 78.000, Test_accy 62.340
2022-05-24 23:32:51,469 [bic.py] => bias_correction => Task 4, Epoch 148/170 => Loss 3.273, Train_accy 77.200, Test_accy 62.400
2022-05-24 23:32:53,251 [bic.py] => bias_correction => Task 4, Epoch 149/170 => Loss 3.273, Train_accy 76.400, Test_accy 62.360
2022-05-24 23:32:54,843 [bic.py] => bias_correction => Task 4, Epoch 150/170 => Loss 3.264, Train_accy 76.000, Test_accy 62.400
2022-05-24 23:32:56,669 [bic.py] => bias_correction => Task 4, Epoch 151/170 => Loss 3.279, Train_accy 80.000, Test_accy 62.400
2022-05-24 23:32:58,400 [bic.py] => bias_correction => Task 4, Epoch 152/170 => Loss 3.276, Train_accy 80.800, Test_accy 62.380
2022-05-24 23:33:00,179 [bic.py] => bias_correction => Task 4, Epoch 153/170 => Loss 3.259, Train_accy 78.000, Test_accy 62.360
2022-05-24 23:33:02,135 [bic.py] => bias_correction => Task 4, Epoch 154/170 => Loss 3.273, Train_accy 76.400, Test_accy 62.400
2022-05-24 23:33:03,970 [bic.py] => bias_correction => Task 4, Epoch 155/170 => Loss 3.265, Train_accy 79.600, Test_accy 62.400
2022-05-24 23:33:05,814 [bic.py] => bias_correction => Task 4, Epoch 156/170 => Loss 3.289, Train_accy 78.400, Test_accy 62.360
2022-05-24 23:33:07,527 [bic.py] => bias_correction => Task 4, Epoch 157/170 => Loss 3.281, Train_accy 79.200, Test_accy 62.400
2022-05-24 23:33:09,372 [bic.py] => bias_correction => Task 4, Epoch 158/170 => Loss 3.266, Train_accy 77.200, Test_accy 62.480
2022-05-24 23:33:11,026 [bic.py] => bias_correction => Task 4, Epoch 159/170 => Loss 3.289, Train_accy 77.200, Test_accy 62.380
2022-05-24 23:33:12,792 [bic.py] => bias_correction => Task 4, Epoch 160/170 => Loss 3.279, Train_accy 78.400, Test_accy 62.420
2022-05-24 23:33:14,560 [bic.py] => bias_correction => Task 4, Epoch 161/170 => Loss 3.280, Train_accy 78.000, Test_accy 62.380
2022-05-24 23:33:16,414 [bic.py] => bias_correction => Task 4, Epoch 162/170 => Loss 3.275, Train_accy 79.200, Test_accy 62.400
2022-05-24 23:33:18,199 [bic.py] => bias_correction => Task 4, Epoch 163/170 => Loss 3.273, Train_accy 76.400, Test_accy 62.360
2022-05-24 23:33:19,889 [bic.py] => bias_correction => Task 4, Epoch 164/170 => Loss 3.270, Train_accy 75.200, Test_accy 62.360
2022-05-24 23:33:21,759 [bic.py] => bias_correction => Task 4, Epoch 165/170 => Loss 3.283, Train_accy 78.000, Test_accy 62.360
2022-05-24 23:33:23,643 [bic.py] => bias_correction => Task 4, Epoch 166/170 => Loss 3.279, Train_accy 76.000, Test_accy 62.420
2022-05-24 23:33:25,403 [bic.py] => bias_correction => Task 4, Epoch 167/170 => Loss 3.280, Train_accy 79.600, Test_accy 62.340
2022-05-24 23:33:27,143 [bic.py] => bias_correction => Task 4, Epoch 168/170 => Loss 3.279, Train_accy 79.200, Test_accy 62.440
2022-05-24 23:33:28,939 [bic.py] => bias_correction => Task 4, Epoch 169/170 => Loss 3.278, Train_accy 78.000, Test_accy 62.460
2022-05-24 23:33:30,596 [bic.py] => bias_correction => Task 4, Epoch 170/170 => Loss 3.281, Train_accy 77.200, Test_accy 62.340
2022-05-24 23:33:30,597 [base.py] => Reducing exemplars...(40 per classes)
2022-05-24 23:33:39,005 [base.py] => Constructing exemplars...(40 per classes)
2022-05-24 23:33:44,508 [bic.py] => Parameters of bias layer:
2022-05-24 23:33:44,509 [bic.py] => 0 => 1.000, 0.000
2022-05-24 23:33:44,509 [bic.py] => 1 => 0.981, -1.523
2022-05-24 23:33:44,509 [bic.py] => 2 => 0.816, -1.587
2022-05-24 23:33:44,509 [bic.py] => 3 => 0.723, -1.178
2022-05-24 23:33:44,509 [bic.py] => 4 => 0.736, -1.143
2022-05-24 23:33:46,434 [bic.py] => Exemplar size: 2000
2022-05-24 23:33:46,434 [trainer.py] => CNN: {'total': 62.34, '00-09': 67.7, '10-19': 55.7, '20-29': 66.9, '30-39': 54.1, '40-49': 67.3, 'old': 61.1, 'new': 67.3}
2022-05-24 23:33:46,434 [trainer.py] => NME: {'total': 62.62, '00-09': 65.6, '10-19': 49.7, '20-29': 65.7, '30-39': 59.3, '40-49': 72.8, 'old': 60.08, 'new': 72.8}
2022-05-24 23:33:46,434 [trainer.py] => CNN top1 curve: [87.5, 75.95, 70.6, 64.53, 62.34]
2022-05-24 23:33:46,434 [trainer.py] => CNN top5 curve: [99.3, 95.5, 93.17, 90.3, 89.32]
2022-05-24 23:33:46,434 [trainer.py] => NME top1 curve: [88.1, 75.6, 71.27, 64.97, 62.62]
2022-05-24 23:33:46,434 [trainer.py] => NME top5 curve: [99.4, 95.4, 93.2, 90.05, 88.58]

2022-05-24 23:33:46,435 [trainer.py] => All params: 467414
2022-05-24 23:33:46,435 [trainer.py] => Trainable params: 467414
2022-05-24 23:33:46,436 [bic.py] => Learning on 50-60
2022-05-24 23:33:46,481 [bic.py] => Stage1 dset: 6760, Stage2 dset: 240
2022-05-24 23:33:46,481 [bic.py] => Lambda: 0.833
2022-05-24 23:33:46,494 [bic.py] => Parameters of bias layer:
2022-05-24 23:33:46,495 [bic.py] => 0 => 1.000, 0.000
2022-05-24 23:33:46,495 [bic.py] => 1 => 0.981, -1.523
2022-05-24 23:33:46,495 [bic.py] => 2 => 0.816, -1.587
2022-05-24 23:33:46,495 [bic.py] => 3 => 0.723, -1.178
2022-05-24 23:33:46,495 [bic.py] => 4 => 0.736, -1.143
2022-05-24 23:33:46,495 [bic.py] => 5 => 1.000, 0.000
2022-05-24 23:33:52,300 [bic.py] => training => Task 5, Epoch 1/170 => Loss 2.475, Train_accy 64.700, Test_accy 39.830
2022-05-24 23:33:57,832 [bic.py] => training => Task 5, Epoch 2/170 => Loss 2.340, Train_accy 73.360, Test_accy 43.580
2022-05-24 23:34:03,326 [bic.py] => training => Task 5, Epoch 3/170 => Loss 2.314, Train_accy 75.150, Test_accy 43.180
2022-05-24 23:34:08,925 [bic.py] => training => Task 5, Epoch 4/170 => Loss 2.302, Train_accy 76.210, Test_accy 42.480
2022-05-24 23:34:14,529 [bic.py] => training => Task 5, Epoch 5/170 => Loss 2.300, Train_accy 76.820, Test_accy 43.350
2022-05-24 23:34:20,121 [bic.py] => training => Task 5, Epoch 6/170 => Loss 2.283, Train_accy 78.540, Test_accy 44.200
2022-05-24 23:34:25,774 [bic.py] => training => Task 5, Epoch 7/170 => Loss 2.279, Train_accy 78.770, Test_accy 42.950
2022-05-24 23:34:31,349 [bic.py] => training => Task 5, Epoch 8/170 => Loss 2.275, Train_accy 80.860, Test_accy 46.120
2022-05-24 23:34:37,235 [bic.py] => training => Task 5, Epoch 9/170 => Loss 2.274, Train_accy 81.660, Test_accy 48.220
2022-05-24 23:34:43,011 [bic.py] => training => Task 5, Epoch 10/170 => Loss 2.263, Train_accy 84.940, Test_accy 45.430
2022-05-24 23:34:48,644 [bic.py] => training => Task 5, Epoch 11/170 => Loss 2.260, Train_accy 82.470, Test_accy 46.300
2022-05-24 23:34:54,442 [bic.py] => training => Task 5, Epoch 12/170 => Loss 2.259, Train_accy 85.560, Test_accy 45.350
2022-05-24 23:35:00,080 [bic.py] => training => Task 5, Epoch 13/170 => Loss 2.255, Train_accy 83.820, Test_accy 45.970
2022-05-24 23:35:05,998 [bic.py] => training => Task 5, Epoch 14/170 => Loss 2.251, Train_accy 86.330, Test_accy 44.920
2022-05-24 23:35:11,800 [bic.py] => training => Task 5, Epoch 15/170 => Loss 2.250, Train_accy 85.380, Test_accy 44.530
2022-05-24 23:35:17,486 [bic.py] => training => Task 5, Epoch 16/170 => Loss 2.248, Train_accy 85.520, Test_accy 43.870
2022-05-24 23:35:23,192 [bic.py] => training => Task 5, Epoch 17/170 => Loss 2.254, Train_accy 86.350, Test_accy 44.480
2022-05-24 23:35:28,919 [bic.py] => training => Task 5, Epoch 18/170 => Loss 2.247, Train_accy 86.070, Test_accy 44.720
2022-05-24 23:35:34,703 [bic.py] => training => Task 5, Epoch 19/170 => Loss 2.249, Train_accy 87.290, Test_accy 47.170
2022-05-24 23:35:40,383 [bic.py] => training => Task 5, Epoch 20/170 => Loss 2.247, Train_accy 82.800, Test_accy 44.080
2022-05-24 23:35:45,976 [bic.py] => training => Task 5, Epoch 21/170 => Loss 2.253, Train_accy 81.430, Test_accy 43.580
2022-05-24 23:35:51,573 [bic.py] => training => Task 5, Epoch 22/170 => Loss 2.244, Train_accy 86.380, Test_accy 45.120
2022-05-24 23:35:57,239 [bic.py] => training => Task 5, Epoch 23/170 => Loss 2.240, Train_accy 86.050, Test_accy 45.270
2022-05-24 23:36:02,880 [bic.py] => training => Task 5, Epoch 24/170 => Loss 2.245, Train_accy 87.220, Test_accy 47.030
2022-05-24 23:36:08,744 [bic.py] => training => Task 5, Epoch 25/170 => Loss 2.245, Train_accy 87.350, Test_accy 46.070
2022-05-24 23:36:14,519 [bic.py] => training => Task 5, Epoch 26/170 => Loss 2.234, Train_accy 91.630, Test_accy 47.570
2022-05-24 23:36:20,323 [bic.py] => training => Task 5, Epoch 27/170 => Loss 2.241, Train_accy 89.820, Test_accy 47.350
2022-05-24 23:36:26,217 [bic.py] => training => Task 5, Epoch 28/170 => Loss 2.238, Train_accy 89.140, Test_accy 48.630
2022-05-24 23:36:32,017 [bic.py] => training => Task 5, Epoch 29/170 => Loss 2.233, Train_accy 90.860, Test_accy 49.170
2022-05-24 23:36:37,733 [bic.py] => training => Task 5, Epoch 30/170 => Loss 2.231, Train_accy 90.220, Test_accy 45.420
2022-05-24 23:36:43,315 [bic.py] => training => Task 5, Epoch 31/170 => Loss 2.231, Train_accy 80.430, Test_accy 39.950
2022-05-24 23:36:49,037 [bic.py] => training => Task 5, Epoch 32/170 => Loss 2.229, Train_accy 88.080, Test_accy 43.250
2022-05-24 23:36:54,911 [bic.py] => training => Task 5, Epoch 33/170 => Loss 2.227, Train_accy 90.530, Test_accy 49.300
2022-05-24 23:37:00,650 [bic.py] => training => Task 5, Epoch 34/170 => Loss 2.233, Train_accy 89.170, Test_accy 47.470
2022-05-24 23:37:06,341 [bic.py] => training => Task 5, Epoch 35/170 => Loss 2.231, Train_accy 91.540, Test_accy 48.230
2022-05-24 23:37:12,020 [bic.py] => training => Task 5, Epoch 36/170 => Loss 2.238, Train_accy 88.140, Test_accy 47.180
2022-05-24 23:37:17,825 [bic.py] => training => Task 5, Epoch 37/170 => Loss 2.234, Train_accy 90.920, Test_accy 44.920
2022-05-24 23:37:23,412 [bic.py] => training => Task 5, Epoch 38/170 => Loss 2.229, Train_accy 90.860, Test_accy 47.230
2022-05-24 23:37:29,289 [bic.py] => training => Task 5, Epoch 39/170 => Loss 2.235, Train_accy 86.780, Test_accy 43.020
2022-05-24 23:37:34,884 [bic.py] => training => Task 5, Epoch 40/170 => Loss 2.234, Train_accy 89.170, Test_accy 46.850
2022-05-24 23:37:40,545 [bic.py] => training => Task 5, Epoch 41/170 => Loss 2.228, Train_accy 91.660, Test_accy 46.470
2022-05-24 23:37:46,336 [bic.py] => training => Task 5, Epoch 42/170 => Loss 2.225, Train_accy 91.940, Test_accy 48.420
2022-05-24 23:37:52,241 [bic.py] => training => Task 5, Epoch 43/170 => Loss 2.221, Train_accy 92.510, Test_accy 47.700
2022-05-24 23:37:58,265 [bic.py] => training => Task 5, Epoch 44/170 => Loss 2.228, Train_accy 88.770, Test_accy 42.170
2022-05-24 23:38:03,929 [bic.py] => training => Task 5, Epoch 45/170 => Loss 2.226, Train_accy 89.330, Test_accy 45.480
2022-05-24 23:38:09,595 [bic.py] => training => Task 5, Epoch 46/170 => Loss 2.223, Train_accy 88.140, Test_accy 48.380
2022-05-24 23:38:15,625 [bic.py] => training => Task 5, Epoch 47/170 => Loss 2.221, Train_accy 85.440, Test_accy 44.530
2022-05-24 23:38:21,342 [bic.py] => training => Task 5, Epoch 48/170 => Loss 2.225, Train_accy 88.670, Test_accy 45.030
2022-05-24 23:38:27,427 [bic.py] => training => Task 5, Epoch 49/170 => Loss 2.224, Train_accy 91.820, Test_accy 47.350
2022-05-24 23:38:33,363 [bic.py] => training => Task 5, Epoch 50/170 => Loss 2.229, Train_accy 91.320, Test_accy 45.120
2022-05-24 23:38:39,295 [bic.py] => training => Task 5, Epoch 51/170 => Loss 2.229, Train_accy 88.540, Test_accy 44.850
2022-05-24 23:38:44,967 [bic.py] => training => Task 5, Epoch 52/170 => Loss 2.224, Train_accy 90.550, Test_accy 46.050
2022-05-24 23:38:50,579 [bic.py] => training => Task 5, Epoch 53/170 => Loss 2.213, Train_accy 84.320, Test_accy 41.720
2022-05-24 23:38:56,348 [bic.py] => training => Task 5, Epoch 54/170 => Loss 2.228, Train_accy 83.240, Test_accy 42.620
2022-05-24 23:39:02,009 [bic.py] => training => Task 5, Epoch 55/170 => Loss 2.226, Train_accy 88.140, Test_accy 44.370
2022-05-24 23:39:07,647 [bic.py] => training => Task 5, Epoch 56/170 => Loss 2.222, Train_accy 90.580, Test_accy 46.020
2022-05-24 23:39:13,477 [bic.py] => training => Task 5, Epoch 57/170 => Loss 2.218, Train_accy 93.270, Test_accy 44.080
2022-05-24 23:39:19,214 [bic.py] => training => Task 5, Epoch 58/170 => Loss 2.212, Train_accy 86.050, Test_accy 43.680
2022-05-24 23:39:25,055 [bic.py] => training => Task 5, Epoch 59/170 => Loss 2.211, Train_accy 92.130, Test_accy 43.170
2022-05-24 23:39:30,928 [bic.py] => training => Task 5, Epoch 60/170 => Loss 2.219, Train_accy 91.420, Test_accy 47.780
2022-05-24 23:39:36,826 [bic.py] => training => Task 5, Epoch 61/170 => Loss 2.194, Train_accy 98.080, Test_accy 51.420
2022-05-24 23:39:42,715 [bic.py] => training => Task 5, Epoch 62/170 => Loss 2.176, Train_accy 98.550, Test_accy 52.000
2022-05-24 23:39:48,607 [bic.py] => training => Task 5, Epoch 63/170 => Loss 2.176, Train_accy 98.930, Test_accy 51.770
2022-05-24 23:39:54,547 [bic.py] => training => Task 5, Epoch 64/170 => Loss 2.167, Train_accy 98.820, Test_accy 51.530
2022-05-24 23:40:00,366 [bic.py] => training => Task 5, Epoch 65/170 => Loss 2.165, Train_accy 98.910, Test_accy 52.020
2022-05-24 23:40:06,234 [bic.py] => training => Task 5, Epoch 66/170 => Loss 2.169, Train_accy 99.290, Test_accy 51.820
2022-05-24 23:40:11,979 [bic.py] => training => Task 5, Epoch 67/170 => Loss 2.165, Train_accy 99.010, Test_accy 51.850
2022-05-24 23:40:17,902 [bic.py] => training => Task 5, Epoch 68/170 => Loss 2.165, Train_accy 99.230, Test_accy 52.130
2022-05-24 23:40:23,594 [bic.py] => training => Task 5, Epoch 69/170 => Loss 2.162, Train_accy 99.330, Test_accy 52.580
2022-05-24 23:40:29,171 [bic.py] => training => Task 5, Epoch 70/170 => Loss 2.166, Train_accy 99.230, Test_accy 52.280
2022-05-24 23:40:35,190 [bic.py] => training => Task 5, Epoch 71/170 => Loss 2.165, Train_accy 99.260, Test_accy 52.050
2022-05-24 23:40:40,918 [bic.py] => training => Task 5, Epoch 72/170 => Loss 2.158, Train_accy 99.330, Test_accy 52.300
2022-05-24 23:40:46,475 [bic.py] => training => Task 5, Epoch 73/170 => Loss 2.158, Train_accy 99.080, Test_accy 51.700
2022-05-24 23:40:52,268 [bic.py] => training => Task 5, Epoch 74/170 => Loss 2.162, Train_accy 99.360, Test_accy 51.780
2022-05-24 23:40:57,811 [bic.py] => training => Task 5, Epoch 75/170 => Loss 2.162, Train_accy 99.100, Test_accy 51.880
2022-05-24 23:41:03,562 [bic.py] => training => Task 5, Epoch 76/170 => Loss 2.159, Train_accy 99.200, Test_accy 51.930
2022-05-24 23:41:09,216 [bic.py] => training => Task 5, Epoch 77/170 => Loss 2.159, Train_accy 99.280, Test_accy 52.250
2022-05-24 23:41:14,743 [bic.py] => training => Task 5, Epoch 78/170 => Loss 2.163, Train_accy 99.320, Test_accy 51.880
2022-05-24 23:41:20,577 [bic.py] => training => Task 5, Epoch 79/170 => Loss 2.162, Train_accy 99.300, Test_accy 51.930
2022-05-24 23:41:26,235 [bic.py] => training => Task 5, Epoch 80/170 => Loss 2.158, Train_accy 99.220, Test_accy 51.730
2022-05-24 23:41:31,714 [bic.py] => training => Task 5, Epoch 81/170 => Loss 2.160, Train_accy 99.350, Test_accy 52.320
2022-05-24 23:41:37,569 [bic.py] => training => Task 5, Epoch 82/170 => Loss 2.158, Train_accy 99.360, Test_accy 51.970
2022-05-24 23:41:43,312 [bic.py] => training => Task 5, Epoch 83/170 => Loss 2.161, Train_accy 99.360, Test_accy 52.400
2022-05-24 23:41:49,101 [bic.py] => training => Task 5, Epoch 84/170 => Loss 2.157, Train_accy 99.220, Test_accy 52.330
2022-05-24 23:41:54,773 [bic.py] => training => Task 5, Epoch 85/170 => Loss 2.155, Train_accy 99.390, Test_accy 52.170
2022-05-24 23:42:00,710 [bic.py] => training => Task 5, Epoch 86/170 => Loss 2.160, Train_accy 99.380, Test_accy 52.130
2022-05-24 23:42:06,759 [bic.py] => training => Task 5, Epoch 87/170 => Loss 2.157, Train_accy 99.450, Test_accy 51.870
2022-05-24 23:42:12,369 [bic.py] => training => Task 5, Epoch 88/170 => Loss 2.159, Train_accy 99.410, Test_accy 52.530
2022-05-24 23:42:18,116 [bic.py] => training => Task 5, Epoch 89/170 => Loss 2.157, Train_accy 99.230, Test_accy 51.470
2022-05-24 23:42:24,015 [bic.py] => training => Task 5, Epoch 90/170 => Loss 2.152, Train_accy 99.360, Test_accy 51.970
2022-05-24 23:42:29,658 [bic.py] => training => Task 5, Epoch 91/170 => Loss 2.156, Train_accy 99.380, Test_accy 52.430
2022-05-24 23:42:35,385 [bic.py] => training => Task 5, Epoch 92/170 => Loss 2.159, Train_accy 99.420, Test_accy 51.830
2022-05-24 23:42:40,968 [bic.py] => training => Task 5, Epoch 93/170 => Loss 2.153, Train_accy 99.350, Test_accy 52.420
2022-05-24 23:42:46,754 [bic.py] => training => Task 5, Epoch 94/170 => Loss 2.157, Train_accy 99.470, Test_accy 52.200
2022-05-24 23:42:52,387 [bic.py] => training => Task 5, Epoch 95/170 => Loss 2.155, Train_accy 99.510, Test_accy 52.380
2022-05-24 23:42:57,982 [bic.py] => training => Task 5, Epoch 96/170 => Loss 2.155, Train_accy 99.570, Test_accy 51.920
2022-05-24 23:43:03,693 [bic.py] => training => Task 5, Epoch 97/170 => Loss 2.154, Train_accy 99.420, Test_accy 52.000
2022-05-24 23:43:09,543 [bic.py] => training => Task 5, Epoch 98/170 => Loss 2.158, Train_accy 99.470, Test_accy 52.200
2022-05-24 23:43:15,196 [bic.py] => training => Task 5, Epoch 99/170 => Loss 2.152, Train_accy 99.450, Test_accy 51.780
2022-05-24 23:43:20,799 [bic.py] => training => Task 5, Epoch 100/170 => Loss 2.157, Train_accy 99.470, Test_accy 51.850
2022-05-24 23:43:26,697 [bic.py] => training => Task 5, Epoch 101/170 => Loss 2.155, Train_accy 99.290, Test_accy 52.000
2022-05-24 23:43:32,357 [bic.py] => training => Task 5, Epoch 102/170 => Loss 2.152, Train_accy 99.450, Test_accy 52.070
2022-05-24 23:43:37,990 [bic.py] => training => Task 5, Epoch 103/170 => Loss 2.151, Train_accy 99.380, Test_accy 51.780
2022-05-24 23:43:43,972 [bic.py] => training => Task 5, Epoch 104/170 => Loss 2.152, Train_accy 99.540, Test_accy 52.370
2022-05-24 23:43:49,752 [bic.py] => training => Task 5, Epoch 105/170 => Loss 2.151, Train_accy 99.750, Test_accy 52.380
2022-05-24 23:43:55,283 [bic.py] => training => Task 5, Epoch 106/170 => Loss 2.149, Train_accy 99.640, Test_accy 52.270
2022-05-24 23:44:00,894 [bic.py] => training => Task 5, Epoch 107/170 => Loss 2.154, Train_accy 99.480, Test_accy 51.920
2022-05-24 23:44:06,543 [bic.py] => training => Task 5, Epoch 108/170 => Loss 2.155, Train_accy 99.510, Test_accy 52.330
2022-05-24 23:44:12,238 [bic.py] => training => Task 5, Epoch 109/170 => Loss 2.150, Train_accy 99.530, Test_accy 52.420
2022-05-24 23:44:17,969 [bic.py] => training => Task 5, Epoch 110/170 => Loss 2.156, Train_accy 99.410, Test_accy 52.250
2022-05-24 23:44:23,767 [bic.py] => training => Task 5, Epoch 111/170 => Loss 2.154, Train_accy 99.670, Test_accy 52.180
2022-05-24 23:44:29,509 [bic.py] => training => Task 5, Epoch 112/170 => Loss 2.150, Train_accy 99.590, Test_accy 52.170
2022-05-24 23:44:35,242 [bic.py] => training => Task 5, Epoch 113/170 => Loss 2.154, Train_accy 99.510, Test_accy 52.400
2022-05-24 23:44:41,094 [bic.py] => training => Task 5, Epoch 114/170 => Loss 2.151, Train_accy 99.600, Test_accy 52.000
2022-05-24 23:44:46,814 [bic.py] => training => Task 5, Epoch 115/170 => Loss 2.155, Train_accy 99.540, Test_accy 52.100
2022-05-24 23:44:52,465 [bic.py] => training => Task 5, Epoch 116/170 => Loss 2.150, Train_accy 99.420, Test_accy 52.120
2022-05-24 23:44:58,210 [bic.py] => training => Task 5, Epoch 117/170 => Loss 2.148, Train_accy 99.450, Test_accy 51.950
2022-05-24 23:45:04,234 [bic.py] => training => Task 5, Epoch 118/170 => Loss 2.150, Train_accy 99.560, Test_accy 51.950
2022-05-24 23:45:10,040 [bic.py] => training => Task 5, Epoch 119/170 => Loss 2.155, Train_accy 99.570, Test_accy 52.200
2022-05-24 23:45:15,733 [bic.py] => training => Task 5, Epoch 120/170 => Loss 2.156, Train_accy 99.540, Test_accy 52.180
2022-05-24 23:45:21,387 [bic.py] => training => Task 5, Epoch 121/170 => Loss 2.148, Train_accy 99.500, Test_accy 52.170
2022-05-24 23:45:27,072 [bic.py] => training => Task 5, Epoch 122/170 => Loss 2.153, Train_accy 99.530, Test_accy 52.070
2022-05-24 23:45:32,997 [bic.py] => training => Task 5, Epoch 123/170 => Loss 2.152, Train_accy 99.420, Test_accy 52.250
2022-05-24 23:45:38,580 [bic.py] => training => Task 5, Epoch 124/170 => Loss 2.151, Train_accy 99.570, Test_accy 52.070
2022-05-24 23:45:44,303 [bic.py] => training => Task 5, Epoch 125/170 => Loss 2.152, Train_accy 99.510, Test_accy 52.180
2022-05-24 23:45:50,090 [bic.py] => training => Task 5, Epoch 126/170 => Loss 2.149, Train_accy 99.620, Test_accy 52.180
2022-05-24 23:45:56,141 [bic.py] => training => Task 5, Epoch 127/170 => Loss 2.147, Train_accy 99.540, Test_accy 52.230
2022-05-24 23:46:01,732 [bic.py] => training => Task 5, Epoch 128/170 => Loss 2.159, Train_accy 99.570, Test_accy 52.370
2022-05-24 23:46:07,431 [bic.py] => training => Task 5, Epoch 129/170 => Loss 2.154, Train_accy 99.640, Test_accy 52.330
2022-05-24 23:46:13,412 [bic.py] => training => Task 5, Epoch 130/170 => Loss 2.150, Train_accy 99.600, Test_accy 51.820
2022-05-24 23:46:18,942 [bic.py] => training => Task 5, Epoch 131/170 => Loss 2.154, Train_accy 99.500, Test_accy 52.120
2022-05-24 23:46:24,726 [bic.py] => training => Task 5, Epoch 132/170 => Loss 2.155, Train_accy 99.560, Test_accy 52.450
2022-05-24 23:46:30,399 [bic.py] => training => Task 5, Epoch 133/170 => Loss 2.152, Train_accy 99.600, Test_accy 52.130
2022-05-24 23:46:36,258 [bic.py] => training => Task 5, Epoch 134/170 => Loss 2.154, Train_accy 99.540, Test_accy 52.070
2022-05-24 23:46:41,908 [bic.py] => training => Task 5, Epoch 135/170 => Loss 2.152, Train_accy 99.480, Test_accy 52.200
2022-05-24 23:46:47,462 [bic.py] => training => Task 5, Epoch 136/170 => Loss 2.149, Train_accy 99.570, Test_accy 52.170
2022-05-24 23:46:53,375 [bic.py] => training => Task 5, Epoch 137/170 => Loss 2.157, Train_accy 99.480, Test_accy 51.870
2022-05-24 23:46:59,052 [bic.py] => training => Task 5, Epoch 138/170 => Loss 2.150, Train_accy 99.500, Test_accy 52.120
2022-05-24 23:47:04,699 [bic.py] => training => Task 5, Epoch 139/170 => Loss 2.157, Train_accy 99.530, Test_accy 52.180
2022-05-24 23:47:10,546 [bic.py] => training => Task 5, Epoch 140/170 => Loss 2.150, Train_accy 99.500, Test_accy 52.500
2022-05-24 23:47:16,425 [bic.py] => training => Task 5, Epoch 141/170 => Loss 2.155, Train_accy 99.440, Test_accy 52.200
2022-05-24 23:47:21,995 [bic.py] => training => Task 5, Epoch 142/170 => Loss 2.152, Train_accy 99.560, Test_accy 52.420
2022-05-24 23:47:27,747 [bic.py] => training => Task 5, Epoch 143/170 => Loss 2.154, Train_accy 99.540, Test_accy 52.620
2022-05-24 23:47:33,355 [bic.py] => training => Task 5, Epoch 144/170 => Loss 2.151, Train_accy 99.530, Test_accy 52.370
2022-05-24 23:47:39,080 [bic.py] => training => Task 5, Epoch 145/170 => Loss 2.153, Train_accy 99.450, Test_accy 52.280
2022-05-24 23:47:44,786 [bic.py] => training => Task 5, Epoch 146/170 => Loss 2.147, Train_accy 99.640, Test_accy 52.250
2022-05-24 23:47:50,682 [bic.py] => training => Task 5, Epoch 147/170 => Loss 2.151, Train_accy 99.600, Test_accy 52.200
2022-05-24 23:47:56,573 [bic.py] => training => Task 5, Epoch 148/170 => Loss 2.149, Train_accy 99.560, Test_accy 52.220
2022-05-24 23:48:02,199 [bic.py] => training => Task 5, Epoch 149/170 => Loss 2.153, Train_accy 99.530, Test_accy 52.350
2022-05-24 23:48:07,998 [bic.py] => training => Task 5, Epoch 150/170 => Loss 2.152, Train_accy 99.500, Test_accy 52.320
2022-05-24 23:48:13,624 [bic.py] => training => Task 5, Epoch 151/170 => Loss 2.154, Train_accy 99.390, Test_accy 52.230
2022-05-24 23:48:19,469 [bic.py] => training => Task 5, Epoch 152/170 => Loss 2.155, Train_accy 99.480, Test_accy 52.550
2022-05-24 23:48:25,305 [bic.py] => training => Task 5, Epoch 153/170 => Loss 2.151, Train_accy 99.530, Test_accy 52.620
2022-05-24 23:48:31,043 [bic.py] => training => Task 5, Epoch 154/170 => Loss 2.150, Train_accy 99.530, Test_accy 52.300
2022-05-24 23:48:36,883 [bic.py] => training => Task 5, Epoch 155/170 => Loss 2.153, Train_accy 99.470, Test_accy 52.200
2022-05-24 23:48:42,558 [bic.py] => training => Task 5, Epoch 156/170 => Loss 2.154, Train_accy 99.470, Test_accy 52.170
2022-05-24 23:48:48,310 [bic.py] => training => Task 5, Epoch 157/170 => Loss 2.149, Train_accy 99.660, Test_accy 52.300
2022-05-24 23:48:53,968 [bic.py] => training => Task 5, Epoch 158/170 => Loss 2.152, Train_accy 99.640, Test_accy 52.230
2022-05-24 23:48:59,879 [bic.py] => training => Task 5, Epoch 159/170 => Loss 2.153, Train_accy 99.530, Test_accy 52.230
2022-05-24 23:49:05,730 [bic.py] => training => Task 5, Epoch 160/170 => Loss 2.147, Train_accy 99.570, Test_accy 52.050
2022-05-24 23:49:11,424 [bic.py] => training => Task 5, Epoch 161/170 => Loss 2.152, Train_accy 99.560, Test_accy 52.030
2022-05-24 23:49:17,257 [bic.py] => training => Task 5, Epoch 162/170 => Loss 2.153, Train_accy 99.620, Test_accy 52.200
2022-05-24 23:49:23,166 [bic.py] => training => Task 5, Epoch 163/170 => Loss 2.154, Train_accy 99.440, Test_accy 52.280
2022-05-24 23:49:28,825 [bic.py] => training => Task 5, Epoch 164/170 => Loss 2.157, Train_accy 99.570, Test_accy 52.000
2022-05-24 23:49:34,656 [bic.py] => training => Task 5, Epoch 165/170 => Loss 2.156, Train_accy 99.530, Test_accy 52.530
2022-05-24 23:49:40,617 [bic.py] => training => Task 5, Epoch 166/170 => Loss 2.157, Train_accy 99.590, Test_accy 51.900
2022-05-24 23:49:46,293 [bic.py] => training => Task 5, Epoch 167/170 => Loss 2.148, Train_accy 99.570, Test_accy 52.220
2022-05-24 23:49:52,058 [bic.py] => training => Task 5, Epoch 168/170 => Loss 2.150, Train_accy 99.500, Test_accy 52.450
2022-05-24 23:49:57,655 [bic.py] => training => Task 5, Epoch 169/170 => Loss 2.154, Train_accy 99.410, Test_accy 52.200
2022-05-24 23:50:03,425 [bic.py] => training => Task 5, Epoch 170/170 => Loss 2.154, Train_accy 99.480, Test_accy 52.170
2022-05-24 23:50:05,236 [bic.py] => bias_correction => Task 5, Epoch 1/170 => Loss 3.560, Train_accy 74.580, Test_accy 55.650
2022-05-24 23:50:07,042 [bic.py] => bias_correction => Task 5, Epoch 2/170 => Loss 3.502, Train_accy 82.500, Test_accy 59.300
2022-05-24 23:50:08,914 [bic.py] => bias_correction => Task 5, Epoch 3/170 => Loss 3.459, Train_accy 80.830, Test_accy 57.200
2022-05-24 23:50:10,662 [bic.py] => bias_correction => Task 5, Epoch 4/170 => Loss 3.498, Train_accy 78.330, Test_accy 54.370
2022-05-24 23:50:12,459 [bic.py] => bias_correction => Task 5, Epoch 5/170 => Loss 3.490, Train_accy 79.170, Test_accy 54.280
2022-05-24 23:50:14,296 [bic.py] => bias_correction => Task 5, Epoch 6/170 => Loss 3.490, Train_accy 77.080, Test_accy 55.470
2022-05-24 23:50:16,052 [bic.py] => bias_correction => Task 5, Epoch 7/170 => Loss 3.490, Train_accy 78.750, Test_accy 58.030
2022-05-24 23:50:17,813 [bic.py] => bias_correction => Task 5, Epoch 8/170 => Loss 3.453, Train_accy 82.500, Test_accy 58.550
2022-05-24 23:50:19,691 [bic.py] => bias_correction => Task 5, Epoch 9/170 => Loss 3.453, Train_accy 79.170, Test_accy 57.480
2022-05-24 23:50:21,566 [bic.py] => bias_correction => Task 5, Epoch 10/170 => Loss 3.469, Train_accy 76.670, Test_accy 57.750
2022-05-24 23:50:23,505 [bic.py] => bias_correction => Task 5, Epoch 11/170 => Loss 3.460, Train_accy 83.750, Test_accy 58.430
2022-05-24 23:50:25,358 [bic.py] => bias_correction => Task 5, Epoch 12/170 => Loss 3.447, Train_accy 84.170, Test_accy 58.380
2022-05-24 23:50:27,250 [bic.py] => bias_correction => Task 5, Epoch 13/170 => Loss 3.446, Train_accy 80.000, Test_accy 58.200
2022-05-24 23:50:29,173 [bic.py] => bias_correction => Task 5, Epoch 14/170 => Loss 3.469, Train_accy 77.920, Test_accy 57.980
2022-05-24 23:50:30,910 [bic.py] => bias_correction => Task 5, Epoch 15/170 => Loss 3.450, Train_accy 82.500, Test_accy 58.380
2022-05-24 23:50:32,818 [bic.py] => bias_correction => Task 5, Epoch 16/170 => Loss 3.448, Train_accy 84.170, Test_accy 58.500
2022-05-24 23:50:34,655 [bic.py] => bias_correction => Task 5, Epoch 17/170 => Loss 3.459, Train_accy 82.500, Test_accy 58.050
2022-05-24 23:50:36,438 [bic.py] => bias_correction => Task 5, Epoch 18/170 => Loss 3.454, Train_accy 82.080, Test_accy 58.050
2022-05-24 23:50:38,334 [bic.py] => bias_correction => Task 5, Epoch 19/170 => Loss 3.458, Train_accy 80.000, Test_accy 58.450
2022-05-24 23:50:40,241 [bic.py] => bias_correction => Task 5, Epoch 20/170 => Loss 3.448, Train_accy 80.830, Test_accy 58.580
2022-05-24 23:50:42,076 [bic.py] => bias_correction => Task 5, Epoch 21/170 => Loss 3.455, Train_accy 81.670, Test_accy 58.520
2022-05-24 23:50:43,975 [bic.py] => bias_correction => Task 5, Epoch 22/170 => Loss 3.455, Train_accy 81.250, Test_accy 58.430
2022-05-24 23:50:45,758 [bic.py] => bias_correction => Task 5, Epoch 23/170 => Loss 3.453, Train_accy 80.000, Test_accy 58.420
2022-05-24 23:50:47,617 [bic.py] => bias_correction => Task 5, Epoch 24/170 => Loss 3.458, Train_accy 82.920, Test_accy 58.450
2022-05-24 23:50:49,320 [bic.py] => bias_correction => Task 5, Epoch 25/170 => Loss 3.459, Train_accy 83.330, Test_accy 58.270
2022-05-24 23:50:51,167 [bic.py] => bias_correction => Task 5, Epoch 26/170 => Loss 3.449, Train_accy 84.170, Test_accy 58.330
2022-05-24 23:50:53,045 [bic.py] => bias_correction => Task 5, Epoch 27/170 => Loss 3.446, Train_accy 81.670, Test_accy 58.280
2022-05-24 23:50:54,924 [bic.py] => bias_correction => Task 5, Epoch 28/170 => Loss 3.457, Train_accy 81.250, Test_accy 58.420
2022-05-24 23:50:56,739 [bic.py] => bias_correction => Task 5, Epoch 29/170 => Loss 3.442, Train_accy 80.420, Test_accy 58.470
2022-05-24 23:50:58,544 [bic.py] => bias_correction => Task 5, Epoch 30/170 => Loss 3.461, Train_accy 82.080, Test_accy 58.500
2022-05-24 23:51:00,440 [bic.py] => bias_correction => Task 5, Epoch 31/170 => Loss 3.442, Train_accy 82.920, Test_accy 58.580
2022-05-24 23:51:02,215 [bic.py] => bias_correction => Task 5, Epoch 32/170 => Loss 3.450, Train_accy 82.080, Test_accy 58.700
2022-05-24 23:51:03,989 [bic.py] => bias_correction => Task 5, Epoch 33/170 => Loss 3.457, Train_accy 82.080, Test_accy 58.630
2022-05-24 23:51:05,909 [bic.py] => bias_correction => Task 5, Epoch 34/170 => Loss 3.455, Train_accy 78.750, Test_accy 58.580
2022-05-24 23:51:07,782 [bic.py] => bias_correction => Task 5, Epoch 35/170 => Loss 3.438, Train_accy 82.080, Test_accy 58.630
2022-05-24 23:51:09,671 [bic.py] => bias_correction => Task 5, Epoch 36/170 => Loss 3.445, Train_accy 82.080, Test_accy 58.630
2022-05-24 23:51:11,519 [bic.py] => bias_correction => Task 5, Epoch 37/170 => Loss 3.440, Train_accy 83.750, Test_accy 58.570
2022-05-24 23:51:13,318 [bic.py] => bias_correction => Task 5, Epoch 38/170 => Loss 3.443, Train_accy 83.750, Test_accy 58.630
2022-05-24 23:51:15,166 [bic.py] => bias_correction => Task 5, Epoch 39/170 => Loss 3.429, Train_accy 81.250, Test_accy 58.500
2022-05-24 23:51:17,021 [bic.py] => bias_correction => Task 5, Epoch 40/170 => Loss 3.459, Train_accy 82.080, Test_accy 58.480
2022-05-24 23:51:18,756 [bic.py] => bias_correction => Task 5, Epoch 41/170 => Loss 3.450, Train_accy 80.830, Test_accy 58.600
2022-05-24 23:51:20,671 [bic.py] => bias_correction => Task 5, Epoch 42/170 => Loss 3.454, Train_accy 83.330, Test_accy 58.430
2022-05-24 23:51:22,471 [bic.py] => bias_correction => Task 5, Epoch 43/170 => Loss 3.441, Train_accy 84.170, Test_accy 58.530
2022-05-24 23:51:24,304 [bic.py] => bias_correction => Task 5, Epoch 44/170 => Loss 3.439, Train_accy 82.080, Test_accy 58.470
2022-05-24 23:51:26,201 [bic.py] => bias_correction => Task 5, Epoch 45/170 => Loss 3.457, Train_accy 79.580, Test_accy 58.600
2022-05-24 23:51:28,104 [bic.py] => bias_correction => Task 5, Epoch 46/170 => Loss 3.439, Train_accy 82.080, Test_accy 58.580
2022-05-24 23:51:29,997 [bic.py] => bias_correction => Task 5, Epoch 47/170 => Loss 3.445, Train_accy 80.000, Test_accy 58.500
2022-05-24 23:51:31,727 [bic.py] => bias_correction => Task 5, Epoch 48/170 => Loss 3.438, Train_accy 83.330, Test_accy 58.630
2022-05-24 23:51:33,538 [bic.py] => bias_correction => Task 5, Epoch 49/170 => Loss 3.457, Train_accy 85.420, Test_accy 58.580
2022-05-24 23:51:35,396 [bic.py] => bias_correction => Task 5, Epoch 50/170 => Loss 3.442, Train_accy 83.750, Test_accy 58.650
2022-05-24 23:51:37,217 [bic.py] => bias_correction => Task 5, Epoch 51/170 => Loss 3.456, Train_accy 82.920, Test_accy 58.630
2022-05-24 23:51:39,036 [bic.py] => bias_correction => Task 5, Epoch 52/170 => Loss 3.447, Train_accy 83.330, Test_accy 58.620
2022-05-24 23:51:40,932 [bic.py] => bias_correction => Task 5, Epoch 53/170 => Loss 3.454, Train_accy 82.920, Test_accy 58.680
2022-05-24 23:51:42,762 [bic.py] => bias_correction => Task 5, Epoch 54/170 => Loss 3.448, Train_accy 81.670, Test_accy 58.700
2022-05-24 23:51:44,640 [bic.py] => bias_correction => Task 5, Epoch 55/170 => Loss 3.435, Train_accy 83.330, Test_accy 58.720
2022-05-24 23:51:46,748 [bic.py] => bias_correction => Task 5, Epoch 56/170 => Loss 3.441, Train_accy 83.750, Test_accy 58.630
2022-05-24 23:51:48,634 [bic.py] => bias_correction => Task 5, Epoch 57/170 => Loss 3.448, Train_accy 81.670, Test_accy 58.620
2022-05-24 23:51:50,591 [bic.py] => bias_correction => Task 5, Epoch 58/170 => Loss 3.444, Train_accy 82.500, Test_accy 58.820
2022-05-24 23:51:52,427 [bic.py] => bias_correction => Task 5, Epoch 59/170 => Loss 3.441, Train_accy 80.000, Test_accy 58.700
2022-05-24 23:51:54,382 [bic.py] => bias_correction => Task 5, Epoch 60/170 => Loss 3.450, Train_accy 84.170, Test_accy 58.800
2022-05-24 23:51:56,242 [bic.py] => bias_correction => Task 5, Epoch 61/170 => Loss 3.443, Train_accy 80.830, Test_accy 58.750
2022-05-24 23:51:58,170 [bic.py] => bias_correction => Task 5, Epoch 62/170 => Loss 3.434, Train_accy 83.750, Test_accy 58.720
2022-05-24 23:52:00,068 [bic.py] => bias_correction => Task 5, Epoch 63/170 => Loss 3.462, Train_accy 82.500, Test_accy 58.750
2022-05-24 23:52:02,037 [bic.py] => bias_correction => Task 5, Epoch 64/170 => Loss 3.448, Train_accy 80.830, Test_accy 58.750
2022-05-24 23:52:03,861 [bic.py] => bias_correction => Task 5, Epoch 65/170 => Loss 3.437, Train_accy 84.580, Test_accy 58.680
2022-05-24 23:52:06,039 [bic.py] => bias_correction => Task 5, Epoch 66/170 => Loss 3.460, Train_accy 81.670, Test_accy 58.580
2022-05-24 23:52:07,998 [bic.py] => bias_correction => Task 5, Epoch 67/170 => Loss 3.435, Train_accy 82.080, Test_accy 58.600
2022-05-24 23:52:09,729 [bic.py] => bias_correction => Task 5, Epoch 68/170 => Loss 3.447, Train_accy 82.080, Test_accy 58.620
2022-05-24 23:52:11,515 [bic.py] => bias_correction => Task 5, Epoch 69/170 => Loss 3.449, Train_accy 81.670, Test_accy 58.650
2022-05-24 23:52:13,370 [bic.py] => bias_correction => Task 5, Epoch 70/170 => Loss 3.455, Train_accy 84.580, Test_accy 58.680
2022-05-24 23:52:15,233 [bic.py] => bias_correction => Task 5, Epoch 71/170 => Loss 3.439, Train_accy 83.750, Test_accy 58.570
2022-05-24 23:52:17,072 [bic.py] => bias_correction => Task 5, Epoch 72/170 => Loss 3.427, Train_accy 82.080, Test_accy 58.720
2022-05-24 23:52:18,972 [bic.py] => bias_correction => Task 5, Epoch 73/170 => Loss 3.457, Train_accy 80.830, Test_accy 58.700
2022-05-24 23:52:20,801 [bic.py] => bias_correction => Task 5, Epoch 74/170 => Loss 3.452, Train_accy 81.670, Test_accy 58.750
2022-05-24 23:52:22,608 [bic.py] => bias_correction => Task 5, Epoch 75/170 => Loss 3.440, Train_accy 80.000, Test_accy 58.700
2022-05-24 23:52:24,436 [bic.py] => bias_correction => Task 5, Epoch 76/170 => Loss 3.442, Train_accy 82.080, Test_accy 58.650
2022-05-24 23:52:26,257 [bic.py] => bias_correction => Task 5, Epoch 77/170 => Loss 3.426, Train_accy 82.920, Test_accy 58.720
2022-05-24 23:52:28,106 [bic.py] => bias_correction => Task 5, Epoch 78/170 => Loss 3.469, Train_accy 81.250, Test_accy 58.720
2022-05-24 23:52:29,974 [bic.py] => bias_correction => Task 5, Epoch 79/170 => Loss 3.430, Train_accy 82.920, Test_accy 58.650
2022-05-24 23:52:31,914 [bic.py] => bias_correction => Task 5, Epoch 80/170 => Loss 3.436, Train_accy 85.000, Test_accy 58.630
2022-05-24 23:52:33,786 [bic.py] => bias_correction => Task 5, Epoch 81/170 => Loss 3.462, Train_accy 83.750, Test_accy 58.620
2022-05-24 23:52:35,559 [bic.py] => bias_correction => Task 5, Epoch 82/170 => Loss 3.446, Train_accy 83.330, Test_accy 58.720
2022-05-24 23:52:37,421 [bic.py] => bias_correction => Task 5, Epoch 83/170 => Loss 3.435, Train_accy 82.920, Test_accy 58.670
2022-05-24 23:52:39,257 [bic.py] => bias_correction => Task 5, Epoch 84/170 => Loss 3.451, Train_accy 77.500, Test_accy 58.700
2022-05-24 23:52:41,057 [bic.py] => bias_correction => Task 5, Epoch 85/170 => Loss 3.450, Train_accy 84.580, Test_accy 58.670
2022-05-24 23:52:42,852 [bic.py] => bias_correction => Task 5, Epoch 86/170 => Loss 3.450, Train_accy 85.420, Test_accy 58.700
2022-05-24 23:52:44,709 [bic.py] => bias_correction => Task 5, Epoch 87/170 => Loss 3.455, Train_accy 82.080, Test_accy 58.670
2022-05-24 23:52:46,676 [bic.py] => bias_correction => Task 5, Epoch 88/170 => Loss 3.462, Train_accy 82.500, Test_accy 58.680
2022-05-24 23:52:48,567 [bic.py] => bias_correction => Task 5, Epoch 89/170 => Loss 3.454, Train_accy 81.250, Test_accy 58.670
2022-05-24 23:52:50,377 [bic.py] => bias_correction => Task 5, Epoch 90/170 => Loss 3.434, Train_accy 81.250, Test_accy 58.680
2022-05-24 23:52:52,243 [bic.py] => bias_correction => Task 5, Epoch 91/170 => Loss 3.445, Train_accy 83.750, Test_accy 58.770
2022-05-24 23:52:54,094 [bic.py] => bias_correction => Task 5, Epoch 92/170 => Loss 3.448, Train_accy 82.080, Test_accy 58.700
2022-05-24 23:52:55,868 [bic.py] => bias_correction => Task 5, Epoch 93/170 => Loss 3.429, Train_accy 82.080, Test_accy 58.730
2022-05-24 23:52:57,729 [bic.py] => bias_correction => Task 5, Epoch 94/170 => Loss 3.452, Train_accy 80.830, Test_accy 58.820
2022-05-24 23:52:59,644 [bic.py] => bias_correction => Task 5, Epoch 95/170 => Loss 3.442, Train_accy 82.500, Test_accy 58.730
2022-05-24 23:53:01,509 [bic.py] => bias_correction => Task 5, Epoch 96/170 => Loss 3.438, Train_accy 82.920, Test_accy 58.720
2022-05-24 23:53:03,380 [bic.py] => bias_correction => Task 5, Epoch 97/170 => Loss 3.437, Train_accy 79.580, Test_accy 58.720
2022-05-24 23:53:05,159 [bic.py] => bias_correction => Task 5, Epoch 98/170 => Loss 3.442, Train_accy 82.920, Test_accy 58.630
2022-05-24 23:53:07,045 [bic.py] => bias_correction => Task 5, Epoch 99/170 => Loss 3.448, Train_accy 85.000, Test_accy 58.650
2022-05-24 23:53:08,890 [bic.py] => bias_correction => Task 5, Epoch 100/170 => Loss 3.445, Train_accy 82.500, Test_accy 58.700
2022-05-24 23:53:10,664 [bic.py] => bias_correction => Task 5, Epoch 101/170 => Loss 3.438, Train_accy 80.420, Test_accy 58.650
2022-05-24 23:53:12,585 [bic.py] => bias_correction => Task 5, Epoch 102/170 => Loss 3.430, Train_accy 80.830, Test_accy 58.700
2022-05-24 23:53:14,316 [bic.py] => bias_correction => Task 5, Epoch 103/170 => Loss 3.452, Train_accy 82.500, Test_accy 58.680
2022-05-24 23:53:16,185 [bic.py] => bias_correction => Task 5, Epoch 104/170 => Loss 3.445, Train_accy 79.580, Test_accy 58.800
2022-05-24 23:53:18,064 [bic.py] => bias_correction => Task 5, Epoch 105/170 => Loss 3.452, Train_accy 82.500, Test_accy 58.720
2022-05-24 23:53:19,885 [bic.py] => bias_correction => Task 5, Epoch 106/170 => Loss 3.443, Train_accy 83.750, Test_accy 58.720
2022-05-24 23:53:21,725 [bic.py] => bias_correction => Task 5, Epoch 107/170 => Loss 3.447, Train_accy 84.170, Test_accy 58.720
2022-05-24 23:53:23,609 [bic.py] => bias_correction => Task 5, Epoch 108/170 => Loss 3.441, Train_accy 82.500, Test_accy 58.770
2022-05-24 23:53:25,463 [bic.py] => bias_correction => Task 5, Epoch 109/170 => Loss 3.446, Train_accy 84.580, Test_accy 58.720
2022-05-24 23:53:27,376 [bic.py] => bias_correction => Task 5, Epoch 110/170 => Loss 3.452, Train_accy 83.330, Test_accy 58.730
2022-05-24 23:53:29,155 [bic.py] => bias_correction => Task 5, Epoch 111/170 => Loss 3.449, Train_accy 83.330, Test_accy 58.650
2022-05-24 23:53:31,025 [bic.py] => bias_correction => Task 5, Epoch 112/170 => Loss 3.448, Train_accy 80.830, Test_accy 58.680
2022-05-24 23:53:32,844 [bic.py] => bias_correction => Task 5, Epoch 113/170 => Loss 3.444, Train_accy 85.000, Test_accy 58.670
2022-05-24 23:53:34,585 [bic.py] => bias_correction => Task 5, Epoch 114/170 => Loss 3.455, Train_accy 82.500, Test_accy 58.720
2022-05-24 23:53:36,575 [bic.py] => bias_correction => Task 5, Epoch 115/170 => Loss 3.435, Train_accy 81.250, Test_accy 58.720
2022-05-24 23:53:38,360 [bic.py] => bias_correction => Task 5, Epoch 116/170 => Loss 3.444, Train_accy 82.080, Test_accy 58.700
2022-05-24 23:53:40,250 [bic.py] => bias_correction => Task 5, Epoch 117/170 => Loss 3.437, Train_accy 82.080, Test_accy 58.730
2022-05-24 23:53:42,216 [bic.py] => bias_correction => Task 5, Epoch 118/170 => Loss 3.448, Train_accy 80.830, Test_accy 58.700
2022-05-24 23:53:43,933 [bic.py] => bias_correction => Task 5, Epoch 119/170 => Loss 3.443, Train_accy 79.170, Test_accy 58.650
2022-05-24 23:53:45,823 [bic.py] => bias_correction => Task 5, Epoch 120/170 => Loss 3.452, Train_accy 84.580, Test_accy 58.750
2022-05-24 23:53:47,669 [bic.py] => bias_correction => Task 5, Epoch 121/170 => Loss 3.444, Train_accy 81.250, Test_accy 58.680
2022-05-24 23:53:49,578 [bic.py] => bias_correction => Task 5, Epoch 122/170 => Loss 3.444, Train_accy 81.250, Test_accy 58.650
2022-05-24 23:53:51,423 [bic.py] => bias_correction => Task 5, Epoch 123/170 => Loss 3.434, Train_accy 80.830, Test_accy 58.600
2022-05-24 23:53:53,238 [bic.py] => bias_correction => Task 5, Epoch 124/170 => Loss 3.446, Train_accy 83.750, Test_accy 58.750
2022-05-24 23:53:55,121 [bic.py] => bias_correction => Task 5, Epoch 125/170 => Loss 3.441, Train_accy 84.170, Test_accy 58.700
2022-05-24 23:53:57,011 [bic.py] => bias_correction => Task 5, Epoch 126/170 => Loss 3.451, Train_accy 80.830, Test_accy 58.680
2022-05-24 23:53:58,819 [bic.py] => bias_correction => Task 5, Epoch 127/170 => Loss 3.441, Train_accy 80.830, Test_accy 58.670
2022-05-24 23:54:00,696 [bic.py] => bias_correction => Task 5, Epoch 128/170 => Loss 3.443, Train_accy 80.830, Test_accy 58.650
2022-05-24 23:54:02,644 [bic.py] => bias_correction => Task 5, Epoch 129/170 => Loss 3.426, Train_accy 82.920, Test_accy 58.680
2022-05-24 23:54:04,532 [bic.py] => bias_correction => Task 5, Epoch 130/170 => Loss 3.439, Train_accy 81.670, Test_accy 58.750
2022-05-24 23:54:06,376 [bic.py] => bias_correction => Task 5, Epoch 131/170 => Loss 3.439, Train_accy 79.170, Test_accy 58.720
2022-05-24 23:54:08,114 [bic.py] => bias_correction => Task 5, Epoch 132/170 => Loss 3.432, Train_accy 81.250, Test_accy 58.620
2022-05-24 23:54:10,027 [bic.py] => bias_correction => Task 5, Epoch 133/170 => Loss 3.439, Train_accy 80.420, Test_accy 58.600
2022-05-24 23:54:11,835 [bic.py] => bias_correction => Task 5, Epoch 134/170 => Loss 3.454, Train_accy 83.750, Test_accy 58.600
2022-05-24 23:54:13,755 [bic.py] => bias_correction => Task 5, Epoch 135/170 => Loss 3.439, Train_accy 82.080, Test_accy 58.620
2022-05-24 23:54:15,622 [bic.py] => bias_correction => Task 5, Epoch 136/170 => Loss 3.437, Train_accy 81.670, Test_accy 58.580
2022-05-24 23:54:17,450 [bic.py] => bias_correction => Task 5, Epoch 137/170 => Loss 3.443, Train_accy 80.420, Test_accy 58.570
2022-05-24 23:54:19,350 [bic.py] => bias_correction => Task 5, Epoch 138/170 => Loss 3.443, Train_accy 81.670, Test_accy 58.620
2022-05-24 23:54:21,230 [bic.py] => bias_correction => Task 5, Epoch 139/170 => Loss 3.435, Train_accy 83.330, Test_accy 58.700
2022-05-24 23:54:22,984 [bic.py] => bias_correction => Task 5, Epoch 140/170 => Loss 3.448, Train_accy 83.330, Test_accy 58.600
2022-05-24 23:54:24,830 [bic.py] => bias_correction => Task 5, Epoch 141/170 => Loss 3.434, Train_accy 77.080, Test_accy 58.620
2022-05-24 23:54:26,693 [bic.py] => bias_correction => Task 5, Epoch 142/170 => Loss 3.439, Train_accy 82.920, Test_accy 58.620
2022-05-24 23:54:28,590 [bic.py] => bias_correction => Task 5, Epoch 143/170 => Loss 3.439, Train_accy 84.580, Test_accy 58.630
2022-05-24 23:54:30,447 [bic.py] => bias_correction => Task 5, Epoch 144/170 => Loss 3.441, Train_accy 80.420, Test_accy 58.630
2022-05-24 23:54:32,200 [bic.py] => bias_correction => Task 5, Epoch 145/170 => Loss 3.450, Train_accy 80.830, Test_accy 58.630
2022-05-24 23:54:33,995 [bic.py] => bias_correction => Task 5, Epoch 146/170 => Loss 3.442, Train_accy 80.420, Test_accy 58.770
2022-05-24 23:54:35,783 [bic.py] => bias_correction => Task 5, Epoch 147/170 => Loss 3.442, Train_accy 81.250, Test_accy 58.680
2022-05-24 23:54:37,640 [bic.py] => bias_correction => Task 5, Epoch 148/170 => Loss 3.450, Train_accy 77.500, Test_accy 58.700
2022-05-24 23:54:39,477 [bic.py] => bias_correction => Task 5, Epoch 149/170 => Loss 3.451, Train_accy 82.920, Test_accy 58.670
2022-05-24 23:54:41,238 [bic.py] => bias_correction => Task 5, Epoch 150/170 => Loss 3.450, Train_accy 80.420, Test_accy 58.650
2022-05-24 23:54:43,247 [bic.py] => bias_correction => Task 5, Epoch 151/170 => Loss 3.447, Train_accy 84.170, Test_accy 58.630
2022-05-24 23:54:45,113 [bic.py] => bias_correction => Task 5, Epoch 152/170 => Loss 3.436, Train_accy 82.080, Test_accy 58.700
2022-05-24 23:54:46,902 [bic.py] => bias_correction => Task 5, Epoch 153/170 => Loss 3.433, Train_accy 82.920, Test_accy 58.750
2022-05-24 23:54:48,874 [bic.py] => bias_correction => Task 5, Epoch 154/170 => Loss 3.434, Train_accy 82.920, Test_accy 58.770
2022-05-24 23:54:50,707 [bic.py] => bias_correction => Task 5, Epoch 155/170 => Loss 3.448, Train_accy 82.500, Test_accy 58.730
2022-05-24 23:54:52,599 [bic.py] => bias_correction => Task 5, Epoch 156/170 => Loss 3.457, Train_accy 82.920, Test_accy 58.670
2022-05-24 23:54:54,451 [bic.py] => bias_correction => Task 5, Epoch 157/170 => Loss 3.453, Train_accy 81.250, Test_accy 58.750
2022-05-24 23:54:56,357 [bic.py] => bias_correction => Task 5, Epoch 158/170 => Loss 3.442, Train_accy 82.920, Test_accy 58.720
2022-05-24 23:54:58,190 [bic.py] => bias_correction => Task 5, Epoch 159/170 => Loss 3.445, Train_accy 79.580, Test_accy 58.670
2022-05-24 23:54:59,967 [bic.py] => bias_correction => Task 5, Epoch 160/170 => Loss 3.436, Train_accy 82.080, Test_accy 58.770
2022-05-24 23:55:01,760 [bic.py] => bias_correction => Task 5, Epoch 161/170 => Loss 3.465, Train_accy 80.000, Test_accy 58.820
2022-05-24 23:55:03,713 [bic.py] => bias_correction => Task 5, Epoch 162/170 => Loss 3.422, Train_accy 79.170, Test_accy 58.780
2022-05-24 23:55:05,577 [bic.py] => bias_correction => Task 5, Epoch 163/170 => Loss 3.437, Train_accy 79.580, Test_accy 58.800
2022-05-24 23:55:07,412 [bic.py] => bias_correction => Task 5, Epoch 164/170 => Loss 3.444, Train_accy 81.250, Test_accy 58.680
2022-05-24 23:55:09,267 [bic.py] => bias_correction => Task 5, Epoch 165/170 => Loss 3.441, Train_accy 82.080, Test_accy 58.770
2022-05-24 23:55:11,166 [bic.py] => bias_correction => Task 5, Epoch 166/170 => Loss 3.447, Train_accy 82.920, Test_accy 58.720
2022-05-24 23:55:13,056 [bic.py] => bias_correction => Task 5, Epoch 167/170 => Loss 3.440, Train_accy 83.330, Test_accy 58.680
2022-05-24 23:55:14,870 [bic.py] => bias_correction => Task 5, Epoch 168/170 => Loss 3.448, Train_accy 82.080, Test_accy 58.680
2022-05-24 23:55:16,882 [bic.py] => bias_correction => Task 5, Epoch 169/170 => Loss 3.443, Train_accy 80.830, Test_accy 58.720
2022-05-24 23:55:18,758 [bic.py] => bias_correction => Task 5, Epoch 170/170 => Loss 3.466, Train_accy 79.580, Test_accy 58.720
2022-05-24 23:55:18,759 [base.py] => Reducing exemplars...(33 per classes)
2022-05-24 23:55:29,088 [base.py] => Constructing exemplars...(33 per classes)
2022-05-24 23:55:35,234 [bic.py] => Parameters of bias layer:
2022-05-24 23:55:35,235 [bic.py] => 0 => 1.000, 0.000
2022-05-24 23:55:35,235 [bic.py] => 1 => 0.981, -1.523
2022-05-24 23:55:35,235 [bic.py] => 2 => 0.816, -1.587
2022-05-24 23:55:35,236 [bic.py] => 3 => 0.723, -1.178
2022-05-24 23:55:35,236 [bic.py] => 4 => 0.736, -1.143
2022-05-24 23:55:35,236 [bic.py] => 5 => 0.746, -1.342
2022-05-24 23:55:37,535 [bic.py] => Exemplar size: 1980
2022-05-24 23:55:37,535 [trainer.py] => CNN: {'total': 58.72, '00-09': 64.4, '10-19': 50.2, '20-29': 62.6, '30-39': 51.9, '40-49': 59.9, '50-59': 63.3, 'old': 57.8, 'new': 63.3}
2022-05-24 23:55:37,535 [trainer.py] => NME: {'total': 59.18, '00-09': 61.6, '10-19': 45.8, '20-29': 63.1, '30-39': 51.9, '40-49': 66.6, '50-59': 66.1, 'old': 57.8, 'new': 66.1}
2022-05-24 23:55:37,536 [trainer.py] => CNN top1 curve: [87.5, 75.95, 70.6, 64.53, 62.34, 58.72]
2022-05-24 23:55:37,536 [trainer.py] => CNN top5 curve: [99.3, 95.5, 93.17, 90.3, 89.32, 86.92]
2022-05-24 23:55:37,536 [trainer.py] => NME top1 curve: [88.1, 75.6, 71.27, 64.97, 62.62, 59.18]
2022-05-24 23:55:37,536 [trainer.py] => NME top5 curve: [99.4, 95.4, 93.2, 90.05, 88.58, 86.03]

2022-05-24 23:55:37,536 [trainer.py] => All params: 468066
2022-05-24 23:55:37,537 [trainer.py] => Trainable params: 468066
2022-05-24 23:55:37,538 [bic.py] => Learning on 60-70
2022-05-24 23:55:37,596 [bic.py] => Stage1 dset: 6770, Stage2 dset: 210
2022-05-24 23:55:37,596 [bic.py] => Lambda: 0.857
2022-05-24 23:55:37,616 [bic.py] => Parameters of bias layer:
2022-05-24 23:55:37,617 [bic.py] => 0 => 1.000, 0.000
2022-05-24 23:55:37,617 [bic.py] => 1 => 0.981, -1.523
2022-05-24 23:55:37,617 [bic.py] => 2 => 0.816, -1.587
2022-05-24 23:55:37,617 [bic.py] => 3 => 0.723, -1.178
2022-05-24 23:55:37,617 [bic.py] => 4 => 0.736, -1.143
2022-05-24 23:55:37,617 [bic.py] => 5 => 0.746, -1.342
2022-05-24 23:55:37,617 [bic.py] => 6 => 1.000, 0.000
2022-05-24 23:55:43,529 [bic.py] => training => Task 6, Epoch 1/170 => Loss 2.698, Train_accy 68.490, Test_accy 38.210
2022-05-24 23:55:49,224 [bic.py] => training => Task 6, Epoch 2/170 => Loss 2.567, Train_accy 76.470, Test_accy 42.210
2022-05-24 23:55:54,851 [bic.py] => training => Task 6, Epoch 3/170 => Loss 2.548, Train_accy 76.510, Test_accy 42.640
2022-05-24 23:56:00,627 [bic.py] => training => Task 6, Epoch 4/170 => Loss 2.537, Train_accy 79.960, Test_accy 42.000
2022-05-24 23:56:06,443 [bic.py] => training => Task 6, Epoch 5/170 => Loss 2.526, Train_accy 77.920, Test_accy 39.140
2022-05-24 23:56:12,056 [bic.py] => training => Task 6, Epoch 6/170 => Loss 2.517, Train_accy 80.240, Test_accy 42.740
2022-05-24 23:56:17,904 [bic.py] => training => Task 6, Epoch 7/170 => Loss 2.522, Train_accy 84.020, Test_accy 41.870
2022-05-24 23:56:23,853 [bic.py] => training => Task 6, Epoch 8/170 => Loss 2.512, Train_accy 82.130, Test_accy 43.600
2022-05-24 23:56:29,625 [bic.py] => training => Task 6, Epoch 9/170 => Loss 2.513, Train_accy 82.290, Test_accy 43.410
2022-05-24 23:56:35,640 [bic.py] => training => Task 6, Epoch 10/170 => Loss 2.503, Train_accy 79.650, Test_accy 41.700
2022-05-24 23:56:41,696 [bic.py] => training => Task 6, Epoch 11/170 => Loss 2.502, Train_accy 86.630, Test_accy 45.070
2022-05-24 23:56:46,825 [bic.py] => training => Task 6, Epoch 12/170 => Loss 2.495, Train_accy 85.760, Test_accy 44.100
2022-05-24 23:56:51,330 [bic.py] => training => Task 6, Epoch 13/170 => Loss 2.498, Train_accy 84.020, Test_accy 41.900
2022-05-24 23:56:55,864 [bic.py] => training => Task 6, Epoch 14/170 => Loss 2.498, Train_accy 86.010, Test_accy 43.540
2022-05-24 23:57:00,542 [bic.py] => training => Task 6, Epoch 15/170 => Loss 2.489, Train_accy 84.510, Test_accy 42.740
2022-05-24 23:57:05,009 [bic.py] => training => Task 6, Epoch 16/170 => Loss 2.494, Train_accy 85.730, Test_accy 44.610
2022-05-24 23:57:09,517 [bic.py] => training => Task 6, Epoch 17/170 => Loss 2.487, Train_accy 88.010, Test_accy 42.460
2022-05-24 23:57:14,015 [bic.py] => training => Task 6, Epoch 18/170 => Loss 2.491, Train_accy 87.360, Test_accy 42.460
2022-05-24 23:57:18,413 [bic.py] => training => Task 6, Epoch 19/170 => Loss 2.483, Train_accy 88.090, Test_accy 43.100
2022-05-24 23:57:23,069 [bic.py] => training => Task 6, Epoch 20/170 => Loss 2.483, Train_accy 88.230, Test_accy 43.090
2022-05-24 23:57:27,886 [bic.py] => training => Task 6, Epoch 21/170 => Loss 2.484, Train_accy 90.070, Test_accy 43.660
2022-05-24 23:57:32,790 [bic.py] => training => Task 6, Epoch 22/170 => Loss 2.476, Train_accy 86.570, Test_accy 44.600
2022-05-24 23:57:37,710 [bic.py] => training => Task 6, Epoch 23/170 => Loss 2.480, Train_accy 91.060, Test_accy 43.860
2022-05-24 23:57:42,330 [bic.py] => training => Task 6, Epoch 24/170 => Loss 2.478, Train_accy 90.220, Test_accy 43.910
2022-05-24 23:57:46,823 [bic.py] => training => Task 6, Epoch 25/170 => Loss 2.482, Train_accy 91.650, Test_accy 44.160
2022-05-24 23:57:51,414 [bic.py] => training => Task 6, Epoch 26/170 => Loss 2.479, Train_accy 88.200, Test_accy 43.970
2022-05-24 23:57:55,920 [bic.py] => training => Task 6, Epoch 27/170 => Loss 2.480, Train_accy 92.350, Test_accy 45.630
2022-05-24 23:58:00,466 [bic.py] => training => Task 6, Epoch 28/170 => Loss 2.477, Train_accy 89.160, Test_accy 45.860
2022-05-24 23:58:05,030 [bic.py] => training => Task 6, Epoch 29/170 => Loss 2.478, Train_accy 90.070, Test_accy 44.060
2022-05-24 23:58:09,456 [bic.py] => training => Task 6, Epoch 30/170 => Loss 2.485, Train_accy 90.380, Test_accy 43.590
2022-05-24 23:58:14,036 [bic.py] => training => Task 6, Epoch 31/170 => Loss 2.479, Train_accy 91.850, Test_accy 44.470
2022-05-24 23:58:18,666 [bic.py] => training => Task 6, Epoch 32/170 => Loss 2.474, Train_accy 91.490, Test_accy 45.400
2022-05-24 23:58:23,157 [bic.py] => training => Task 6, Epoch 33/170 => Loss 2.475, Train_accy 91.980, Test_accy 44.310
2022-05-24 23:58:27,716 [bic.py] => training => Task 6, Epoch 34/170 => Loss 2.472, Train_accy 90.310, Test_accy 46.010
2022-05-24 23:58:32,076 [bic.py] => training => Task 6, Epoch 35/170 => Loss 2.472, Train_accy 91.650, Test_accy 44.940
2022-05-24 23:58:36,574 [bic.py] => training => Task 6, Epoch 36/170 => Loss 2.472, Train_accy 93.840, Test_accy 47.440
2022-05-24 23:58:41,086 [bic.py] => training => Task 6, Epoch 37/170 => Loss 2.476, Train_accy 89.530, Test_accy 42.370
2022-05-24 23:58:45,710 [bic.py] => training => Task 6, Epoch 38/170 => Loss 2.478, Train_accy 91.400, Test_accy 44.910
2022-05-24 23:58:50,650 [bic.py] => training => Task 6, Epoch 39/170 => Loss 2.480, Train_accy 92.070, Test_accy 46.130
2022-05-24 23:58:55,544 [bic.py] => training => Task 6, Epoch 40/170 => Loss 2.472, Train_accy 87.310, Test_accy 40.390
2022-05-24 23:59:00,290 [bic.py] => training => Task 6, Epoch 41/170 => Loss 2.463, Train_accy 90.770, Test_accy 43.210
2022-05-24 23:59:05,011 [bic.py] => training => Task 6, Epoch 42/170 => Loss 2.468, Train_accy 92.630, Test_accy 45.260
2022-05-24 23:59:09,689 [bic.py] => training => Task 6, Epoch 43/170 => Loss 2.476, Train_accy 91.550, Test_accy 45.860
2022-05-24 23:59:14,268 [bic.py] => training => Task 6, Epoch 44/170 => Loss 2.469, Train_accy 92.790, Test_accy 47.370
2022-05-24 23:59:18,822 [bic.py] => training => Task 6, Epoch 45/170 => Loss 2.464, Train_accy 92.730, Test_accy 42.500
2022-05-24 23:59:23,362 [bic.py] => training => Task 6, Epoch 46/170 => Loss 2.466, Train_accy 90.070, Test_accy 44.390
2022-05-24 23:59:27,767 [bic.py] => training => Task 6, Epoch 47/170 => Loss 2.474, Train_accy 94.330, Test_accy 48.130
2022-05-24 23:59:32,285 [bic.py] => training => Task 6, Epoch 48/170 => Loss 2.474, Train_accy 89.560, Test_accy 41.870
2022-05-24 23:59:36,998 [bic.py] => training => Task 6, Epoch 49/170 => Loss 2.476, Train_accy 92.670, Test_accy 44.670
2022-05-24 23:59:41,548 [bic.py] => training => Task 6, Epoch 50/170 => Loss 2.469, Train_accy 94.220, Test_accy 47.830
2022-05-24 23:59:46,099 [bic.py] => training => Task 6, Epoch 51/170 => Loss 2.464, Train_accy 92.450, Test_accy 45.410
2022-05-24 23:59:50,564 [bic.py] => training => Task 6, Epoch 52/170 => Loss 2.466, Train_accy 92.780, Test_accy 44.530
2022-05-24 23:59:54,985 [bic.py] => training => Task 6, Epoch 53/170 => Loss 2.471, Train_accy 87.980, Test_accy 44.010
2022-05-24 23:59:59,485 [bic.py] => training => Task 6, Epoch 54/170 => Loss 2.476, Train_accy 91.300, Test_accy 45.490
2022-05-25 00:00:04,057 [bic.py] => training => Task 6, Epoch 55/170 => Loss 2.465, Train_accy 95.080, Test_accy 45.770
2022-05-25 00:00:08,599 [bic.py] => training => Task 6, Epoch 56/170 => Loss 2.464, Train_accy 90.750, Test_accy 43.740
2022-05-25 00:00:13,105 [bic.py] => training => Task 6, Epoch 57/170 => Loss 2.472, Train_accy 94.430, Test_accy 46.010
2022-05-25 00:00:17,603 [bic.py] => training => Task 6, Epoch 58/170 => Loss 2.474, Train_accy 94.030, Test_accy 46.460
2022-05-25 00:00:22,175 [bic.py] => training => Task 6, Epoch 59/170 => Loss 2.476, Train_accy 87.610, Test_accy 42.160
2022-05-25 00:00:26,746 [bic.py] => training => Task 6, Epoch 60/170 => Loss 2.472, Train_accy 93.250, Test_accy 47.110
2022-05-25 00:00:31,202 [bic.py] => training => Task 6, Epoch 61/170 => Loss 2.442, Train_accy 98.360, Test_accy 49.030
2022-05-25 00:00:35,706 [bic.py] => training => Task 6, Epoch 62/170 => Loss 2.437, Train_accy 98.760, Test_accy 49.800
2022-05-25 00:00:40,328 [bic.py] => training => Task 6, Epoch 63/170 => Loss 2.426, Train_accy 99.080, Test_accy 49.590
2022-05-25 00:00:45,097 [bic.py] => training => Task 6, Epoch 64/170 => Loss 2.426, Train_accy 98.950, Test_accy 49.930
2022-05-25 00:00:49,648 [bic.py] => training => Task 6, Epoch 65/170 => Loss 2.423, Train_accy 99.070, Test_accy 50.040
2022-05-25 00:00:54,279 [bic.py] => training => Task 6, Epoch 66/170 => Loss 2.419, Train_accy 98.710, Test_accy 49.990
2022-05-25 00:00:58,896 [bic.py] => training => Task 6, Epoch 67/170 => Loss 2.424, Train_accy 98.950, Test_accy 49.440
2022-05-25 00:01:03,448 [bic.py] => training => Task 6, Epoch 68/170 => Loss 2.418, Train_accy 98.970, Test_accy 49.770
2022-05-25 00:01:08,012 [bic.py] => training => Task 6, Epoch 69/170 => Loss 2.421, Train_accy 99.160, Test_accy 49.940
2022-05-25 00:01:12,576 [bic.py] => training => Task 6, Epoch 70/170 => Loss 2.425, Train_accy 99.010, Test_accy 49.560
2022-05-25 00:01:17,004 [bic.py] => training => Task 6, Epoch 71/170 => Loss 2.419, Train_accy 99.280, Test_accy 49.930
2022-05-25 00:01:21,561 [bic.py] => training => Task 6, Epoch 72/170 => Loss 2.417, Train_accy 99.350, Test_accy 49.890
2022-05-25 00:01:26,002 [bic.py] => training => Task 6, Epoch 73/170 => Loss 2.413, Train_accy 99.170, Test_accy 49.970
2022-05-25 00:01:30,594 [bic.py] => training => Task 6, Epoch 74/170 => Loss 2.414, Train_accy 99.100, Test_accy 49.710
2022-05-25 00:01:35,120 [bic.py] => training => Task 6, Epoch 75/170 => Loss 2.418, Train_accy 99.260, Test_accy 49.610
2022-05-25 00:01:39,606 [bic.py] => training => Task 6, Epoch 76/170 => Loss 2.420, Train_accy 99.040, Test_accy 49.590
2022-05-25 00:01:44,122 [bic.py] => training => Task 6, Epoch 77/170 => Loss 2.408, Train_accy 99.410, Test_accy 49.900
2022-05-25 00:01:48,591 [bic.py] => training => Task 6, Epoch 78/170 => Loss 2.418, Train_accy 99.350, Test_accy 49.930
2022-05-25 00:01:53,254 [bic.py] => training => Task 6, Epoch 79/170 => Loss 2.410, Train_accy 99.310, Test_accy 49.770
2022-05-25 00:01:57,860 [bic.py] => training => Task 6, Epoch 80/170 => Loss 2.418, Train_accy 99.220, Test_accy 49.460
2022-05-25 00:02:02,451 [bic.py] => training => Task 6, Epoch 81/170 => Loss 2.411, Train_accy 99.340, Test_accy 49.930
2022-05-25 00:02:07,077 [bic.py] => training => Task 6, Epoch 82/170 => Loss 2.415, Train_accy 99.410, Test_accy 50.210
2022-05-25 00:02:11,519 [bic.py] => training => Task 6, Epoch 83/170 => Loss 2.407, Train_accy 99.450, Test_accy 49.840
2022-05-25 00:02:16,087 [bic.py] => training => Task 6, Epoch 84/170 => Loss 2.413, Train_accy 99.390, Test_accy 50.140
2022-05-25 00:02:20,721 [bic.py] => training => Task 6, Epoch 85/170 => Loss 2.412, Train_accy 99.340, Test_accy 49.630
2022-05-25 00:02:25,232 [bic.py] => training => Task 6, Epoch 86/170 => Loss 2.414, Train_accy 99.220, Test_accy 49.870
2022-05-25 00:02:29,660 [bic.py] => training => Task 6, Epoch 87/170 => Loss 2.417, Train_accy 99.410, Test_accy 50.610
2022-05-25 00:02:34,170 [bic.py] => training => Task 6, Epoch 88/170 => Loss 2.411, Train_accy 99.530, Test_accy 49.790
2022-05-25 00:02:38,793 [bic.py] => training => Task 6, Epoch 89/170 => Loss 2.409, Train_accy 99.380, Test_accy 49.640
2022-05-25 00:02:43,357 [bic.py] => training => Task 6, Epoch 90/170 => Loss 2.410, Train_accy 99.350, Test_accy 49.940
2022-05-25 00:02:47,841 [bic.py] => training => Task 6, Epoch 91/170 => Loss 2.413, Train_accy 99.340, Test_accy 49.790
2022-05-25 00:02:52,408 [bic.py] => training => Task 6, Epoch 92/170 => Loss 2.416, Train_accy 99.350, Test_accy 49.870
2022-05-25 00:02:56,905 [bic.py] => training => Task 6, Epoch 93/170 => Loss 2.409, Train_accy 99.600, Test_accy 50.040
2022-05-25 00:03:01,365 [bic.py] => training => Task 6, Epoch 94/170 => Loss 2.415, Train_accy 99.280, Test_accy 49.670
2022-05-25 00:03:05,805 [bic.py] => training => Task 6, Epoch 95/170 => Loss 2.417, Train_accy 99.390, Test_accy 50.260
2022-05-25 00:03:10,276 [bic.py] => training => Task 6, Epoch 96/170 => Loss 2.413, Train_accy 99.470, Test_accy 49.860
2022-05-25 00:03:14,768 [bic.py] => training => Task 6, Epoch 97/170 => Loss 2.407, Train_accy 99.440, Test_accy 49.890
2022-05-25 00:03:19,292 [bic.py] => training => Task 6, Epoch 98/170 => Loss 2.409, Train_accy 99.350, Test_accy 49.730
2022-05-25 00:03:23,770 [bic.py] => training => Task 6, Epoch 99/170 => Loss 2.414, Train_accy 99.600, Test_accy 49.610
2022-05-25 00:03:28,324 [bic.py] => training => Task 6, Epoch 100/170 => Loss 2.406, Train_accy 99.390, Test_accy 49.470
2022-05-25 00:03:32,901 [bic.py] => training => Task 6, Epoch 101/170 => Loss 2.411, Train_accy 99.500, Test_accy 49.800
2022-05-25 00:03:37,302 [bic.py] => training => Task 6, Epoch 102/170 => Loss 2.413, Train_accy 99.530, Test_accy 49.740
2022-05-25 00:03:41,885 [bic.py] => training => Task 6, Epoch 103/170 => Loss 2.406, Train_accy 99.440, Test_accy 49.970
2022-05-25 00:03:46,654 [bic.py] => training => Task 6, Epoch 104/170 => Loss 2.408, Train_accy 99.440, Test_accy 50.040
2022-05-25 00:03:51,103 [bic.py] => training => Task 6, Epoch 105/170 => Loss 2.413, Train_accy 99.440, Test_accy 49.930
2022-05-25 00:03:55,603 [bic.py] => training => Task 6, Epoch 106/170 => Loss 2.411, Train_accy 99.540, Test_accy 49.630
2022-05-25 00:04:00,175 [bic.py] => training => Task 6, Epoch 107/170 => Loss 2.412, Train_accy 99.570, Test_accy 50.310
2022-05-25 00:04:04,701 [bic.py] => training => Task 6, Epoch 108/170 => Loss 2.412, Train_accy 99.320, Test_accy 49.790
2022-05-25 00:04:09,323 [bic.py] => training => Task 6, Epoch 109/170 => Loss 2.411, Train_accy 99.540, Test_accy 49.830
2022-05-25 00:04:14,015 [bic.py] => training => Task 6, Epoch 110/170 => Loss 2.410, Train_accy 99.530, Test_accy 50.070
2022-05-25 00:04:18,498 [bic.py] => training => Task 6, Epoch 111/170 => Loss 2.409, Train_accy 99.570, Test_accy 50.060
2022-05-25 00:04:23,049 [bic.py] => training => Task 6, Epoch 112/170 => Loss 2.407, Train_accy 99.560, Test_accy 50.070
2022-05-25 00:04:27,583 [bic.py] => training => Task 6, Epoch 113/170 => Loss 2.415, Train_accy 99.500, Test_accy 49.940
2022-05-25 00:04:32,037 [bic.py] => training => Task 6, Epoch 114/170 => Loss 2.408, Train_accy 99.530, Test_accy 50.170
2022-05-25 00:04:36,588 [bic.py] => training => Task 6, Epoch 115/170 => Loss 2.411, Train_accy 99.470, Test_accy 49.940
2022-05-25 00:04:41,190 [bic.py] => training => Task 6, Epoch 116/170 => Loss 2.406, Train_accy 99.510, Test_accy 49.700
2022-05-25 00:04:45,688 [bic.py] => training => Task 6, Epoch 117/170 => Loss 2.409, Train_accy 99.540, Test_accy 49.860
2022-05-25 00:04:50,226 [bic.py] => training => Task 6, Epoch 118/170 => Loss 2.410, Train_accy 99.650, Test_accy 49.970
2022-05-25 00:04:54,772 [bic.py] => training => Task 6, Epoch 119/170 => Loss 2.406, Train_accy 99.510, Test_accy 49.710
2022-05-25 00:04:59,379 [bic.py] => training => Task 6, Epoch 120/170 => Loss 2.407, Train_accy 99.500, Test_accy 49.690
2022-05-25 00:05:03,890 [bic.py] => training => Task 6, Epoch 121/170 => Loss 2.403, Train_accy 99.450, Test_accy 49.840
2022-05-25 00:05:08,293 [bic.py] => training => Task 6, Epoch 122/170 => Loss 2.411, Train_accy 99.560, Test_accy 50.160
2022-05-25 00:05:12,847 [bic.py] => training => Task 6, Epoch 123/170 => Loss 2.410, Train_accy 99.470, Test_accy 50.130
2022-05-25 00:05:17,436 [bic.py] => training => Task 6, Epoch 124/170 => Loss 2.413, Train_accy 99.440, Test_accy 49.700
2022-05-25 00:05:21,932 [bic.py] => training => Task 6, Epoch 125/170 => Loss 2.413, Train_accy 99.680, Test_accy 49.770
2022-05-25 00:05:26,643 [bic.py] => training => Task 6, Epoch 126/170 => Loss 2.409, Train_accy 99.600, Test_accy 50.010
2022-05-25 00:05:31,262 [bic.py] => training => Task 6, Epoch 127/170 => Loss 2.413, Train_accy 99.540, Test_accy 50.210
2022-05-25 00:05:35,732 [bic.py] => training => Task 6, Epoch 128/170 => Loss 2.412, Train_accy 99.530, Test_accy 49.960
2022-05-25 00:05:40,270 [bic.py] => training => Task 6, Epoch 129/170 => Loss 2.406, Train_accy 99.450, Test_accy 49.930
2022-05-25 00:05:44,850 [bic.py] => training => Task 6, Epoch 130/170 => Loss 2.408, Train_accy 99.390, Test_accy 50.190
2022-05-25 00:05:49,442 [bic.py] => training => Task 6, Epoch 131/170 => Loss 2.406, Train_accy 99.470, Test_accy 49.840
2022-05-25 00:05:53,922 [bic.py] => training => Task 6, Epoch 132/170 => Loss 2.413, Train_accy 99.630, Test_accy 50.040
2022-05-25 00:05:58,365 [bic.py] => training => Task 6, Epoch 133/170 => Loss 2.406, Train_accy 99.590, Test_accy 50.060
2022-05-25 00:06:02,931 [bic.py] => training => Task 6, Epoch 134/170 => Loss 2.408, Train_accy 99.570, Test_accy 49.990
2022-05-25 00:06:07,438 [bic.py] => training => Task 6, Epoch 135/170 => Loss 2.401, Train_accy 99.570, Test_accy 49.870
2022-05-25 00:06:11,995 [bic.py] => training => Task 6, Epoch 136/170 => Loss 2.409, Train_accy 99.620, Test_accy 50.030
2022-05-25 00:06:16,658 [bic.py] => training => Task 6, Epoch 137/170 => Loss 2.412, Train_accy 99.590, Test_accy 49.700
2022-05-25 00:06:21,115 [bic.py] => training => Task 6, Epoch 138/170 => Loss 2.409, Train_accy 99.480, Test_accy 50.070
2022-05-25 00:06:25,675 [bic.py] => training => Task 6, Epoch 139/170 => Loss 2.410, Train_accy 99.590, Test_accy 50.030
2022-05-25 00:06:30,129 [bic.py] => training => Task 6, Epoch 140/170 => Loss 2.409, Train_accy 99.500, Test_accy 49.800
2022-05-25 00:06:34,656 [bic.py] => training => Task 6, Epoch 141/170 => Loss 2.409, Train_accy 99.600, Test_accy 49.800
2022-05-25 00:06:39,262 [bic.py] => training => Task 6, Epoch 142/170 => Loss 2.409, Train_accy 99.500, Test_accy 50.330
2022-05-25 00:06:43,735 [bic.py] => training => Task 6, Epoch 143/170 => Loss 2.407, Train_accy 99.570, Test_accy 49.970
2022-05-25 00:06:48,255 [bic.py] => training => Task 6, Epoch 144/170 => Loss 2.410, Train_accy 99.570, Test_accy 50.190
2022-05-25 00:06:52,860 [bic.py] => training => Task 6, Epoch 145/170 => Loss 2.410, Train_accy 99.530, Test_accy 49.960
2022-05-25 00:06:57,531 [bic.py] => training => Task 6, Epoch 146/170 => Loss 2.409, Train_accy 99.590, Test_accy 50.010
2022-05-25 00:07:02,006 [bic.py] => training => Task 6, Epoch 147/170 => Loss 2.404, Train_accy 99.410, Test_accy 49.960
2022-05-25 00:07:06,503 [bic.py] => training => Task 6, Epoch 148/170 => Loss 2.407, Train_accy 99.500, Test_accy 50.060
2022-05-25 00:07:11,106 [bic.py] => training => Task 6, Epoch 149/170 => Loss 2.412, Train_accy 99.570, Test_accy 50.110
2022-05-25 00:07:15,625 [bic.py] => training => Task 6, Epoch 150/170 => Loss 2.408, Train_accy 99.600, Test_accy 49.970
2022-05-25 00:07:20,168 [bic.py] => training => Task 6, Epoch 151/170 => Loss 2.406, Train_accy 99.500, Test_accy 50.210
2022-05-25 00:07:24,615 [bic.py] => training => Task 6, Epoch 152/170 => Loss 2.417, Train_accy 99.510, Test_accy 50.000
2022-05-25 00:07:29,181 [bic.py] => training => Task 6, Epoch 153/170 => Loss 2.404, Train_accy 99.570, Test_accy 50.170
2022-05-25 00:07:33,624 [bic.py] => training => Task 6, Epoch 154/170 => Loss 2.412, Train_accy 99.380, Test_accy 50.000
2022-05-25 00:07:38,162 [bic.py] => training => Task 6, Epoch 155/170 => Loss 2.406, Train_accy 99.450, Test_accy 50.190
2022-05-25 00:07:42,772 [bic.py] => training => Task 6, Epoch 156/170 => Loss 2.408, Train_accy 99.570, Test_accy 49.800
2022-05-25 00:07:47,345 [bic.py] => training => Task 6, Epoch 157/170 => Loss 2.406, Train_accy 99.470, Test_accy 50.210
2022-05-25 00:07:51,938 [bic.py] => training => Task 6, Epoch 158/170 => Loss 2.409, Train_accy 99.480, Test_accy 50.160
2022-05-25 00:07:56,404 [bic.py] => training => Task 6, Epoch 159/170 => Loss 2.404, Train_accy 99.600, Test_accy 50.070
2022-05-25 00:08:00,977 [bic.py] => training => Task 6, Epoch 160/170 => Loss 2.410, Train_accy 99.470, Test_accy 49.990
2022-05-25 00:08:05,485 [bic.py] => training => Task 6, Epoch 161/170 => Loss 2.409, Train_accy 99.440, Test_accy 49.800
2022-05-25 00:08:09,939 [bic.py] => training => Task 6, Epoch 162/170 => Loss 2.408, Train_accy 99.600, Test_accy 50.170
2022-05-25 00:08:14,410 [bic.py] => training => Task 6, Epoch 163/170 => Loss 2.407, Train_accy 99.650, Test_accy 50.230
2022-05-25 00:08:18,904 [bic.py] => training => Task 6, Epoch 164/170 => Loss 2.415, Train_accy 99.600, Test_accy 50.030
2022-05-25 00:08:23,450 [bic.py] => training => Task 6, Epoch 165/170 => Loss 2.410, Train_accy 99.530, Test_accy 50.000
2022-05-25 00:08:27,945 [bic.py] => training => Task 6, Epoch 166/170 => Loss 2.407, Train_accy 99.650, Test_accy 50.270
2022-05-25 00:08:32,642 [bic.py] => training => Task 6, Epoch 167/170 => Loss 2.406, Train_accy 99.510, Test_accy 49.870
2022-05-25 00:08:37,093 [bic.py] => training => Task 6, Epoch 168/170 => Loss 2.412, Train_accy 99.630, Test_accy 49.940
2022-05-25 00:08:41,625 [bic.py] => training => Task 6, Epoch 169/170 => Loss 2.410, Train_accy 99.650, Test_accy 50.140
2022-05-25 00:08:46,140 [bic.py] => training => Task 6, Epoch 170/170 => Loss 2.412, Train_accy 99.510, Test_accy 50.160
2022-05-25 00:08:47,909 [bic.py] => bias_correction => Task 6, Epoch 1/170 => Loss 3.742, Train_accy 71.900, Test_accy 53.570
2022-05-25 00:08:49,713 [bic.py] => bias_correction => Task 6, Epoch 2/170 => Loss 3.671, Train_accy 79.520, Test_accy 57.100
2022-05-25 00:08:51,479 [bic.py] => bias_correction => Task 6, Epoch 3/170 => Loss 3.641, Train_accy 78.570, Test_accy 52.940
2022-05-25 00:08:53,243 [bic.py] => bias_correction => Task 6, Epoch 4/170 => Loss 3.673, Train_accy 75.710, Test_accy 50.560
2022-05-25 00:08:55,016 [bic.py] => bias_correction => Task 6, Epoch 5/170 => Loss 3.666, Train_accy 71.430, Test_accy 49.810
2022-05-25 00:08:56,922 [bic.py] => bias_correction => Task 6, Epoch 6/170 => Loss 3.677, Train_accy 72.860, Test_accy 49.660
2022-05-25 00:08:58,768 [bic.py] => bias_correction => Task 6, Epoch 7/170 => Loss 3.686, Train_accy 71.900, Test_accy 49.530
2022-05-25 00:09:00,530 [bic.py] => bias_correction => Task 6, Epoch 8/170 => Loss 3.679, Train_accy 73.810, Test_accy 49.930
2022-05-25 00:09:02,256 [bic.py] => bias_correction => Task 6, Epoch 9/170 => Loss 3.667, Train_accy 74.290, Test_accy 51.060
2022-05-25 00:09:04,036 [bic.py] => bias_correction => Task 6, Epoch 10/170 => Loss 3.668, Train_accy 76.670, Test_accy 53.860
2022-05-25 00:09:05,756 [bic.py] => bias_correction => Task 6, Epoch 11/170 => Loss 3.643, Train_accy 82.860, Test_accy 55.590
2022-05-25 00:09:07,461 [bic.py] => bias_correction => Task 6, Epoch 12/170 => Loss 3.622, Train_accy 76.670, Test_accy 54.770
2022-05-25 00:09:09,173 [bic.py] => bias_correction => Task 6, Epoch 13/170 => Loss 3.661, Train_accy 76.670, Test_accy 54.640
2022-05-25 00:09:10,905 [bic.py] => bias_correction => Task 6, Epoch 14/170 => Loss 3.665, Train_accy 77.620, Test_accy 55.290
2022-05-25 00:09:12,657 [bic.py] => bias_correction => Task 6, Epoch 15/170 => Loss 3.655, Train_accy 79.050, Test_accy 55.210
2022-05-25 00:09:14,409 [bic.py] => bias_correction => Task 6, Epoch 16/170 => Loss 3.645, Train_accy 78.100, Test_accy 53.990
2022-05-25 00:09:16,092 [bic.py] => bias_correction => Task 6, Epoch 17/170 => Loss 3.658, Train_accy 75.710, Test_accy 53.470
2022-05-25 00:09:17,872 [bic.py] => bias_correction => Task 6, Epoch 18/170 => Loss 3.654, Train_accy 81.430, Test_accy 54.230
2022-05-25 00:09:19,552 [bic.py] => bias_correction => Task 6, Epoch 19/170 => Loss 3.659, Train_accy 80.480, Test_accy 55.200
2022-05-25 00:09:21,351 [bic.py] => bias_correction => Task 6, Epoch 20/170 => Loss 3.625, Train_accy 79.520, Test_accy 55.340
2022-05-25 00:09:23,184 [bic.py] => bias_correction => Task 6, Epoch 21/170 => Loss 3.638, Train_accy 75.710, Test_accy 55.270
2022-05-25 00:09:24,951 [bic.py] => bias_correction => Task 6, Epoch 22/170 => Loss 3.644, Train_accy 79.520, Test_accy 55.430
2022-05-25 00:09:26,729 [bic.py] => bias_correction => Task 6, Epoch 23/170 => Loss 3.628, Train_accy 79.050, Test_accy 55.260
2022-05-25 00:09:28,461 [bic.py] => bias_correction => Task 6, Epoch 24/170 => Loss 3.628, Train_accy 80.000, Test_accy 55.170
2022-05-25 00:09:30,266 [bic.py] => bias_correction => Task 6, Epoch 25/170 => Loss 3.629, Train_accy 79.520, Test_accy 55.260
2022-05-25 00:09:32,050 [bic.py] => bias_correction => Task 6, Epoch 26/170 => Loss 3.647, Train_accy 76.670, Test_accy 55.110
2022-05-25 00:09:33,782 [bic.py] => bias_correction => Task 6, Epoch 27/170 => Loss 3.636, Train_accy 82.380, Test_accy 55.210
2022-05-25 00:09:35,537 [bic.py] => bias_correction => Task 6, Epoch 28/170 => Loss 3.646, Train_accy 78.100, Test_accy 55.330
2022-05-25 00:09:37,274 [bic.py] => bias_correction => Task 6, Epoch 29/170 => Loss 3.633, Train_accy 80.950, Test_accy 55.340
2022-05-25 00:09:39,039 [bic.py] => bias_correction => Task 6, Epoch 30/170 => Loss 3.625, Train_accy 77.140, Test_accy 55.310
2022-05-25 00:09:40,809 [bic.py] => bias_correction => Task 6, Epoch 31/170 => Loss 3.628, Train_accy 79.050, Test_accy 55.700
2022-05-25 00:09:42,489 [bic.py] => bias_correction => Task 6, Epoch 32/170 => Loss 3.641, Train_accy 79.050, Test_accy 55.600
2022-05-25 00:09:44,265 [bic.py] => bias_correction => Task 6, Epoch 33/170 => Loss 3.644, Train_accy 80.000, Test_accy 55.400
2022-05-25 00:09:46,054 [bic.py] => bias_correction => Task 6, Epoch 34/170 => Loss 3.621, Train_accy 77.140, Test_accy 55.140
2022-05-25 00:09:47,827 [bic.py] => bias_correction => Task 6, Epoch 35/170 => Loss 3.624, Train_accy 81.900, Test_accy 54.910
2022-05-25 00:09:49,592 [bic.py] => bias_correction => Task 6, Epoch 36/170 => Loss 3.654, Train_accy 79.050, Test_accy 54.710
2022-05-25 00:09:51,398 [bic.py] => bias_correction => Task 6, Epoch 37/170 => Loss 3.626, Train_accy 81.430, Test_accy 54.940
2022-05-25 00:09:53,192 [bic.py] => bias_correction => Task 6, Epoch 38/170 => Loss 3.655, Train_accy 80.480, Test_accy 55.230
2022-05-25 00:09:55,067 [bic.py] => bias_correction => Task 6, Epoch 39/170 => Loss 3.626, Train_accy 79.050, Test_accy 55.530
2022-05-25 00:09:56,830 [bic.py] => bias_correction => Task 6, Epoch 40/170 => Loss 3.648, Train_accy 78.570, Test_accy 55.590
2022-05-25 00:09:58,637 [bic.py] => bias_correction => Task 6, Epoch 41/170 => Loss 3.633, Train_accy 80.480, Test_accy 55.430
2022-05-25 00:10:00,330 [bic.py] => bias_correction => Task 6, Epoch 42/170 => Loss 3.640, Train_accy 79.520, Test_accy 55.500
2022-05-25 00:10:02,075 [bic.py] => bias_correction => Task 6, Epoch 43/170 => Loss 3.645, Train_accy 78.100, Test_accy 55.300
2022-05-25 00:10:03,935 [bic.py] => bias_correction => Task 6, Epoch 44/170 => Loss 3.634, Train_accy 80.950, Test_accy 55.310
2022-05-25 00:10:05,699 [bic.py] => bias_correction => Task 6, Epoch 45/170 => Loss 3.637, Train_accy 80.950, Test_accy 55.390
2022-05-25 00:10:07,510 [bic.py] => bias_correction => Task 6, Epoch 46/170 => Loss 3.626, Train_accy 82.380, Test_accy 55.530
2022-05-25 00:10:09,235 [bic.py] => bias_correction => Task 6, Epoch 47/170 => Loss 3.640, Train_accy 82.380, Test_accy 55.600
2022-05-25 00:10:10,982 [bic.py] => bias_correction => Task 6, Epoch 48/170 => Loss 3.640, Train_accy 79.520, Test_accy 55.510
2022-05-25 00:10:12,830 [bic.py] => bias_correction => Task 6, Epoch 49/170 => Loss 3.619, Train_accy 80.950, Test_accy 55.600
2022-05-25 00:10:14,609 [bic.py] => bias_correction => Task 6, Epoch 50/170 => Loss 3.636, Train_accy 76.670, Test_accy 55.540
2022-05-25 00:10:16,371 [bic.py] => bias_correction => Task 6, Epoch 51/170 => Loss 3.607, Train_accy 77.620, Test_accy 55.300
2022-05-25 00:10:18,113 [bic.py] => bias_correction => Task 6, Epoch 52/170 => Loss 3.640, Train_accy 78.100, Test_accy 55.140
2022-05-25 00:10:19,885 [bic.py] => bias_correction => Task 6, Epoch 53/170 => Loss 3.633, Train_accy 82.860, Test_accy 55.060
2022-05-25 00:10:21,687 [bic.py] => bias_correction => Task 6, Epoch 54/170 => Loss 3.618, Train_accy 76.670, Test_accy 55.190
2022-05-25 00:10:23,444 [bic.py] => bias_correction => Task 6, Epoch 55/170 => Loss 3.641, Train_accy 79.050, Test_accy 55.210
2022-05-25 00:10:25,264 [bic.py] => bias_correction => Task 6, Epoch 56/170 => Loss 3.637, Train_accy 82.860, Test_accy 55.400
2022-05-25 00:10:27,078 [bic.py] => bias_correction => Task 6, Epoch 57/170 => Loss 3.633, Train_accy 80.000, Test_accy 55.490
2022-05-25 00:10:28,891 [bic.py] => bias_correction => Task 6, Epoch 58/170 => Loss 3.619, Train_accy 80.950, Test_accy 55.530
2022-05-25 00:10:30,653 [bic.py] => bias_correction => Task 6, Epoch 59/170 => Loss 3.619, Train_accy 78.570, Test_accy 55.570
2022-05-25 00:10:32,361 [bic.py] => bias_correction => Task 6, Epoch 60/170 => Loss 3.618, Train_accy 77.620, Test_accy 55.530
2022-05-25 00:10:34,079 [bic.py] => bias_correction => Task 6, Epoch 61/170 => Loss 3.649, Train_accy 78.570, Test_accy 55.570
2022-05-25 00:10:35,801 [bic.py] => bias_correction => Task 6, Epoch 62/170 => Loss 3.636, Train_accy 78.570, Test_accy 55.560
2022-05-25 00:10:37,547 [bic.py] => bias_correction => Task 6, Epoch 63/170 => Loss 3.641, Train_accy 78.570, Test_accy 55.500
2022-05-25 00:10:39,407 [bic.py] => bias_correction => Task 6, Epoch 64/170 => Loss 3.639, Train_accy 79.050, Test_accy 55.440
2022-05-25 00:10:41,193 [bic.py] => bias_correction => Task 6, Epoch 65/170 => Loss 3.627, Train_accy 82.380, Test_accy 55.560
2022-05-25 00:10:42,959 [bic.py] => bias_correction => Task 6, Epoch 66/170 => Loss 3.652, Train_accy 78.570, Test_accy 55.440
2022-05-25 00:10:44,698 [bic.py] => bias_correction => Task 6, Epoch 67/170 => Loss 3.625, Train_accy 79.050, Test_accy 55.430
2022-05-25 00:10:46,515 [bic.py] => bias_correction => Task 6, Epoch 68/170 => Loss 3.634, Train_accy 80.950, Test_accy 55.400
2022-05-25 00:10:48,340 [bic.py] => bias_correction => Task 6, Epoch 69/170 => Loss 3.634, Train_accy 78.570, Test_accy 55.400
2022-05-25 00:10:50,242 [bic.py] => bias_correction => Task 6, Epoch 70/170 => Loss 3.635, Train_accy 80.480, Test_accy 55.400
2022-05-25 00:10:51,996 [bic.py] => bias_correction => Task 6, Epoch 71/170 => Loss 3.643, Train_accy 80.480, Test_accy 55.490
2022-05-25 00:10:53,764 [bic.py] => bias_correction => Task 6, Epoch 72/170 => Loss 3.631, Train_accy 79.050, Test_accy 55.410
2022-05-25 00:10:55,507 [bic.py] => bias_correction => Task 6, Epoch 73/170 => Loss 3.634, Train_accy 75.240, Test_accy 55.430
2022-05-25 00:10:57,384 [bic.py] => bias_correction => Task 6, Epoch 74/170 => Loss 3.639, Train_accy 81.430, Test_accy 55.500
2022-05-25 00:10:59,090 [bic.py] => bias_correction => Task 6, Epoch 75/170 => Loss 3.633, Train_accy 80.000, Test_accy 55.660
2022-05-25 00:11:00,850 [bic.py] => bias_correction => Task 6, Epoch 76/170 => Loss 3.632, Train_accy 79.050, Test_accy 55.570
2022-05-25 00:11:02,563 [bic.py] => bias_correction => Task 6, Epoch 77/170 => Loss 3.627, Train_accy 79.520, Test_accy 55.600
2022-05-25 00:11:04,350 [bic.py] => bias_correction => Task 6, Epoch 78/170 => Loss 3.631, Train_accy 75.710, Test_accy 55.600
2022-05-25 00:11:06,247 [bic.py] => bias_correction => Task 6, Epoch 79/170 => Loss 3.639, Train_accy 80.000, Test_accy 55.630
2022-05-25 00:11:08,115 [bic.py] => bias_correction => Task 6, Epoch 80/170 => Loss 3.611, Train_accy 77.620, Test_accy 55.510
2022-05-25 00:11:10,057 [bic.py] => bias_correction => Task 6, Epoch 81/170 => Loss 3.632, Train_accy 77.620, Test_accy 55.540
2022-05-25 00:11:11,786 [bic.py] => bias_correction => Task 6, Epoch 82/170 => Loss 3.643, Train_accy 80.950, Test_accy 55.540
2022-05-25 00:11:13,557 [bic.py] => bias_correction => Task 6, Epoch 83/170 => Loss 3.631, Train_accy 75.240, Test_accy 55.530
2022-05-25 00:11:15,411 [bic.py] => bias_correction => Task 6, Epoch 84/170 => Loss 3.632, Train_accy 80.480, Test_accy 55.540
2022-05-25 00:11:17,226 [bic.py] => bias_correction => Task 6, Epoch 85/170 => Loss 3.644, Train_accy 78.570, Test_accy 55.690
2022-05-25 00:11:19,001 [bic.py] => bias_correction => Task 6, Epoch 86/170 => Loss 3.640, Train_accy 79.520, Test_accy 55.560
2022-05-25 00:11:20,753 [bic.py] => bias_correction => Task 6, Epoch 87/170 => Loss 3.627, Train_accy 77.140, Test_accy 55.660
2022-05-25 00:11:22,692 [bic.py] => bias_correction => Task 6, Epoch 88/170 => Loss 3.648, Train_accy 79.050, Test_accy 55.570
2022-05-25 00:11:24,506 [bic.py] => bias_correction => Task 6, Epoch 89/170 => Loss 3.640, Train_accy 78.100, Test_accy 55.560
2022-05-25 00:11:26,396 [bic.py] => bias_correction => Task 6, Epoch 90/170 => Loss 3.627, Train_accy 76.670, Test_accy 55.610
2022-05-25 00:11:28,173 [bic.py] => bias_correction => Task 6, Epoch 91/170 => Loss 3.617, Train_accy 78.570, Test_accy 55.460
2022-05-25 00:11:29,973 [bic.py] => bias_correction => Task 6, Epoch 92/170 => Loss 3.632, Train_accy 78.100, Test_accy 55.440
2022-05-25 00:11:31,795 [bic.py] => bias_correction => Task 6, Epoch 93/170 => Loss 3.636, Train_accy 79.050, Test_accy 55.490
2022-05-25 00:11:33,628 [bic.py] => bias_correction => Task 6, Epoch 94/170 => Loss 3.622, Train_accy 81.430, Test_accy 55.500
2022-05-25 00:11:35,506 [bic.py] => bias_correction => Task 6, Epoch 95/170 => Loss 3.637, Train_accy 77.620, Test_accy 55.430
2022-05-25 00:11:37,346 [bic.py] => bias_correction => Task 6, Epoch 96/170 => Loss 3.638, Train_accy 81.430, Test_accy 55.500
2022-05-25 00:11:39,187 [bic.py] => bias_correction => Task 6, Epoch 97/170 => Loss 3.621, Train_accy 78.100, Test_accy 55.560
2022-05-25 00:11:40,855 [bic.py] => bias_correction => Task 6, Epoch 98/170 => Loss 3.633, Train_accy 80.000, Test_accy 55.500
2022-05-25 00:11:42,681 [bic.py] => bias_correction => Task 6, Epoch 99/170 => Loss 3.640, Train_accy 78.100, Test_accy 55.460
2022-05-25 00:11:44,379 [bic.py] => bias_correction => Task 6, Epoch 100/170 => Loss 3.626, Train_accy 80.950, Test_accy 55.510
2022-05-25 00:11:46,200 [bic.py] => bias_correction => Task 6, Epoch 101/170 => Loss 3.633, Train_accy 80.480, Test_accy 55.490
2022-05-25 00:11:47,913 [bic.py] => bias_correction => Task 6, Epoch 102/170 => Loss 3.637, Train_accy 78.100, Test_accy 55.530
2022-05-25 00:11:49,689 [bic.py] => bias_correction => Task 6, Epoch 103/170 => Loss 3.636, Train_accy 80.000, Test_accy 55.600
2022-05-25 00:11:51,366 [bic.py] => bias_correction => Task 6, Epoch 104/170 => Loss 3.642, Train_accy 80.480, Test_accy 55.460
2022-05-25 00:11:53,183 [bic.py] => bias_correction => Task 6, Epoch 105/170 => Loss 3.620, Train_accy 78.570, Test_accy 55.560
2022-05-25 00:11:55,015 [bic.py] => bias_correction => Task 6, Epoch 106/170 => Loss 3.609, Train_accy 79.050, Test_accy 55.560
2022-05-25 00:11:56,789 [bic.py] => bias_correction => Task 6, Epoch 107/170 => Loss 3.619, Train_accy 75.240, Test_accy 55.600
2022-05-25 00:11:58,535 [bic.py] => bias_correction => Task 6, Epoch 108/170 => Loss 3.632, Train_accy 78.570, Test_accy 55.660
2022-05-25 00:12:00,310 [bic.py] => bias_correction => Task 6, Epoch 109/170 => Loss 3.615, Train_accy 79.520, Test_accy 55.610
2022-05-25 00:12:02,046 [bic.py] => bias_correction => Task 6, Epoch 110/170 => Loss 3.628, Train_accy 80.000, Test_accy 55.690
2022-05-25 00:12:03,815 [bic.py] => bias_correction => Task 6, Epoch 111/170 => Loss 3.629, Train_accy 78.570, Test_accy 55.710
2022-05-25 00:12:05,575 [bic.py] => bias_correction => Task 6, Epoch 112/170 => Loss 3.627, Train_accy 79.050, Test_accy 55.690
2022-05-25 00:12:07,373 [bic.py] => bias_correction => Task 6, Epoch 113/170 => Loss 3.632, Train_accy 76.190, Test_accy 55.570
2022-05-25 00:12:09,088 [bic.py] => bias_correction => Task 6, Epoch 114/170 => Loss 3.642, Train_accy 80.000, Test_accy 55.540
2022-05-25 00:12:10,841 [bic.py] => bias_correction => Task 6, Epoch 115/170 => Loss 3.637, Train_accy 79.520, Test_accy 55.470
2022-05-25 00:12:12,524 [bic.py] => bias_correction => Task 6, Epoch 116/170 => Loss 3.623, Train_accy 80.000, Test_accy 55.590
2022-05-25 00:12:14,351 [bic.py] => bias_correction => Task 6, Epoch 117/170 => Loss 3.634, Train_accy 80.950, Test_accy 55.600
2022-05-25 00:12:16,157 [bic.py] => bias_correction => Task 6, Epoch 118/170 => Loss 3.642, Train_accy 79.520, Test_accy 55.630
2022-05-25 00:12:18,000 [bic.py] => bias_correction => Task 6, Epoch 119/170 => Loss 3.639, Train_accy 80.480, Test_accy 55.630
2022-05-25 00:12:19,756 [bic.py] => bias_correction => Task 6, Epoch 120/170 => Loss 3.611, Train_accy 78.100, Test_accy 55.640
2022-05-25 00:12:21,569 [bic.py] => bias_correction => Task 6, Epoch 121/170 => Loss 3.631, Train_accy 76.670, Test_accy 55.660
2022-05-25 00:12:23,238 [bic.py] => bias_correction => Task 6, Epoch 122/170 => Loss 3.643, Train_accy 80.000, Test_accy 55.560
2022-05-25 00:12:25,079 [bic.py] => bias_correction => Task 6, Epoch 123/170 => Loss 3.627, Train_accy 80.000, Test_accy 55.540
2022-05-25 00:12:26,931 [bic.py] => bias_correction => Task 6, Epoch 124/170 => Loss 3.629, Train_accy 78.570, Test_accy 55.630
2022-05-25 00:12:28,680 [bic.py] => bias_correction => Task 6, Epoch 125/170 => Loss 3.642, Train_accy 81.430, Test_accy 55.590
2022-05-25 00:12:30,470 [bic.py] => bias_correction => Task 6, Epoch 126/170 => Loss 3.641, Train_accy 80.480, Test_accy 55.600
2022-05-25 00:12:32,226 [bic.py] => bias_correction => Task 6, Epoch 127/170 => Loss 3.632, Train_accy 83.810, Test_accy 55.470
2022-05-25 00:12:34,048 [bic.py] => bias_correction => Task 6, Epoch 128/170 => Loss 3.633, Train_accy 78.570, Test_accy 55.530
2022-05-25 00:12:35,900 [bic.py] => bias_correction => Task 6, Epoch 129/170 => Loss 3.637, Train_accy 80.950, Test_accy 55.540
2022-05-25 00:12:37,633 [bic.py] => bias_correction => Task 6, Epoch 130/170 => Loss 3.620, Train_accy 80.480, Test_accy 55.540
2022-05-25 00:12:39,491 [bic.py] => bias_correction => Task 6, Epoch 131/170 => Loss 3.624, Train_accy 80.480, Test_accy 55.610
2022-05-25 00:12:41,292 [bic.py] => bias_correction => Task 6, Epoch 132/170 => Loss 3.623, Train_accy 78.100, Test_accy 55.600
2022-05-25 00:12:43,083 [bic.py] => bias_correction => Task 6, Epoch 133/170 => Loss 3.648, Train_accy 79.520, Test_accy 55.530
2022-05-25 00:12:44,878 [bic.py] => bias_correction => Task 6, Epoch 134/170 => Loss 3.620, Train_accy 79.520, Test_accy 55.490
2022-05-25 00:12:46,626 [bic.py] => bias_correction => Task 6, Epoch 135/170 => Loss 3.630, Train_accy 80.480, Test_accy 55.670
2022-05-25 00:12:48,466 [bic.py] => bias_correction => Task 6, Epoch 136/170 => Loss 3.632, Train_accy 80.480, Test_accy 55.600
2022-05-25 00:12:50,204 [bic.py] => bias_correction => Task 6, Epoch 137/170 => Loss 3.634, Train_accy 77.140, Test_accy 55.610
2022-05-25 00:12:51,971 [bic.py] => bias_correction => Task 6, Epoch 138/170 => Loss 3.644, Train_accy 78.570, Test_accy 55.710
2022-05-25 00:12:53,738 [bic.py] => bias_correction => Task 6, Epoch 139/170 => Loss 3.622, Train_accy 77.140, Test_accy 55.540
2022-05-25 00:12:55,508 [bic.py] => bias_correction => Task 6, Epoch 140/170 => Loss 3.626, Train_accy 80.480, Test_accy 55.610
2022-05-25 00:12:57,243 [bic.py] => bias_correction => Task 6, Epoch 141/170 => Loss 3.631, Train_accy 80.480, Test_accy 55.660
2022-05-25 00:12:58,990 [bic.py] => bias_correction => Task 6, Epoch 142/170 => Loss 3.643, Train_accy 81.430, Test_accy 55.600
2022-05-25 00:13:00,834 [bic.py] => bias_correction => Task 6, Epoch 143/170 => Loss 3.629, Train_accy 78.570, Test_accy 55.660
2022-05-25 00:13:02,732 [bic.py] => bias_correction => Task 6, Epoch 144/170 => Loss 3.637, Train_accy 80.480, Test_accy 55.640
2022-05-25 00:13:04,549 [bic.py] => bias_correction => Task 6, Epoch 145/170 => Loss 3.615, Train_accy 80.000, Test_accy 55.600
2022-05-25 00:13:06,248 [bic.py] => bias_correction => Task 6, Epoch 146/170 => Loss 3.611, Train_accy 80.480, Test_accy 55.530
2022-05-25 00:13:08,003 [bic.py] => bias_correction => Task 6, Epoch 147/170 => Loss 3.653, Train_accy 78.100, Test_accy 55.560
2022-05-25 00:13:09,831 [bic.py] => bias_correction => Task 6, Epoch 148/170 => Loss 3.614, Train_accy 78.570, Test_accy 55.570
2022-05-25 00:13:11,556 [bic.py] => bias_correction => Task 6, Epoch 149/170 => Loss 3.632, Train_accy 78.100, Test_accy 55.530
2022-05-25 00:13:13,436 [bic.py] => bias_correction => Task 6, Epoch 150/170 => Loss 3.621, Train_accy 81.430, Test_accy 55.540
2022-05-25 00:13:15,218 [bic.py] => bias_correction => Task 6, Epoch 151/170 => Loss 3.652, Train_accy 78.100, Test_accy 55.510
2022-05-25 00:13:16,981 [bic.py] => bias_correction => Task 6, Epoch 152/170 => Loss 3.633, Train_accy 77.620, Test_accy 55.530
2022-05-25 00:13:18,813 [bic.py] => bias_correction => Task 6, Epoch 153/170 => Loss 3.620, Train_accy 79.050, Test_accy 55.500
2022-05-25 00:13:20,652 [bic.py] => bias_correction => Task 6, Epoch 154/170 => Loss 3.639, Train_accy 80.950, Test_accy 55.570
2022-05-25 00:13:22,366 [bic.py] => bias_correction => Task 6, Epoch 155/170 => Loss 3.623, Train_accy 80.950, Test_accy 55.560
2022-05-25 00:13:24,127 [bic.py] => bias_correction => Task 6, Epoch 156/170 => Loss 3.630, Train_accy 80.950, Test_accy 55.560
2022-05-25 00:13:25,933 [bic.py] => bias_correction => Task 6, Epoch 157/170 => Loss 3.633, Train_accy 79.520, Test_accy 55.490
2022-05-25 00:13:27,701 [bic.py] => bias_correction => Task 6, Epoch 158/170 => Loss 3.640, Train_accy 78.570, Test_accy 55.560
2022-05-25 00:13:29,524 [bic.py] => bias_correction => Task 6, Epoch 159/170 => Loss 3.629, Train_accy 80.950, Test_accy 55.610
2022-05-25 00:13:31,205 [bic.py] => bias_correction => Task 6, Epoch 160/170 => Loss 3.632, Train_accy 80.480, Test_accy 55.410
2022-05-25 00:13:33,047 [bic.py] => bias_correction => Task 6, Epoch 161/170 => Loss 3.632, Train_accy 79.050, Test_accy 55.400
2022-05-25 00:13:34,850 [bic.py] => bias_correction => Task 6, Epoch 162/170 => Loss 3.623, Train_accy 76.670, Test_accy 55.470
2022-05-25 00:13:36,644 [bic.py] => bias_correction => Task 6, Epoch 163/170 => Loss 3.621, Train_accy 79.050, Test_accy 55.500
2022-05-25 00:13:38,476 [bic.py] => bias_correction => Task 6, Epoch 164/170 => Loss 3.626, Train_accy 80.000, Test_accy 55.460
2022-05-25 00:13:40,343 [bic.py] => bias_correction => Task 6, Epoch 165/170 => Loss 3.632, Train_accy 78.100, Test_accy 55.560
2022-05-25 00:13:42,002 [bic.py] => bias_correction => Task 6, Epoch 166/170 => Loss 3.618, Train_accy 81.900, Test_accy 55.610
2022-05-25 00:13:43,818 [bic.py] => bias_correction => Task 6, Epoch 167/170 => Loss 3.639, Train_accy 80.950, Test_accy 55.690
2022-05-25 00:13:45,672 [bic.py] => bias_correction => Task 6, Epoch 168/170 => Loss 3.628, Train_accy 80.480, Test_accy 55.600
2022-05-25 00:13:47,395 [bic.py] => bias_correction => Task 6, Epoch 169/170 => Loss 3.638, Train_accy 80.000, Test_accy 55.560
2022-05-25 00:13:49,133 [bic.py] => bias_correction => Task 6, Epoch 170/170 => Loss 3.640, Train_accy 79.050, Test_accy 55.690
2022-05-25 00:13:49,134 [base.py] => Reducing exemplars...(28 per classes)
2022-05-25 00:14:01,587 [base.py] => Constructing exemplars...(28 per classes)
2022-05-25 00:14:07,361 [bic.py] => Parameters of bias layer:
2022-05-25 00:14:07,362 [bic.py] => 0 => 1.000, 0.000
2022-05-25 00:14:07,362 [bic.py] => 1 => 0.981, -1.523
2022-05-25 00:14:07,362 [bic.py] => 2 => 0.816, -1.587
2022-05-25 00:14:07,363 [bic.py] => 3 => 0.723, -1.178
2022-05-25 00:14:07,363 [bic.py] => 4 => 0.736, -1.143
2022-05-25 00:14:07,363 [bic.py] => 5 => 0.746, -1.342
2022-05-25 00:14:07,363 [bic.py] => 6 => 0.696, -1.160
2022-05-25 00:14:09,497 [bic.py] => Exemplar size: 1960
2022-05-25 00:14:09,498 [trainer.py] => CNN: {'total': 55.69, '00-09': 62.2, '10-19': 48.1, '20-29': 59.3, '30-39': 49.5, '40-49': 55.8, '50-59': 54.3, '60-69': 60.6, 'old': 54.87, 'new': 60.6}
2022-05-25 00:14:09,499 [trainer.py] => NME: {'total': 57.14, '00-09': 59.5, '10-19': 43.4, '20-29': 60.8, '30-39': 48.4, '40-49': 61.3, '50-59': 58.5, '60-69': 68.1, 'old': 55.32, 'new': 68.1}
2022-05-25 00:14:09,499 [trainer.py] => CNN top1 curve: [87.5, 75.95, 70.6, 64.53, 62.34, 58.72, 55.69]
2022-05-25 00:14:09,499 [trainer.py] => CNN top5 curve: [99.3, 95.5, 93.17, 90.3, 89.32, 86.92, 84.71]
2022-05-25 00:14:09,499 [trainer.py] => NME top1 curve: [88.1, 75.6, 71.27, 64.97, 62.62, 59.18, 57.14]
2022-05-25 00:14:09,499 [trainer.py] => NME top5 curve: [99.4, 95.4, 93.2, 90.05, 88.58, 86.03, 83.64]

2022-05-25 00:14:09,499 [trainer.py] => All params: 468718
2022-05-25 00:14:09,500 [trainer.py] => Trainable params: 468718
2022-05-25 00:14:09,501 [bic.py] => Learning on 70-80
2022-05-25 00:14:09,561 [bic.py] => Stage1 dset: 6800, Stage2 dset: 160
2022-05-25 00:14:09,561 [bic.py] => Lambda: 0.875
2022-05-25 00:14:09,582 [bic.py] => Parameters of bias layer:
2022-05-25 00:14:09,582 [bic.py] => 0 => 1.000, 0.000
2022-05-25 00:14:09,582 [bic.py] => 1 => 0.981, -1.523
2022-05-25 00:14:09,582 [bic.py] => 2 => 0.816, -1.587
2022-05-25 00:14:09,583 [bic.py] => 3 => 0.723, -1.178
2022-05-25 00:14:09,583 [bic.py] => 4 => 0.736, -1.143
2022-05-25 00:14:09,583 [bic.py] => 5 => 0.746, -1.342
2022-05-25 00:14:09,583 [bic.py] => 6 => 0.696, -1.160
2022-05-25 00:14:09,583 [bic.py] => 7 => 1.000, 0.000
2022-05-25 00:14:14,399 [bic.py] => training => Task 7, Epoch 1/170 => Loss 2.861, Train_accy 68.090, Test_accy 35.440
2022-05-25 00:14:19,072 [bic.py] => training => Task 7, Epoch 2/170 => Loss 2.786, Train_accy 67.570, Test_accy 33.560
2022-05-25 00:14:23,773 [bic.py] => training => Task 7, Epoch 3/170 => Loss 2.783, Train_accy 68.440, Test_accy 32.190
2022-05-25 00:14:28,523 [bic.py] => training => Task 7, Epoch 4/170 => Loss 2.767, Train_accy 75.500, Test_accy 37.220
2022-05-25 00:14:33,231 [bic.py] => training => Task 7, Epoch 5/170 => Loss 2.748, Train_accy 71.240, Test_accy 33.250
2022-05-25 00:14:37,871 [bic.py] => training => Task 7, Epoch 6/170 => Loss 2.733, Train_accy 76.940, Test_accy 36.610
2022-05-25 00:14:42,629 [bic.py] => training => Task 7, Epoch 7/170 => Loss 2.732, Train_accy 79.400, Test_accy 37.920
2022-05-25 00:14:47,331 [bic.py] => training => Task 7, Epoch 8/170 => Loss 2.747, Train_accy 81.930, Test_accy 38.860
2022-05-25 00:14:52,082 [bic.py] => training => Task 7, Epoch 9/170 => Loss 2.727, Train_accy 77.750, Test_accy 37.340
2022-05-25 00:14:56,763 [bic.py] => training => Task 7, Epoch 10/170 => Loss 2.734, Train_accy 81.960, Test_accy 39.690
2022-05-25 00:15:01,362 [bic.py] => training => Task 7, Epoch 11/170 => Loss 2.729, Train_accy 83.340, Test_accy 38.670
2022-05-25 00:15:05,975 [bic.py] => training => Task 7, Epoch 12/170 => Loss 2.727, Train_accy 82.280, Test_accy 39.960
2022-05-25 00:15:10,590 [bic.py] => training => Task 7, Epoch 13/170 => Loss 2.734, Train_accy 83.460, Test_accy 40.110
2022-05-25 00:15:15,239 [bic.py] => training => Task 7, Epoch 14/170 => Loss 2.728, Train_accy 84.870, Test_accy 40.500
2022-05-25 00:15:19,890 [bic.py] => training => Task 7, Epoch 15/170 => Loss 2.731, Train_accy 81.630, Test_accy 38.350
2022-05-25 00:15:24,566 [bic.py] => training => Task 7, Epoch 16/170 => Loss 2.735, Train_accy 81.490, Test_accy 38.050
2022-05-25 00:15:29,183 [bic.py] => training => Task 7, Epoch 17/170 => Loss 2.712, Train_accy 84.740, Test_accy 38.220
2022-05-25 00:15:33,888 [bic.py] => training => Task 7, Epoch 18/170 => Loss 2.701, Train_accy 85.440, Test_accy 39.850
2022-05-25 00:15:38,558 [bic.py] => training => Task 7, Epoch 19/170 => Loss 2.728, Train_accy 83.090, Test_accy 38.650
2022-05-25 00:15:43,362 [bic.py] => training => Task 7, Epoch 20/170 => Loss 2.728, Train_accy 86.910, Test_accy 42.610
2022-05-25 00:15:48,293 [bic.py] => training => Task 7, Epoch 21/170 => Loss 2.707, Train_accy 86.120, Test_accy 37.850
2022-05-25 00:15:52,869 [bic.py] => training => Task 7, Epoch 22/170 => Loss 2.705, Train_accy 87.880, Test_accy 42.010
2022-05-25 00:15:57,567 [bic.py] => training => Task 7, Epoch 23/170 => Loss 2.704, Train_accy 82.250, Test_accy 37.920
2022-05-25 00:16:02,286 [bic.py] => training => Task 7, Epoch 24/170 => Loss 2.699, Train_accy 88.160, Test_accy 39.850
2022-05-25 00:16:07,175 [bic.py] => training => Task 7, Epoch 25/170 => Loss 2.697, Train_accy 87.260, Test_accy 39.860
2022-05-25 00:16:11,823 [bic.py] => training => Task 7, Epoch 26/170 => Loss 2.710, Train_accy 86.660, Test_accy 37.780
2022-05-25 00:16:16,436 [bic.py] => training => Task 7, Epoch 27/170 => Loss 2.702, Train_accy 87.460, Test_accy 41.290
2022-05-25 00:16:21,166 [bic.py] => training => Task 7, Epoch 28/170 => Loss 2.698, Train_accy 86.780, Test_accy 42.460
2022-05-25 00:16:25,743 [bic.py] => training => Task 7, Epoch 29/170 => Loss 2.697, Train_accy 86.220, Test_accy 38.200
2022-05-25 00:16:30,633 [bic.py] => training => Task 7, Epoch 30/170 => Loss 2.712, Train_accy 86.040, Test_accy 38.170
2022-05-25 00:16:35,297 [bic.py] => training => Task 7, Epoch 31/170 => Loss 2.724, Train_accy 75.280, Test_accy 34.110
2022-05-25 00:16:40,101 [bic.py] => training => Task 7, Epoch 32/170 => Loss 2.711, Train_accy 90.220, Test_accy 38.950
2022-05-25 00:16:44,645 [bic.py] => training => Task 7, Epoch 33/170 => Loss 2.700, Train_accy 89.320, Test_accy 39.150
2022-05-25 00:16:49,519 [bic.py] => training => Task 7, Epoch 34/170 => Loss 2.683, Train_accy 82.430, Test_accy 38.090
2022-05-25 00:16:54,228 [bic.py] => training => Task 7, Epoch 35/170 => Loss 2.715, Train_accy 86.940, Test_accy 39.540
2022-05-25 00:16:59,408 [bic.py] => training => Task 7, Epoch 36/170 => Loss 2.696, Train_accy 88.500, Test_accy 37.390
2022-05-25 00:17:04,473 [bic.py] => training => Task 7, Epoch 37/170 => Loss 2.717, Train_accy 85.060, Test_accy 35.580
2022-05-25 00:17:09,557 [bic.py] => training => Task 7, Epoch 38/170 => Loss 2.702, Train_accy 85.160, Test_accy 35.760
2022-05-25 00:17:14,505 [bic.py] => training => Task 7, Epoch 39/170 => Loss 2.703, Train_accy 87.930, Test_accy 40.710
2022-05-25 00:17:19,318 [bic.py] => training => Task 7, Epoch 40/170 => Loss 2.697, Train_accy 88.780, Test_accy 42.300
2022-05-25 00:17:24,147 [bic.py] => training => Task 7, Epoch 41/170 => Loss 2.697, Train_accy 86.380, Test_accy 39.960
2022-05-25 00:17:29,029 [bic.py] => training => Task 7, Epoch 42/170 => Loss 2.709, Train_accy 89.260, Test_accy 40.110
2022-05-25 00:17:33,805 [bic.py] => training => Task 7, Epoch 43/170 => Loss 2.707, Train_accy 86.930, Test_accy 35.640
2022-05-25 00:17:38,613 [bic.py] => training => Task 7, Epoch 44/170 => Loss 2.700, Train_accy 90.790, Test_accy 39.290
2022-05-25 00:17:43,340 [bic.py] => training => Task 7, Epoch 45/170 => Loss 2.691, Train_accy 90.090, Test_accy 42.000
2022-05-25 00:17:48,063 [bic.py] => training => Task 7, Epoch 46/170 => Loss 2.689, Train_accy 90.870, Test_accy 40.330
2022-05-25 00:17:52,820 [bic.py] => training => Task 7, Epoch 47/170 => Loss 2.682, Train_accy 89.190, Test_accy 37.110
2022-05-25 00:17:57,466 [bic.py] => training => Task 7, Epoch 48/170 => Loss 2.687, Train_accy 91.910, Test_accy 40.100
2022-05-25 00:18:02,187 [bic.py] => training => Task 7, Epoch 49/170 => Loss 2.691, Train_accy 90.190, Test_accy 41.550
2022-05-25 00:18:06,945 [bic.py] => training => Task 7, Epoch 50/170 => Loss 2.691, Train_accy 89.250, Test_accy 40.480
2022-05-25 00:18:11,859 [bic.py] => training => Task 7, Epoch 51/170 => Loss 2.708, Train_accy 85.490, Test_accy 39.400
2022-05-25 00:18:16,661 [bic.py] => training => Task 7, Epoch 52/170 => Loss 2.738, Train_accy 89.400, Test_accy 42.210
2022-05-25 00:18:21,554 [bic.py] => training => Task 7, Epoch 53/170 => Loss 2.712, Train_accy 91.090, Test_accy 41.610
2022-05-25 00:18:26,291 [bic.py] => training => Task 7, Epoch 54/170 => Loss 2.699, Train_accy 92.530, Test_accy 41.420
2022-05-25 00:18:30,929 [bic.py] => training => Task 7, Epoch 55/170 => Loss 2.697, Train_accy 88.850, Test_accy 38.720
2022-05-25 00:18:35,580 [bic.py] => training => Task 7, Epoch 56/170 => Loss 2.720, Train_accy 87.510, Test_accy 38.950
2022-05-25 00:18:40,339 [bic.py] => training => Task 7, Epoch 57/170 => Loss 2.696, Train_accy 84.510, Test_accy 35.400
2022-05-25 00:18:45,025 [bic.py] => training => Task 7, Epoch 58/170 => Loss 2.705, Train_accy 87.650, Test_accy 39.850
2022-05-25 00:18:49,715 [bic.py] => training => Task 7, Epoch 59/170 => Loss 2.689, Train_accy 92.310, Test_accy 38.990
2022-05-25 00:18:54,397 [bic.py] => training => Task 7, Epoch 60/170 => Loss 2.677, Train_accy 90.880, Test_accy 40.460
2022-05-25 00:18:58,968 [bic.py] => training => Task 7, Epoch 61/170 => Loss 2.664, Train_accy 97.260, Test_accy 44.700
2022-05-25 00:19:03,521 [bic.py] => training => Task 7, Epoch 62/170 => Loss 2.652, Train_accy 97.340, Test_accy 44.860
2022-05-25 00:19:08,182 [bic.py] => training => Task 7, Epoch 63/170 => Loss 2.646, Train_accy 97.440, Test_accy 44.010
2022-05-25 00:19:12,892 [bic.py] => training => Task 7, Epoch 64/170 => Loss 2.649, Train_accy 97.710, Test_accy 44.180
2022-05-25 00:19:17,608 [bic.py] => training => Task 7, Epoch 65/170 => Loss 2.642, Train_accy 97.930, Test_accy 44.190
2022-05-25 00:19:22,326 [bic.py] => training => Task 7, Epoch 66/170 => Loss 2.641, Train_accy 97.900, Test_accy 43.990
2022-05-25 00:19:27,025 [bic.py] => training => Task 7, Epoch 67/170 => Loss 2.639, Train_accy 97.790, Test_accy 43.950
2022-05-25 00:19:31,738 [bic.py] => training => Task 7, Epoch 68/170 => Loss 2.641, Train_accy 97.840, Test_accy 44.300
2022-05-25 00:19:36,575 [bic.py] => training => Task 7, Epoch 69/170 => Loss 2.643, Train_accy 97.960, Test_accy 44.200
2022-05-25 00:19:41,300 [bic.py] => training => Task 7, Epoch 70/170 => Loss 2.639, Train_accy 97.910, Test_accy 43.880
2022-05-25 00:19:45,932 [bic.py] => training => Task 7, Epoch 71/170 => Loss 2.637, Train_accy 98.180, Test_accy 44.160
2022-05-25 00:19:50,624 [bic.py] => training => Task 7, Epoch 72/170 => Loss 2.636, Train_accy 98.060, Test_accy 44.240
2022-05-25 00:19:55,191 [bic.py] => training => Task 7, Epoch 73/170 => Loss 2.639, Train_accy 97.960, Test_accy 43.780
2022-05-25 00:19:59,847 [bic.py] => training => Task 7, Epoch 74/170 => Loss 2.632, Train_accy 97.940, Test_accy 44.860
2022-05-25 00:20:04,530 [bic.py] => training => Task 7, Epoch 75/170 => Loss 2.637, Train_accy 98.260, Test_accy 44.320
2022-05-25 00:20:09,174 [bic.py] => training => Task 7, Epoch 76/170 => Loss 2.633, Train_accy 98.400, Test_accy 44.100
2022-05-25 00:20:13,858 [bic.py] => training => Task 7, Epoch 77/170 => Loss 2.637, Train_accy 98.340, Test_accy 44.580
2022-05-25 00:20:18,573 [bic.py] => training => Task 7, Epoch 78/170 => Loss 2.632, Train_accy 98.150, Test_accy 43.850
2022-05-25 00:20:23,210 [bic.py] => training => Task 7, Epoch 79/170 => Loss 2.641, Train_accy 98.250, Test_accy 43.690
2022-05-25 00:20:27,877 [bic.py] => training => Task 7, Epoch 80/170 => Loss 2.640, Train_accy 98.280, Test_accy 43.790
2022-05-25 00:20:32,509 [bic.py] => training => Task 7, Epoch 81/170 => Loss 2.640, Train_accy 98.370, Test_accy 44.280
2022-05-25 00:20:37,114 [bic.py] => training => Task 7, Epoch 82/170 => Loss 2.633, Train_accy 98.120, Test_accy 43.850
2022-05-25 00:20:41,730 [bic.py] => training => Task 7, Epoch 83/170 => Loss 2.633, Train_accy 98.280, Test_accy 43.910
2022-05-25 00:20:46,386 [bic.py] => training => Task 7, Epoch 84/170 => Loss 2.626, Train_accy 98.280, Test_accy 43.660
2022-05-25 00:20:51,171 [bic.py] => training => Task 7, Epoch 85/170 => Loss 2.633, Train_accy 98.490, Test_accy 44.100
2022-05-25 00:20:55,974 [bic.py] => training => Task 7, Epoch 86/170 => Loss 2.630, Train_accy 98.340, Test_accy 44.360
2022-05-25 00:21:00,646 [bic.py] => training => Task 7, Epoch 87/170 => Loss 2.640, Train_accy 98.660, Test_accy 45.040
2022-05-25 00:21:05,310 [bic.py] => training => Task 7, Epoch 88/170 => Loss 2.632, Train_accy 98.490, Test_accy 44.550
2022-05-25 00:21:10,009 [bic.py] => training => Task 7, Epoch 89/170 => Loss 2.634, Train_accy 98.430, Test_accy 43.910
2022-05-25 00:21:14,753 [bic.py] => training => Task 7, Epoch 90/170 => Loss 2.635, Train_accy 98.740, Test_accy 44.410
2022-05-25 00:21:19,404 [bic.py] => training => Task 7, Epoch 91/170 => Loss 2.638, Train_accy 98.340, Test_accy 44.080
2022-05-25 00:21:23,975 [bic.py] => training => Task 7, Epoch 92/170 => Loss 2.638, Train_accy 98.680, Test_accy 44.590
2022-05-25 00:21:28,700 [bic.py] => training => Task 7, Epoch 93/170 => Loss 2.635, Train_accy 98.590, Test_accy 44.060
2022-05-25 00:21:33,356 [bic.py] => training => Task 7, Epoch 94/170 => Loss 2.631, Train_accy 98.560, Test_accy 44.580
2022-05-25 00:21:38,051 [bic.py] => training => Task 7, Epoch 95/170 => Loss 2.635, Train_accy 98.530, Test_accy 44.820
2022-05-25 00:21:42,647 [bic.py] => training => Task 7, Epoch 96/170 => Loss 2.633, Train_accy 98.570, Test_accy 44.250
2022-05-25 00:21:47,364 [bic.py] => training => Task 7, Epoch 97/170 => Loss 2.631, Train_accy 98.590, Test_accy 43.950
2022-05-25 00:21:52,024 [bic.py] => training => Task 7, Epoch 98/170 => Loss 2.635, Train_accy 98.650, Test_accy 44.000
2022-05-25 00:21:56,736 [bic.py] => training => Task 7, Epoch 99/170 => Loss 2.628, Train_accy 98.570, Test_accy 44.390
2022-05-25 00:22:01,470 [bic.py] => training => Task 7, Epoch 100/170 => Loss 2.638, Train_accy 98.750, Test_accy 44.460
2022-05-25 00:22:06,150 [bic.py] => training => Task 7, Epoch 101/170 => Loss 2.629, Train_accy 98.720, Test_accy 43.940
2022-05-25 00:22:10,817 [bic.py] => training => Task 7, Epoch 102/170 => Loss 2.631, Train_accy 98.710, Test_accy 44.660
2022-05-25 00:22:15,485 [bic.py] => training => Task 7, Epoch 103/170 => Loss 2.630, Train_accy 98.540, Test_accy 44.450
2022-05-25 00:22:20,177 [bic.py] => training => Task 7, Epoch 104/170 => Loss 2.628, Train_accy 98.540, Test_accy 44.100
2022-05-25 00:22:24,882 [bic.py] => training => Task 7, Epoch 105/170 => Loss 2.631, Train_accy 98.810, Test_accy 44.400
2022-05-25 00:22:29,530 [bic.py] => training => Task 7, Epoch 106/170 => Loss 2.626, Train_accy 98.780, Test_accy 44.320
2022-05-25 00:22:34,236 [bic.py] => training => Task 7, Epoch 107/170 => Loss 2.627, Train_accy 98.760, Test_accy 43.880
2022-05-25 00:22:38,879 [bic.py] => training => Task 7, Epoch 108/170 => Loss 2.626, Train_accy 98.650, Test_accy 44.240
2022-05-25 00:22:43,531 [bic.py] => training => Task 7, Epoch 109/170 => Loss 2.633, Train_accy 98.760, Test_accy 44.840
2022-05-25 00:22:48,253 [bic.py] => training => Task 7, Epoch 110/170 => Loss 2.634, Train_accy 99.000, Test_accy 44.880
2022-05-25 00:22:52,940 [bic.py] => training => Task 7, Epoch 111/170 => Loss 2.625, Train_accy 98.850, Test_accy 44.400
2022-05-25 00:22:57,668 [bic.py] => training => Task 7, Epoch 112/170 => Loss 2.629, Train_accy 98.660, Test_accy 43.910
2022-05-25 00:23:02,454 [bic.py] => training => Task 7, Epoch 113/170 => Loss 2.635, Train_accy 98.650, Test_accy 44.290
2022-05-25 00:23:07,108 [bic.py] => training => Task 7, Epoch 114/170 => Loss 2.629, Train_accy 98.760, Test_accy 43.840
2022-05-25 00:23:11,840 [bic.py] => training => Task 7, Epoch 115/170 => Loss 2.627, Train_accy 98.900, Test_accy 44.410
2022-05-25 00:23:16,523 [bic.py] => training => Task 7, Epoch 116/170 => Loss 2.630, Train_accy 98.750, Test_accy 44.300
2022-05-25 00:23:21,234 [bic.py] => training => Task 7, Epoch 117/170 => Loss 2.630, Train_accy 98.720, Test_accy 44.590
2022-05-25 00:23:26,005 [bic.py] => training => Task 7, Epoch 118/170 => Loss 2.631, Train_accy 98.710, Test_accy 45.050
2022-05-25 00:23:30,722 [bic.py] => training => Task 7, Epoch 119/170 => Loss 2.630, Train_accy 98.750, Test_accy 44.640
2022-05-25 00:23:35,369 [bic.py] => training => Task 7, Epoch 120/170 => Loss 2.622, Train_accy 98.680, Test_accy 44.210
2022-05-25 00:23:40,116 [bic.py] => training => Task 7, Epoch 121/170 => Loss 2.624, Train_accy 98.820, Test_accy 44.900
2022-05-25 00:23:44,818 [bic.py] => training => Task 7, Epoch 122/170 => Loss 2.629, Train_accy 98.910, Test_accy 44.400
2022-05-25 00:23:49,518 [bic.py] => training => Task 7, Epoch 123/170 => Loss 2.633, Train_accy 98.690, Test_accy 44.780
2022-05-25 00:23:54,168 [bic.py] => training => Task 7, Epoch 124/170 => Loss 2.629, Train_accy 98.590, Test_accy 44.420
2022-05-25 00:23:58,855 [bic.py] => training => Task 7, Epoch 125/170 => Loss 2.634, Train_accy 98.820, Test_accy 44.310
2022-05-25 00:24:03,566 [bic.py] => training => Task 7, Epoch 126/170 => Loss 2.629, Train_accy 98.820, Test_accy 44.040
2022-05-25 00:24:08,337 [bic.py] => training => Task 7, Epoch 127/170 => Loss 2.635, Train_accy 98.660, Test_accy 44.620
2022-05-25 00:24:13,056 [bic.py] => training => Task 7, Epoch 128/170 => Loss 2.624, Train_accy 98.710, Test_accy 44.360
2022-05-25 00:24:17,743 [bic.py] => training => Task 7, Epoch 129/170 => Loss 2.631, Train_accy 98.810, Test_accy 44.180
2022-05-25 00:24:22,417 [bic.py] => training => Task 7, Epoch 130/170 => Loss 2.630, Train_accy 98.790, Test_accy 44.450
2022-05-25 00:24:27,120 [bic.py] => training => Task 7, Epoch 131/170 => Loss 2.632, Train_accy 98.870, Test_accy 44.120
2022-05-25 00:24:31,579 [bic.py] => training => Task 7, Epoch 132/170 => Loss 2.628, Train_accy 98.750, Test_accy 44.150
2022-05-25 00:24:36,264 [bic.py] => training => Task 7, Epoch 133/170 => Loss 2.631, Train_accy 98.630, Test_accy 44.360
2022-05-25 00:24:40,832 [bic.py] => training => Task 7, Epoch 134/170 => Loss 2.628, Train_accy 98.690, Test_accy 44.210
2022-05-25 00:24:45,540 [bic.py] => training => Task 7, Epoch 135/170 => Loss 2.627, Train_accy 98.810, Test_accy 44.720
2022-05-25 00:24:50,211 [bic.py] => training => Task 7, Epoch 136/170 => Loss 2.635, Train_accy 98.960, Test_accy 44.750
2022-05-25 00:24:54,882 [bic.py] => training => Task 7, Epoch 137/170 => Loss 2.625, Train_accy 98.590, Test_accy 43.840
2022-05-25 00:24:59,398 [bic.py] => training => Task 7, Epoch 138/170 => Loss 2.632, Train_accy 98.940, Test_accy 44.310
2022-05-25 00:25:04,014 [bic.py] => training => Task 7, Epoch 139/170 => Loss 2.634, Train_accy 98.850, Test_accy 44.080
2022-05-25 00:25:08,680 [bic.py] => training => Task 7, Epoch 140/170 => Loss 2.632, Train_accy 98.930, Test_accy 44.720
2022-05-25 00:25:13,275 [bic.py] => training => Task 7, Epoch 141/170 => Loss 2.627, Train_accy 98.750, Test_accy 44.550
2022-05-25 00:25:17,926 [bic.py] => training => Task 7, Epoch 142/170 => Loss 2.627, Train_accy 98.780, Test_accy 43.850
2022-05-25 00:25:22,624 [bic.py] => training => Task 7, Epoch 143/170 => Loss 2.628, Train_accy 98.760, Test_accy 43.660
2022-05-25 00:25:27,351 [bic.py] => training => Task 7, Epoch 144/170 => Loss 2.624, Train_accy 98.910, Test_accy 44.660
2022-05-25 00:25:32,038 [bic.py] => training => Task 7, Epoch 145/170 => Loss 2.624, Train_accy 99.120, Test_accy 44.520
2022-05-25 00:25:36,665 [bic.py] => training => Task 7, Epoch 146/170 => Loss 2.632, Train_accy 98.710, Test_accy 43.890
2022-05-25 00:25:41,361 [bic.py] => training => Task 7, Epoch 147/170 => Loss 2.621, Train_accy 98.720, Test_accy 43.880
2022-05-25 00:25:46,023 [bic.py] => training => Task 7, Epoch 148/170 => Loss 2.627, Train_accy 98.810, Test_accy 44.520
2022-05-25 00:25:50,783 [bic.py] => training => Task 7, Epoch 149/170 => Loss 2.624, Train_accy 98.720, Test_accy 44.420
2022-05-25 00:25:55,489 [bic.py] => training => Task 7, Epoch 150/170 => Loss 2.634, Train_accy 98.750, Test_accy 44.140
2022-05-25 00:26:00,179 [bic.py] => training => Task 7, Epoch 151/170 => Loss 2.628, Train_accy 98.820, Test_accy 44.300
2022-05-25 00:26:04,827 [bic.py] => training => Task 7, Epoch 152/170 => Loss 2.625, Train_accy 98.690, Test_accy 43.980
2022-05-25 00:26:09,582 [bic.py] => training => Task 7, Epoch 153/170 => Loss 2.632, Train_accy 98.840, Test_accy 43.900
2022-05-25 00:26:14,299 [bic.py] => training => Task 7, Epoch 154/170 => Loss 2.621, Train_accy 98.740, Test_accy 44.640
2022-05-25 00:26:18,965 [bic.py] => training => Task 7, Epoch 155/170 => Loss 2.629, Train_accy 98.900, Test_accy 44.140
2022-05-25 00:26:23,689 [bic.py] => training => Task 7, Epoch 156/170 => Loss 2.623, Train_accy 98.720, Test_accy 44.510
2022-05-25 00:26:28,385 [bic.py] => training => Task 7, Epoch 157/170 => Loss 2.628, Train_accy 98.780, Test_accy 44.410
2022-05-25 00:26:33,087 [bic.py] => training => Task 7, Epoch 158/170 => Loss 2.626, Train_accy 98.850, Test_accy 44.660
2022-05-25 00:26:37,777 [bic.py] => training => Task 7, Epoch 159/170 => Loss 2.630, Train_accy 98.790, Test_accy 44.510
2022-05-25 00:26:42,472 [bic.py] => training => Task 7, Epoch 160/170 => Loss 2.631, Train_accy 98.880, Test_accy 44.620
2022-05-25 00:26:47,223 [bic.py] => training => Task 7, Epoch 161/170 => Loss 2.630, Train_accy 98.720, Test_accy 44.660
2022-05-25 00:26:51,894 [bic.py] => training => Task 7, Epoch 162/170 => Loss 2.626, Train_accy 98.930, Test_accy 43.920
2022-05-25 00:26:56,546 [bic.py] => training => Task 7, Epoch 163/170 => Loss 2.626, Train_accy 98.880, Test_accy 44.900
2022-05-25 00:27:01,278 [bic.py] => training => Task 7, Epoch 164/170 => Loss 2.629, Train_accy 98.840, Test_accy 44.280
2022-05-25 00:27:05,860 [bic.py] => training => Task 7, Epoch 165/170 => Loss 2.630, Train_accy 98.750, Test_accy 44.520
2022-05-25 00:27:10,643 [bic.py] => training => Task 7, Epoch 166/170 => Loss 2.632, Train_accy 98.740, Test_accy 44.150
2022-05-25 00:27:15,378 [bic.py] => training => Task 7, Epoch 167/170 => Loss 2.626, Train_accy 98.850, Test_accy 44.400
2022-05-25 00:27:20,116 [bic.py] => training => Task 7, Epoch 168/170 => Loss 2.626, Train_accy 98.780, Test_accy 44.360
2022-05-25 00:27:24,822 [bic.py] => training => Task 7, Epoch 169/170 => Loss 2.634, Train_accy 98.760, Test_accy 44.490
2022-05-25 00:27:29,550 [bic.py] => training => Task 7, Epoch 170/170 => Loss 2.635, Train_accy 98.750, Test_accy 44.280
2022-05-25 00:27:31,409 [bic.py] => bias_correction => Task 7, Epoch 1/170 => Loss 3.981, Train_accy 63.750, Test_accy 46.410
2022-05-25 00:27:33,334 [bic.py] => bias_correction => Task 7, Epoch 2/170 => Loss 3.918, Train_accy 77.500, Test_accy 51.490
2022-05-25 00:27:35,231 [bic.py] => bias_correction => Task 7, Epoch 3/170 => Loss 3.866, Train_accy 76.880, Test_accy 50.740
2022-05-25 00:27:37,007 [bic.py] => bias_correction => Task 7, Epoch 4/170 => Loss 3.860, Train_accy 75.000, Test_accy 48.080
2022-05-25 00:27:38,910 [bic.py] => bias_correction => Task 7, Epoch 5/170 => Loss 3.810, Train_accy 75.620, Test_accy 47.690
2022-05-25 00:27:40,750 [bic.py] => bias_correction => Task 7, Epoch 6/170 => Loss 3.839, Train_accy 75.620, Test_accy 47.590
2022-05-25 00:27:42,594 [bic.py] => bias_correction => Task 7, Epoch 7/170 => Loss 3.855, Train_accy 76.880, Test_accy 47.490
2022-05-25 00:27:44,494 [bic.py] => bias_correction => Task 7, Epoch 8/170 => Loss 3.805, Train_accy 72.500, Test_accy 47.480
2022-05-25 00:27:46,445 [bic.py] => bias_correction => Task 7, Epoch 9/170 => Loss 3.840, Train_accy 76.250, Test_accy 47.480
2022-05-25 00:27:48,311 [bic.py] => bias_correction => Task 7, Epoch 10/170 => Loss 3.809, Train_accy 76.880, Test_accy 47.320
2022-05-25 00:27:50,196 [bic.py] => bias_correction => Task 7, Epoch 11/170 => Loss 3.843, Train_accy 73.120, Test_accy 47.380
2022-05-25 00:27:52,048 [bic.py] => bias_correction => Task 7, Epoch 12/170 => Loss 3.823, Train_accy 73.750, Test_accy 47.390
2022-05-25 00:27:54,013 [bic.py] => bias_correction => Task 7, Epoch 13/170 => Loss 3.842, Train_accy 73.120, Test_accy 47.420
2022-05-25 00:27:55,816 [bic.py] => bias_correction => Task 7, Epoch 14/170 => Loss 3.820, Train_accy 76.250, Test_accy 47.410
2022-05-25 00:27:57,636 [bic.py] => bias_correction => Task 7, Epoch 15/170 => Loss 3.808, Train_accy 75.000, Test_accy 47.340
2022-05-25 00:27:59,585 [bic.py] => bias_correction => Task 7, Epoch 16/170 => Loss 3.837, Train_accy 73.750, Test_accy 47.300
2022-05-25 00:28:01,487 [bic.py] => bias_correction => Task 7, Epoch 17/170 => Loss 3.886, Train_accy 73.750, Test_accy 47.390
2022-05-25 00:28:03,330 [bic.py] => bias_correction => Task 7, Epoch 18/170 => Loss 3.818, Train_accy 71.880, Test_accy 47.310
2022-05-25 00:28:05,123 [bic.py] => bias_correction => Task 7, Epoch 19/170 => Loss 3.822, Train_accy 72.500, Test_accy 47.220
2022-05-25 00:28:06,994 [bic.py] => bias_correction => Task 7, Epoch 20/170 => Loss 3.890, Train_accy 72.500, Test_accy 47.260
2022-05-25 00:28:08,822 [bic.py] => bias_correction => Task 7, Epoch 21/170 => Loss 3.840, Train_accy 74.380, Test_accy 47.260
2022-05-25 00:28:10,674 [bic.py] => bias_correction => Task 7, Epoch 22/170 => Loss 3.834, Train_accy 74.380, Test_accy 47.180
2022-05-25 00:28:12,541 [bic.py] => bias_correction => Task 7, Epoch 23/170 => Loss 3.856, Train_accy 73.750, Test_accy 47.020
2022-05-25 00:28:14,445 [bic.py] => bias_correction => Task 7, Epoch 24/170 => Loss 3.819, Train_accy 73.750, Test_accy 46.920
2022-05-25 00:28:16,283 [bic.py] => bias_correction => Task 7, Epoch 25/170 => Loss 3.841, Train_accy 71.250, Test_accy 47.080
2022-05-25 00:28:18,127 [bic.py] => bias_correction => Task 7, Epoch 26/170 => Loss 3.803, Train_accy 76.880, Test_accy 47.090
2022-05-25 00:28:19,948 [bic.py] => bias_correction => Task 7, Epoch 27/170 => Loss 3.820, Train_accy 75.620, Test_accy 46.980
2022-05-25 00:28:21,761 [bic.py] => bias_correction => Task 7, Epoch 28/170 => Loss 3.802, Train_accy 75.620, Test_accy 46.880
2022-05-25 00:28:23,671 [bic.py] => bias_correction => Task 7, Epoch 29/170 => Loss 3.830, Train_accy 72.500, Test_accy 47.240
2022-05-25 00:28:25,638 [bic.py] => bias_correction => Task 7, Epoch 30/170 => Loss 3.824, Train_accy 73.120, Test_accy 47.150
2022-05-25 00:28:27,549 [bic.py] => bias_correction => Task 7, Epoch 31/170 => Loss 3.880, Train_accy 73.120, Test_accy 47.090
2022-05-25 00:28:29,468 [bic.py] => bias_correction => Task 7, Epoch 32/170 => Loss 3.853, Train_accy 78.120, Test_accy 47.280
2022-05-25 00:28:31,376 [bic.py] => bias_correction => Task 7, Epoch 33/170 => Loss 3.801, Train_accy 74.380, Test_accy 47.180
2022-05-25 00:28:33,220 [bic.py] => bias_correction => Task 7, Epoch 34/170 => Loss 3.835, Train_accy 75.620, Test_accy 47.150
2022-05-25 00:28:35,039 [bic.py] => bias_correction => Task 7, Epoch 35/170 => Loss 3.833, Train_accy 70.620, Test_accy 47.220
2022-05-25 00:28:36,912 [bic.py] => bias_correction => Task 7, Epoch 36/170 => Loss 3.882, Train_accy 73.120, Test_accy 47.060
2022-05-25 00:28:38,815 [bic.py] => bias_correction => Task 7, Epoch 37/170 => Loss 3.825, Train_accy 76.250, Test_accy 47.200
2022-05-25 00:28:40,664 [bic.py] => bias_correction => Task 7, Epoch 38/170 => Loss 3.826, Train_accy 73.120, Test_accy 47.120
2022-05-25 00:28:42,503 [bic.py] => bias_correction => Task 7, Epoch 39/170 => Loss 3.843, Train_accy 75.620, Test_accy 47.140
2022-05-25 00:28:44,349 [bic.py] => bias_correction => Task 7, Epoch 40/170 => Loss 3.835, Train_accy 78.120, Test_accy 47.020
2022-05-25 00:28:46,212 [bic.py] => bias_correction => Task 7, Epoch 41/170 => Loss 3.811, Train_accy 73.750, Test_accy 46.990
2022-05-25 00:28:48,060 [bic.py] => bias_correction => Task 7, Epoch 42/170 => Loss 3.842, Train_accy 75.620, Test_accy 47.110
2022-05-25 00:28:49,901 [bic.py] => bias_correction => Task 7, Epoch 43/170 => Loss 3.819, Train_accy 75.620, Test_accy 46.980
2022-05-25 00:28:51,830 [bic.py] => bias_correction => Task 7, Epoch 44/170 => Loss 3.860, Train_accy 75.620, Test_accy 47.020
2022-05-25 00:28:53,716 [bic.py] => bias_correction => Task 7, Epoch 45/170 => Loss 3.855, Train_accy 73.750, Test_accy 47.180
2022-05-25 00:28:55,586 [bic.py] => bias_correction => Task 7, Epoch 46/170 => Loss 3.829, Train_accy 73.750, Test_accy 46.920
2022-05-25 00:28:57,425 [bic.py] => bias_correction => Task 7, Epoch 47/170 => Loss 3.835, Train_accy 74.380, Test_accy 46.890
2022-05-25 00:28:59,322 [bic.py] => bias_correction => Task 7, Epoch 48/170 => Loss 3.813, Train_accy 75.620, Test_accy 46.840
2022-05-25 00:29:01,147 [bic.py] => bias_correction => Task 7, Epoch 49/170 => Loss 3.844, Train_accy 76.250, Test_accy 47.020
2022-05-25 00:29:03,063 [bic.py] => bias_correction => Task 7, Epoch 50/170 => Loss 3.852, Train_accy 73.120, Test_accy 47.120
2022-05-25 00:29:04,924 [bic.py] => bias_correction => Task 7, Epoch 51/170 => Loss 3.813, Train_accy 73.120, Test_accy 46.920
2022-05-25 00:29:06,723 [bic.py] => bias_correction => Task 7, Epoch 52/170 => Loss 3.895, Train_accy 75.000, Test_accy 47.020
2022-05-25 00:29:08,564 [bic.py] => bias_correction => Task 7, Epoch 53/170 => Loss 3.863, Train_accy 73.120, Test_accy 46.890
2022-05-25 00:29:10,555 [bic.py] => bias_correction => Task 7, Epoch 54/170 => Loss 3.880, Train_accy 75.620, Test_accy 47.000
2022-05-25 00:29:12,359 [bic.py] => bias_correction => Task 7, Epoch 55/170 => Loss 3.827, Train_accy 74.380, Test_accy 46.920
2022-05-25 00:29:14,201 [bic.py] => bias_correction => Task 7, Epoch 56/170 => Loss 3.834, Train_accy 75.620, Test_accy 46.880
2022-05-25 00:29:16,091 [bic.py] => bias_correction => Task 7, Epoch 57/170 => Loss 3.864, Train_accy 73.750, Test_accy 47.040
2022-05-25 00:29:17,917 [bic.py] => bias_correction => Task 7, Epoch 58/170 => Loss 3.826, Train_accy 74.380, Test_accy 46.880
2022-05-25 00:29:19,806 [bic.py] => bias_correction => Task 7, Epoch 59/170 => Loss 3.830, Train_accy 75.000, Test_accy 47.120
2022-05-25 00:29:21,730 [bic.py] => bias_correction => Task 7, Epoch 60/170 => Loss 3.864, Train_accy 72.500, Test_accy 46.880
2022-05-25 00:29:23,648 [bic.py] => bias_correction => Task 7, Epoch 61/170 => Loss 3.853, Train_accy 72.500, Test_accy 47.020
2022-05-25 00:29:25,639 [bic.py] => bias_correction => Task 7, Epoch 62/170 => Loss 3.867, Train_accy 73.750, Test_accy 47.110
2022-05-25 00:29:27,692 [bic.py] => bias_correction => Task 7, Epoch 63/170 => Loss 3.833, Train_accy 71.880, Test_accy 47.210
2022-05-25 00:29:29,771 [bic.py] => bias_correction => Task 7, Epoch 64/170 => Loss 3.813, Train_accy 70.620, Test_accy 47.080
2022-05-25 00:29:31,803 [bic.py] => bias_correction => Task 7, Epoch 65/170 => Loss 3.813, Train_accy 74.380, Test_accy 46.960
2022-05-25 00:29:33,749 [bic.py] => bias_correction => Task 7, Epoch 66/170 => Loss 3.838, Train_accy 75.000, Test_accy 47.100
2022-05-25 00:29:35,695 [bic.py] => bias_correction => Task 7, Epoch 67/170 => Loss 3.817, Train_accy 73.120, Test_accy 47.020
2022-05-25 00:29:37,666 [bic.py] => bias_correction => Task 7, Epoch 68/170 => Loss 3.801, Train_accy 73.120, Test_accy 46.990
2022-05-25 00:29:39,690 [bic.py] => bias_correction => Task 7, Epoch 69/170 => Loss 3.848, Train_accy 74.380, Test_accy 46.820
2022-05-25 00:29:41,723 [bic.py] => bias_correction => Task 7, Epoch 70/170 => Loss 3.839, Train_accy 77.500, Test_accy 46.800
2022-05-25 00:29:43,809 [bic.py] => bias_correction => Task 7, Epoch 71/170 => Loss 3.863, Train_accy 76.880, Test_accy 46.790
2022-05-25 00:29:45,772 [bic.py] => bias_correction => Task 7, Epoch 72/170 => Loss 3.851, Train_accy 76.250, Test_accy 46.700
2022-05-25 00:29:47,723 [bic.py] => bias_correction => Task 7, Epoch 73/170 => Loss 3.828, Train_accy 73.750, Test_accy 46.710
2022-05-25 00:29:49,611 [bic.py] => bias_correction => Task 7, Epoch 74/170 => Loss 3.823, Train_accy 76.880, Test_accy 46.720
2022-05-25 00:29:51,430 [bic.py] => bias_correction => Task 7, Epoch 75/170 => Loss 3.800, Train_accy 76.880, Test_accy 46.790
2022-05-25 00:29:53,294 [bic.py] => bias_correction => Task 7, Epoch 76/170 => Loss 3.856, Train_accy 75.000, Test_accy 46.810
2022-05-25 00:29:55,121 [bic.py] => bias_correction => Task 7, Epoch 77/170 => Loss 3.836, Train_accy 75.000, Test_accy 46.940
2022-05-25 00:29:57,017 [bic.py] => bias_correction => Task 7, Epoch 78/170 => Loss 3.859, Train_accy 74.380, Test_accy 47.050
2022-05-25 00:29:58,901 [bic.py] => bias_correction => Task 7, Epoch 79/170 => Loss 3.823, Train_accy 72.500, Test_accy 46.890
2022-05-25 00:30:00,799 [bic.py] => bias_correction => Task 7, Epoch 80/170 => Loss 3.794, Train_accy 73.120, Test_accy 46.680
2022-05-25 00:30:02,659 [bic.py] => bias_correction => Task 7, Epoch 81/170 => Loss 3.844, Train_accy 75.620, Test_accy 46.810
2022-05-25 00:30:04,444 [bic.py] => bias_correction => Task 7, Epoch 82/170 => Loss 3.816, Train_accy 73.750, Test_accy 46.680
2022-05-25 00:30:06,278 [bic.py] => bias_correction => Task 7, Epoch 83/170 => Loss 3.819, Train_accy 74.380, Test_accy 46.920
2022-05-25 00:30:08,143 [bic.py] => bias_correction => Task 7, Epoch 84/170 => Loss 3.833, Train_accy 75.000, Test_accy 46.890
2022-05-25 00:30:10,017 [bic.py] => bias_correction => Task 7, Epoch 85/170 => Loss 3.809, Train_accy 74.380, Test_accy 46.800
2022-05-25 00:30:11,924 [bic.py] => bias_correction => Task 7, Epoch 86/170 => Loss 3.817, Train_accy 75.000, Test_accy 46.800
2022-05-25 00:30:13,809 [bic.py] => bias_correction => Task 7, Epoch 87/170 => Loss 3.857, Train_accy 78.120, Test_accy 47.000
2022-05-25 00:30:15,692 [bic.py] => bias_correction => Task 7, Epoch 88/170 => Loss 3.808, Train_accy 75.620, Test_accy 47.020
2022-05-25 00:30:17,508 [bic.py] => bias_correction => Task 7, Epoch 89/170 => Loss 3.803, Train_accy 75.000, Test_accy 46.960
2022-05-25 00:30:19,370 [bic.py] => bias_correction => Task 7, Epoch 90/170 => Loss 3.848, Train_accy 75.000, Test_accy 47.010
2022-05-25 00:30:21,225 [bic.py] => bias_correction => Task 7, Epoch 91/170 => Loss 3.853, Train_accy 74.380, Test_accy 47.250
2022-05-25 00:30:23,138 [bic.py] => bias_correction => Task 7, Epoch 92/170 => Loss 3.859, Train_accy 73.750, Test_accy 46.980
2022-05-25 00:30:25,064 [bic.py] => bias_correction => Task 7, Epoch 93/170 => Loss 3.866, Train_accy 76.250, Test_accy 47.040
2022-05-25 00:30:26,886 [bic.py] => bias_correction => Task 7, Epoch 94/170 => Loss 3.848, Train_accy 74.380, Test_accy 47.000
2022-05-25 00:30:28,748 [bic.py] => bias_correction => Task 7, Epoch 95/170 => Loss 3.853, Train_accy 76.250, Test_accy 47.150
2022-05-25 00:30:30,498 [bic.py] => bias_correction => Task 7, Epoch 96/170 => Loss 3.844, Train_accy 76.250, Test_accy 47.220
2022-05-25 00:30:32,342 [bic.py] => bias_correction => Task 7, Epoch 97/170 => Loss 3.839, Train_accy 70.620, Test_accy 47.200
2022-05-25 00:30:34,213 [bic.py] => bias_correction => Task 7, Epoch 98/170 => Loss 3.822, Train_accy 72.500, Test_accy 47.250
2022-05-25 00:30:36,106 [bic.py] => bias_correction => Task 7, Epoch 99/170 => Loss 3.863, Train_accy 75.000, Test_accy 47.220
2022-05-25 00:30:38,098 [bic.py] => bias_correction => Task 7, Epoch 100/170 => Loss 3.886, Train_accy 73.750, Test_accy 47.080
2022-05-25 00:30:40,069 [bic.py] => bias_correction => Task 7, Epoch 101/170 => Loss 3.858, Train_accy 76.250, Test_accy 47.020
2022-05-25 00:30:41,995 [bic.py] => bias_correction => Task 7, Epoch 102/170 => Loss 3.850, Train_accy 72.500, Test_accy 47.040
2022-05-25 00:30:44,033 [bic.py] => bias_correction => Task 7, Epoch 103/170 => Loss 3.806, Train_accy 75.620, Test_accy 47.160
2022-05-25 00:30:45,990 [bic.py] => bias_correction => Task 7, Epoch 104/170 => Loss 3.839, Train_accy 75.000, Test_accy 47.060
2022-05-25 00:30:47,957 [bic.py] => bias_correction => Task 7, Epoch 105/170 => Loss 3.828, Train_accy 75.620, Test_accy 47.100
2022-05-25 00:30:49,942 [bic.py] => bias_correction => Task 7, Epoch 106/170 => Loss 3.848, Train_accy 76.880, Test_accy 47.090
2022-05-25 00:30:51,924 [bic.py] => bias_correction => Task 7, Epoch 107/170 => Loss 3.812, Train_accy 73.120, Test_accy 46.990
2022-05-25 00:30:53,925 [bic.py] => bias_correction => Task 7, Epoch 108/170 => Loss 3.832, Train_accy 75.000, Test_accy 47.040
2022-05-25 00:30:55,887 [bic.py] => bias_correction => Task 7, Epoch 109/170 => Loss 3.801, Train_accy 75.620, Test_accy 47.010
2022-05-25 00:30:57,895 [bic.py] => bias_correction => Task 7, Epoch 110/170 => Loss 3.825, Train_accy 75.000, Test_accy 47.180
2022-05-25 00:30:59,863 [bic.py] => bias_correction => Task 7, Epoch 111/170 => Loss 3.867, Train_accy 73.120, Test_accy 47.210
2022-05-25 00:31:01,745 [bic.py] => bias_correction => Task 7, Epoch 112/170 => Loss 3.821, Train_accy 76.250, Test_accy 47.100
2022-05-25 00:31:03,540 [bic.py] => bias_correction => Task 7, Epoch 113/170 => Loss 3.789, Train_accy 78.120, Test_accy 47.110
2022-05-25 00:31:05,470 [bic.py] => bias_correction => Task 7, Epoch 114/170 => Loss 3.866, Train_accy 73.750, Test_accy 47.220
2022-05-25 00:31:07,353 [bic.py] => bias_correction => Task 7, Epoch 115/170 => Loss 3.830, Train_accy 76.250, Test_accy 47.190
2022-05-25 00:31:09,297 [bic.py] => bias_correction => Task 7, Epoch 116/170 => Loss 3.866, Train_accy 72.500, Test_accy 47.050
2022-05-25 00:31:11,154 [bic.py] => bias_correction => Task 7, Epoch 117/170 => Loss 3.812, Train_accy 75.000, Test_accy 47.160
2022-05-25 00:31:13,046 [bic.py] => bias_correction => Task 7, Epoch 118/170 => Loss 3.824, Train_accy 74.380, Test_accy 47.190
2022-05-25 00:31:14,971 [bic.py] => bias_correction => Task 7, Epoch 119/170 => Loss 3.830, Train_accy 75.000, Test_accy 47.240
2022-05-25 00:31:16,852 [bic.py] => bias_correction => Task 7, Epoch 120/170 => Loss 3.826, Train_accy 76.880, Test_accy 47.220
2022-05-25 00:31:18,751 [bic.py] => bias_correction => Task 7, Epoch 121/170 => Loss 3.851, Train_accy 73.750, Test_accy 47.350
2022-05-25 00:31:20,607 [bic.py] => bias_correction => Task 7, Epoch 122/170 => Loss 3.847, Train_accy 76.250, Test_accy 47.560
2022-05-25 00:31:22,488 [bic.py] => bias_correction => Task 7, Epoch 123/170 => Loss 3.844, Train_accy 73.120, Test_accy 47.450
2022-05-25 00:31:24,359 [bic.py] => bias_correction => Task 7, Epoch 124/170 => Loss 3.835, Train_accy 72.500, Test_accy 47.580
2022-05-25 00:31:26,244 [bic.py] => bias_correction => Task 7, Epoch 125/170 => Loss 3.850, Train_accy 75.000, Test_accy 47.340
2022-05-25 00:31:28,080 [bic.py] => bias_correction => Task 7, Epoch 126/170 => Loss 3.796, Train_accy 76.250, Test_accy 47.220
2022-05-25 00:31:29,924 [bic.py] => bias_correction => Task 7, Epoch 127/170 => Loss 3.831, Train_accy 74.380, Test_accy 47.010
2022-05-25 00:31:31,743 [bic.py] => bias_correction => Task 7, Epoch 128/170 => Loss 3.818, Train_accy 73.750, Test_accy 47.140
2022-05-25 00:31:33,660 [bic.py] => bias_correction => Task 7, Epoch 129/170 => Loss 3.851, Train_accy 73.750, Test_accy 47.180
2022-05-25 00:31:35,546 [bic.py] => bias_correction => Task 7, Epoch 130/170 => Loss 3.835, Train_accy 76.250, Test_accy 47.300
2022-05-25 00:31:37,428 [bic.py] => bias_correction => Task 7, Epoch 131/170 => Loss 3.834, Train_accy 75.620, Test_accy 47.010
2022-05-25 00:31:39,303 [bic.py] => bias_correction => Task 7, Epoch 132/170 => Loss 3.839, Train_accy 74.380, Test_accy 46.980
2022-05-25 00:31:41,159 [bic.py] => bias_correction => Task 7, Epoch 133/170 => Loss 3.829, Train_accy 75.620, Test_accy 47.000
2022-05-25 00:31:43,024 [bic.py] => bias_correction => Task 7, Epoch 134/170 => Loss 3.882, Train_accy 75.000, Test_accy 46.990
2022-05-25 00:31:44,867 [bic.py] => bias_correction => Task 7, Epoch 135/170 => Loss 3.846, Train_accy 74.380, Test_accy 47.100
2022-05-25 00:31:46,696 [bic.py] => bias_correction => Task 7, Epoch 136/170 => Loss 3.833, Train_accy 74.380, Test_accy 47.050
2022-05-25 00:31:48,605 [bic.py] => bias_correction => Task 7, Epoch 137/170 => Loss 3.871, Train_accy 73.750, Test_accy 47.020
2022-05-25 00:31:50,512 [bic.py] => bias_correction => Task 7, Epoch 138/170 => Loss 3.797, Train_accy 77.500, Test_accy 46.990
2022-05-25 00:31:52,468 [bic.py] => bias_correction => Task 7, Epoch 139/170 => Loss 3.834, Train_accy 74.380, Test_accy 47.040
2022-05-25 00:31:54,398 [bic.py] => bias_correction => Task 7, Epoch 140/170 => Loss 3.810, Train_accy 75.620, Test_accy 47.040
2022-05-25 00:31:56,201 [bic.py] => bias_correction => Task 7, Epoch 141/170 => Loss 3.825, Train_accy 74.380, Test_accy 46.940
2022-05-25 00:31:58,103 [bic.py] => bias_correction => Task 7, Epoch 142/170 => Loss 3.855, Train_accy 74.380, Test_accy 47.060
2022-05-25 00:31:59,973 [bic.py] => bias_correction => Task 7, Epoch 143/170 => Loss 3.814, Train_accy 75.620, Test_accy 47.020
2022-05-25 00:32:01,885 [bic.py] => bias_correction => Task 7, Epoch 144/170 => Loss 3.828, Train_accy 75.620, Test_accy 47.100
2022-05-25 00:32:03,752 [bic.py] => bias_correction => Task 7, Epoch 145/170 => Loss 3.847, Train_accy 76.250, Test_accy 46.990
2022-05-25 00:32:05,610 [bic.py] => bias_correction => Task 7, Epoch 146/170 => Loss 3.856, Train_accy 73.750, Test_accy 46.950
2022-05-25 00:32:07,488 [bic.py] => bias_correction => Task 7, Epoch 147/170 => Loss 3.820, Train_accy 73.120, Test_accy 47.060
2022-05-25 00:32:09,440 [bic.py] => bias_correction => Task 7, Epoch 148/170 => Loss 3.847, Train_accy 75.620, Test_accy 46.860
2022-05-25 00:32:11,352 [bic.py] => bias_correction => Task 7, Epoch 149/170 => Loss 3.840, Train_accy 75.000, Test_accy 46.960
2022-05-25 00:32:13,219 [bic.py] => bias_correction => Task 7, Epoch 150/170 => Loss 3.851, Train_accy 77.500, Test_accy 47.020
2022-05-25 00:32:15,092 [bic.py] => bias_correction => Task 7, Epoch 151/170 => Loss 3.816, Train_accy 74.380, Test_accy 46.980
2022-05-25 00:32:16,937 [bic.py] => bias_correction => Task 7, Epoch 152/170 => Loss 3.851, Train_accy 75.000, Test_accy 46.860
2022-05-25 00:32:18,733 [bic.py] => bias_correction => Task 7, Epoch 153/170 => Loss 3.826, Train_accy 75.000, Test_accy 46.710
2022-05-25 00:32:20,576 [bic.py] => bias_correction => Task 7, Epoch 154/170 => Loss 3.845, Train_accy 76.250, Test_accy 46.700
2022-05-25 00:32:22,498 [bic.py] => bias_correction => Task 7, Epoch 155/170 => Loss 3.859, Train_accy 74.380, Test_accy 46.710
2022-05-25 00:32:24,365 [bic.py] => bias_correction => Task 7, Epoch 156/170 => Loss 3.835, Train_accy 73.750, Test_accy 46.990
2022-05-25 00:32:26,165 [bic.py] => bias_correction => Task 7, Epoch 157/170 => Loss 3.849, Train_accy 74.380, Test_accy 47.160
2022-05-25 00:32:27,993 [bic.py] => bias_correction => Task 7, Epoch 158/170 => Loss 3.808, Train_accy 75.620, Test_accy 47.200
2022-05-25 00:32:29,984 [bic.py] => bias_correction => Task 7, Epoch 159/170 => Loss 3.877, Train_accy 75.000, Test_accy 47.260
2022-05-25 00:32:31,870 [bic.py] => bias_correction => Task 7, Epoch 160/170 => Loss 3.842, Train_accy 74.380, Test_accy 47.120
2022-05-25 00:32:33,734 [bic.py] => bias_correction => Task 7, Epoch 161/170 => Loss 3.846, Train_accy 77.500, Test_accy 47.060
2022-05-25 00:32:35,636 [bic.py] => bias_correction => Task 7, Epoch 162/170 => Loss 3.826, Train_accy 75.000, Test_accy 46.960
2022-05-25 00:32:37,494 [bic.py] => bias_correction => Task 7, Epoch 163/170 => Loss 3.837, Train_accy 76.250, Test_accy 47.290
2022-05-25 00:32:39,420 [bic.py] => bias_correction => Task 7, Epoch 164/170 => Loss 3.823, Train_accy 74.380, Test_accy 47.290
2022-05-25 00:32:41,294 [bic.py] => bias_correction => Task 7, Epoch 165/170 => Loss 3.877, Train_accy 75.620, Test_accy 47.390
2022-05-25 00:32:43,145 [bic.py] => bias_correction => Task 7, Epoch 166/170 => Loss 3.828, Train_accy 75.000, Test_accy 47.090
2022-05-25 00:32:45,020 [bic.py] => bias_correction => Task 7, Epoch 167/170 => Loss 3.835, Train_accy 75.000, Test_accy 47.050
2022-05-25 00:32:46,930 [bic.py] => bias_correction => Task 7, Epoch 168/170 => Loss 3.842, Train_accy 74.380, Test_accy 47.380
2022-05-25 00:32:48,866 [bic.py] => bias_correction => Task 7, Epoch 169/170 => Loss 3.831, Train_accy 75.620, Test_accy 47.090
2022-05-25 00:32:50,735 [bic.py] => bias_correction => Task 7, Epoch 170/170 => Loss 3.867, Train_accy 74.380, Test_accy 47.100
2022-05-25 00:32:50,736 [base.py] => Reducing exemplars...(25 per classes)
2022-05-25 00:33:05,768 [base.py] => Constructing exemplars...(25 per classes)
2022-05-25 00:33:11,598 [bic.py] => Parameters of bias layer:
2022-05-25 00:33:11,599 [bic.py] => 0 => 1.000, 0.000
2022-05-25 00:33:11,599 [bic.py] => 1 => 0.981, -1.523
2022-05-25 00:33:11,599 [bic.py] => 2 => 0.816, -1.587
2022-05-25 00:33:11,599 [bic.py] => 3 => 0.723, -1.178
2022-05-25 00:33:11,599 [bic.py] => 4 => 0.736, -1.143
2022-05-25 00:33:11,599 [bic.py] => 5 => 0.746, -1.342
2022-05-25 00:33:11,599 [bic.py] => 6 => 0.696, -1.160
2022-05-25 00:33:11,600 [bic.py] => 7 => -0.020, -0.768
2022-05-25 00:33:13,660 [bic.py] => Exemplar size: 2000
2022-05-25 00:33:13,661 [trainer.py] => CNN: {'total': 47.1, '00-09': 59.9, '10-19': 44.7, '20-29': 58.4, '30-39': 48.7, '40-49': 56.0, '50-59': 52.1, '60-69': 57.0, '70-79': 0.0, 'old': 53.83, 'new': 0.0}
2022-05-25 00:33:13,661 [trainer.py] => NME: {'total': 53.65, '00-09': 56.9, '10-19': 40.0, '20-29': 58.6, '30-39': 45.7, '40-49': 55.5, '50-59': 47.2, '60-69': 60.6, '70-79': 64.7, 'old': 52.07, 'new': 64.7}
2022-05-25 00:33:13,661 [trainer.py] => CNN top1 curve: [87.5, 75.95, 70.6, 64.53, 62.34, 58.72, 55.69, 47.1]
2022-05-25 00:33:13,661 [trainer.py] => CNN top5 curve: [99.3, 95.5, 93.17, 90.3, 89.32, 86.92, 84.71, 73.3]
2022-05-25 00:33:13,661 [trainer.py] => NME top1 curve: [88.1, 75.6, 71.27, 64.97, 62.62, 59.18, 57.14, 53.65]
2022-05-25 00:33:13,661 [trainer.py] => NME top5 curve: [99.4, 95.4, 93.2, 90.05, 88.58, 86.03, 83.64, 82.11]

2022-05-25 00:33:13,661 [trainer.py] => All params: 469370
2022-05-25 00:33:13,662 [trainer.py] => Trainable params: 469370
2022-05-25 00:33:13,663 [bic.py] => Learning on 80-90
2022-05-25 00:33:13,719 [bic.py] => Stage1 dset: 6820, Stage2 dset: 180
2022-05-25 00:33:13,719 [bic.py] => Lambda: 0.889
2022-05-25 00:33:13,746 [bic.py] => Parameters of bias layer:
2022-05-25 00:33:13,746 [bic.py] => 0 => 1.000, 0.000
2022-05-25 00:33:13,747 [bic.py] => 1 => 0.981, -1.523
2022-05-25 00:33:13,747 [bic.py] => 2 => 0.816, -1.587
2022-05-25 00:33:13,747 [bic.py] => 3 => 0.723, -1.178
2022-05-25 00:33:13,747 [bic.py] => 4 => 0.736, -1.143
2022-05-25 00:33:13,747 [bic.py] => 5 => 0.746, -1.342
2022-05-25 00:33:13,747 [bic.py] => 6 => 0.696, -1.160
2022-05-25 00:33:13,747 [bic.py] => 7 => -0.020, -0.768
2022-05-25 00:33:13,747 [bic.py] => 8 => 1.000, 0.000
2022-05-25 00:33:18,414 [bic.py] => training => Task 8, Epoch 1/170 => Loss 3.129, Train_accy 69.970, Test_accy 30.960
2022-05-25 00:33:23,264 [bic.py] => training => Task 8, Epoch 2/170 => Loss 3.043, Train_accy 74.090, Test_accy 31.820
2022-05-25 00:33:28,088 [bic.py] => training => Task 8, Epoch 3/170 => Loss 3.028, Train_accy 77.300, Test_accy 32.110
2022-05-25 00:33:32,918 [bic.py] => training => Task 8, Epoch 4/170 => Loss 3.010, Train_accy 79.080, Test_accy 36.010
2022-05-25 00:33:37,770 [bic.py] => training => Task 8, Epoch 5/170 => Loss 3.015, Train_accy 80.120, Test_accy 34.230
2022-05-25 00:33:42,598 [bic.py] => training => Task 8, Epoch 6/170 => Loss 3.010, Train_accy 77.960, Test_accy 29.990
2022-05-25 00:33:47,389 [bic.py] => training => Task 8, Epoch 7/170 => Loss 3.002, Train_accy 80.630, Test_accy 34.840
2022-05-25 00:33:52,322 [bic.py] => training => Task 8, Epoch 8/170 => Loss 3.003, Train_accy 77.400, Test_accy 28.240
2022-05-25 00:33:57,170 [bic.py] => training => Task 8, Epoch 9/170 => Loss 3.000, Train_accy 84.590, Test_accy 36.330
2022-05-25 00:34:01,975 [bic.py] => training => Task 8, Epoch 10/170 => Loss 3.000, Train_accy 84.470, Test_accy 31.880
2022-05-25 00:34:06,813 [bic.py] => training => Task 8, Epoch 11/170 => Loss 2.999, Train_accy 86.300, Test_accy 34.320
2022-05-25 00:34:11,521 [bic.py] => training => Task 8, Epoch 12/170 => Loss 2.990, Train_accy 86.380, Test_accy 35.420
2022-05-25 00:34:16,317 [bic.py] => training => Task 8, Epoch 13/170 => Loss 2.989, Train_accy 85.890, Test_accy 36.710
2022-05-25 00:34:21,099 [bic.py] => training => Task 8, Epoch 14/170 => Loss 2.992, Train_accy 85.090, Test_accy 33.220
2022-05-25 00:34:25,892 [bic.py] => training => Task 8, Epoch 15/170 => Loss 2.988, Train_accy 83.700, Test_accy 34.860
2022-05-25 00:34:30,669 [bic.py] => training => Task 8, Epoch 16/170 => Loss 2.988, Train_accy 82.820, Test_accy 35.030
2022-05-25 00:34:35,513 [bic.py] => training => Task 8, Epoch 17/170 => Loss 2.987, Train_accy 85.230, Test_accy 34.810
2022-05-25 00:34:40,263 [bic.py] => training => Task 8, Epoch 18/170 => Loss 2.982, Train_accy 87.040, Test_accy 33.990
2022-05-25 00:34:45,070 [bic.py] => training => Task 8, Epoch 19/170 => Loss 2.987, Train_accy 86.760, Test_accy 33.580
2022-05-25 00:34:49,858 [bic.py] => training => Task 8, Epoch 20/170 => Loss 2.990, Train_accy 86.360, Test_accy 36.040
2022-05-25 00:34:54,611 [bic.py] => training => Task 8, Epoch 21/170 => Loss 2.986, Train_accy 88.500, Test_accy 35.700
2022-05-25 00:34:59,431 [bic.py] => training => Task 8, Epoch 22/170 => Loss 2.984, Train_accy 87.210, Test_accy 34.840
2022-05-25 00:35:04,273 [bic.py] => training => Task 8, Epoch 23/170 => Loss 2.982, Train_accy 85.590, Test_accy 33.590
2022-05-25 00:35:09,143 [bic.py] => training => Task 8, Epoch 24/170 => Loss 2.986, Train_accy 89.270, Test_accy 34.430
2022-05-25 00:35:13,922 [bic.py] => training => Task 8, Epoch 25/170 => Loss 2.984, Train_accy 85.430, Test_accy 33.600
2022-05-25 00:35:18,689 [bic.py] => training => Task 8, Epoch 26/170 => Loss 2.985, Train_accy 86.990, Test_accy 35.100
2022-05-25 00:35:23,528 [bic.py] => training => Task 8, Epoch 27/170 => Loss 2.992, Train_accy 87.980, Test_accy 31.860
2022-05-25 00:35:28,355 [bic.py] => training => Task 8, Epoch 28/170 => Loss 2.988, Train_accy 85.590, Test_accy 35.690
2022-05-25 00:35:33,128 [bic.py] => training => Task 8, Epoch 29/170 => Loss 2.984, Train_accy 89.120, Test_accy 35.520
2022-05-25 00:35:37,829 [bic.py] => training => Task 8, Epoch 30/170 => Loss 2.986, Train_accy 86.030, Test_accy 33.390
2022-05-25 00:35:42,625 [bic.py] => training => Task 8, Epoch 31/170 => Loss 2.991, Train_accy 89.650, Test_accy 36.310
2022-05-25 00:35:47,411 [bic.py] => training => Task 8, Epoch 32/170 => Loss 2.988, Train_accy 88.120, Test_accy 35.570
2022-05-25 00:35:52,218 [bic.py] => training => Task 8, Epoch 33/170 => Loss 2.982, Train_accy 89.370, Test_accy 34.980
2022-05-25 00:35:57,193 [bic.py] => training => Task 8, Epoch 34/170 => Loss 2.984, Train_accy 87.170, Test_accy 35.580
2022-05-25 00:36:01,998 [bic.py] => training => Task 8, Epoch 35/170 => Loss 2.983, Train_accy 85.630, Test_accy 32.920
2022-05-25 00:36:06,783 [bic.py] => training => Task 8, Epoch 36/170 => Loss 2.980, Train_accy 89.110, Test_accy 35.110
2022-05-25 00:36:11,664 [bic.py] => training => Task 8, Epoch 37/170 => Loss 2.983, Train_accy 90.450, Test_accy 35.860
2022-05-25 00:36:16,471 [bic.py] => training => Task 8, Epoch 38/170 => Loss 2.979, Train_accy 88.090, Test_accy 34.430
2022-05-25 00:36:21,337 [bic.py] => training => Task 8, Epoch 39/170 => Loss 2.975, Train_accy 89.410, Test_accy 35.680
2022-05-25 00:36:26,152 [bic.py] => training => Task 8, Epoch 40/170 => Loss 2.981, Train_accy 89.060, Test_accy 34.020
2022-05-25 00:36:30,923 [bic.py] => training => Task 8, Epoch 41/170 => Loss 2.978, Train_accy 87.480, Test_accy 32.640
2022-05-25 00:36:35,724 [bic.py] => training => Task 8, Epoch 42/170 => Loss 2.981, Train_accy 91.070, Test_accy 36.660
2022-05-25 00:36:40,494 [bic.py] => training => Task 8, Epoch 43/170 => Loss 2.977, Train_accy 87.160, Test_accy 32.090
2022-05-25 00:36:45,275 [bic.py] => training => Task 8, Epoch 44/170 => Loss 2.979, Train_accy 90.320, Test_accy 37.070
2022-05-25 00:36:50,094 [bic.py] => training => Task 8, Epoch 45/170 => Loss 2.974, Train_accy 86.110, Test_accy 31.660
2022-05-25 00:36:54,957 [bic.py] => training => Task 8, Epoch 46/170 => Loss 2.978, Train_accy 90.700, Test_accy 39.080
2022-05-25 00:36:59,828 [bic.py] => training => Task 8, Epoch 47/170 => Loss 2.976, Train_accy 89.840, Test_accy 34.830
2022-05-25 00:37:04,688 [bic.py] => training => Task 8, Epoch 48/170 => Loss 2.980, Train_accy 91.410, Test_accy 34.520
2022-05-25 00:37:09,653 [bic.py] => training => Task 8, Epoch 49/170 => Loss 2.982, Train_accy 88.140, Test_accy 34.590
2022-05-25 00:37:14,297 [bic.py] => training => Task 8, Epoch 50/170 => Loss 2.978, Train_accy 89.880, Test_accy 32.900
2022-05-25 00:37:19,098 [bic.py] => training => Task 8, Epoch 51/170 => Loss 2.977, Train_accy 88.990, Test_accy 36.390
2022-05-25 00:37:23,847 [bic.py] => training => Task 8, Epoch 52/170 => Loss 2.976, Train_accy 87.580, Test_accy 36.500
2022-05-25 00:37:28,693 [bic.py] => training => Task 8, Epoch 53/170 => Loss 2.977, Train_accy 90.190, Test_accy 34.070
2022-05-25 00:37:33,569 [bic.py] => training => Task 8, Epoch 54/170 => Loss 2.975, Train_accy 90.380, Test_accy 37.790
2022-05-25 00:37:38,513 [bic.py] => training => Task 8, Epoch 55/170 => Loss 2.979, Train_accy 84.090, Test_accy 32.140
2022-05-25 00:37:43,314 [bic.py] => training => Task 8, Epoch 56/170 => Loss 2.985, Train_accy 90.560, Test_accy 35.090
2022-05-25 00:37:48,169 [bic.py] => training => Task 8, Epoch 57/170 => Loss 2.981, Train_accy 86.260, Test_accy 34.240
2022-05-25 00:37:53,014 [bic.py] => training => Task 8, Epoch 58/170 => Loss 2.978, Train_accy 88.720, Test_accy 32.700
2022-05-25 00:37:57,774 [bic.py] => training => Task 8, Epoch 59/170 => Loss 2.973, Train_accy 88.170, Test_accy 33.600
2022-05-25 00:38:02,602 [bic.py] => training => Task 8, Epoch 60/170 => Loss 2.981, Train_accy 90.290, Test_accy 36.520
2022-05-25 00:38:07,408 [bic.py] => training => Task 8, Epoch 61/170 => Loss 2.942, Train_accy 95.650, Test_accy 39.740
2022-05-25 00:38:12,099 [bic.py] => training => Task 8, Epoch 62/170 => Loss 2.942, Train_accy 95.630, Test_accy 39.020
2022-05-25 00:38:16,933 [bic.py] => training => Task 8, Epoch 63/170 => Loss 2.944, Train_accy 95.880, Test_accy 39.810
2022-05-25 00:38:21,670 [bic.py] => training => Task 8, Epoch 64/170 => Loss 2.943, Train_accy 95.970, Test_accy 39.590
2022-05-25 00:38:26,307 [bic.py] => training => Task 8, Epoch 65/170 => Loss 2.940, Train_accy 95.910, Test_accy 39.300
2022-05-25 00:38:31,025 [bic.py] => training => Task 8, Epoch 66/170 => Loss 2.937, Train_accy 96.030, Test_accy 39.690
2022-05-25 00:38:35,814 [bic.py] => training => Task 8, Epoch 67/170 => Loss 2.941, Train_accy 95.950, Test_accy 39.420
2022-05-25 00:38:40,574 [bic.py] => training => Task 8, Epoch 68/170 => Loss 2.936, Train_accy 96.100, Test_accy 39.780
2022-05-25 00:38:45,360 [bic.py] => training => Task 8, Epoch 69/170 => Loss 2.941, Train_accy 96.130, Test_accy 39.460
2022-05-25 00:38:50,146 [bic.py] => training => Task 8, Epoch 70/170 => Loss 2.938, Train_accy 96.130, Test_accy 40.420
2022-05-25 00:38:54,973 [bic.py] => training => Task 8, Epoch 71/170 => Loss 2.932, Train_accy 96.040, Test_accy 39.110
2022-05-25 00:38:59,747 [bic.py] => training => Task 8, Epoch 72/170 => Loss 2.930, Train_accy 96.040, Test_accy 39.640
2022-05-25 00:39:04,583 [bic.py] => training => Task 8, Epoch 73/170 => Loss 2.932, Train_accy 96.200, Test_accy 39.840
2022-05-25 00:39:09,466 [bic.py] => training => Task 8, Epoch 74/170 => Loss 2.927, Train_accy 96.160, Test_accy 39.400
2022-05-25 00:39:14,323 [bic.py] => training => Task 8, Epoch 75/170 => Loss 2.921, Train_accy 96.090, Test_accy 39.430
2022-05-25 00:39:19,211 [bic.py] => training => Task 8, Epoch 76/170 => Loss 2.932, Train_accy 96.280, Test_accy 39.940
2022-05-25 00:39:24,030 [bic.py] => training => Task 8, Epoch 77/170 => Loss 2.933, Train_accy 96.220, Test_accy 39.700
2022-05-25 00:39:28,802 [bic.py] => training => Task 8, Epoch 78/170 => Loss 2.932, Train_accy 96.160, Test_accy 40.040
2022-05-25 00:39:33,399 [bic.py] => training => Task 8, Epoch 79/170 => Loss 2.933, Train_accy 96.260, Test_accy 40.060
2022-05-25 00:39:38,149 [bic.py] => training => Task 8, Epoch 80/170 => Loss 2.931, Train_accy 96.220, Test_accy 40.090
2022-05-25 00:39:42,946 [bic.py] => training => Task 8, Epoch 81/170 => Loss 2.929, Train_accy 96.230, Test_accy 39.610
2022-05-25 00:39:47,728 [bic.py] => training => Task 8, Epoch 82/170 => Loss 2.929, Train_accy 96.170, Test_accy 39.640
2022-05-25 00:39:52,383 [bic.py] => training => Task 8, Epoch 83/170 => Loss 2.932, Train_accy 96.170, Test_accy 39.410
2022-05-25 00:39:57,197 [bic.py] => training => Task 8, Epoch 84/170 => Loss 2.934, Train_accy 96.230, Test_accy 40.060
2022-05-25 00:40:01,981 [bic.py] => training => Task 8, Epoch 85/170 => Loss 2.931, Train_accy 96.110, Test_accy 39.720
2022-05-25 00:40:06,718 [bic.py] => training => Task 8, Epoch 86/170 => Loss 2.930, Train_accy 96.200, Test_accy 39.070
2022-05-25 00:40:11,518 [bic.py] => training => Task 8, Epoch 87/170 => Loss 2.930, Train_accy 96.320, Test_accy 40.190
2022-05-25 00:40:16,369 [bic.py] => training => Task 8, Epoch 88/170 => Loss 2.937, Train_accy 96.250, Test_accy 39.630
2022-05-25 00:40:21,164 [bic.py] => training => Task 8, Epoch 89/170 => Loss 2.932, Train_accy 96.290, Test_accy 40.000
2022-05-25 00:40:25,956 [bic.py] => training => Task 8, Epoch 90/170 => Loss 2.934, Train_accy 96.330, Test_accy 39.670
2022-05-25 00:40:30,625 [bic.py] => training => Task 8, Epoch 91/170 => Loss 2.932, Train_accy 96.290, Test_accy 39.880
2022-05-25 00:40:35,434 [bic.py] => training => Task 8, Epoch 92/170 => Loss 2.928, Train_accy 96.260, Test_accy 39.790
2022-05-25 00:40:40,286 [bic.py] => training => Task 8, Epoch 93/170 => Loss 2.928, Train_accy 96.290, Test_accy 39.430
2022-05-25 00:40:45,139 [bic.py] => training => Task 8, Epoch 94/170 => Loss 2.929, Train_accy 96.350, Test_accy 40.020
2022-05-25 00:40:49,969 [bic.py] => training => Task 8, Epoch 95/170 => Loss 2.925, Train_accy 96.390, Test_accy 39.640
2022-05-25 00:40:54,816 [bic.py] => training => Task 8, Epoch 96/170 => Loss 2.932, Train_accy 96.230, Test_accy 39.620
2022-05-25 00:40:59,657 [bic.py] => training => Task 8, Epoch 97/170 => Loss 2.935, Train_accy 96.390, Test_accy 40.090
2022-05-25 00:41:04,446 [bic.py] => training => Task 8, Epoch 98/170 => Loss 2.930, Train_accy 96.330, Test_accy 40.060
2022-05-25 00:41:09,205 [bic.py] => training => Task 8, Epoch 99/170 => Loss 2.925, Train_accy 96.410, Test_accy 39.780
2022-05-25 00:41:13,989 [bic.py] => training => Task 8, Epoch 100/170 => Loss 2.927, Train_accy 96.300, Test_accy 39.560
2022-05-25 00:41:18,655 [bic.py] => training => Task 8, Epoch 101/170 => Loss 2.924, Train_accy 96.420, Test_accy 39.790
2022-05-25 00:41:23,554 [bic.py] => training => Task 8, Epoch 102/170 => Loss 2.929, Train_accy 96.320, Test_accy 39.670
2022-05-25 00:41:28,416 [bic.py] => training => Task 8, Epoch 103/170 => Loss 2.932, Train_accy 96.360, Test_accy 40.120
2022-05-25 00:41:33,228 [bic.py] => training => Task 8, Epoch 104/170 => Loss 2.929, Train_accy 96.420, Test_accy 40.090
2022-05-25 00:41:38,085 [bic.py] => training => Task 8, Epoch 105/170 => Loss 2.930, Train_accy 96.350, Test_accy 39.630
2022-05-25 00:41:42,882 [bic.py] => training => Task 8, Epoch 106/170 => Loss 2.927, Train_accy 96.320, Test_accy 39.860
2022-05-25 00:41:47,623 [bic.py] => training => Task 8, Epoch 107/170 => Loss 2.927, Train_accy 96.320, Test_accy 40.040
2022-05-25 00:41:52,516 [bic.py] => training => Task 8, Epoch 108/170 => Loss 2.935, Train_accy 96.250, Test_accy 39.970
2022-05-25 00:41:57,203 [bic.py] => training => Task 8, Epoch 109/170 => Loss 2.928, Train_accy 96.320, Test_accy 40.000
2022-05-25 00:42:02,067 [bic.py] => training => Task 8, Epoch 110/170 => Loss 2.928, Train_accy 96.300, Test_accy 39.660
2022-05-25 00:42:06,856 [bic.py] => training => Task 8, Epoch 111/170 => Loss 2.927, Train_accy 96.360, Test_accy 40.130
2022-05-25 00:42:11,654 [bic.py] => training => Task 8, Epoch 112/170 => Loss 2.930, Train_accy 96.360, Test_accy 39.540
2022-05-25 00:42:16,294 [bic.py] => training => Task 8, Epoch 113/170 => Loss 2.928, Train_accy 96.420, Test_accy 39.760
2022-05-25 00:42:21,216 [bic.py] => training => Task 8, Epoch 114/170 => Loss 2.927, Train_accy 96.320, Test_accy 39.690
2022-05-25 00:42:26,313 [bic.py] => training => Task 8, Epoch 115/170 => Loss 2.928, Train_accy 96.380, Test_accy 39.570
2022-05-25 00:42:31,364 [bic.py] => training => Task 8, Epoch 116/170 => Loss 2.928, Train_accy 96.290, Test_accy 39.580
2022-05-25 00:42:36,459 [bic.py] => training => Task 8, Epoch 117/170 => Loss 2.927, Train_accy 96.290, Test_accy 39.220
2022-05-25 00:42:41,529 [bic.py] => training => Task 8, Epoch 118/170 => Loss 2.926, Train_accy 96.380, Test_accy 39.920
2022-05-25 00:42:46,419 [bic.py] => training => Task 8, Epoch 119/170 => Loss 2.926, Train_accy 96.420, Test_accy 40.160
2022-05-25 00:42:51,161 [bic.py] => training => Task 8, Epoch 120/170 => Loss 2.926, Train_accy 96.280, Test_accy 39.510
2022-05-25 00:42:55,949 [bic.py] => training => Task 8, Epoch 121/170 => Loss 2.928, Train_accy 96.260, Test_accy 39.920
2022-05-25 00:43:00,731 [bic.py] => training => Task 8, Epoch 122/170 => Loss 2.931, Train_accy 96.330, Test_accy 39.720
2022-05-25 00:43:05,579 [bic.py] => training => Task 8, Epoch 123/170 => Loss 2.927, Train_accy 96.280, Test_accy 39.570
2022-05-25 00:43:10,492 [bic.py] => training => Task 8, Epoch 124/170 => Loss 2.927, Train_accy 96.390, Test_accy 39.670
2022-05-25 00:43:15,295 [bic.py] => training => Task 8, Epoch 125/170 => Loss 2.922, Train_accy 96.290, Test_accy 39.660
2022-05-25 00:43:20,383 [bic.py] => training => Task 8, Epoch 126/170 => Loss 2.926, Train_accy 96.510, Test_accy 39.860
2022-05-25 00:43:25,492 [bic.py] => training => Task 8, Epoch 127/170 => Loss 2.928, Train_accy 96.280, Test_accy 39.870
2022-05-25 00:43:30,411 [bic.py] => training => Task 8, Epoch 128/170 => Loss 2.927, Train_accy 96.360, Test_accy 39.860
2022-05-25 00:43:35,481 [bic.py] => training => Task 8, Epoch 129/170 => Loss 2.925, Train_accy 96.290, Test_accy 40.340
2022-05-25 00:43:40,388 [bic.py] => training => Task 8, Epoch 130/170 => Loss 2.925, Train_accy 96.360, Test_accy 40.010
2022-05-25 00:43:45,339 [bic.py] => training => Task 8, Epoch 131/170 => Loss 2.926, Train_accy 96.390, Test_accy 39.570
2022-05-25 00:43:50,399 [bic.py] => training => Task 8, Epoch 132/170 => Loss 2.923, Train_accy 96.380, Test_accy 39.900
2022-05-25 00:43:55,356 [bic.py] => training => Task 8, Epoch 133/170 => Loss 2.931, Train_accy 96.330, Test_accy 39.960
2022-05-25 00:44:00,101 [bic.py] => training => Task 8, Epoch 134/170 => Loss 2.928, Train_accy 96.450, Test_accy 39.930
2022-05-25 00:44:04,964 [bic.py] => training => Task 8, Epoch 135/170 => Loss 2.928, Train_accy 96.320, Test_accy 39.980
2022-05-25 00:44:09,818 [bic.py] => training => Task 8, Epoch 136/170 => Loss 2.929, Train_accy 96.360, Test_accy 39.790
2022-05-25 00:44:14,640 [bic.py] => training => Task 8, Epoch 137/170 => Loss 2.926, Train_accy 96.350, Test_accy 40.030
2022-05-25 00:44:19,476 [bic.py] => training => Task 8, Epoch 138/170 => Loss 2.928, Train_accy 96.260, Test_accy 39.490
2022-05-25 00:44:24,278 [bic.py] => training => Task 8, Epoch 139/170 => Loss 2.930, Train_accy 96.360, Test_accy 39.890
2022-05-25 00:44:28,998 [bic.py] => training => Task 8, Epoch 140/170 => Loss 2.926, Train_accy 96.320, Test_accy 39.880
2022-05-25 00:44:33,610 [bic.py] => training => Task 8, Epoch 141/170 => Loss 2.926, Train_accy 96.330, Test_accy 40.180
2022-05-25 00:44:38,375 [bic.py] => training => Task 8, Epoch 142/170 => Loss 2.931, Train_accy 96.330, Test_accy 39.790
2022-05-25 00:44:43,164 [bic.py] => training => Task 8, Epoch 143/170 => Loss 2.926, Train_accy 96.250, Test_accy 39.780
2022-05-25 00:44:47,852 [bic.py] => training => Task 8, Epoch 144/170 => Loss 2.930, Train_accy 96.290, Test_accy 40.110
2022-05-25 00:44:52,573 [bic.py] => training => Task 8, Epoch 145/170 => Loss 2.925, Train_accy 96.330, Test_accy 39.680
2022-05-25 00:44:57,197 [bic.py] => training => Task 8, Epoch 146/170 => Loss 2.932, Train_accy 96.260, Test_accy 39.770
2022-05-25 00:45:02,035 [bic.py] => training => Task 8, Epoch 147/170 => Loss 2.929, Train_accy 96.420, Test_accy 40.010
2022-05-25 00:45:06,817 [bic.py] => training => Task 8, Epoch 148/170 => Loss 2.926, Train_accy 96.390, Test_accy 39.460
2022-05-25 00:45:11,728 [bic.py] => training => Task 8, Epoch 149/170 => Loss 2.929, Train_accy 96.320, Test_accy 39.600
2022-05-25 00:45:16,554 [bic.py] => training => Task 8, Epoch 150/170 => Loss 2.930, Train_accy 96.330, Test_accy 40.000
2022-05-25 00:45:21,283 [bic.py] => training => Task 8, Epoch 151/170 => Loss 2.923, Train_accy 96.410, Test_accy 39.930
2022-05-25 00:45:26,110 [bic.py] => training => Task 8, Epoch 152/170 => Loss 2.928, Train_accy 96.320, Test_accy 39.530
2022-05-25 00:45:30,861 [bic.py] => training => Task 8, Epoch 153/170 => Loss 2.925, Train_accy 96.330, Test_accy 39.780
2022-05-25 00:45:35,645 [bic.py] => training => Task 8, Epoch 154/170 => Loss 2.929, Train_accy 96.360, Test_accy 40.070
2022-05-25 00:45:40,341 [bic.py] => training => Task 8, Epoch 155/170 => Loss 2.929, Train_accy 96.410, Test_accy 40.120
2022-05-25 00:45:45,022 [bic.py] => training => Task 8, Epoch 156/170 => Loss 2.930, Train_accy 96.350, Test_accy 39.840
2022-05-25 00:45:49,745 [bic.py] => training => Task 8, Epoch 157/170 => Loss 2.925, Train_accy 96.410, Test_accy 40.220
2022-05-25 00:45:54,565 [bic.py] => training => Task 8, Epoch 158/170 => Loss 2.925, Train_accy 96.330, Test_accy 39.680
2022-05-25 00:45:59,267 [bic.py] => training => Task 8, Epoch 159/170 => Loss 2.925, Train_accy 96.390, Test_accy 39.310
2022-05-25 00:46:04,200 [bic.py] => training => Task 8, Epoch 160/170 => Loss 2.922, Train_accy 96.230, Test_accy 39.660
2022-05-25 00:46:09,016 [bic.py] => training => Task 8, Epoch 161/170 => Loss 2.930, Train_accy 96.280, Test_accy 40.140
2022-05-25 00:46:13,831 [bic.py] => training => Task 8, Epoch 162/170 => Loss 2.933, Train_accy 96.360, Test_accy 39.620
2022-05-25 00:46:18,523 [bic.py] => training => Task 8, Epoch 163/170 => Loss 2.931, Train_accy 96.360, Test_accy 40.100
2022-05-25 00:46:23,300 [bic.py] => training => Task 8, Epoch 164/170 => Loss 2.926, Train_accy 96.360, Test_accy 39.630
2022-05-25 00:46:28,004 [bic.py] => training => Task 8, Epoch 165/170 => Loss 2.928, Train_accy 96.320, Test_accy 39.910
2022-05-25 00:46:32,700 [bic.py] => training => Task 8, Epoch 166/170 => Loss 2.928, Train_accy 96.380, Test_accy 40.030
2022-05-25 00:46:37,409 [bic.py] => training => Task 8, Epoch 167/170 => Loss 2.929, Train_accy 96.320, Test_accy 39.980
2022-05-25 00:46:42,161 [bic.py] => training => Task 8, Epoch 168/170 => Loss 2.931, Train_accy 96.350, Test_accy 39.710
2022-05-25 00:46:46,899 [bic.py] => training => Task 8, Epoch 169/170 => Loss 2.922, Train_accy 96.350, Test_accy 39.880
2022-05-25 00:46:51,638 [bic.py] => training => Task 8, Epoch 170/170 => Loss 2.929, Train_accy 96.410, Test_accy 39.780
2022-05-25 00:46:53,493 [bic.py] => bias_correction => Task 8, Epoch 1/170 => Loss 4.115, Train_accy 61.670, Test_accy 41.860
2022-05-25 00:46:55,319 [bic.py] => bias_correction => Task 8, Epoch 2/170 => Loss 4.072, Train_accy 70.560, Test_accy 45.980
2022-05-25 00:46:57,209 [bic.py] => bias_correction => Task 8, Epoch 3/170 => Loss 4.010, Train_accy 71.110, Test_accy 44.790
2022-05-25 00:46:59,085 [bic.py] => bias_correction => Task 8, Epoch 4/170 => Loss 4.034, Train_accy 66.670, Test_accy 41.780
2022-05-25 00:47:00,903 [bic.py] => bias_correction => Task 8, Epoch 5/170 => Loss 4.015, Train_accy 68.330, Test_accy 40.840
2022-05-25 00:47:02,741 [bic.py] => bias_correction => Task 8, Epoch 6/170 => Loss 4.023, Train_accy 65.560, Test_accy 40.710
2022-05-25 00:47:04,561 [bic.py] => bias_correction => Task 8, Epoch 7/170 => Loss 3.999, Train_accy 67.780, Test_accy 40.510
2022-05-25 00:47:06,459 [bic.py] => bias_correction => Task 8, Epoch 8/170 => Loss 4.029, Train_accy 66.670, Test_accy 40.470
2022-05-25 00:47:08,283 [bic.py] => bias_correction => Task 8, Epoch 9/170 => Loss 4.026, Train_accy 68.890, Test_accy 40.370
2022-05-25 00:47:10,052 [bic.py] => bias_correction => Task 8, Epoch 10/170 => Loss 4.035, Train_accy 66.670, Test_accy 40.190
2022-05-25 00:47:11,846 [bic.py] => bias_correction => Task 8, Epoch 11/170 => Loss 4.034, Train_accy 68.890, Test_accy 40.200
2022-05-25 00:47:13,696 [bic.py] => bias_correction => Task 8, Epoch 12/170 => Loss 4.027, Train_accy 66.110, Test_accy 40.110
2022-05-25 00:47:15,559 [bic.py] => bias_correction => Task 8, Epoch 13/170 => Loss 4.030, Train_accy 66.110, Test_accy 40.140
2022-05-25 00:47:17,559 [bic.py] => bias_correction => Task 8, Epoch 14/170 => Loss 4.039, Train_accy 66.670, Test_accy 39.980
2022-05-25 00:47:19,393 [bic.py] => bias_correction => Task 8, Epoch 15/170 => Loss 4.034, Train_accy 65.000, Test_accy 39.920
2022-05-25 00:47:21,345 [bic.py] => bias_correction => Task 8, Epoch 16/170 => Loss 4.030, Train_accy 67.220, Test_accy 39.860
2022-05-25 00:47:23,206 [bic.py] => bias_correction => Task 8, Epoch 17/170 => Loss 4.018, Train_accy 67.780, Test_accy 39.860
2022-05-25 00:47:25,061 [bic.py] => bias_correction => Task 8, Epoch 18/170 => Loss 4.036, Train_accy 68.330, Test_accy 39.770
2022-05-25 00:47:26,871 [bic.py] => bias_correction => Task 8, Epoch 19/170 => Loss 4.036, Train_accy 65.000, Test_accy 39.840
2022-05-25 00:47:28,793 [bic.py] => bias_correction => Task 8, Epoch 20/170 => Loss 4.025, Train_accy 67.220, Test_accy 39.830
2022-05-25 00:47:30,650 [bic.py] => bias_correction => Task 8, Epoch 21/170 => Loss 4.028, Train_accy 68.330, Test_accy 39.800
2022-05-25 00:47:32,516 [bic.py] => bias_correction => Task 8, Epoch 22/170 => Loss 4.035, Train_accy 66.110, Test_accy 39.840
2022-05-25 00:47:34,459 [bic.py] => bias_correction => Task 8, Epoch 23/170 => Loss 4.027, Train_accy 66.110, Test_accy 39.890
2022-05-25 00:47:36,388 [bic.py] => bias_correction => Task 8, Epoch 24/170 => Loss 4.033, Train_accy 68.330, Test_accy 39.780
2022-05-25 00:47:38,339 [bic.py] => bias_correction => Task 8, Epoch 25/170 => Loss 4.023, Train_accy 66.110, Test_accy 39.820
2022-05-25 00:47:40,160 [bic.py] => bias_correction => Task 8, Epoch 26/170 => Loss 4.012, Train_accy 68.330, Test_accy 39.830
2022-05-25 00:47:41,982 [bic.py] => bias_correction => Task 8, Epoch 27/170 => Loss 4.012, Train_accy 64.440, Test_accy 39.930
2022-05-25 00:47:43,890 [bic.py] => bias_correction => Task 8, Epoch 28/170 => Loss 4.026, Train_accy 66.670, Test_accy 39.880
2022-05-25 00:47:45,722 [bic.py] => bias_correction => Task 8, Epoch 29/170 => Loss 4.039, Train_accy 66.110, Test_accy 39.890
2022-05-25 00:47:47,639 [bic.py] => bias_correction => Task 8, Epoch 30/170 => Loss 4.018, Train_accy 68.330, Test_accy 39.880
2022-05-25 00:47:49,506 [bic.py] => bias_correction => Task 8, Epoch 31/170 => Loss 4.001, Train_accy 67.780, Test_accy 39.720
2022-05-25 00:47:51,292 [bic.py] => bias_correction => Task 8, Epoch 32/170 => Loss 4.035, Train_accy 66.670, Test_accy 39.720
2022-05-25 00:47:53,162 [bic.py] => bias_correction => Task 8, Epoch 33/170 => Loss 4.027, Train_accy 63.890, Test_accy 39.680
2022-05-25 00:47:55,084 [bic.py] => bias_correction => Task 8, Epoch 34/170 => Loss 4.031, Train_accy 67.220, Test_accy 39.680
2022-05-25 00:47:57,022 [bic.py] => bias_correction => Task 8, Epoch 35/170 => Loss 4.025, Train_accy 65.000, Test_accy 39.690
2022-05-25 00:47:58,987 [bic.py] => bias_correction => Task 8, Epoch 36/170 => Loss 4.039, Train_accy 65.560, Test_accy 39.760
2022-05-25 00:48:00,910 [bic.py] => bias_correction => Task 8, Epoch 37/170 => Loss 4.046, Train_accy 67.780, Test_accy 39.830
2022-05-25 00:48:02,663 [bic.py] => bias_correction => Task 8, Epoch 38/170 => Loss 4.031, Train_accy 66.670, Test_accy 39.770
2022-05-25 00:48:04,474 [bic.py] => bias_correction => Task 8, Epoch 39/170 => Loss 4.040, Train_accy 65.000, Test_accy 39.920
2022-05-25 00:48:06,287 [bic.py] => bias_correction => Task 8, Epoch 40/170 => Loss 4.016, Train_accy 65.560, Test_accy 39.920
2022-05-25 00:48:08,098 [bic.py] => bias_correction => Task 8, Epoch 41/170 => Loss 4.029, Train_accy 66.670, Test_accy 39.920
2022-05-25 00:48:09,983 [bic.py] => bias_correction => Task 8, Epoch 42/170 => Loss 4.048, Train_accy 69.440, Test_accy 39.920
2022-05-25 00:48:11,969 [bic.py] => bias_correction => Task 8, Epoch 43/170 => Loss 4.014, Train_accy 68.890, Test_accy 39.860
2022-05-25 00:48:13,875 [bic.py] => bias_correction => Task 8, Epoch 44/170 => Loss 4.017, Train_accy 68.890, Test_accy 39.900
2022-05-25 00:48:15,735 [bic.py] => bias_correction => Task 8, Epoch 45/170 => Loss 4.032, Train_accy 67.220, Test_accy 39.840
2022-05-25 00:48:17,619 [bic.py] => bias_correction => Task 8, Epoch 46/170 => Loss 4.008, Train_accy 64.440, Test_accy 40.040
2022-05-25 00:48:19,563 [bic.py] => bias_correction => Task 8, Epoch 47/170 => Loss 4.011, Train_accy 67.780, Test_accy 40.070
2022-05-25 00:48:21,481 [bic.py] => bias_correction => Task 8, Epoch 48/170 => Loss 3.994, Train_accy 66.670, Test_accy 40.040
2022-05-25 00:48:23,319 [bic.py] => bias_correction => Task 8, Epoch 49/170 => Loss 4.013, Train_accy 67.220, Test_accy 39.880
2022-05-25 00:48:25,083 [bic.py] => bias_correction => Task 8, Epoch 50/170 => Loss 4.005, Train_accy 67.780, Test_accy 39.840
2022-05-25 00:48:26,913 [bic.py] => bias_correction => Task 8, Epoch 51/170 => Loss 4.026, Train_accy 70.000, Test_accy 39.830
2022-05-25 00:48:28,814 [bic.py] => bias_correction => Task 8, Epoch 52/170 => Loss 4.065, Train_accy 67.220, Test_accy 39.820
2022-05-25 00:48:30,692 [bic.py] => bias_correction => Task 8, Epoch 53/170 => Loss 4.011, Train_accy 66.670, Test_accy 39.830
2022-05-25 00:48:32,548 [bic.py] => bias_correction => Task 8, Epoch 54/170 => Loss 4.024, Train_accy 65.560, Test_accy 39.900
2022-05-25 00:48:34,327 [bic.py] => bias_correction => Task 8, Epoch 55/170 => Loss 4.018, Train_accy 67.780, Test_accy 39.860
2022-05-25 00:48:36,122 [bic.py] => bias_correction => Task 8, Epoch 56/170 => Loss 4.025, Train_accy 68.330, Test_accy 39.840
2022-05-25 00:48:38,021 [bic.py] => bias_correction => Task 8, Epoch 57/170 => Loss 4.024, Train_accy 65.560, Test_accy 39.960
2022-05-25 00:48:39,849 [bic.py] => bias_correction => Task 8, Epoch 58/170 => Loss 4.027, Train_accy 65.000, Test_accy 40.030
2022-05-25 00:48:41,700 [bic.py] => bias_correction => Task 8, Epoch 59/170 => Loss 3.999, Train_accy 65.560, Test_accy 40.030
2022-05-25 00:48:43,620 [bic.py] => bias_correction => Task 8, Epoch 60/170 => Loss 4.028, Train_accy 67.780, Test_accy 39.980
2022-05-25 00:48:45,556 [bic.py] => bias_correction => Task 8, Epoch 61/170 => Loss 4.032, Train_accy 66.110, Test_accy 40.140
2022-05-25 00:48:47,380 [bic.py] => bias_correction => Task 8, Epoch 62/170 => Loss 4.027, Train_accy 67.780, Test_accy 40.020
2022-05-25 00:48:49,172 [bic.py] => bias_correction => Task 8, Epoch 63/170 => Loss 4.023, Train_accy 66.670, Test_accy 40.060
2022-05-25 00:48:51,153 [bic.py] => bias_correction => Task 8, Epoch 64/170 => Loss 4.003, Train_accy 67.220, Test_accy 40.110
2022-05-25 00:48:53,008 [bic.py] => bias_correction => Task 8, Epoch 65/170 => Loss 4.005, Train_accy 64.440, Test_accy 40.020
2022-05-25 00:48:54,881 [bic.py] => bias_correction => Task 8, Epoch 66/170 => Loss 4.008, Train_accy 65.560, Test_accy 40.020
2022-05-25 00:48:56,780 [bic.py] => bias_correction => Task 8, Epoch 67/170 => Loss 4.001, Train_accy 67.780, Test_accy 40.010
2022-05-25 00:48:58,633 [bic.py] => bias_correction => Task 8, Epoch 68/170 => Loss 4.044, Train_accy 67.780, Test_accy 39.970
2022-05-25 00:49:00,449 [bic.py] => bias_correction => Task 8, Epoch 69/170 => Loss 4.056, Train_accy 63.890, Test_accy 39.990
2022-05-25 00:49:02,261 [bic.py] => bias_correction => Task 8, Epoch 70/170 => Loss 4.030, Train_accy 67.220, Test_accy 40.180
2022-05-25 00:49:04,062 [bic.py] => bias_correction => Task 8, Epoch 71/170 => Loss 4.020, Train_accy 67.220, Test_accy 40.120
2022-05-25 00:49:05,936 [bic.py] => bias_correction => Task 8, Epoch 72/170 => Loss 4.017, Train_accy 66.110, Test_accy 40.230
2022-05-25 00:49:07,764 [bic.py] => bias_correction => Task 8, Epoch 73/170 => Loss 4.010, Train_accy 67.780, Test_accy 40.380
2022-05-25 00:49:09,602 [bic.py] => bias_correction => Task 8, Epoch 74/170 => Loss 4.038, Train_accy 67.780, Test_accy 40.510
2022-05-25 00:49:11,444 [bic.py] => bias_correction => Task 8, Epoch 75/170 => Loss 4.034, Train_accy 68.890, Test_accy 40.390
2022-05-25 00:49:13,395 [bic.py] => bias_correction => Task 8, Epoch 76/170 => Loss 4.042, Train_accy 65.000, Test_accy 40.410
2022-05-25 00:49:15,252 [bic.py] => bias_correction => Task 8, Epoch 77/170 => Loss 4.000, Train_accy 68.330, Test_accy 40.670
2022-05-25 00:49:17,111 [bic.py] => bias_correction => Task 8, Epoch 78/170 => Loss 4.033, Train_accy 66.670, Test_accy 40.780
2022-05-25 00:49:18,883 [bic.py] => bias_correction => Task 8, Epoch 79/170 => Loss 4.029, Train_accy 66.110, Test_accy 40.890
2022-05-25 00:49:20,720 [bic.py] => bias_correction => Task 8, Epoch 80/170 => Loss 4.034, Train_accy 67.780, Test_accy 40.920
2022-05-25 00:49:22,512 [bic.py] => bias_correction => Task 8, Epoch 81/170 => Loss 4.037, Train_accy 66.110, Test_accy 40.980
2022-05-25 00:49:24,334 [bic.py] => bias_correction => Task 8, Epoch 82/170 => Loss 4.035, Train_accy 67.220, Test_accy 41.170
2022-05-25 00:49:26,166 [bic.py] => bias_correction => Task 8, Epoch 83/170 => Loss 4.011, Train_accy 68.890, Test_accy 41.130
2022-05-25 00:49:28,083 [bic.py] => bias_correction => Task 8, Epoch 84/170 => Loss 4.019, Train_accy 67.220, Test_accy 41.300
2022-05-25 00:49:29,883 [bic.py] => bias_correction => Task 8, Epoch 85/170 => Loss 4.022, Train_accy 66.670, Test_accy 41.470
2022-05-25 00:49:31,649 [bic.py] => bias_correction => Task 8, Epoch 86/170 => Loss 3.992, Train_accy 64.440, Test_accy 41.620
2022-05-25 00:49:33,592 [bic.py] => bias_correction => Task 8, Epoch 87/170 => Loss 4.022, Train_accy 67.780, Test_accy 41.840
2022-05-25 00:49:35,442 [bic.py] => bias_correction => Task 8, Epoch 88/170 => Loss 4.011, Train_accy 69.440, Test_accy 42.020
2022-05-25 00:49:37,254 [bic.py] => bias_correction => Task 8, Epoch 89/170 => Loss 4.009, Train_accy 66.670, Test_accy 42.230
2022-05-25 00:49:39,105 [bic.py] => bias_correction => Task 8, Epoch 90/170 => Loss 4.038, Train_accy 67.780, Test_accy 42.300
2022-05-25 00:49:40,979 [bic.py] => bias_correction => Task 8, Epoch 91/170 => Loss 4.012, Train_accy 65.560, Test_accy 42.490
2022-05-25 00:49:42,795 [bic.py] => bias_correction => Task 8, Epoch 92/170 => Loss 3.994, Train_accy 69.440, Test_accy 42.760
2022-05-25 00:49:44,678 [bic.py] => bias_correction => Task 8, Epoch 93/170 => Loss 4.023, Train_accy 68.330, Test_accy 43.030
2022-05-25 00:49:46,567 [bic.py] => bias_correction => Task 8, Epoch 94/170 => Loss 4.028, Train_accy 66.670, Test_accy 43.480
2022-05-25 00:49:48,505 [bic.py] => bias_correction => Task 8, Epoch 95/170 => Loss 4.014, Train_accy 71.670, Test_accy 43.620
2022-05-25 00:49:50,333 [bic.py] => bias_correction => Task 8, Epoch 96/170 => Loss 4.009, Train_accy 69.440, Test_accy 43.830
2022-05-25 00:49:52,163 [bic.py] => bias_correction => Task 8, Epoch 97/170 => Loss 3.992, Train_accy 70.000, Test_accy 43.930
2022-05-25 00:49:54,111 [bic.py] => bias_correction => Task 8, Epoch 98/170 => Loss 4.018, Train_accy 70.560, Test_accy 44.040
2022-05-25 00:49:55,977 [bic.py] => bias_correction => Task 8, Epoch 99/170 => Loss 4.035, Train_accy 71.110, Test_accy 44.260
2022-05-25 00:49:57,862 [bic.py] => bias_correction => Task 8, Epoch 100/170 => Loss 3.983, Train_accy 70.000, Test_accy 44.240
2022-05-25 00:49:59,746 [bic.py] => bias_correction => Task 8, Epoch 101/170 => Loss 4.017, Train_accy 68.890, Test_accy 44.270
2022-05-25 00:50:01,567 [bic.py] => bias_correction => Task 8, Epoch 102/170 => Loss 3.990, Train_accy 68.890, Test_accy 44.410
2022-05-25 00:50:03,346 [bic.py] => bias_correction => Task 8, Epoch 103/170 => Loss 4.006, Train_accy 68.330, Test_accy 44.240
2022-05-25 00:50:05,174 [bic.py] => bias_correction => Task 8, Epoch 104/170 => Loss 3.993, Train_accy 69.440, Test_accy 44.380
2022-05-25 00:50:07,083 [bic.py] => bias_correction => Task 8, Epoch 105/170 => Loss 3.986, Train_accy 69.440, Test_accy 44.440
2022-05-25 00:50:08,906 [bic.py] => bias_correction => Task 8, Epoch 106/170 => Loss 4.008, Train_accy 70.560, Test_accy 44.510
2022-05-25 00:50:10,751 [bic.py] => bias_correction => Task 8, Epoch 107/170 => Loss 4.026, Train_accy 71.110, Test_accy 44.590
2022-05-25 00:50:12,567 [bic.py] => bias_correction => Task 8, Epoch 108/170 => Loss 3.987, Train_accy 72.220, Test_accy 44.590
2022-05-25 00:50:14,445 [bic.py] => bias_correction => Task 8, Epoch 109/170 => Loss 4.008, Train_accy 67.780, Test_accy 44.430
2022-05-25 00:50:16,270 [bic.py] => bias_correction => Task 8, Epoch 110/170 => Loss 4.011, Train_accy 67.780, Test_accy 44.320
2022-05-25 00:50:18,040 [bic.py] => bias_correction => Task 8, Epoch 111/170 => Loss 4.027, Train_accy 67.780, Test_accy 44.220
2022-05-25 00:50:19,918 [bic.py] => bias_correction => Task 8, Epoch 112/170 => Loss 4.000, Train_accy 69.440, Test_accy 44.170
2022-05-25 00:50:21,698 [bic.py] => bias_correction => Task 8, Epoch 113/170 => Loss 4.015, Train_accy 71.110, Test_accy 44.230
2022-05-25 00:50:23,481 [bic.py] => bias_correction => Task 8, Epoch 114/170 => Loss 4.002, Train_accy 70.560, Test_accy 44.230
2022-05-25 00:50:25,309 [bic.py] => bias_correction => Task 8, Epoch 115/170 => Loss 4.005, Train_accy 73.890, Test_accy 44.310
2022-05-25 00:50:27,137 [bic.py] => bias_correction => Task 8, Epoch 116/170 => Loss 4.022, Train_accy 72.220, Test_accy 44.440
2022-05-25 00:50:28,998 [bic.py] => bias_correction => Task 8, Epoch 117/170 => Loss 4.025, Train_accy 70.000, Test_accy 44.320
2022-05-25 00:50:30,816 [bic.py] => bias_correction => Task 8, Epoch 118/170 => Loss 4.018, Train_accy 68.330, Test_accy 44.160
2022-05-25 00:50:32,563 [bic.py] => bias_correction => Task 8, Epoch 119/170 => Loss 4.022, Train_accy 72.220, Test_accy 44.200
2022-05-25 00:50:34,400 [bic.py] => bias_correction => Task 8, Epoch 120/170 => Loss 4.012, Train_accy 69.440, Test_accy 44.220
2022-05-25 00:50:36,293 [bic.py] => bias_correction => Task 8, Epoch 121/170 => Loss 4.023, Train_accy 71.110, Test_accy 44.120
2022-05-25 00:50:38,121 [bic.py] => bias_correction => Task 8, Epoch 122/170 => Loss 4.024, Train_accy 70.000, Test_accy 44.170
2022-05-25 00:50:39,935 [bic.py] => bias_correction => Task 8, Epoch 123/170 => Loss 4.002, Train_accy 70.560, Test_accy 44.220
2022-05-25 00:50:41,846 [bic.py] => bias_correction => Task 8, Epoch 124/170 => Loss 4.018, Train_accy 67.780, Test_accy 44.280
2022-05-25 00:50:43,667 [bic.py] => bias_correction => Task 8, Epoch 125/170 => Loss 4.013, Train_accy 71.670, Test_accy 44.260
2022-05-25 00:50:45,417 [bic.py] => bias_correction => Task 8, Epoch 126/170 => Loss 4.008, Train_accy 71.670, Test_accy 44.330
2022-05-25 00:50:47,291 [bic.py] => bias_correction => Task 8, Epoch 127/170 => Loss 4.014, Train_accy 71.110, Test_accy 44.190
2022-05-25 00:50:49,150 [bic.py] => bias_correction => Task 8, Epoch 128/170 => Loss 4.014, Train_accy 69.440, Test_accy 44.280
2022-05-25 00:50:50,959 [bic.py] => bias_correction => Task 8, Epoch 129/170 => Loss 4.015, Train_accy 71.110, Test_accy 44.480
2022-05-25 00:50:52,828 [bic.py] => bias_correction => Task 8, Epoch 130/170 => Loss 4.027, Train_accy 73.890, Test_accy 44.600
2022-05-25 00:50:54,636 [bic.py] => bias_correction => Task 8, Epoch 131/170 => Loss 4.014, Train_accy 71.670, Test_accy 44.530
2022-05-25 00:50:56,496 [bic.py] => bias_correction => Task 8, Epoch 132/170 => Loss 4.024, Train_accy 69.440, Test_accy 44.520
2022-05-25 00:50:58,307 [bic.py] => bias_correction => Task 8, Epoch 133/170 => Loss 3.977, Train_accy 71.110, Test_accy 44.430
2022-05-25 00:51:00,226 [bic.py] => bias_correction => Task 8, Epoch 134/170 => Loss 3.997, Train_accy 71.670, Test_accy 44.570
2022-05-25 00:51:02,106 [bic.py] => bias_correction => Task 8, Epoch 135/170 => Loss 4.024, Train_accy 71.670, Test_accy 44.270
2022-05-25 00:51:03,970 [bic.py] => bias_correction => Task 8, Epoch 136/170 => Loss 3.991, Train_accy 71.110, Test_accy 44.390
2022-05-25 00:51:05,867 [bic.py] => bias_correction => Task 8, Epoch 137/170 => Loss 3.999, Train_accy 70.000, Test_accy 44.270
2022-05-25 00:51:07,715 [bic.py] => bias_correction => Task 8, Epoch 138/170 => Loss 4.000, Train_accy 70.000, Test_accy 44.280
2022-05-25 00:51:09,516 [bic.py] => bias_correction => Task 8, Epoch 139/170 => Loss 4.012, Train_accy 71.670, Test_accy 44.200
2022-05-25 00:51:11,328 [bic.py] => bias_correction => Task 8, Epoch 140/170 => Loss 4.019, Train_accy 70.560, Test_accy 44.230
2022-05-25 00:51:13,089 [bic.py] => bias_correction => Task 8, Epoch 141/170 => Loss 4.029, Train_accy 72.220, Test_accy 44.240
2022-05-25 00:51:14,903 [bic.py] => bias_correction => Task 8, Epoch 142/170 => Loss 4.019, Train_accy 66.110, Test_accy 44.370
2022-05-25 00:51:16,788 [bic.py] => bias_correction => Task 8, Epoch 143/170 => Loss 4.018, Train_accy 70.000, Test_accy 44.330
2022-05-25 00:51:18,709 [bic.py] => bias_correction => Task 8, Epoch 144/170 => Loss 3.995, Train_accy 72.780, Test_accy 44.390
2022-05-25 00:51:20,775 [bic.py] => bias_correction => Task 8, Epoch 145/170 => Loss 4.012, Train_accy 70.560, Test_accy 44.410
2022-05-25 00:51:22,618 [bic.py] => bias_correction => Task 8, Epoch 146/170 => Loss 4.022, Train_accy 71.670, Test_accy 44.520
2022-05-25 00:51:24,506 [bic.py] => bias_correction => Task 8, Epoch 147/170 => Loss 3.995, Train_accy 71.110, Test_accy 44.530
2022-05-25 00:51:26,355 [bic.py] => bias_correction => Task 8, Epoch 148/170 => Loss 4.014, Train_accy 66.670, Test_accy 44.510
2022-05-25 00:51:28,277 [bic.py] => bias_correction => Task 8, Epoch 149/170 => Loss 3.997, Train_accy 69.440, Test_accy 44.400
2022-05-25 00:51:30,220 [bic.py] => bias_correction => Task 8, Epoch 150/170 => Loss 4.021, Train_accy 68.890, Test_accy 44.400
2022-05-25 00:51:32,059 [bic.py] => bias_correction => Task 8, Epoch 151/170 => Loss 4.021, Train_accy 71.110, Test_accy 44.430
2022-05-25 00:51:33,978 [bic.py] => bias_correction => Task 8, Epoch 152/170 => Loss 4.008, Train_accy 73.330, Test_accy 44.470
2022-05-25 00:51:35,934 [bic.py] => bias_correction => Task 8, Epoch 153/170 => Loss 4.019, Train_accy 71.670, Test_accy 44.440
2022-05-25 00:51:37,877 [bic.py] => bias_correction => Task 8, Epoch 154/170 => Loss 4.017, Train_accy 68.890, Test_accy 44.360
2022-05-25 00:51:39,710 [bic.py] => bias_correction => Task 8, Epoch 155/170 => Loss 3.992, Train_accy 69.440, Test_accy 44.360
2022-05-25 00:51:41,636 [bic.py] => bias_correction => Task 8, Epoch 156/170 => Loss 3.992, Train_accy 70.560, Test_accy 44.270
2022-05-25 00:51:43,528 [bic.py] => bias_correction => Task 8, Epoch 157/170 => Loss 4.020, Train_accy 70.560, Test_accy 44.340
2022-05-25 00:51:45,499 [bic.py] => bias_correction => Task 8, Epoch 158/170 => Loss 4.017, Train_accy 73.330, Test_accy 44.370
2022-05-25 00:51:47,444 [bic.py] => bias_correction => Task 8, Epoch 159/170 => Loss 3.983, Train_accy 72.220, Test_accy 44.380
2022-05-25 00:51:49,280 [bic.py] => bias_correction => Task 8, Epoch 160/170 => Loss 3.979, Train_accy 70.560, Test_accy 44.320
2022-05-25 00:51:51,183 [bic.py] => bias_correction => Task 8, Epoch 161/170 => Loss 4.003, Train_accy 68.890, Test_accy 44.470
2022-05-25 00:51:53,036 [bic.py] => bias_correction => Task 8, Epoch 162/170 => Loss 4.027, Train_accy 71.670, Test_accy 44.420
2022-05-25 00:51:54,800 [bic.py] => bias_correction => Task 8, Epoch 163/170 => Loss 4.007, Train_accy 69.440, Test_accy 44.530
2022-05-25 00:51:56,615 [bic.py] => bias_correction => Task 8, Epoch 164/170 => Loss 4.034, Train_accy 70.000, Test_accy 44.540
2022-05-25 00:51:58,584 [bic.py] => bias_correction => Task 8, Epoch 165/170 => Loss 3.969, Train_accy 68.890, Test_accy 44.540
2022-05-25 00:52:00,499 [bic.py] => bias_correction => Task 8, Epoch 166/170 => Loss 4.022, Train_accy 69.440, Test_accy 44.580
2022-05-25 00:52:02,273 [bic.py] => bias_correction => Task 8, Epoch 167/170 => Loss 4.021, Train_accy 71.110, Test_accy 44.490
2022-05-25 00:52:04,097 [bic.py] => bias_correction => Task 8, Epoch 168/170 => Loss 4.025, Train_accy 70.000, Test_accy 44.510
2022-05-25 00:52:05,963 [bic.py] => bias_correction => Task 8, Epoch 169/170 => Loss 4.014, Train_accy 70.560, Test_accy 44.460
2022-05-25 00:52:07,835 [bic.py] => bias_correction => Task 8, Epoch 170/170 => Loss 4.024, Train_accy 71.670, Test_accy 44.520
2022-05-25 00:52:07,836 [base.py] => Reducing exemplars...(22 per classes)
2022-05-25 00:52:23,921 [base.py] => Constructing exemplars...(22 per classes)
2022-05-25 00:52:29,950 [bic.py] => Parameters of bias layer:
2022-05-25 00:52:29,951 [bic.py] => 0 => 1.000, 0.000
2022-05-25 00:52:29,951 [bic.py] => 1 => 0.981, -1.523
2022-05-25 00:52:29,951 [bic.py] => 2 => 0.816, -1.587
2022-05-25 00:52:29,951 [bic.py] => 3 => 0.723, -1.178
2022-05-25 00:52:29,952 [bic.py] => 4 => 0.736, -1.143
2022-05-25 00:52:29,952 [bic.py] => 5 => 0.746, -1.342
2022-05-25 00:52:29,952 [bic.py] => 6 => 0.696, -1.160
2022-05-25 00:52:29,952 [bic.py] => 7 => -0.020, -0.768
2022-05-25 00:52:29,952 [bic.py] => 8 => 0.610, -0.611
2022-05-25 00:52:32,546 [bic.py] => Exemplar size: 1980
2022-05-25 00:52:32,547 [trainer.py] => CNN: {'total': 44.52, '00-09': 56.3, '10-19': 41.4, '20-29': 54.8, '30-39': 42.1, '40-49': 52.5, '50-59': 47.7, '60-69': 53.2, '70-79': 0.0, '80-89': 52.7, 'old': 43.5, 'new': 52.7}
2022-05-25 00:52:32,547 [trainer.py] => NME: {'total': 50.24, '00-09': 53.0, '10-19': 36.9, '20-29': 54.8, '30-39': 41.9, '40-49': 54.4, '50-59': 44.4, '60-69': 55.0, '70-79': 49.2, '80-89': 62.6, 'old': 48.7, 'new': 62.6}
2022-05-25 00:52:32,547 [trainer.py] => CNN top1 curve: [87.5, 75.95, 70.6, 64.53, 62.34, 58.72, 55.69, 47.1, 44.52]
2022-05-25 00:52:32,547 [trainer.py] => CNN top5 curve: [99.3, 95.5, 93.17, 90.3, 89.32, 86.92, 84.71, 73.3, 71.1]
2022-05-25 00:52:32,547 [trainer.py] => NME top1 curve: [88.1, 75.6, 71.27, 64.97, 62.62, 59.18, 57.14, 53.65, 50.24]
2022-05-25 00:52:32,547 [trainer.py] => NME top5 curve: [99.4, 95.4, 93.2, 90.05, 88.58, 86.03, 83.64, 82.11, 78.32]

2022-05-25 00:52:32,548 [trainer.py] => All params: 470022
2022-05-25 00:52:32,548 [trainer.py] => Trainable params: 470022
2022-05-25 00:52:32,549 [bic.py] => Learning on 90-100
2022-05-25 00:52:32,607 [bic.py] => Stage1 dset: 6780, Stage2 dset: 200
2022-05-25 00:52:32,607 [bic.py] => Lambda: 0.900
2022-05-25 00:52:32,629 [bic.py] => Parameters of bias layer:
2022-05-25 00:52:32,630 [bic.py] => 0 => 1.000, 0.000
2022-05-25 00:52:32,630 [bic.py] => 1 => 0.981, -1.523
2022-05-25 00:52:32,630 [bic.py] => 2 => 0.816, -1.587
2022-05-25 00:52:32,630 [bic.py] => 3 => 0.723, -1.178
2022-05-25 00:52:32,630 [bic.py] => 4 => 0.736, -1.143
2022-05-25 00:52:32,630 [bic.py] => 5 => 0.746, -1.342
2022-05-25 00:52:32,630 [bic.py] => 6 => 0.696, -1.160
2022-05-25 00:52:32,630 [bic.py] => 7 => -0.020, -0.768
2022-05-25 00:52:32,630 [bic.py] => 8 => 0.610, -0.611
2022-05-25 00:52:32,630 [bic.py] => 9 => 1.000, 0.000
2022-05-25 00:52:37,462 [bic.py] => training => Task 9, Epoch 1/170 => Loss 3.401, Train_accy 63.420, Test_accy 28.560
2022-05-25 00:52:42,191 [bic.py] => training => Task 9, Epoch 2/170 => Loss 3.332, Train_accy 66.120, Test_accy 25.980
2022-05-25 00:52:47,004 [bic.py] => training => Task 9, Epoch 3/170 => Loss 3.318, Train_accy 72.600, Test_accy 29.650
2022-05-25 00:52:51,860 [bic.py] => training => Task 9, Epoch 4/170 => Loss 3.314, Train_accy 72.860, Test_accy 29.620
2022-05-25 00:52:56,632 [bic.py] => training => Task 9, Epoch 5/170 => Loss 3.305, Train_accy 75.800, Test_accy 31.940
2022-05-25 00:53:01,381 [bic.py] => training => Task 9, Epoch 6/170 => Loss 3.305, Train_accy 74.910, Test_accy 28.290
2022-05-25 00:53:06,226 [bic.py] => training => Task 9, Epoch 7/170 => Loss 3.299, Train_accy 77.910, Test_accy 30.310
2022-05-25 00:53:11,046 [bic.py] => training => Task 9, Epoch 8/170 => Loss 3.293, Train_accy 76.420, Test_accy 28.450
2022-05-25 00:53:16,000 [bic.py] => training => Task 9, Epoch 9/170 => Loss 3.293, Train_accy 79.480, Test_accy 29.380
2022-05-25 00:53:20,756 [bic.py] => training => Task 9, Epoch 10/170 => Loss 3.291, Train_accy 80.040, Test_accy 31.100
2022-05-25 00:53:25,625 [bic.py] => training => Task 9, Epoch 11/170 => Loss 3.289, Train_accy 82.610, Test_accy 34.070
2022-05-25 00:53:30,499 [bic.py] => training => Task 9, Epoch 12/170 => Loss 3.283, Train_accy 80.660, Test_accy 30.440
2022-05-25 00:53:35,273 [bic.py] => training => Task 9, Epoch 13/170 => Loss 3.283, Train_accy 81.170, Test_accy 32.440
2022-05-25 00:53:40,069 [bic.py] => training => Task 9, Epoch 14/170 => Loss 3.284, Train_accy 80.270, Test_accy 28.460
2022-05-25 00:53:44,714 [bic.py] => training => Task 9, Epoch 15/170 => Loss 3.281, Train_accy 81.580, Test_accy 30.670
2022-05-25 00:53:49,486 [bic.py] => training => Task 9, Epoch 16/170 => Loss 3.283, Train_accy 80.810, Test_accy 32.000
2022-05-25 00:53:54,256 [bic.py] => training => Task 9, Epoch 17/170 => Loss 3.277, Train_accy 83.630, Test_accy 33.530
2022-05-25 00:53:58,859 [bic.py] => training => Task 9, Epoch 18/170 => Loss 3.281, Train_accy 83.970, Test_accy 30.850
2022-05-25 00:54:03,628 [bic.py] => training => Task 9, Epoch 19/170 => Loss 3.271, Train_accy 81.980, Test_accy 29.460
2022-05-25 00:54:08,559 [bic.py] => training => Task 9, Epoch 20/170 => Loss 3.271, Train_accy 85.130, Test_accy 32.850
2022-05-25 00:54:13,084 [bic.py] => training => Task 9, Epoch 21/170 => Loss 3.273, Train_accy 83.820, Test_accy 29.500
2022-05-25 00:54:17,902 [bic.py] => training => Task 9, Epoch 22/170 => Loss 3.281, Train_accy 81.050, Test_accy 27.690
2022-05-25 00:54:22,797 [bic.py] => training => Task 9, Epoch 23/170 => Loss 3.280, Train_accy 86.060, Test_accy 32.640
2022-05-25 00:54:27,574 [bic.py] => training => Task 9, Epoch 24/170 => Loss 3.273, Train_accy 82.670, Test_accy 31.070
2022-05-25 00:54:32,412 [bic.py] => training => Task 9, Epoch 25/170 => Loss 3.269, Train_accy 85.780, Test_accy 30.010
2022-05-25 00:54:37,338 [bic.py] => training => Task 9, Epoch 26/170 => Loss 3.272, Train_accy 84.620, Test_accy 29.870
2022-05-25 00:54:42,138 [bic.py] => training => Task 9, Epoch 27/170 => Loss 3.272, Train_accy 84.040, Test_accy 33.110
2022-05-25 00:54:46,915 [bic.py] => training => Task 9, Epoch 28/170 => Loss 3.266, Train_accy 85.130, Test_accy 33.450
2022-05-25 00:54:51,615 [bic.py] => training => Task 9, Epoch 29/170 => Loss 3.267, Train_accy 86.620, Test_accy 34.170
2022-05-25 00:54:56,453 [bic.py] => training => Task 9, Epoch 30/170 => Loss 3.267, Train_accy 87.550, Test_accy 33.180
2022-05-25 00:55:01,257 [bic.py] => training => Task 9, Epoch 31/170 => Loss 3.267, Train_accy 87.060, Test_accy 33.000
2022-05-25 00:55:05,994 [bic.py] => training => Task 9, Epoch 32/170 => Loss 3.270, Train_accy 84.990, Test_accy 34.250
2022-05-25 00:55:10,706 [bic.py] => training => Task 9, Epoch 33/170 => Loss 3.269, Train_accy 82.430, Test_accy 30.280
2022-05-25 00:55:15,472 [bic.py] => training => Task 9, Epoch 34/170 => Loss 3.266, Train_accy 83.380, Test_accy 33.070
2022-05-25 00:55:20,291 [bic.py] => training => Task 9, Epoch 35/170 => Loss 3.272, Train_accy 83.980, Test_accy 31.810
2022-05-25 00:55:25,014 [bic.py] => training => Task 9, Epoch 36/170 => Loss 3.266, Train_accy 86.870, Test_accy 33.260
2022-05-25 00:55:29,772 [bic.py] => training => Task 9, Epoch 37/170 => Loss 3.269, Train_accy 82.980, Test_accy 29.300
2022-05-25 00:55:34,498 [bic.py] => training => Task 9, Epoch 38/170 => Loss 3.261, Train_accy 87.910, Test_accy 33.130
2022-05-25 00:55:39,248 [bic.py] => training => Task 9, Epoch 39/170 => Loss 3.261, Train_accy 88.110, Test_accy 30.650
2022-05-25 00:55:43,952 [bic.py] => training => Task 9, Epoch 40/170 => Loss 3.263, Train_accy 88.580, Test_accy 32.520
2022-05-25 00:55:48,675 [bic.py] => training => Task 9, Epoch 41/170 => Loss 3.265, Train_accy 88.480, Test_accy 33.010
2022-05-25 00:55:53,397 [bic.py] => training => Task 9, Epoch 42/170 => Loss 3.267, Train_accy 88.350, Test_accy 32.900
2022-05-25 00:55:58,121 [bic.py] => training => Task 9, Epoch 43/170 => Loss 3.263, Train_accy 86.700, Test_accy 32.460
2022-05-25 00:56:02,874 [bic.py] => training => Task 9, Epoch 44/170 => Loss 3.269, Train_accy 88.720, Test_accy 34.350
2022-05-25 00:56:07,435 [bic.py] => training => Task 9, Epoch 45/170 => Loss 3.257, Train_accy 88.970, Test_accy 32.540
2022-05-25 00:56:12,362 [bic.py] => training => Task 9, Epoch 46/170 => Loss 3.253, Train_accy 87.140, Test_accy 29.310
2022-05-25 00:56:17,101 [bic.py] => training => Task 9, Epoch 47/170 => Loss 3.258, Train_accy 87.570, Test_accy 30.160
2022-05-25 00:56:21,667 [bic.py] => training => Task 9, Epoch 48/170 => Loss 3.261, Train_accy 87.950, Test_accy 33.580
2022-05-25 00:56:26,405 [bic.py] => training => Task 9, Epoch 49/170 => Loss 3.263, Train_accy 88.160, Test_accy 30.900
2022-05-25 00:56:31,370 [bic.py] => training => Task 9, Epoch 50/170 => Loss 3.263, Train_accy 82.650, Test_accy 27.660
2022-05-25 00:56:36,189 [bic.py] => training => Task 9, Epoch 51/170 => Loss 3.258, Train_accy 89.160, Test_accy 32.050
2022-05-25 00:56:40,884 [bic.py] => training => Task 9, Epoch 52/170 => Loss 3.260, Train_accy 87.940, Test_accy 31.080
2022-05-25 00:56:45,646 [bic.py] => training => Task 9, Epoch 53/170 => Loss 3.256, Train_accy 85.990, Test_accy 30.680
2022-05-25 00:56:50,491 [bic.py] => training => Task 9, Epoch 54/170 => Loss 3.253, Train_accy 88.290, Test_accy 32.510
2022-05-25 00:56:55,301 [bic.py] => training => Task 9, Epoch 55/170 => Loss 3.262, Train_accy 89.130, Test_accy 35.730
2022-05-25 00:57:00,039 [bic.py] => training => Task 9, Epoch 56/170 => Loss 3.262, Train_accy 89.250, Test_accy 32.860
2022-05-25 00:57:04,816 [bic.py] => training => Task 9, Epoch 57/170 => Loss 3.262, Train_accy 78.420, Test_accy 25.890
2022-05-25 00:57:09,618 [bic.py] => training => Task 9, Epoch 58/170 => Loss 3.259, Train_accy 88.260, Test_accy 32.770
2022-05-25 00:57:14,352 [bic.py] => training => Task 9, Epoch 59/170 => Loss 3.258, Train_accy 90.130, Test_accy 35.730
2022-05-25 00:57:19,149 [bic.py] => training => Task 9, Epoch 60/170 => Loss 3.257, Train_accy 88.910, Test_accy 37.170
2022-05-25 00:57:23,927 [bic.py] => training => Task 9, Epoch 61/170 => Loss 3.236, Train_accy 95.150, Test_accy 36.440
2022-05-25 00:57:28,705 [bic.py] => training => Task 9, Epoch 62/170 => Loss 3.219, Train_accy 95.810, Test_accy 37.260
2022-05-25 00:57:33,533 [bic.py] => training => Task 9, Epoch 63/170 => Loss 3.219, Train_accy 95.800, Test_accy 37.130
2022-05-25 00:57:38,348 [bic.py] => training => Task 9, Epoch 64/170 => Loss 3.224, Train_accy 95.930, Test_accy 36.990
2022-05-25 00:57:43,126 [bic.py] => training => Task 9, Epoch 65/170 => Loss 3.219, Train_accy 96.170, Test_accy 37.170
2022-05-25 00:57:47,884 [bic.py] => training => Task 9, Epoch 66/170 => Loss 3.223, Train_accy 96.150, Test_accy 36.930
2022-05-25 00:57:52,626 [bic.py] => training => Task 9, Epoch 67/170 => Loss 3.218, Train_accy 95.800, Test_accy 37.070
2022-05-25 00:57:57,369 [bic.py] => training => Task 9, Epoch 68/170 => Loss 3.217, Train_accy 96.080, Test_accy 37.290
2022-05-25 00:58:02,173 [bic.py] => training => Task 9, Epoch 69/170 => Loss 3.219, Train_accy 96.280, Test_accy 37.600
2022-05-25 00:58:06,908 [bic.py] => training => Task 9, Epoch 70/170 => Loss 3.219, Train_accy 96.370, Test_accy 37.140
2022-05-25 00:58:11,700 [bic.py] => training => Task 9, Epoch 71/170 => Loss 3.216, Train_accy 96.250, Test_accy 36.950
2022-05-25 00:58:16,596 [bic.py] => training => Task 9, Epoch 72/170 => Loss 3.215, Train_accy 96.270, Test_accy 37.560
2022-05-25 00:58:21,445 [bic.py] => training => Task 9, Epoch 73/170 => Loss 3.213, Train_accy 96.140, Test_accy 37.270
2022-05-25 00:58:26,160 [bic.py] => training => Task 9, Epoch 74/170 => Loss 3.214, Train_accy 96.340, Test_accy 37.670
2022-05-25 00:58:30,856 [bic.py] => training => Task 9, Epoch 75/170 => Loss 3.213, Train_accy 96.240, Test_accy 37.740
2022-05-25 00:58:35,785 [bic.py] => training => Task 9, Epoch 76/170 => Loss 3.218, Train_accy 96.140, Test_accy 37.150
2022-05-25 00:58:40,662 [bic.py] => training => Task 9, Epoch 77/170 => Loss 3.215, Train_accy 96.220, Test_accy 37.580
2022-05-25 00:58:45,466 [bic.py] => training => Task 9, Epoch 78/170 => Loss 3.218, Train_accy 96.280, Test_accy 37.590
2022-05-25 00:58:50,031 [bic.py] => training => Task 9, Epoch 79/170 => Loss 3.210, Train_accy 96.340, Test_accy 37.740
2022-05-25 00:58:54,729 [bic.py] => training => Task 9, Epoch 80/170 => Loss 3.214, Train_accy 96.390, Test_accy 37.750
2022-05-25 00:58:59,711 [bic.py] => training => Task 9, Epoch 81/170 => Loss 3.214, Train_accy 96.360, Test_accy 37.060
2022-05-25 00:59:04,478 [bic.py] => training => Task 9, Epoch 82/170 => Loss 3.212, Train_accy 96.310, Test_accy 37.200
2022-05-25 00:59:09,279 [bic.py] => training => Task 9, Epoch 83/170 => Loss 3.213, Train_accy 96.420, Test_accy 37.560
2022-05-25 00:59:14,154 [bic.py] => training => Task 9, Epoch 84/170 => Loss 3.212, Train_accy 96.370, Test_accy 37.590
2022-05-25 00:59:18,893 [bic.py] => training => Task 9, Epoch 85/170 => Loss 3.218, Train_accy 96.430, Test_accy 37.870
2022-05-25 00:59:23,637 [bic.py] => training => Task 9, Epoch 86/170 => Loss 3.210, Train_accy 96.460, Test_accy 37.670
2022-05-25 00:59:28,365 [bic.py] => training => Task 9, Epoch 87/170 => Loss 3.217, Train_accy 96.340, Test_accy 37.400
2022-05-25 00:59:32,926 [bic.py] => training => Task 9, Epoch 88/170 => Loss 3.210, Train_accy 96.590, Test_accy 37.700
2022-05-25 00:59:37,762 [bic.py] => training => Task 9, Epoch 89/170 => Loss 3.216, Train_accy 96.340, Test_accy 37.480
2022-05-25 00:59:42,603 [bic.py] => training => Task 9, Epoch 90/170 => Loss 3.213, Train_accy 96.460, Test_accy 37.570
2022-05-25 00:59:47,506 [bic.py] => training => Task 9, Epoch 91/170 => Loss 3.211, Train_accy 96.500, Test_accy 37.460
2022-05-25 00:59:52,243 [bic.py] => training => Task 9, Epoch 92/170 => Loss 3.210, Train_accy 96.460, Test_accy 37.640
2022-05-25 00:59:57,013 [bic.py] => training => Task 9, Epoch 93/170 => Loss 3.209, Train_accy 96.300, Test_accy 37.180
2022-05-25 01:00:01,748 [bic.py] => training => Task 9, Epoch 94/170 => Loss 3.210, Train_accy 96.390, Test_accy 36.940
2022-05-25 01:00:06,451 [bic.py] => training => Task 9, Epoch 95/170 => Loss 3.211, Train_accy 96.490, Test_accy 37.840
2022-05-25 01:00:11,195 [bic.py] => training => Task 9, Epoch 96/170 => Loss 3.209, Train_accy 96.450, Test_accy 37.190
2022-05-25 01:00:16,095 [bic.py] => training => Task 9, Epoch 97/170 => Loss 3.211, Train_accy 96.420, Test_accy 37.300
2022-05-25 01:00:21,031 [bic.py] => training => Task 9, Epoch 98/170 => Loss 3.213, Train_accy 96.470, Test_accy 37.380
2022-05-25 01:00:25,803 [bic.py] => training => Task 9, Epoch 99/170 => Loss 3.208, Train_accy 96.470, Test_accy 37.120
2022-05-25 01:00:30,651 [bic.py] => training => Task 9, Epoch 100/170 => Loss 3.214, Train_accy 96.550, Test_accy 37.320
2022-05-25 01:00:35,353 [bic.py] => training => Task 9, Epoch 101/170 => Loss 3.211, Train_accy 96.390, Test_accy 37.620
2022-05-25 01:00:40,066 [bic.py] => training => Task 9, Epoch 102/170 => Loss 3.211, Train_accy 96.420, Test_accy 37.640
2022-05-25 01:00:44,946 [bic.py] => training => Task 9, Epoch 103/170 => Loss 3.207, Train_accy 96.520, Test_accy 37.620
2022-05-25 01:00:49,749 [bic.py] => training => Task 9, Epoch 104/170 => Loss 3.212, Train_accy 96.420, Test_accy 37.880
2022-05-25 01:00:54,483 [bic.py] => training => Task 9, Epoch 105/170 => Loss 3.211, Train_accy 96.550, Test_accy 37.550
2022-05-25 01:00:59,338 [bic.py] => training => Task 9, Epoch 106/170 => Loss 3.211, Train_accy 96.470, Test_accy 37.620
2022-05-25 01:01:04,286 [bic.py] => training => Task 9, Epoch 107/170 => Loss 3.208, Train_accy 96.450, Test_accy 37.610
2022-05-25 01:01:09,133 [bic.py] => training => Task 9, Epoch 108/170 => Loss 3.213, Train_accy 96.560, Test_accy 37.540
2022-05-25 01:01:13,819 [bic.py] => training => Task 9, Epoch 109/170 => Loss 3.207, Train_accy 96.550, Test_accy 37.430
2022-05-25 01:01:18,536 [bic.py] => training => Task 9, Epoch 110/170 => Loss 3.210, Train_accy 96.470, Test_accy 37.510
2022-05-25 01:01:23,360 [bic.py] => training => Task 9, Epoch 111/170 => Loss 3.209, Train_accy 96.580, Test_accy 37.570
2022-05-25 01:01:28,185 [bic.py] => training => Task 9, Epoch 112/170 => Loss 3.210, Train_accy 96.420, Test_accy 37.680
2022-05-25 01:01:32,796 [bic.py] => training => Task 9, Epoch 113/170 => Loss 3.213, Train_accy 96.580, Test_accy 37.980
2022-05-25 01:01:37,614 [bic.py] => training => Task 9, Epoch 114/170 => Loss 3.206, Train_accy 96.470, Test_accy 37.730
2022-05-25 01:01:42,404 [bic.py] => training => Task 9, Epoch 115/170 => Loss 3.211, Train_accy 96.500, Test_accy 37.790
2022-05-25 01:01:47,161 [bic.py] => training => Task 9, Epoch 116/170 => Loss 3.207, Train_accy 96.520, Test_accy 37.660
2022-05-25 01:01:51,924 [bic.py] => training => Task 9, Epoch 117/170 => Loss 3.207, Train_accy 96.550, Test_accy 37.660
2022-05-25 01:01:56,820 [bic.py] => training => Task 9, Epoch 118/170 => Loss 3.207, Train_accy 96.450, Test_accy 37.300
2022-05-25 01:02:01,547 [bic.py] => training => Task 9, Epoch 119/170 => Loss 3.209, Train_accy 96.590, Test_accy 37.800
2022-05-25 01:02:06,312 [bic.py] => training => Task 9, Epoch 120/170 => Loss 3.211, Train_accy 96.650, Test_accy 37.670
2022-05-25 01:02:10,913 [bic.py] => training => Task 9, Epoch 121/170 => Loss 3.211, Train_accy 96.590, Test_accy 37.490
2022-05-25 01:02:15,757 [bic.py] => training => Task 9, Epoch 122/170 => Loss 3.210, Train_accy 96.430, Test_accy 37.600
2022-05-25 01:02:20,529 [bic.py] => training => Task 9, Epoch 123/170 => Loss 3.205, Train_accy 96.460, Test_accy 37.550
2022-05-25 01:02:25,325 [bic.py] => training => Task 9, Epoch 124/170 => Loss 3.210, Train_accy 96.520, Test_accy 37.760
2022-05-25 01:02:30,026 [bic.py] => training => Task 9, Epoch 125/170 => Loss 3.207, Train_accy 96.640, Test_accy 37.790
2022-05-25 01:02:34,868 [bic.py] => training => Task 9, Epoch 126/170 => Loss 3.206, Train_accy 96.470, Test_accy 37.730
2022-05-25 01:02:39,673 [bic.py] => training => Task 9, Epoch 127/170 => Loss 3.207, Train_accy 96.420, Test_accy 37.540
2022-05-25 01:02:44,498 [bic.py] => training => Task 9, Epoch 128/170 => Loss 3.210, Train_accy 96.520, Test_accy 37.550
2022-05-25 01:02:49,307 [bic.py] => training => Task 9, Epoch 129/170 => Loss 3.212, Train_accy 96.580, Test_accy 37.870
2022-05-25 01:02:54,126 [bic.py] => training => Task 9, Epoch 130/170 => Loss 3.204, Train_accy 96.530, Test_accy 37.780
2022-05-25 01:02:58,906 [bic.py] => training => Task 9, Epoch 131/170 => Loss 3.213, Train_accy 96.550, Test_accy 37.550
2022-05-25 01:03:03,550 [bic.py] => training => Task 9, Epoch 132/170 => Loss 3.208, Train_accy 96.550, Test_accy 37.810
2022-05-25 01:03:08,207 [bic.py] => training => Task 9, Epoch 133/170 => Loss 3.207, Train_accy 96.640, Test_accy 37.310
2022-05-25 01:03:12,846 [bic.py] => training => Task 9, Epoch 134/170 => Loss 3.215, Train_accy 96.620, Test_accy 37.590
2022-05-25 01:03:17,650 [bic.py] => training => Task 9, Epoch 135/170 => Loss 3.212, Train_accy 96.530, Test_accy 37.790
2022-05-25 01:03:22,413 [bic.py] => training => Task 9, Epoch 136/170 => Loss 3.211, Train_accy 96.430, Test_accy 37.420
2022-05-25 01:03:27,249 [bic.py] => training => Task 9, Epoch 137/170 => Loss 3.207, Train_accy 96.530, Test_accy 37.550
2022-05-25 01:03:31,985 [bic.py] => training => Task 9, Epoch 138/170 => Loss 3.209, Train_accy 96.450, Test_accy 37.280
2022-05-25 01:03:36,857 [bic.py] => training => Task 9, Epoch 139/170 => Loss 3.204, Train_accy 96.550, Test_accy 37.280
2022-05-25 01:03:41,846 [bic.py] => training => Task 9, Epoch 140/170 => Loss 3.213, Train_accy 96.580, Test_accy 37.760
2022-05-25 01:03:46,838 [bic.py] => training => Task 9, Epoch 141/170 => Loss 3.208, Train_accy 96.460, Test_accy 37.740
2022-05-25 01:03:51,674 [bic.py] => training => Task 9, Epoch 142/170 => Loss 3.210, Train_accy 96.530, Test_accy 37.850
2022-05-25 01:03:56,582 [bic.py] => training => Task 9, Epoch 143/170 => Loss 3.211, Train_accy 96.560, Test_accy 37.840
2022-05-25 01:04:01,602 [bic.py] => training => Task 9, Epoch 144/170 => Loss 3.207, Train_accy 96.460, Test_accy 37.480
2022-05-25 01:04:06,508 [bic.py] => training => Task 9, Epoch 145/170 => Loss 3.209, Train_accy 96.590, Test_accy 37.340
2022-05-25 01:04:11,290 [bic.py] => training => Task 9, Epoch 146/170 => Loss 3.206, Train_accy 96.550, Test_accy 37.700
2022-05-25 01:04:16,049 [bic.py] => training => Task 9, Epoch 147/170 => Loss 3.206, Train_accy 96.560, Test_accy 37.500
2022-05-25 01:04:20,874 [bic.py] => training => Task 9, Epoch 148/170 => Loss 3.213, Train_accy 96.460, Test_accy 37.950
2022-05-25 01:04:25,574 [bic.py] => training => Task 9, Epoch 149/170 => Loss 3.209, Train_accy 96.640, Test_accy 37.750
2022-05-25 01:04:30,296 [bic.py] => training => Task 9, Epoch 150/170 => Loss 3.208, Train_accy 96.430, Test_accy 37.520
2022-05-25 01:04:35,014 [bic.py] => training => Task 9, Epoch 151/170 => Loss 3.209, Train_accy 96.670, Test_accy 37.790
2022-05-25 01:04:39,724 [bic.py] => training => Task 9, Epoch 152/170 => Loss 3.207, Train_accy 96.560, Test_accy 37.640
2022-05-25 01:04:44,462 [bic.py] => training => Task 9, Epoch 153/170 => Loss 3.207, Train_accy 96.430, Test_accy 37.260
2022-05-25 01:04:49,300 [bic.py] => training => Task 9, Epoch 154/170 => Loss 3.211, Train_accy 96.490, Test_accy 37.640
2022-05-25 01:04:54,142 [bic.py] => training => Task 9, Epoch 155/170 => Loss 3.207, Train_accy 96.450, Test_accy 37.730
2022-05-25 01:04:58,938 [bic.py] => training => Task 9, Epoch 156/170 => Loss 3.208, Train_accy 96.550, Test_accy 37.550
2022-05-25 01:05:03,720 [bic.py] => training => Task 9, Epoch 157/170 => Loss 3.211, Train_accy 96.520, Test_accy 37.080
2022-05-25 01:05:08,487 [bic.py] => training => Task 9, Epoch 158/170 => Loss 3.208, Train_accy 96.610, Test_accy 37.690
2022-05-25 01:05:13,266 [bic.py] => training => Task 9, Epoch 159/170 => Loss 3.212, Train_accy 96.500, Test_accy 37.840
2022-05-25 01:05:18,157 [bic.py] => training => Task 9, Epoch 160/170 => Loss 3.206, Train_accy 96.490, Test_accy 37.550
2022-05-25 01:05:22,797 [bic.py] => training => Task 9, Epoch 161/170 => Loss 3.207, Train_accy 96.580, Test_accy 37.770
2022-05-25 01:05:27,565 [bic.py] => training => Task 9, Epoch 162/170 => Loss 3.209, Train_accy 96.490, Test_accy 37.480
2022-05-25 01:05:32,350 [bic.py] => training => Task 9, Epoch 163/170 => Loss 3.210, Train_accy 96.370, Test_accy 37.630
2022-05-25 01:05:37,045 [bic.py] => training => Task 9, Epoch 164/170 => Loss 3.214, Train_accy 96.470, Test_accy 37.740
2022-05-25 01:05:41,763 [bic.py] => training => Task 9, Epoch 165/170 => Loss 3.211, Train_accy 96.520, Test_accy 37.670
2022-05-25 01:05:46,529 [bic.py] => training => Task 9, Epoch 166/170 => Loss 3.207, Train_accy 96.590, Test_accy 37.940
2022-05-25 01:05:51,423 [bic.py] => training => Task 9, Epoch 167/170 => Loss 3.209, Train_accy 96.700, Test_accy 37.750
2022-05-25 01:05:56,287 [bic.py] => training => Task 9, Epoch 168/170 => Loss 3.210, Train_accy 96.590, Test_accy 37.820
2022-05-25 01:06:01,184 [bic.py] => training => Task 9, Epoch 169/170 => Loss 3.210, Train_accy 96.420, Test_accy 37.220
2022-05-25 01:06:05,940 [bic.py] => training => Task 9, Epoch 170/170 => Loss 3.211, Train_accy 96.580, Test_accy 37.490
2022-05-25 01:06:07,972 [bic.py] => bias_correction => Task 9, Epoch 1/170 => Loss 4.242, Train_accy 59.500, Test_accy 39.460
2022-05-25 01:06:09,864 [bic.py] => bias_correction => Task 9, Epoch 2/170 => Loss 4.216, Train_accy 68.000, Test_accy 43.140
2022-05-25 01:06:11,841 [bic.py] => bias_correction => Task 9, Epoch 3/170 => Loss 4.132, Train_accy 70.500, Test_accy 44.270
2022-05-25 01:06:13,751 [bic.py] => bias_correction => Task 9, Epoch 4/170 => Loss 4.167, Train_accy 69.000, Test_accy 41.690
2022-05-25 01:06:15,602 [bic.py] => bias_correction => Task 9, Epoch 5/170 => Loss 4.156, Train_accy 70.500, Test_accy 40.670
2022-05-25 01:06:17,505 [bic.py] => bias_correction => Task 9, Epoch 6/170 => Loss 4.147, Train_accy 67.000, Test_accy 40.580
2022-05-25 01:06:19,437 [bic.py] => bias_correction => Task 9, Epoch 7/170 => Loss 4.161, Train_accy 66.000, Test_accy 40.490
2022-05-25 01:06:21,382 [bic.py] => bias_correction => Task 9, Epoch 8/170 => Loss 4.167, Train_accy 65.000, Test_accy 40.420
2022-05-25 01:06:23,269 [bic.py] => bias_correction => Task 9, Epoch 9/170 => Loss 4.170, Train_accy 69.500, Test_accy 40.390
2022-05-25 01:06:25,123 [bic.py] => bias_correction => Task 9, Epoch 10/170 => Loss 4.159, Train_accy 68.500, Test_accy 40.200
2022-05-25 01:06:27,093 [bic.py] => bias_correction => Task 9, Epoch 11/170 => Loss 4.163, Train_accy 69.000, Test_accy 40.230
2022-05-25 01:06:29,003 [bic.py] => bias_correction => Task 9, Epoch 12/170 => Loss 4.162, Train_accy 68.000, Test_accy 40.230
2022-05-25 01:06:30,936 [bic.py] => bias_correction => Task 9, Epoch 13/170 => Loss 4.160, Train_accy 64.500, Test_accy 40.190
2022-05-25 01:06:32,872 [bic.py] => bias_correction => Task 9, Epoch 14/170 => Loss 4.183, Train_accy 65.500, Test_accy 40.290
2022-05-25 01:06:34,844 [bic.py] => bias_correction => Task 9, Epoch 15/170 => Loss 4.140, Train_accy 67.000, Test_accy 40.260
2022-05-25 01:06:36,847 [bic.py] => bias_correction => Task 9, Epoch 16/170 => Loss 4.164, Train_accy 64.500, Test_accy 40.220
2022-05-25 01:06:38,961 [bic.py] => bias_correction => Task 9, Epoch 17/170 => Loss 4.166, Train_accy 67.000, Test_accy 40.160
2022-05-25 01:06:40,840 [bic.py] => bias_correction => Task 9, Epoch 18/170 => Loss 4.152, Train_accy 67.000, Test_accy 40.070
2022-05-25 01:06:42,746 [bic.py] => bias_correction => Task 9, Epoch 19/170 => Loss 4.175, Train_accy 65.000, Test_accy 40.040
2022-05-25 01:06:44,633 [bic.py] => bias_correction => Task 9, Epoch 20/170 => Loss 4.167, Train_accy 65.500, Test_accy 40.010
2022-05-25 01:06:46,562 [bic.py] => bias_correction => Task 9, Epoch 21/170 => Loss 4.162, Train_accy 68.000, Test_accy 40.020
2022-05-25 01:06:48,480 [bic.py] => bias_correction => Task 9, Epoch 22/170 => Loss 4.167, Train_accy 69.000, Test_accy 39.920
2022-05-25 01:06:50,469 [bic.py] => bias_correction => Task 9, Epoch 23/170 => Loss 4.163, Train_accy 64.500, Test_accy 39.940
2022-05-25 01:06:52,519 [bic.py] => bias_correction => Task 9, Epoch 24/170 => Loss 4.173, Train_accy 64.500, Test_accy 39.970
2022-05-25 01:06:54,460 [bic.py] => bias_correction => Task 9, Epoch 25/170 => Loss 4.170, Train_accy 65.500, Test_accy 39.990
2022-05-25 01:06:56,300 [bic.py] => bias_correction => Task 9, Epoch 26/170 => Loss 4.157, Train_accy 67.000, Test_accy 40.020
2022-05-25 01:06:58,264 [bic.py] => bias_correction => Task 9, Epoch 27/170 => Loss 4.170, Train_accy 65.500, Test_accy 39.940
2022-05-25 01:07:00,213 [bic.py] => bias_correction => Task 9, Epoch 28/170 => Loss 4.157, Train_accy 63.000, Test_accy 39.840
2022-05-25 01:07:02,246 [bic.py] => bias_correction => Task 9, Epoch 29/170 => Loss 4.153, Train_accy 66.000, Test_accy 40.000
2022-05-25 01:07:04,274 [bic.py] => bias_correction => Task 9, Epoch 30/170 => Loss 4.169, Train_accy 64.500, Test_accy 39.940
2022-05-25 01:07:06,249 [bic.py] => bias_correction => Task 9, Epoch 31/170 => Loss 4.151, Train_accy 65.000, Test_accy 40.080
2022-05-25 01:07:08,190 [bic.py] => bias_correction => Task 9, Epoch 32/170 => Loss 4.153, Train_accy 69.000, Test_accy 40.050
2022-05-25 01:07:10,050 [bic.py] => bias_correction => Task 9, Epoch 33/170 => Loss 4.146, Train_accy 68.000, Test_accy 40.040
2022-05-25 01:07:12,012 [bic.py] => bias_correction => Task 9, Epoch 34/170 => Loss 4.174, Train_accy 65.000, Test_accy 39.960
2022-05-25 01:07:14,009 [bic.py] => bias_correction => Task 9, Epoch 35/170 => Loss 4.154, Train_accy 66.500, Test_accy 40.000
2022-05-25 01:07:15,956 [bic.py] => bias_correction => Task 9, Epoch 36/170 => Loss 4.151, Train_accy 64.500, Test_accy 40.010
2022-05-25 01:07:17,890 [bic.py] => bias_correction => Task 9, Epoch 37/170 => Loss 4.154, Train_accy 66.500, Test_accy 40.010
2022-05-25 01:07:19,752 [bic.py] => bias_correction => Task 9, Epoch 38/170 => Loss 4.175, Train_accy 65.500, Test_accy 40.010
2022-05-25 01:07:21,701 [bic.py] => bias_correction => Task 9, Epoch 39/170 => Loss 4.163, Train_accy 67.500, Test_accy 40.170
2022-05-25 01:07:23,608 [bic.py] => bias_correction => Task 9, Epoch 40/170 => Loss 4.155, Train_accy 67.500, Test_accy 40.120
2022-05-25 01:07:25,543 [bic.py] => bias_correction => Task 9, Epoch 41/170 => Loss 4.171, Train_accy 65.000, Test_accy 40.040
2022-05-25 01:07:27,508 [bic.py] => bias_correction => Task 9, Epoch 42/170 => Loss 4.164, Train_accy 65.500, Test_accy 40.060
2022-05-25 01:07:29,367 [bic.py] => bias_correction => Task 9, Epoch 43/170 => Loss 4.175, Train_accy 66.500, Test_accy 39.970
2022-05-25 01:07:31,283 [bic.py] => bias_correction => Task 9, Epoch 44/170 => Loss 4.154, Train_accy 65.500, Test_accy 40.060
2022-05-25 01:07:33,169 [bic.py] => bias_correction => Task 9, Epoch 45/170 => Loss 4.160, Train_accy 65.000, Test_accy 39.960
2022-05-25 01:07:35,059 [bic.py] => bias_correction => Task 9, Epoch 46/170 => Loss 4.142, Train_accy 64.500, Test_accy 39.930
2022-05-25 01:07:36,983 [bic.py] => bias_correction => Task 9, Epoch 47/170 => Loss 4.172, Train_accy 66.000, Test_accy 40.030
2022-05-25 01:07:38,922 [bic.py] => bias_correction => Task 9, Epoch 48/170 => Loss 4.160, Train_accy 66.500, Test_accy 40.000
2022-05-25 01:07:40,815 [bic.py] => bias_correction => Task 9, Epoch 49/170 => Loss 4.164, Train_accy 66.000, Test_accy 39.940
2022-05-25 01:07:42,744 [bic.py] => bias_correction => Task 9, Epoch 50/170 => Loss 4.175, Train_accy 66.000, Test_accy 39.900
2022-05-25 01:07:44,668 [bic.py] => bias_correction => Task 9, Epoch 51/170 => Loss 4.171, Train_accy 67.000, Test_accy 39.800
2022-05-25 01:07:46,636 [bic.py] => bias_correction => Task 9, Epoch 52/170 => Loss 4.153, Train_accy 65.500, Test_accy 39.900
2022-05-25 01:07:48,505 [bic.py] => bias_correction => Task 9, Epoch 53/170 => Loss 4.157, Train_accy 65.500, Test_accy 39.980
2022-05-25 01:07:50,429 [bic.py] => bias_correction => Task 9, Epoch 54/170 => Loss 4.147, Train_accy 66.500, Test_accy 40.000
2022-05-25 01:07:52,423 [bic.py] => bias_correction => Task 9, Epoch 55/170 => Loss 4.160, Train_accy 66.000, Test_accy 39.990
2022-05-25 01:07:54,337 [bic.py] => bias_correction => Task 9, Epoch 56/170 => Loss 4.136, Train_accy 67.500, Test_accy 40.070
2022-05-25 01:07:56,156 [bic.py] => bias_correction => Task 9, Epoch 57/170 => Loss 4.168, Train_accy 66.500, Test_accy 40.120
2022-05-25 01:07:58,009 [bic.py] => bias_correction => Task 9, Epoch 58/170 => Loss 4.156, Train_accy 65.500, Test_accy 40.230
2022-05-25 01:07:59,922 [bic.py] => bias_correction => Task 9, Epoch 59/170 => Loss 4.168, Train_accy 65.500, Test_accy 40.110
2022-05-25 01:08:01,840 [bic.py] => bias_correction => Task 9, Epoch 60/170 => Loss 4.147, Train_accy 66.500, Test_accy 40.120
2022-05-25 01:08:03,771 [bic.py] => bias_correction => Task 9, Epoch 61/170 => Loss 4.166, Train_accy 65.500, Test_accy 40.060
2022-05-25 01:08:05,800 [bic.py] => bias_correction => Task 9, Epoch 62/170 => Loss 4.172, Train_accy 68.000, Test_accy 40.020
2022-05-25 01:08:07,741 [bic.py] => bias_correction => Task 9, Epoch 63/170 => Loss 4.168, Train_accy 66.500, Test_accy 40.060
2022-05-25 01:08:09,710 [bic.py] => bias_correction => Task 9, Epoch 64/170 => Loss 4.153, Train_accy 68.000, Test_accy 40.080
2022-05-25 01:08:11,582 [bic.py] => bias_correction => Task 9, Epoch 65/170 => Loss 4.147, Train_accy 65.000, Test_accy 40.080
2022-05-25 01:08:13,438 [bic.py] => bias_correction => Task 9, Epoch 66/170 => Loss 4.166, Train_accy 66.000, Test_accy 40.100
2022-05-25 01:08:15,279 [bic.py] => bias_correction => Task 9, Epoch 67/170 => Loss 4.160, Train_accy 68.500, Test_accy 40.170
2022-05-25 01:08:17,122 [bic.py] => bias_correction => Task 9, Epoch 68/170 => Loss 4.149, Train_accy 66.000, Test_accy 40.030
2022-05-25 01:08:19,050 [bic.py] => bias_correction => Task 9, Epoch 69/170 => Loss 4.167, Train_accy 67.500, Test_accy 40.070
2022-05-25 01:08:21,085 [bic.py] => bias_correction => Task 9, Epoch 70/170 => Loss 4.170, Train_accy 66.500, Test_accy 40.170
2022-05-25 01:08:23,070 [bic.py] => bias_correction => Task 9, Epoch 71/170 => Loss 4.166, Train_accy 67.500, Test_accy 40.050
2022-05-25 01:08:25,092 [bic.py] => bias_correction => Task 9, Epoch 72/170 => Loss 4.170, Train_accy 68.500, Test_accy 40.100
2022-05-25 01:08:27,044 [bic.py] => bias_correction => Task 9, Epoch 73/170 => Loss 4.156, Train_accy 67.000, Test_accy 40.050
2022-05-25 01:08:29,017 [bic.py] => bias_correction => Task 9, Epoch 74/170 => Loss 4.156, Train_accy 69.000, Test_accy 40.110
2022-05-25 01:08:30,957 [bic.py] => bias_correction => Task 9, Epoch 75/170 => Loss 4.149, Train_accy 70.500, Test_accy 40.230
2022-05-25 01:08:32,878 [bic.py] => bias_correction => Task 9, Epoch 76/170 => Loss 4.166, Train_accy 67.500, Test_accy 40.210
2022-05-25 01:08:34,768 [bic.py] => bias_correction => Task 9, Epoch 77/170 => Loss 4.162, Train_accy 66.500, Test_accy 40.240
2022-05-25 01:08:36,714 [bic.py] => bias_correction => Task 9, Epoch 78/170 => Loss 4.163, Train_accy 69.000, Test_accy 40.290
2022-05-25 01:08:38,622 [bic.py] => bias_correction => Task 9, Epoch 79/170 => Loss 4.145, Train_accy 64.500, Test_accy 40.230
2022-05-25 01:08:40,559 [bic.py] => bias_correction => Task 9, Epoch 80/170 => Loss 4.169, Train_accy 65.500, Test_accy 40.210
2022-05-25 01:08:42,494 [bic.py] => bias_correction => Task 9, Epoch 81/170 => Loss 4.157, Train_accy 66.500, Test_accy 40.320
2022-05-25 01:08:44,298 [bic.py] => bias_correction => Task 9, Epoch 82/170 => Loss 4.170, Train_accy 66.000, Test_accy 40.370
2022-05-25 01:08:46,189 [bic.py] => bias_correction => Task 9, Epoch 83/170 => Loss 4.158, Train_accy 69.000, Test_accy 40.430
2022-05-25 01:08:48,147 [bic.py] => bias_correction => Task 9, Epoch 84/170 => Loss 4.134, Train_accy 66.000, Test_accy 40.500
2022-05-25 01:08:50,060 [bic.py] => bias_correction => Task 9, Epoch 85/170 => Loss 4.156, Train_accy 67.000, Test_accy 40.520
2022-05-25 01:08:52,046 [bic.py] => bias_correction => Task 9, Epoch 86/170 => Loss 4.161, Train_accy 65.500, Test_accy 40.670
2022-05-25 01:08:53,998 [bic.py] => bias_correction => Task 9, Epoch 87/170 => Loss 4.151, Train_accy 66.000, Test_accy 40.800
2022-05-25 01:08:55,916 [bic.py] => bias_correction => Task 9, Epoch 88/170 => Loss 4.153, Train_accy 65.500, Test_accy 40.980
2022-05-25 01:08:57,895 [bic.py] => bias_correction => Task 9, Epoch 89/170 => Loss 4.153, Train_accy 64.000, Test_accy 41.250
2022-05-25 01:08:59,796 [bic.py] => bias_correction => Task 9, Epoch 90/170 => Loss 4.150, Train_accy 66.000, Test_accy 41.440
2022-05-25 01:09:01,726 [bic.py] => bias_correction => Task 9, Epoch 91/170 => Loss 4.158, Train_accy 66.000, Test_accy 41.560
2022-05-25 01:09:03,739 [bic.py] => bias_correction => Task 9, Epoch 92/170 => Loss 4.158, Train_accy 68.500, Test_accy 41.780
2022-05-25 01:09:05,671 [bic.py] => bias_correction => Task 9, Epoch 93/170 => Loss 4.145, Train_accy 69.000, Test_accy 42.010
2022-05-25 01:09:07,688 [bic.py] => bias_correction => Task 9, Epoch 94/170 => Loss 4.161, Train_accy 69.500, Test_accy 42.320
2022-05-25 01:09:09,558 [bic.py] => bias_correction => Task 9, Epoch 95/170 => Loss 4.143, Train_accy 66.500, Test_accy 42.710
2022-05-25 01:09:11,467 [bic.py] => bias_correction => Task 9, Epoch 96/170 => Loss 4.130, Train_accy 68.000, Test_accy 42.820
2022-05-25 01:09:13,460 [bic.py] => bias_correction => Task 9, Epoch 97/170 => Loss 4.148, Train_accy 73.500, Test_accy 43.170
2022-05-25 01:09:15,315 [bic.py] => bias_correction => Task 9, Epoch 98/170 => Loss 4.148, Train_accy 70.000, Test_accy 43.520
2022-05-25 01:09:17,229 [bic.py] => bias_correction => Task 9, Epoch 99/170 => Loss 4.161, Train_accy 71.000, Test_accy 43.780
2022-05-25 01:09:19,254 [bic.py] => bias_correction => Task 9, Epoch 100/170 => Loss 4.125, Train_accy 73.500, Test_accy 43.940
2022-05-25 01:09:21,129 [bic.py] => bias_correction => Task 9, Epoch 101/170 => Loss 4.127, Train_accy 72.500, Test_accy 44.010
2022-05-25 01:09:23,048 [bic.py] => bias_correction => Task 9, Epoch 102/170 => Loss 4.118, Train_accy 69.000, Test_accy 43.910
2022-05-25 01:09:24,927 [bic.py] => bias_correction => Task 9, Epoch 103/170 => Loss 4.134, Train_accy 70.500, Test_accy 43.990
2022-05-25 01:09:26,822 [bic.py] => bias_correction => Task 9, Epoch 104/170 => Loss 4.121, Train_accy 69.000, Test_accy 44.010
2022-05-25 01:09:28,661 [bic.py] => bias_correction => Task 9, Epoch 105/170 => Loss 4.147, Train_accy 73.000, Test_accy 44.030
2022-05-25 01:09:30,553 [bic.py] => bias_correction => Task 9, Epoch 106/170 => Loss 4.135, Train_accy 71.500, Test_accy 44.030
2022-05-25 01:09:32,552 [bic.py] => bias_correction => Task 9, Epoch 107/170 => Loss 4.136, Train_accy 68.500, Test_accy 44.040
2022-05-25 01:09:34,607 [bic.py] => bias_correction => Task 9, Epoch 108/170 => Loss 4.128, Train_accy 69.000, Test_accy 44.150
2022-05-25 01:09:36,477 [bic.py] => bias_correction => Task 9, Epoch 109/170 => Loss 4.154, Train_accy 74.000, Test_accy 44.010
2022-05-25 01:09:38,382 [bic.py] => bias_correction => Task 9, Epoch 110/170 => Loss 4.116, Train_accy 69.500, Test_accy 44.090
2022-05-25 01:09:40,349 [bic.py] => bias_correction => Task 9, Epoch 111/170 => Loss 4.122, Train_accy 73.000, Test_accy 44.220
2022-05-25 01:09:42,190 [bic.py] => bias_correction => Task 9, Epoch 112/170 => Loss 4.119, Train_accy 72.500, Test_accy 44.230
2022-05-25 01:09:44,176 [bic.py] => bias_correction => Task 9, Epoch 113/170 => Loss 4.136, Train_accy 70.500, Test_accy 44.290
2022-05-25 01:09:46,071 [bic.py] => bias_correction => Task 9, Epoch 114/170 => Loss 4.131, Train_accy 71.000, Test_accy 44.150
2022-05-25 01:09:48,019 [bic.py] => bias_correction => Task 9, Epoch 115/170 => Loss 4.129, Train_accy 72.000, Test_accy 44.080
2022-05-25 01:09:50,043 [bic.py] => bias_correction => Task 9, Epoch 116/170 => Loss 4.134, Train_accy 72.000, Test_accy 44.160
2022-05-25 01:09:52,017 [bic.py] => bias_correction => Task 9, Epoch 117/170 => Loss 4.138, Train_accy 68.000, Test_accy 44.090
2022-05-25 01:09:53,969 [bic.py] => bias_correction => Task 9, Epoch 118/170 => Loss 4.149, Train_accy 68.500, Test_accy 44.080
2022-05-25 01:09:56,056 [bic.py] => bias_correction => Task 9, Epoch 119/170 => Loss 4.129, Train_accy 71.000, Test_accy 44.100
2022-05-25 01:09:58,061 [bic.py] => bias_correction => Task 9, Epoch 120/170 => Loss 4.130, Train_accy 73.500, Test_accy 44.240
2022-05-25 01:10:00,046 [bic.py] => bias_correction => Task 9, Epoch 121/170 => Loss 4.118, Train_accy 72.000, Test_accy 44.100
2022-05-25 01:10:01,944 [bic.py] => bias_correction => Task 9, Epoch 122/170 => Loss 4.123, Train_accy 72.000, Test_accy 44.160
2022-05-25 01:10:03,887 [bic.py] => bias_correction => Task 9, Epoch 123/170 => Loss 4.121, Train_accy 72.500, Test_accy 44.120
2022-05-25 01:10:05,804 [bic.py] => bias_correction => Task 9, Epoch 124/170 => Loss 4.141, Train_accy 72.500, Test_accy 44.130
2022-05-25 01:10:07,825 [bic.py] => bias_correction => Task 9, Epoch 125/170 => Loss 4.118, Train_accy 73.500, Test_accy 44.110
2022-05-25 01:10:09,866 [bic.py] => bias_correction => Task 9, Epoch 126/170 => Loss 4.140, Train_accy 71.500, Test_accy 44.170
2022-05-25 01:10:11,788 [bic.py] => bias_correction => Task 9, Epoch 127/170 => Loss 4.127, Train_accy 70.000, Test_accy 44.230
2022-05-25 01:10:13,736 [bic.py] => bias_correction => Task 9, Epoch 128/170 => Loss 4.127, Train_accy 71.500, Test_accy 44.330
2022-05-25 01:10:15,638 [bic.py] => bias_correction => Task 9, Epoch 129/170 => Loss 4.126, Train_accy 72.000, Test_accy 44.330
2022-05-25 01:10:17,552 [bic.py] => bias_correction => Task 9, Epoch 130/170 => Loss 4.123, Train_accy 70.500, Test_accy 44.300
2022-05-25 01:10:19,513 [bic.py] => bias_correction => Task 9, Epoch 131/170 => Loss 4.125, Train_accy 72.500, Test_accy 44.270
2022-05-25 01:10:21,381 [bic.py] => bias_correction => Task 9, Epoch 132/170 => Loss 4.121, Train_accy 71.500, Test_accy 44.320
2022-05-25 01:10:23,285 [bic.py] => bias_correction => Task 9, Epoch 133/170 => Loss 4.115, Train_accy 72.500, Test_accy 44.260
2022-05-25 01:10:25,253 [bic.py] => bias_correction => Task 9, Epoch 134/170 => Loss 4.157, Train_accy 70.500, Test_accy 44.170
2022-05-25 01:10:27,113 [bic.py] => bias_correction => Task 9, Epoch 135/170 => Loss 4.103, Train_accy 70.500, Test_accy 44.200
2022-05-25 01:10:28,916 [bic.py] => bias_correction => Task 9, Epoch 136/170 => Loss 4.120, Train_accy 73.500, Test_accy 44.160
2022-05-25 01:10:30,827 [bic.py] => bias_correction => Task 9, Epoch 137/170 => Loss 4.125, Train_accy 71.500, Test_accy 44.170
2022-05-25 01:10:32,685 [bic.py] => bias_correction => Task 9, Epoch 138/170 => Loss 4.132, Train_accy 71.500, Test_accy 44.130
2022-05-25 01:10:34,565 [bic.py] => bias_correction => Task 9, Epoch 139/170 => Loss 4.121, Train_accy 73.500, Test_accy 44.270
2022-05-25 01:10:36,473 [bic.py] => bias_correction => Task 9, Epoch 140/170 => Loss 4.115, Train_accy 72.500, Test_accy 44.280
2022-05-25 01:10:38,444 [bic.py] => bias_correction => Task 9, Epoch 141/170 => Loss 4.149, Train_accy 68.500, Test_accy 44.270
2022-05-25 01:10:40,408 [bic.py] => bias_correction => Task 9, Epoch 142/170 => Loss 4.137, Train_accy 72.500, Test_accy 44.270
2022-05-25 01:10:42,352 [bic.py] => bias_correction => Task 9, Epoch 143/170 => Loss 4.130, Train_accy 71.500, Test_accy 44.270
2022-05-25 01:10:44,233 [bic.py] => bias_correction => Task 9, Epoch 144/170 => Loss 4.130, Train_accy 71.000, Test_accy 44.380
2022-05-25 01:10:46,106 [bic.py] => bias_correction => Task 9, Epoch 145/170 => Loss 4.126, Train_accy 72.500, Test_accy 44.240
2022-05-25 01:10:48,042 [bic.py] => bias_correction => Task 9, Epoch 146/170 => Loss 4.121, Train_accy 69.500, Test_accy 44.330
2022-05-25 01:10:49,938 [bic.py] => bias_correction => Task 9, Epoch 147/170 => Loss 4.135, Train_accy 72.000, Test_accy 44.290
2022-05-25 01:10:51,823 [bic.py] => bias_correction => Task 9, Epoch 148/170 => Loss 4.124, Train_accy 72.000, Test_accy 44.230
2022-05-25 01:10:53,706 [bic.py] => bias_correction => Task 9, Epoch 149/170 => Loss 4.134, Train_accy 71.000, Test_accy 44.380
2022-05-25 01:10:55,587 [bic.py] => bias_correction => Task 9, Epoch 150/170 => Loss 4.129, Train_accy 70.000, Test_accy 44.270
2022-05-25 01:10:57,598 [bic.py] => bias_correction => Task 9, Epoch 151/170 => Loss 4.133, Train_accy 74.000, Test_accy 44.280
2022-05-25 01:10:59,542 [bic.py] => bias_correction => Task 9, Epoch 152/170 => Loss 4.128, Train_accy 70.500, Test_accy 44.220
2022-05-25 01:11:01,416 [bic.py] => bias_correction => Task 9, Epoch 153/170 => Loss 4.125, Train_accy 72.000, Test_accy 44.090
2022-05-25 01:11:03,307 [bic.py] => bias_correction => Task 9, Epoch 154/170 => Loss 4.142, Train_accy 70.000, Test_accy 44.190
2022-05-25 01:11:05,211 [bic.py] => bias_correction => Task 9, Epoch 155/170 => Loss 4.126, Train_accy 70.500, Test_accy 44.230
2022-05-25 01:11:07,119 [bic.py] => bias_correction => Task 9, Epoch 156/170 => Loss 4.131, Train_accy 74.500, Test_accy 44.280
2022-05-25 01:11:09,053 [bic.py] => bias_correction => Task 9, Epoch 157/170 => Loss 4.131, Train_accy 75.000, Test_accy 44.310
2022-05-25 01:11:10,943 [bic.py] => bias_correction => Task 9, Epoch 158/170 => Loss 4.100, Train_accy 74.000, Test_accy 44.320
2022-05-25 01:11:12,908 [bic.py] => bias_correction => Task 9, Epoch 159/170 => Loss 4.124, Train_accy 71.500, Test_accy 44.250
2022-05-25 01:11:14,852 [bic.py] => bias_correction => Task 9, Epoch 160/170 => Loss 4.145, Train_accy 71.000, Test_accy 44.330
2022-05-25 01:11:16,832 [bic.py] => bias_correction => Task 9, Epoch 161/170 => Loss 4.123, Train_accy 70.500, Test_accy 44.410
2022-05-25 01:11:18,749 [bic.py] => bias_correction => Task 9, Epoch 162/170 => Loss 4.142, Train_accy 72.500, Test_accy 44.240
2022-05-25 01:11:20,625 [bic.py] => bias_correction => Task 9, Epoch 163/170 => Loss 4.121, Train_accy 73.000, Test_accy 44.120
2022-05-25 01:11:22,579 [bic.py] => bias_correction => Task 9, Epoch 164/170 => Loss 4.138, Train_accy 70.500, Test_accy 44.170
2022-05-25 01:11:24,560 [bic.py] => bias_correction => Task 9, Epoch 165/170 => Loss 4.139, Train_accy 68.500, Test_accy 44.230
2022-05-25 01:11:26,485 [bic.py] => bias_correction => Task 9, Epoch 166/170 => Loss 4.124, Train_accy 71.000, Test_accy 44.220
2022-05-25 01:11:28,543 [bic.py] => bias_correction => Task 9, Epoch 167/170 => Loss 4.116, Train_accy 72.000, Test_accy 44.270
2022-05-25 01:11:30,549 [bic.py] => bias_correction => Task 9, Epoch 168/170 => Loss 4.141, Train_accy 71.500, Test_accy 44.240
2022-05-25 01:11:32,510 [bic.py] => bias_correction => Task 9, Epoch 169/170 => Loss 4.129, Train_accy 72.500, Test_accy 44.300
2022-05-25 01:11:34,401 [bic.py] => bias_correction => Task 9, Epoch 170/170 => Loss 4.124, Train_accy 73.000, Test_accy 44.290
2022-05-25 01:11:34,402 [base.py] => Reducing exemplars...(20 per classes)
2022-05-25 01:11:52,030 [base.py] => Constructing exemplars...(20 per classes)
2022-05-25 01:11:57,295 [bic.py] => Parameters of bias layer:
2022-05-25 01:11:57,296 [bic.py] => 0 => 1.000, 0.000
2022-05-25 01:11:57,296 [bic.py] => 1 => 0.981, -1.523
2022-05-25 01:11:57,296 [bic.py] => 2 => 0.816, -1.587
2022-05-25 01:11:57,296 [bic.py] => 3 => 0.723, -1.178
2022-05-25 01:11:57,297 [bic.py] => 4 => 0.736, -1.143
2022-05-25 01:11:57,297 [bic.py] => 5 => 0.746, -1.342
2022-05-25 01:11:57,297 [bic.py] => 6 => 0.696, -1.160
2022-05-25 01:11:57,297 [bic.py] => 7 => -0.020, -0.768
2022-05-25 01:11:57,297 [bic.py] => 8 => 0.610, -0.611
2022-05-25 01:11:57,297 [bic.py] => 9 => 0.580, -0.691
2022-05-25 01:11:59,695 [bic.py] => Exemplar size: 2000
2022-05-25 01:11:59,695 [trainer.py] => CNN: {'total': 44.29, '00-09': 55.4, '10-19': 38.1, '20-29': 51.6, '30-39': 39.6, '40-49': 53.1, '50-59': 46.7, '60-69': 53.8, '70-79': 0.0, '80-89': 46.8, '90-99': 57.8, 'old': 42.79, 'new': 57.8}
2022-05-25 01:11:59,695 [trainer.py] => NME: {'total': 48.4, '00-09': 51.5, '10-19': 35.4, '20-29': 51.3, '30-39': 39.9, '40-49': 52.2, '50-59': 41.0, '60-69': 53.4, '70-79': 43.0, '80-89': 57.2, '90-99': 59.1, 'old': 47.21, 'new': 59.1}
2022-05-25 01:11:59,695 [trainer.py] => CNN top1 curve: [87.5, 75.95, 70.6, 64.53, 62.34, 58.72, 55.69, 47.1, 44.52, 44.29]
2022-05-25 01:11:59,695 [trainer.py] => CNN top5 curve: [99.3, 95.5, 93.17, 90.3, 89.32, 86.92, 84.71, 73.3, 71.1, 70.55]
2022-05-25 01:11:59,695 [trainer.py] => NME top1 curve: [88.1, 75.6, 71.27, 64.97, 62.62, 59.18, 57.14, 53.65, 50.24, 48.4]
2022-05-25 01:11:59,696 [trainer.py] => NME top5 curve: [99.4, 95.4, 93.2, 90.05, 88.58, 86.03, 83.64, 82.11, 78.32, 76.61]

