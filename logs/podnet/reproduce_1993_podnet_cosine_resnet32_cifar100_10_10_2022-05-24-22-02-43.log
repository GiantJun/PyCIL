2022-05-24 22:02:43,353 [trainer.py] => config: exps/podnet.json
2022-05-24 22:02:43,354 [trainer.py] => prefix: reproduce
2022-05-24 22:02:43,354 [trainer.py] => dataset: cifar100
2022-05-24 22:02:43,354 [trainer.py] => memory_size: 2000
2022-05-24 22:02:43,354 [trainer.py] => memory_per_class: 20
2022-05-24 22:02:43,354 [trainer.py] => fixed_memory: False
2022-05-24 22:02:43,354 [trainer.py] => shuffle: True
2022-05-24 22:02:43,354 [trainer.py] => init_cls: 10
2022-05-24 22:02:43,354 [trainer.py] => increment: 10
2022-05-24 22:02:43,354 [trainer.py] => model_name: podnet
2022-05-24 22:02:43,354 [trainer.py] => convnet_type: cosine_resnet32
2022-05-24 22:02:43,354 [trainer.py] => device: [device(type='cuda', index=1)]
2022-05-24 22:02:43,354 [trainer.py] => seed: 1993
2022-05-24 22:02:45,457 [data_manager.py] => class order: [68, 56, 78, 8, 23, 84, 90, 65, 74, 76, 40, 89, 3, 92, 55, 9, 26, 80, 43, 38, 58, 70, 77, 1, 85, 19, 17, 50, 28, 53, 13, 81, 45, 82, 6, 59, 83, 16, 15, 44, 91, 41, 72, 60, 79, 52, 20, 10, 31, 54, 37, 95, 14, 71, 96, 98, 97, 2, 64, 66, 42, 22, 35, 86, 24, 34, 87, 21, 99, 0, 88, 27, 18, 94, 11, 12, 47, 25, 30, 46, 62, 69, 36, 61, 7, 63, 75, 5, 32, 4, 51, 48, 73, 93, 39, 67, 29, 49, 57, 33]
2022-05-24 22:02:45,894 [trainer.py] => All params: 466256
2022-05-24 22:02:45,895 [trainer.py] => Trainable params: 466256
2022-05-24 22:02:45,896 [podnet.py] => Learning on 0-10
2022-05-24 22:02:45,908 [podnet.py] => Adaptive factor: 0
2022-05-24 22:02:51,404 [podnet.py] => Task 0, Epoch 1/160 (LR 0.09999) => LSC_loss 2.30, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 14.30, Test_acc 23.70
2022-05-24 22:02:53,681 [podnet.py] => Task 0, Epoch 2/160 (LR 0.09996) => LSC_loss 2.17, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 26.36, Test_acc 17.90
2022-05-24 22:02:55,982 [podnet.py] => Task 0, Epoch 3/160 (LR 0.09991) => LSC_loss 1.92, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 31.80, Test_acc 26.90
2022-05-24 22:02:58,284 [podnet.py] => Task 0, Epoch 4/160 (LR 0.09985) => LSC_loss 1.72, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 42.20, Test_acc 36.50
2022-05-24 22:03:00,541 [podnet.py] => Task 0, Epoch 5/160 (LR 0.09976) => LSC_loss 1.60, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 45.60, Test_acc 46.10
2022-05-24 22:03:02,863 [podnet.py] => Task 0, Epoch 6/160 (LR 0.09965) => LSC_loss 1.53, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 47.46, Test_acc 41.40
2022-05-24 22:03:05,132 [podnet.py] => Task 0, Epoch 7/160 (LR 0.09953) => LSC_loss 1.38, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 54.48, Test_acc 51.40
2022-05-24 22:03:07,507 [podnet.py] => Task 0, Epoch 8/160 (LR 0.09938) => LSC_loss 1.33, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 56.98, Test_acc 52.00
2022-05-24 22:03:09,768 [podnet.py] => Task 0, Epoch 9/160 (LR 0.09922) => LSC_loss 1.26, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 58.44, Test_acc 55.00
2022-05-24 22:03:12,134 [podnet.py] => Task 0, Epoch 10/160 (LR 0.09904) => LSC_loss 1.16, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 62.02, Test_acc 51.70
2022-05-24 22:03:14,380 [podnet.py] => Task 0, Epoch 11/160 (LR 0.09884) => LSC_loss 1.21, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 61.30, Test_acc 60.50
2022-05-24 22:03:16,671 [podnet.py] => Task 0, Epoch 12/160 (LR 0.09862) => LSC_loss 1.07, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 66.68, Test_acc 58.60
2022-05-24 22:03:19,079 [podnet.py] => Task 0, Epoch 13/160 (LR 0.09838) => LSC_loss 1.18, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 64.28, Test_acc 58.30
2022-05-24 22:03:21,306 [podnet.py] => Task 0, Epoch 14/160 (LR 0.09812) => LSC_loss 1.04, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 68.56, Test_acc 56.30
2022-05-24 22:03:23,646 [podnet.py] => Task 0, Epoch 15/160 (LR 0.09785) => LSC_loss 1.08, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 66.28, Test_acc 67.20
2022-05-24 22:03:26,054 [podnet.py] => Task 0, Epoch 16/160 (LR 0.09755) => LSC_loss 0.92, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 71.46, Test_acc 70.90
2022-05-24 22:03:28,432 [podnet.py] => Task 0, Epoch 17/160 (LR 0.09724) => LSC_loss 0.85, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 73.16, Test_acc 71.70
2022-05-24 22:03:30,662 [podnet.py] => Task 0, Epoch 18/160 (LR 0.09691) => LSC_loss 0.80, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 75.72, Test_acc 68.30
2022-05-24 22:03:33,178 [podnet.py] => Task 0, Epoch 19/160 (LR 0.09656) => LSC_loss 0.84, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 74.36, Test_acc 61.20
2022-05-24 22:03:35,353 [podnet.py] => Task 0, Epoch 20/160 (LR 0.09619) => LSC_loss 0.78, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 76.26, Test_acc 69.40
2022-05-24 22:03:37,541 [podnet.py] => Task 0, Epoch 21/160 (LR 0.09581) => LSC_loss 0.91, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 72.18, Test_acc 63.20
2022-05-24 22:03:39,904 [podnet.py] => Task 0, Epoch 22/160 (LR 0.09541) => LSC_loss 0.79, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 74.90, Test_acc 77.50
2022-05-24 22:03:42,173 [podnet.py] => Task 0, Epoch 23/160 (LR 0.09499) => LSC_loss 0.66, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 79.96, Test_acc 73.30
2022-05-24 22:03:44,453 [podnet.py] => Task 0, Epoch 24/160 (LR 0.09455) => LSC_loss 0.67, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 80.20, Test_acc 75.50
2022-05-24 22:03:46,957 [podnet.py] => Task 0, Epoch 25/160 (LR 0.09410) => LSC_loss 0.63, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 80.94, Test_acc 69.00
2022-05-24 22:03:49,352 [podnet.py] => Task 0, Epoch 26/160 (LR 0.09362) => LSC_loss 0.70, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 78.62, Test_acc 76.50
2022-05-24 22:03:51,684 [podnet.py] => Task 0, Epoch 27/160 (LR 0.09314) => LSC_loss 0.57, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 82.76, Test_acc 75.50
2022-05-24 22:03:53,952 [podnet.py] => Task 0, Epoch 28/160 (LR 0.09263) => LSC_loss 0.57, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 82.66, Test_acc 76.80
2022-05-24 22:03:56,117 [podnet.py] => Task 0, Epoch 29/160 (LR 0.09211) => LSC_loss 0.64, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 80.60, Test_acc 75.50
2022-05-24 22:03:58,194 [podnet.py] => Task 0, Epoch 30/160 (LR 0.09157) => LSC_loss 0.72, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 77.90, Test_acc 75.80
2022-05-24 22:04:00,284 [podnet.py] => Task 0, Epoch 31/160 (LR 0.09102) => LSC_loss 0.62, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 80.44, Test_acc 79.50
2022-05-24 22:04:02,377 [podnet.py] => Task 0, Epoch 32/160 (LR 0.09045) => LSC_loss 0.55, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 84.54, Test_acc 72.90
2022-05-24 22:04:04,409 [podnet.py] => Task 0, Epoch 33/160 (LR 0.08987) => LSC_loss 0.53, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 83.64, Test_acc 75.40
2022-05-24 22:04:06,484 [podnet.py] => Task 0, Epoch 34/160 (LR 0.08927) => LSC_loss 0.54, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 83.62, Test_acc 76.90
2022-05-24 22:04:08,608 [podnet.py] => Task 0, Epoch 35/160 (LR 0.08865) => LSC_loss 0.49, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 85.36, Test_acc 78.00
2022-05-24 22:04:10,748 [podnet.py] => Task 0, Epoch 36/160 (LR 0.08802) => LSC_loss 0.43, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 87.44, Test_acc 73.50
2022-05-24 22:04:12,924 [podnet.py] => Task 0, Epoch 37/160 (LR 0.08738) => LSC_loss 0.45, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 86.46, Test_acc 74.10
2022-05-24 22:04:15,072 [podnet.py] => Task 0, Epoch 38/160 (LR 0.08672) => LSC_loss 0.45, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 87.18, Test_acc 79.70
2022-05-24 22:04:17,208 [podnet.py] => Task 0, Epoch 39/160 (LR 0.08604) => LSC_loss 0.48, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 86.34, Test_acc 76.30
2022-05-24 22:04:19,286 [podnet.py] => Task 0, Epoch 40/160 (LR 0.08536) => LSC_loss 0.68, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 80.50, Test_acc 69.70
2022-05-24 22:04:21,438 [podnet.py] => Task 0, Epoch 41/160 (LR 0.08465) => LSC_loss 0.60, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 82.00, Test_acc 77.70
2022-05-24 22:04:23,584 [podnet.py] => Task 0, Epoch 42/160 (LR 0.08394) => LSC_loss 0.47, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 85.80, Test_acc 78.00
2022-05-24 22:04:25,766 [podnet.py] => Task 0, Epoch 43/160 (LR 0.08321) => LSC_loss 0.45, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 86.44, Test_acc 80.50
2022-05-24 22:04:28,082 [podnet.py] => Task 0, Epoch 44/160 (LR 0.08247) => LSC_loss 0.42, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 87.64, Test_acc 84.20
2022-05-24 22:04:31,338 [podnet.py] => Task 0, Epoch 45/160 (LR 0.08172) => LSC_loss 0.44, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 86.46, Test_acc 79.50
2022-05-24 22:04:34,283 [podnet.py] => Task 0, Epoch 46/160 (LR 0.08095) => LSC_loss 0.38, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 90.10, Test_acc 78.90
2022-05-24 22:04:37,129 [podnet.py] => Task 0, Epoch 47/160 (LR 0.08018) => LSC_loss 0.43, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 87.72, Test_acc 83.50
2022-05-24 22:04:40,131 [podnet.py] => Task 0, Epoch 48/160 (LR 0.07939) => LSC_loss 0.50, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 85.70, Test_acc 79.70
2022-05-24 22:04:43,083 [podnet.py] => Task 0, Epoch 49/160 (LR 0.07859) => LSC_loss 0.52, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 84.54, Test_acc 78.30
2022-05-24 22:04:46,303 [podnet.py] => Task 0, Epoch 50/160 (LR 0.07778) => LSC_loss 0.41, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 88.04, Test_acc 79.40
2022-05-24 22:04:49,442 [podnet.py] => Task 0, Epoch 51/160 (LR 0.07696) => LSC_loss 0.44, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 87.54, Test_acc 82.10
2022-05-24 22:04:52,659 [podnet.py] => Task 0, Epoch 52/160 (LR 0.07612) => LSC_loss 0.36, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 89.24, Test_acc 82.70
2022-05-24 22:04:55,873 [podnet.py] => Task 0, Epoch 53/160 (LR 0.07528) => LSC_loss 0.32, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 90.14, Test_acc 81.80
2022-05-24 22:04:59,140 [podnet.py] => Task 0, Epoch 54/160 (LR 0.07443) => LSC_loss 0.45, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 86.76, Test_acc 81.90
2022-05-24 22:05:02,224 [podnet.py] => Task 0, Epoch 55/160 (LR 0.07357) => LSC_loss 0.44, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 87.26, Test_acc 80.90
2022-05-24 22:05:05,155 [podnet.py] => Task 0, Epoch 56/160 (LR 0.07270) => LSC_loss 0.45, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 86.66, Test_acc 81.60
2022-05-24 22:05:08,058 [podnet.py] => Task 0, Epoch 57/160 (LR 0.07182) => LSC_loss 0.32, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 90.56, Test_acc 84.50
2022-05-24 22:05:11,271 [podnet.py] => Task 0, Epoch 58/160 (LR 0.07093) => LSC_loss 0.31, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 91.06, Test_acc 85.50
2022-05-24 22:05:14,575 [podnet.py] => Task 0, Epoch 59/160 (LR 0.07004) => LSC_loss 0.34, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 90.00, Test_acc 81.40
2022-05-24 22:05:17,588 [podnet.py] => Task 0, Epoch 60/160 (LR 0.06913) => LSC_loss 0.32, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 90.68, Test_acc 82.20
2022-05-24 22:05:20,990 [podnet.py] => Task 0, Epoch 61/160 (LR 0.06822) => LSC_loss 0.39, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 89.22, Test_acc 81.30
2022-05-24 22:05:24,322 [podnet.py] => Task 0, Epoch 62/160 (LR 0.06731) => LSC_loss 0.36, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 89.46, Test_acc 84.70
2022-05-24 22:05:27,605 [podnet.py] => Task 0, Epoch 63/160 (LR 0.06638) => LSC_loss 0.35, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 90.34, Test_acc 85.40
2022-05-24 22:05:30,748 [podnet.py] => Task 0, Epoch 64/160 (LR 0.06545) => LSC_loss 0.26, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 92.48, Test_acc 82.60
2022-05-24 22:05:33,674 [podnet.py] => Task 0, Epoch 65/160 (LR 0.06451) => LSC_loss 0.31, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 90.50, Test_acc 83.10
2022-05-24 22:05:36,643 [podnet.py] => Task 0, Epoch 66/160 (LR 0.06357) => LSC_loss 0.35, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 90.36, Test_acc 85.50
2022-05-24 22:05:39,735 [podnet.py] => Task 0, Epoch 67/160 (LR 0.06262) => LSC_loss 0.34, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 90.24, Test_acc 81.40
2022-05-24 22:05:43,079 [podnet.py] => Task 0, Epoch 68/160 (LR 0.06167) => LSC_loss 0.28, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 92.20, Test_acc 83.50
2022-05-24 22:05:46,110 [podnet.py] => Task 0, Epoch 69/160 (LR 0.06072) => LSC_loss 0.27, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 92.04, Test_acc 87.30
2022-05-24 22:05:49,298 [podnet.py] => Task 0, Epoch 70/160 (LR 0.05975) => LSC_loss 0.25, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 92.68, Test_acc 82.90
2022-05-24 22:05:52,599 [podnet.py] => Task 0, Epoch 71/160 (LR 0.05879) => LSC_loss 0.30, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 90.94, Test_acc 84.50
2022-05-24 22:05:55,928 [podnet.py] => Task 0, Epoch 72/160 (LR 0.05782) => LSC_loss 0.22, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 93.14, Test_acc 86.50
2022-05-24 22:05:59,135 [podnet.py] => Task 0, Epoch 73/160 (LR 0.05685) => LSC_loss 0.18, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 94.76, Test_acc 86.90
2022-05-24 22:06:02,105 [podnet.py] => Task 0, Epoch 74/160 (LR 0.05588) => LSC_loss 0.28, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 91.84, Test_acc 85.80
2022-05-24 22:06:05,114 [podnet.py] => Task 0, Epoch 75/160 (LR 0.05490) => LSC_loss 0.26, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 92.56, Test_acc 86.80
2022-05-24 22:06:08,064 [podnet.py] => Task 0, Epoch 76/160 (LR 0.05392) => LSC_loss 0.21, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 94.52, Test_acc 86.00
2022-05-24 22:06:11,348 [podnet.py] => Task 0, Epoch 77/160 (LR 0.05294) => LSC_loss 0.17, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 94.96, Test_acc 87.80
2022-05-24 22:06:14,528 [podnet.py] => Task 0, Epoch 78/160 (LR 0.05196) => LSC_loss 0.16, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 95.08, Test_acc 85.40
2022-05-24 22:06:17,454 [podnet.py] => Task 0, Epoch 79/160 (LR 0.05098) => LSC_loss 0.16, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 95.28, Test_acc 84.70
2022-05-24 22:06:20,596 [podnet.py] => Task 0, Epoch 80/160 (LR 0.05000) => LSC_loss 0.26, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 92.24, Test_acc 85.70
2022-05-24 22:06:23,949 [podnet.py] => Task 0, Epoch 81/160 (LR 0.04902) => LSC_loss 0.28, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 91.58, Test_acc 87.00
2022-05-24 22:06:27,317 [podnet.py] => Task 0, Epoch 82/160 (LR 0.04804) => LSC_loss 0.23, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 93.06, Test_acc 86.20
2022-05-24 22:06:30,574 [podnet.py] => Task 0, Epoch 83/160 (LR 0.04706) => LSC_loss 0.16, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 95.24, Test_acc 86.50
2022-05-24 22:06:33,655 [podnet.py] => Task 0, Epoch 84/160 (LR 0.04608) => LSC_loss 0.16, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 95.64, Test_acc 85.40
2022-05-24 22:06:36,689 [podnet.py] => Task 0, Epoch 85/160 (LR 0.04510) => LSC_loss 0.27, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 92.04, Test_acc 84.50
2022-05-24 22:06:40,162 [podnet.py] => Task 0, Epoch 86/160 (LR 0.04412) => LSC_loss 0.17, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 95.08, Test_acc 86.70
2022-05-24 22:06:43,250 [podnet.py] => Task 0, Epoch 87/160 (LR 0.04315) => LSC_loss 0.17, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 94.92, Test_acc 86.60
2022-05-24 22:06:46,494 [podnet.py] => Task 0, Epoch 88/160 (LR 0.04218) => LSC_loss 0.14, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 96.50, Test_acc 86.60
2022-05-24 22:06:49,827 [podnet.py] => Task 0, Epoch 89/160 (LR 0.04121) => LSC_loss 0.30, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 91.42, Test_acc 86.20
2022-05-24 22:06:53,342 [podnet.py] => Task 0, Epoch 90/160 (LR 0.04025) => LSC_loss 0.21, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 93.80, Test_acc 88.20
2022-05-24 22:06:56,521 [podnet.py] => Task 0, Epoch 91/160 (LR 0.03928) => LSC_loss 0.18, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 94.96, Test_acc 85.70
2022-05-24 22:06:59,638 [podnet.py] => Task 0, Epoch 92/160 (LR 0.03833) => LSC_loss 0.24, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 92.52, Test_acc 87.00
2022-05-24 22:07:02,642 [podnet.py] => Task 0, Epoch 93/160 (LR 0.03738) => LSC_loss 0.16, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 96.30, Test_acc 86.40
2022-05-24 22:07:05,591 [podnet.py] => Task 0, Epoch 94/160 (LR 0.03643) => LSC_loss 0.31, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 91.30, Test_acc 85.50
2022-05-24 22:07:09,046 [podnet.py] => Task 0, Epoch 95/160 (LR 0.03549) => LSC_loss 0.22, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 93.60, Test_acc 83.60
2022-05-24 22:07:12,235 [podnet.py] => Task 0, Epoch 96/160 (LR 0.03455) => LSC_loss 0.19, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 94.68, Test_acc 86.80
2022-05-24 22:07:15,638 [podnet.py] => Task 0, Epoch 97/160 (LR 0.03362) => LSC_loss 0.22, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 93.86, Test_acc 85.50
2022-05-24 22:07:19,011 [podnet.py] => Task 0, Epoch 98/160 (LR 0.03269) => LSC_loss 0.18, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 94.96, Test_acc 87.30
2022-05-24 22:07:22,392 [podnet.py] => Task 0, Epoch 99/160 (LR 0.03178) => LSC_loss 0.17, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 95.36, Test_acc 88.10
2022-05-24 22:07:25,444 [podnet.py] => Task 0, Epoch 100/160 (LR 0.03087) => LSC_loss 0.16, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 95.26, Test_acc 86.30
2022-05-24 22:07:28,426 [podnet.py] => Task 0, Epoch 101/160 (LR 0.02996) => LSC_loss 0.11, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.38, Test_acc 87.80
2022-05-24 22:07:31,489 [podnet.py] => Task 0, Epoch 102/160 (LR 0.02907) => LSC_loss 0.16, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 95.56, Test_acc 89.80
2022-05-24 22:07:34,365 [podnet.py] => Task 0, Epoch 103/160 (LR 0.02818) => LSC_loss 0.14, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.08, Test_acc 88.50
2022-05-24 22:07:37,827 [podnet.py] => Task 0, Epoch 104/160 (LR 0.02730) => LSC_loss 0.13, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 96.34, Test_acc 88.20
2022-05-24 22:07:41,037 [podnet.py] => Task 0, Epoch 105/160 (LR 0.02643) => LSC_loss 0.08, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.74, Test_acc 89.40
2022-05-24 22:07:44,400 [podnet.py] => Task 0, Epoch 106/160 (LR 0.02557) => LSC_loss 0.07, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.28, Test_acc 88.60
2022-05-24 22:07:47,761 [podnet.py] => Task 0, Epoch 107/160 (LR 0.02472) => LSC_loss 0.08, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.04, Test_acc 89.30
2022-05-24 22:07:51,129 [podnet.py] => Task 0, Epoch 108/160 (LR 0.02388) => LSC_loss 0.12, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 96.60, Test_acc 87.30
2022-05-24 22:07:54,269 [podnet.py] => Task 0, Epoch 109/160 (LR 0.02304) => LSC_loss 0.16, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 95.68, Test_acc 87.80
2022-05-24 22:07:57,290 [podnet.py] => Task 0, Epoch 110/160 (LR 0.02222) => LSC_loss 0.11, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 96.52, Test_acc 88.70
2022-05-24 22:08:00,431 [podnet.py] => Task 0, Epoch 111/160 (LR 0.02141) => LSC_loss 0.08, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.76, Test_acc 88.50
2022-05-24 22:08:03,543 [podnet.py] => Task 0, Epoch 112/160 (LR 0.02061) => LSC_loss 0.15, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 96.38, Test_acc 87.60
2022-05-24 22:08:06,969 [podnet.py] => Task 0, Epoch 113/160 (LR 0.01982) => LSC_loss 0.18, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 95.00, Test_acc 86.60
2022-05-24 22:08:10,423 [podnet.py] => Task 0, Epoch 114/160 (LR 0.01905) => LSC_loss 0.18, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 95.34, Test_acc 88.10
2022-05-24 22:08:13,692 [podnet.py] => Task 0, Epoch 115/160 (LR 0.01828) => LSC_loss 0.11, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 97.24, Test_acc 89.20
2022-05-24 22:08:17,041 [podnet.py] => Task 0, Epoch 116/160 (LR 0.01753) => LSC_loss 0.18, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 95.50, Test_acc 88.10
2022-05-24 22:08:20,415 [podnet.py] => Task 0, Epoch 117/160 (LR 0.01679) => LSC_loss 0.13, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 96.36, Test_acc 89.20
2022-05-24 22:08:23,538 [podnet.py] => Task 0, Epoch 118/160 (LR 0.01606) => LSC_loss 0.11, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 96.96, Test_acc 89.00
2022-05-24 22:08:26,499 [podnet.py] => Task 0, Epoch 119/160 (LR 0.01535) => LSC_loss 0.06, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.06, Test_acc 89.20
2022-05-24 22:08:29,593 [podnet.py] => Task 0, Epoch 120/160 (LR 0.01464) => LSC_loss 0.07, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.22, Test_acc 89.70
2022-05-24 22:08:32,591 [podnet.py] => Task 0, Epoch 121/160 (LR 0.01396) => LSC_loss 0.04, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.06, Test_acc 89.30
2022-05-24 22:08:36,123 [podnet.py] => Task 0, Epoch 122/160 (LR 0.01328) => LSC_loss 0.04, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.18, Test_acc 89.60
2022-05-24 22:08:39,506 [podnet.py] => Task 0, Epoch 123/160 (LR 0.01262) => LSC_loss 0.08, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.38, Test_acc 90.10
2022-05-24 22:08:42,745 [podnet.py] => Task 0, Epoch 124/160 (LR 0.01198) => LSC_loss 0.05, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.90, Test_acc 90.00
2022-05-24 22:08:45,871 [podnet.py] => Task 0, Epoch 125/160 (LR 0.01135) => LSC_loss 0.06, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.40, Test_acc 89.00
2022-05-24 22:08:49,509 [podnet.py] => Task 0, Epoch 126/160 (LR 0.01073) => LSC_loss 0.05, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.00, Test_acc 90.10
2022-05-24 22:08:52,266 [podnet.py] => Task 0, Epoch 127/160 (LR 0.01013) => LSC_loss 0.07, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.38, Test_acc 89.20
2022-05-24 22:08:55,206 [podnet.py] => Task 0, Epoch 128/160 (LR 0.00955) => LSC_loss 0.06, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 98.50, Test_acc 89.60
2022-05-24 22:08:58,315 [podnet.py] => Task 0, Epoch 129/160 (LR 0.00898) => LSC_loss 0.04, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.18, Test_acc 90.00
2022-05-24 22:09:01,593 [podnet.py] => Task 0, Epoch 130/160 (LR 0.00843) => LSC_loss 0.04, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.40, Test_acc 89.90
2022-05-24 22:09:05,005 [podnet.py] => Task 0, Epoch 131/160 (LR 0.00789) => LSC_loss 0.05, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.02, Test_acc 90.50
2022-05-24 22:09:08,405 [podnet.py] => Task 0, Epoch 132/160 (LR 0.00737) => LSC_loss 0.04, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.18, Test_acc 90.30
2022-05-24 22:09:11,654 [podnet.py] => Task 0, Epoch 133/160 (LR 0.00686) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.32, Test_acc 90.60
2022-05-24 22:09:14,825 [podnet.py] => Task 0, Epoch 134/160 (LR 0.00638) => LSC_loss 0.04, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.22, Test_acc 90.30
2022-05-24 22:09:18,181 [podnet.py] => Task 0, Epoch 135/160 (LR 0.00590) => LSC_loss 0.05, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.46, Test_acc 90.80
2022-05-24 22:09:21,148 [podnet.py] => Task 0, Epoch 136/160 (LR 0.00545) => LSC_loss 0.04, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.34, Test_acc 90.10
2022-05-24 22:09:24,142 [podnet.py] => Task 0, Epoch 137/160 (LR 0.00501) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.12, Test_acc 90.30
2022-05-24 22:09:27,227 [podnet.py] => Task 0, Epoch 138/160 (LR 0.00459) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.56, Test_acc 90.80
2022-05-24 22:09:30,472 [podnet.py] => Task 0, Epoch 139/160 (LR 0.00419) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.60, Test_acc 90.80
2022-05-24 22:09:33,907 [podnet.py] => Task 0, Epoch 140/160 (LR 0.00381) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.42, Test_acc 90.60
2022-05-24 22:09:37,212 [podnet.py] => Task 0, Epoch 141/160 (LR 0.00344) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.70, Test_acc 90.60
2022-05-24 22:09:40,506 [podnet.py] => Task 0, Epoch 142/160 (LR 0.00309) => LSC_loss 0.05, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.38, Test_acc 90.20
2022-05-24 22:09:43,670 [podnet.py] => Task 0, Epoch 143/160 (LR 0.00276) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.28, Test_acc 90.10
2022-05-24 22:09:47,218 [podnet.py] => Task 0, Epoch 144/160 (LR 0.00245) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.64, Test_acc 90.40
2022-05-24 22:09:50,312 [podnet.py] => Task 0, Epoch 145/160 (LR 0.00215) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.54, Test_acc 90.40
2022-05-24 22:09:53,367 [podnet.py] => Task 0, Epoch 146/160 (LR 0.00188) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.64, Test_acc 90.50
2022-05-24 22:09:56,220 [podnet.py] => Task 0, Epoch 147/160 (LR 0.00162) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.68, Test_acc 90.80
2022-05-24 22:09:59,450 [podnet.py] => Task 0, Epoch 148/160 (LR 0.00138) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.72, Test_acc 90.00
2022-05-24 22:10:02,762 [podnet.py] => Task 0, Epoch 149/160 (LR 0.00116) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.66, Test_acc 90.50
2022-05-24 22:10:06,110 [podnet.py] => Task 0, Epoch 150/160 (LR 0.00096) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.78, Test_acc 90.30
2022-05-24 22:10:09,468 [podnet.py] => Task 0, Epoch 151/160 (LR 0.00078) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.72, Test_acc 90.70
2022-05-24 22:10:12,811 [podnet.py] => Task 0, Epoch 152/160 (LR 0.00062) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.72, Test_acc 90.40
2022-05-24 22:10:16,222 [podnet.py] => Task 0, Epoch 153/160 (LR 0.00047) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.76, Test_acc 90.00
2022-05-24 22:10:19,175 [podnet.py] => Task 0, Epoch 154/160 (LR 0.00035) => LSC_loss 0.04, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.68, Test_acc 90.00
2022-05-24 22:10:22,279 [podnet.py] => Task 0, Epoch 155/160 (LR 0.00024) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.64, Test_acc 90.00
2022-05-24 22:10:25,344 [podnet.py] => Task 0, Epoch 156/160 (LR 0.00015) => LSC_loss 0.04, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.54, Test_acc 90.60
2022-05-24 22:10:28,473 [podnet.py] => Task 0, Epoch 157/160 (LR 0.00009) => LSC_loss 0.03, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.72, Test_acc 90.10
2022-05-24 22:10:31,913 [podnet.py] => Task 0, Epoch 158/160 (LR 0.00004) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.80, Test_acc 90.50
2022-05-24 22:10:35,509 [podnet.py] => Task 0, Epoch 159/160 (LR 0.00001) => LSC_loss 0.02, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.84, Test_acc 89.80
2022-05-24 22:10:38,982 [podnet.py] => Task 0, Epoch 160/160 (LR 0.00000) => LSC_loss 0.04, Spatial_loss 0.00, Flat_loss 0.00, Train_acc 99.70, Test_acc 90.70
2022-05-24 22:10:38,983 [base.py] => Reducing exemplars...(200 per classes)
2022-05-24 22:10:38,983 [base.py] => Constructing exemplars...(200 per classes)
2022-05-24 22:10:45,732 [podnet.py] => Exemplar size: 2000
2022-05-24 22:10:45,733 [trainer.py] => CNN: {'total': 90.7, '00-09': 90.7, 'old': 0, 'new': 90.7}
2022-05-24 22:10:45,733 [trainer.py] => NME: {'total': 90.8, '00-09': 90.8, 'old': 0, 'new': 90.8}
2022-05-24 22:10:45,733 [trainer.py] => CNN top1 curve: [90.7]
2022-05-24 22:10:45,733 [trainer.py] => CNN top5 curve: [99.2]
2022-05-24 22:10:45,733 [trainer.py] => NME top1 curve: [90.8]
2022-05-24 22:10:45,733 [trainer.py] => NME top5 curve: [99.3]

2022-05-24 22:10:45,734 [trainer.py] => All params: 472657
2022-05-24 22:10:45,734 [trainer.py] => Trainable params: 472657
2022-05-24 22:10:45,735 [podnet.py] => Learning on 10-20
2022-05-24 22:10:45,803 [podnet.py] => Adaptive factor: 1.4142135623730951
2022-05-24 22:10:51,305 [podnet.py] => Task 1, Epoch 1/160 (LR 0.09999) => LSC_loss 2.01, Spatial_loss 1.55, Flat_loss 0.30, Train_acc 42.57, Test_acc 54.45
2022-05-24 22:10:56,311 [podnet.py] => Task 1, Epoch 2/160 (LR 0.09996) => LSC_loss 1.47, Spatial_loss 1.33, Flat_loss 0.18, Train_acc 54.10, Test_acc 53.60
2022-05-24 22:11:01,720 [podnet.py] => Task 1, Epoch 3/160 (LR 0.09991) => LSC_loss 1.36, Spatial_loss 1.37, Flat_loss 0.17, Train_acc 57.41, Test_acc 54.95
2022-05-24 22:11:07,262 [podnet.py] => Task 1, Epoch 4/160 (LR 0.09985) => LSC_loss 1.29, Spatial_loss 1.37, Flat_loss 0.17, Train_acc 60.01, Test_acc 57.20
2022-05-24 22:11:12,891 [podnet.py] => Task 1, Epoch 5/160 (LR 0.09976) => LSC_loss 1.25, Spatial_loss 1.37, Flat_loss 0.18, Train_acc 61.61, Test_acc 57.95
2022-05-24 22:11:18,690 [podnet.py] => Task 1, Epoch 6/160 (LR 0.09965) => LSC_loss 1.16, Spatial_loss 1.34, Flat_loss 0.18, Train_acc 64.61, Test_acc 60.00
2022-05-24 22:11:23,855 [podnet.py] => Task 1, Epoch 7/160 (LR 0.09953) => LSC_loss 1.13, Spatial_loss 1.36, Flat_loss 0.19, Train_acc 65.20, Test_acc 53.95
2022-05-24 22:11:29,090 [podnet.py] => Task 1, Epoch 8/160 (LR 0.09938) => LSC_loss 1.08, Spatial_loss 1.38, Flat_loss 0.19, Train_acc 67.06, Test_acc 57.65
2022-05-24 22:11:34,506 [podnet.py] => Task 1, Epoch 9/160 (LR 0.09922) => LSC_loss 1.06, Spatial_loss 1.38, Flat_loss 0.20, Train_acc 68.09, Test_acc 60.15
2022-05-24 22:11:40,042 [podnet.py] => Task 1, Epoch 10/160 (LR 0.09904) => LSC_loss 1.01, Spatial_loss 1.35, Flat_loss 0.20, Train_acc 69.66, Test_acc 62.50
2022-05-24 22:11:45,584 [podnet.py] => Task 1, Epoch 11/160 (LR 0.09884) => LSC_loss 0.99, Spatial_loss 1.35, Flat_loss 0.20, Train_acc 69.67, Test_acc 63.10
2022-05-24 22:11:50,868 [podnet.py] => Task 1, Epoch 12/160 (LR 0.09862) => LSC_loss 0.97, Spatial_loss 1.36, Flat_loss 0.21, Train_acc 70.64, Test_acc 58.90
2022-05-24 22:11:56,012 [podnet.py] => Task 1, Epoch 13/160 (LR 0.09838) => LSC_loss 0.94, Spatial_loss 1.36, Flat_loss 0.21, Train_acc 71.59, Test_acc 62.00
2022-05-24 22:12:01,768 [podnet.py] => Task 1, Epoch 14/160 (LR 0.09812) => LSC_loss 0.95, Spatial_loss 1.40, Flat_loss 0.21, Train_acc 70.74, Test_acc 62.60
2022-05-24 22:12:07,242 [podnet.py] => Task 1, Epoch 15/160 (LR 0.09785) => LSC_loss 0.90, Spatial_loss 1.39, Flat_loss 0.21, Train_acc 72.50, Test_acc 62.05
2022-05-24 22:12:12,119 [podnet.py] => Task 1, Epoch 16/160 (LR 0.09755) => LSC_loss 0.89, Spatial_loss 1.39, Flat_loss 0.22, Train_acc 72.87, Test_acc 62.70
2022-05-24 22:12:17,555 [podnet.py] => Task 1, Epoch 17/160 (LR 0.09724) => LSC_loss 0.87, Spatial_loss 1.37, Flat_loss 0.22, Train_acc 74.09, Test_acc 60.80
2022-05-24 22:12:23,281 [podnet.py] => Task 1, Epoch 18/160 (LR 0.09691) => LSC_loss 0.84, Spatial_loss 1.36, Flat_loss 0.22, Train_acc 74.11, Test_acc 60.90
2022-05-24 22:12:28,436 [podnet.py] => Task 1, Epoch 19/160 (LR 0.09656) => LSC_loss 0.82, Spatial_loss 1.34, Flat_loss 0.22, Train_acc 75.16, Test_acc 60.60
2022-05-24 22:12:33,729 [podnet.py] => Task 1, Epoch 20/160 (LR 0.09619) => LSC_loss 0.80, Spatial_loss 1.36, Flat_loss 0.22, Train_acc 75.91, Test_acc 64.75
2022-05-24 22:12:39,257 [podnet.py] => Task 1, Epoch 21/160 (LR 0.09581) => LSC_loss 0.78, Spatial_loss 1.33, Flat_loss 0.22, Train_acc 76.43, Test_acc 65.90
2022-05-24 22:12:44,636 [podnet.py] => Task 1, Epoch 22/160 (LR 0.09541) => LSC_loss 0.77, Spatial_loss 1.34, Flat_loss 0.22, Train_acc 77.23, Test_acc 57.70
2022-05-24 22:12:49,874 [podnet.py] => Task 1, Epoch 23/160 (LR 0.09499) => LSC_loss 0.75, Spatial_loss 1.36, Flat_loss 0.22, Train_acc 77.39, Test_acc 62.70
2022-05-24 22:12:54,996 [podnet.py] => Task 1, Epoch 24/160 (LR 0.09455) => LSC_loss 0.75, Spatial_loss 1.38, Flat_loss 0.23, Train_acc 76.97, Test_acc 65.20
2022-05-24 22:13:00,634 [podnet.py] => Task 1, Epoch 25/160 (LR 0.09410) => LSC_loss 0.74, Spatial_loss 1.37, Flat_loss 0.23, Train_acc 77.74, Test_acc 62.55
2022-05-24 22:13:06,290 [podnet.py] => Task 1, Epoch 26/160 (LR 0.09362) => LSC_loss 0.72, Spatial_loss 1.35, Flat_loss 0.23, Train_acc 78.67, Test_acc 64.10
2022-05-24 22:13:11,326 [podnet.py] => Task 1, Epoch 27/160 (LR 0.09314) => LSC_loss 0.71, Spatial_loss 1.36, Flat_loss 0.23, Train_acc 78.81, Test_acc 60.05
2022-05-24 22:13:16,735 [podnet.py] => Task 1, Epoch 28/160 (LR 0.09263) => LSC_loss 0.66, Spatial_loss 1.33, Flat_loss 0.23, Train_acc 80.20, Test_acc 66.75
2022-05-24 22:13:22,165 [podnet.py] => Task 1, Epoch 29/160 (LR 0.09211) => LSC_loss 0.69, Spatial_loss 1.35, Flat_loss 0.23, Train_acc 79.07, Test_acc 65.80
2022-05-24 22:13:27,400 [podnet.py] => Task 1, Epoch 30/160 (LR 0.09157) => LSC_loss 0.71, Spatial_loss 1.36, Flat_loss 0.23, Train_acc 78.99, Test_acc 61.05
2022-05-24 22:13:32,683 [podnet.py] => Task 1, Epoch 31/160 (LR 0.09102) => LSC_loss 0.67, Spatial_loss 1.34, Flat_loss 0.23, Train_acc 80.16, Test_acc 67.20
2022-05-24 22:13:38,210 [podnet.py] => Task 1, Epoch 32/160 (LR 0.09045) => LSC_loss 0.66, Spatial_loss 1.35, Flat_loss 0.23, Train_acc 80.10, Test_acc 62.10
2022-05-24 22:13:43,534 [podnet.py] => Task 1, Epoch 33/160 (LR 0.08987) => LSC_loss 0.64, Spatial_loss 1.35, Flat_loss 0.23, Train_acc 80.94, Test_acc 67.15
2022-05-24 22:13:48,781 [podnet.py] => Task 1, Epoch 34/160 (LR 0.08927) => LSC_loss 0.64, Spatial_loss 1.37, Flat_loss 0.23, Train_acc 80.89, Test_acc 65.55
2022-05-24 22:13:53,987 [podnet.py] => Task 1, Epoch 35/160 (LR 0.08865) => LSC_loss 0.64, Spatial_loss 1.35, Flat_loss 0.23, Train_acc 80.93, Test_acc 68.10
2022-05-24 22:13:59,880 [podnet.py] => Task 1, Epoch 36/160 (LR 0.08802) => LSC_loss 0.62, Spatial_loss 1.34, Flat_loss 0.24, Train_acc 81.91, Test_acc 65.10
2022-05-24 22:14:05,559 [podnet.py] => Task 1, Epoch 37/160 (LR 0.08738) => LSC_loss 0.62, Spatial_loss 1.36, Flat_loss 0.23, Train_acc 81.91, Test_acc 69.30
2022-05-24 22:14:10,975 [podnet.py] => Task 1, Epoch 38/160 (LR 0.08672) => LSC_loss 0.58, Spatial_loss 1.32, Flat_loss 0.23, Train_acc 82.69, Test_acc 67.15
2022-05-24 22:14:16,106 [podnet.py] => Task 1, Epoch 39/160 (LR 0.08604) => LSC_loss 0.58, Spatial_loss 1.33, Flat_loss 0.24, Train_acc 83.09, Test_acc 67.05
2022-05-24 22:14:22,008 [podnet.py] => Task 1, Epoch 40/160 (LR 0.08536) => LSC_loss 0.60, Spatial_loss 1.36, Flat_loss 0.24, Train_acc 82.20, Test_acc 63.95
2022-05-24 22:14:27,786 [podnet.py] => Task 1, Epoch 41/160 (LR 0.08465) => LSC_loss 0.56, Spatial_loss 1.32, Flat_loss 0.24, Train_acc 83.37, Test_acc 61.45
2022-05-24 22:14:33,416 [podnet.py] => Task 1, Epoch 42/160 (LR 0.08394) => LSC_loss 0.58, Spatial_loss 1.34, Flat_loss 0.24, Train_acc 83.24, Test_acc 63.20
2022-05-24 22:14:39,294 [podnet.py] => Task 1, Epoch 43/160 (LR 0.08321) => LSC_loss 0.58, Spatial_loss 1.32, Flat_loss 0.24, Train_acc 82.90, Test_acc 59.30
2022-05-24 22:14:45,438 [podnet.py] => Task 1, Epoch 44/160 (LR 0.08247) => LSC_loss 0.57, Spatial_loss 1.35, Flat_loss 0.24, Train_acc 83.13, Test_acc 64.60
2022-05-24 22:14:51,530 [podnet.py] => Task 1, Epoch 45/160 (LR 0.08172) => LSC_loss 0.55, Spatial_loss 1.33, Flat_loss 0.24, Train_acc 83.70, Test_acc 60.80
2022-05-24 22:14:56,887 [podnet.py] => Task 1, Epoch 46/160 (LR 0.08095) => LSC_loss 0.54, Spatial_loss 1.33, Flat_loss 0.24, Train_acc 84.11, Test_acc 67.40
2022-05-24 22:15:02,713 [podnet.py] => Task 1, Epoch 47/160 (LR 0.08018) => LSC_loss 0.53, Spatial_loss 1.32, Flat_loss 0.24, Train_acc 84.41, Test_acc 65.30
2022-05-24 22:15:08,846 [podnet.py] => Task 1, Epoch 48/160 (LR 0.07939) => LSC_loss 0.52, Spatial_loss 1.31, Flat_loss 0.24, Train_acc 84.96, Test_acc 67.10
2022-05-24 22:15:15,011 [podnet.py] => Task 1, Epoch 49/160 (LR 0.07859) => LSC_loss 0.52, Spatial_loss 1.33, Flat_loss 0.24, Train_acc 84.69, Test_acc 68.65
2022-05-24 22:15:20,996 [podnet.py] => Task 1, Epoch 50/160 (LR 0.07778) => LSC_loss 0.49, Spatial_loss 1.29, Flat_loss 0.24, Train_acc 85.93, Test_acc 65.25
2022-05-24 22:15:26,330 [podnet.py] => Task 1, Epoch 51/160 (LR 0.07696) => LSC_loss 0.48, Spatial_loss 1.31, Flat_loss 0.24, Train_acc 86.01, Test_acc 63.95
2022-05-24 22:15:32,213 [podnet.py] => Task 1, Epoch 52/160 (LR 0.07612) => LSC_loss 0.48, Spatial_loss 1.29, Flat_loss 0.24, Train_acc 86.16, Test_acc 60.40
2022-05-24 22:15:38,423 [podnet.py] => Task 1, Epoch 53/160 (LR 0.07528) => LSC_loss 0.49, Spatial_loss 1.32, Flat_loss 0.23, Train_acc 86.44, Test_acc 61.90
2022-05-24 22:15:44,226 [podnet.py] => Task 1, Epoch 54/160 (LR 0.07443) => LSC_loss 0.47, Spatial_loss 1.30, Flat_loss 0.24, Train_acc 86.67, Test_acc 68.25
2022-05-24 22:15:50,041 [podnet.py] => Task 1, Epoch 55/160 (LR 0.07357) => LSC_loss 0.47, Spatial_loss 1.30, Flat_loss 0.24, Train_acc 86.43, Test_acc 68.70
2022-05-24 22:15:55,776 [podnet.py] => Task 1, Epoch 56/160 (LR 0.07270) => LSC_loss 0.46, Spatial_loss 1.29, Flat_loss 0.24, Train_acc 86.64, Test_acc 65.65
2022-05-24 22:16:01,528 [podnet.py] => Task 1, Epoch 57/160 (LR 0.07182) => LSC_loss 0.46, Spatial_loss 1.28, Flat_loss 0.24, Train_acc 86.51, Test_acc 67.30
2022-05-24 22:16:07,576 [podnet.py] => Task 1, Epoch 58/160 (LR 0.07093) => LSC_loss 0.45, Spatial_loss 1.27, Flat_loss 0.24, Train_acc 87.01, Test_acc 67.70
2022-05-24 22:16:13,673 [podnet.py] => Task 1, Epoch 59/160 (LR 0.07004) => LSC_loss 0.41, Spatial_loss 1.26, Flat_loss 0.23, Train_acc 88.79, Test_acc 67.35
2022-05-24 22:16:19,351 [podnet.py] => Task 1, Epoch 60/160 (LR 0.06913) => LSC_loss 0.41, Spatial_loss 1.25, Flat_loss 0.23, Train_acc 88.06, Test_acc 70.00
2022-05-24 22:16:25,036 [podnet.py] => Task 1, Epoch 61/160 (LR 0.06822) => LSC_loss 0.41, Spatial_loss 1.27, Flat_loss 0.24, Train_acc 87.97, Test_acc 64.05
2022-05-24 22:16:30,807 [podnet.py] => Task 1, Epoch 62/160 (LR 0.06731) => LSC_loss 0.43, Spatial_loss 1.28, Flat_loss 0.24, Train_acc 87.41, Test_acc 68.55
2022-05-24 22:16:36,983 [podnet.py] => Task 1, Epoch 63/160 (LR 0.06638) => LSC_loss 0.41, Spatial_loss 1.26, Flat_loss 0.24, Train_acc 88.00, Test_acc 62.75
2022-05-24 22:16:43,160 [podnet.py] => Task 1, Epoch 64/160 (LR 0.06545) => LSC_loss 0.43, Spatial_loss 1.26, Flat_loss 0.24, Train_acc 87.69, Test_acc 69.35
2022-05-24 22:16:48,959 [podnet.py] => Task 1, Epoch 65/160 (LR 0.06451) => LSC_loss 0.41, Spatial_loss 1.25, Flat_loss 0.23, Train_acc 88.44, Test_acc 65.15
2022-05-24 22:16:54,733 [podnet.py] => Task 1, Epoch 66/160 (LR 0.06357) => LSC_loss 0.39, Spatial_loss 1.24, Flat_loss 0.24, Train_acc 89.23, Test_acc 66.50
2022-05-24 22:17:00,370 [podnet.py] => Task 1, Epoch 67/160 (LR 0.06262) => LSC_loss 0.43, Spatial_loss 1.29, Flat_loss 0.24, Train_acc 87.76, Test_acc 68.10
2022-05-24 22:17:06,075 [podnet.py] => Task 1, Epoch 68/160 (LR 0.06167) => LSC_loss 0.38, Spatial_loss 1.22, Flat_loss 0.24, Train_acc 89.03, Test_acc 64.20
2022-05-24 22:17:12,037 [podnet.py] => Task 1, Epoch 69/160 (LR 0.06072) => LSC_loss 0.38, Spatial_loss 1.27, Flat_loss 0.24, Train_acc 89.26, Test_acc 65.10
2022-05-24 22:17:17,936 [podnet.py] => Task 1, Epoch 70/160 (LR 0.05975) => LSC_loss 0.37, Spatial_loss 1.23, Flat_loss 0.23, Train_acc 89.47, Test_acc 69.50
2022-05-24 22:17:23,311 [podnet.py] => Task 1, Epoch 71/160 (LR 0.05879) => LSC_loss 0.39, Spatial_loss 1.27, Flat_loss 0.24, Train_acc 88.69, Test_acc 63.00
2022-05-24 22:17:29,536 [podnet.py] => Task 1, Epoch 72/160 (LR 0.05782) => LSC_loss 0.38, Spatial_loss 1.26, Flat_loss 0.24, Train_acc 89.31, Test_acc 67.20
2022-05-24 22:17:35,812 [podnet.py] => Task 1, Epoch 73/160 (LR 0.05685) => LSC_loss 0.37, Spatial_loss 1.27, Flat_loss 0.24, Train_acc 89.06, Test_acc 64.50
2022-05-24 22:17:41,931 [podnet.py] => Task 1, Epoch 74/160 (LR 0.05588) => LSC_loss 0.35, Spatial_loss 1.24, Flat_loss 0.24, Train_acc 90.06, Test_acc 67.95
2022-05-24 22:17:47,960 [podnet.py] => Task 1, Epoch 75/160 (LR 0.05490) => LSC_loss 0.34, Spatial_loss 1.22, Flat_loss 0.23, Train_acc 90.40, Test_acc 66.10
2022-05-24 22:17:53,342 [podnet.py] => Task 1, Epoch 76/160 (LR 0.05392) => LSC_loss 0.34, Spatial_loss 1.21, Flat_loss 0.23, Train_acc 90.21, Test_acc 67.95
2022-05-24 22:17:59,150 [podnet.py] => Task 1, Epoch 77/160 (LR 0.05294) => LSC_loss 0.33, Spatial_loss 1.19, Flat_loss 0.23, Train_acc 90.79, Test_acc 70.75
2022-05-24 22:18:05,045 [podnet.py] => Task 1, Epoch 78/160 (LR 0.05196) => LSC_loss 0.32, Spatial_loss 1.19, Flat_loss 0.23, Train_acc 91.01, Test_acc 70.25
2022-05-24 22:18:11,092 [podnet.py] => Task 1, Epoch 79/160 (LR 0.05098) => LSC_loss 0.31, Spatial_loss 1.18, Flat_loss 0.23, Train_acc 91.29, Test_acc 70.90
2022-05-24 22:18:17,194 [podnet.py] => Task 1, Epoch 80/160 (LR 0.05000) => LSC_loss 0.32, Spatial_loss 1.20, Flat_loss 0.23, Train_acc 91.34, Test_acc 67.25
2022-05-24 22:18:23,347 [podnet.py] => Task 1, Epoch 81/160 (LR 0.04902) => LSC_loss 0.31, Spatial_loss 1.17, Flat_loss 0.23, Train_acc 91.20, Test_acc 66.75
2022-05-24 22:18:29,033 [podnet.py] => Task 1, Epoch 82/160 (LR 0.04804) => LSC_loss 0.29, Spatial_loss 1.17, Flat_loss 0.23, Train_acc 92.29, Test_acc 70.95
2022-05-24 22:18:34,810 [podnet.py] => Task 1, Epoch 83/160 (LR 0.04706) => LSC_loss 0.28, Spatial_loss 1.15, Flat_loss 0.23, Train_acc 92.30, Test_acc 67.90
2022-05-24 22:18:40,580 [podnet.py] => Task 1, Epoch 84/160 (LR 0.04608) => LSC_loss 0.28, Spatial_loss 1.16, Flat_loss 0.23, Train_acc 92.47, Test_acc 68.85
2022-05-24 22:18:46,893 [podnet.py] => Task 1, Epoch 85/160 (LR 0.04510) => LSC_loss 0.28, Spatial_loss 1.15, Flat_loss 0.23, Train_acc 92.60, Test_acc 66.65
2022-05-24 22:18:53,076 [podnet.py] => Task 1, Epoch 86/160 (LR 0.04412) => LSC_loss 0.29, Spatial_loss 1.17, Flat_loss 0.23, Train_acc 92.20, Test_acc 68.85
2022-05-24 22:18:59,050 [podnet.py] => Task 1, Epoch 87/160 (LR 0.04315) => LSC_loss 0.28, Spatial_loss 1.16, Flat_loss 0.23, Train_acc 92.04, Test_acc 67.35
2022-05-24 22:19:05,049 [podnet.py] => Task 1, Epoch 88/160 (LR 0.04218) => LSC_loss 0.28, Spatial_loss 1.15, Flat_loss 0.23, Train_acc 92.31, Test_acc 69.90
2022-05-24 22:19:10,953 [podnet.py] => Task 1, Epoch 89/160 (LR 0.04121) => LSC_loss 0.26, Spatial_loss 1.13, Flat_loss 0.23, Train_acc 92.93, Test_acc 69.70
2022-05-24 22:19:16,528 [podnet.py] => Task 1, Epoch 90/160 (LR 0.04025) => LSC_loss 0.27, Spatial_loss 1.13, Flat_loss 0.23, Train_acc 92.73, Test_acc 69.10
2022-05-24 22:19:22,535 [podnet.py] => Task 1, Epoch 91/160 (LR 0.03928) => LSC_loss 0.25, Spatial_loss 1.12, Flat_loss 0.22, Train_acc 93.44, Test_acc 70.55
2022-05-24 22:19:28,725 [podnet.py] => Task 1, Epoch 92/160 (LR 0.03833) => LSC_loss 0.23, Spatial_loss 1.10, Flat_loss 0.22, Train_acc 94.01, Test_acc 66.60
2022-05-24 22:19:34,476 [podnet.py] => Task 1, Epoch 93/160 (LR 0.03738) => LSC_loss 0.25, Spatial_loss 1.11, Flat_loss 0.23, Train_acc 93.20, Test_acc 68.75
2022-05-24 22:19:40,073 [podnet.py] => Task 1, Epoch 94/160 (LR 0.03643) => LSC_loss 0.24, Spatial_loss 1.08, Flat_loss 0.22, Train_acc 93.84, Test_acc 70.65
2022-05-24 22:19:45,879 [podnet.py] => Task 1, Epoch 95/160 (LR 0.03549) => LSC_loss 0.25, Spatial_loss 1.11, Flat_loss 0.22, Train_acc 93.34, Test_acc 67.65
2022-05-24 22:19:51,913 [podnet.py] => Task 1, Epoch 96/160 (LR 0.03455) => LSC_loss 0.24, Spatial_loss 1.09, Flat_loss 0.22, Train_acc 93.39, Test_acc 69.75
2022-05-24 22:19:58,013 [podnet.py] => Task 1, Epoch 97/160 (LR 0.03362) => LSC_loss 0.22, Spatial_loss 1.07, Flat_loss 0.22, Train_acc 94.29, Test_acc 70.25
2022-05-24 22:20:03,639 [podnet.py] => Task 1, Epoch 98/160 (LR 0.03269) => LSC_loss 0.21, Spatial_loss 1.05, Flat_loss 0.22, Train_acc 94.49, Test_acc 70.00
2022-05-24 22:20:09,413 [podnet.py] => Task 1, Epoch 99/160 (LR 0.03178) => LSC_loss 0.22, Spatial_loss 1.04, Flat_loss 0.22, Train_acc 94.40, Test_acc 69.80
2022-05-24 22:20:15,304 [podnet.py] => Task 1, Epoch 100/160 (LR 0.03087) => LSC_loss 0.22, Spatial_loss 1.05, Flat_loss 0.22, Train_acc 94.57, Test_acc 70.40
2022-05-24 22:20:21,099 [podnet.py] => Task 1, Epoch 101/160 (LR 0.02996) => LSC_loss 0.22, Spatial_loss 1.06, Flat_loss 0.22, Train_acc 94.60, Test_acc 71.60
2022-05-24 22:20:27,050 [podnet.py] => Task 1, Epoch 102/160 (LR 0.02907) => LSC_loss 0.21, Spatial_loss 1.05, Flat_loss 0.22, Train_acc 94.77, Test_acc 69.45
2022-05-24 22:20:33,062 [podnet.py] => Task 1, Epoch 103/160 (LR 0.02818) => LSC_loss 0.21, Spatial_loss 1.03, Flat_loss 0.22, Train_acc 94.90, Test_acc 71.60
2022-05-24 22:20:38,295 [podnet.py] => Task 1, Epoch 104/160 (LR 0.02730) => LSC_loss 0.19, Spatial_loss 1.03, Flat_loss 0.21, Train_acc 95.44, Test_acc 70.30
2022-05-24 22:20:44,259 [podnet.py] => Task 1, Epoch 105/160 (LR 0.02643) => LSC_loss 0.19, Spatial_loss 1.00, Flat_loss 0.21, Train_acc 95.69, Test_acc 70.55
2022-05-24 22:20:50,388 [podnet.py] => Task 1, Epoch 106/160 (LR 0.02557) => LSC_loss 0.19, Spatial_loss 1.02, Flat_loss 0.21, Train_acc 95.24, Test_acc 71.20
2022-05-24 22:20:56,493 [podnet.py] => Task 1, Epoch 107/160 (LR 0.02472) => LSC_loss 0.18, Spatial_loss 1.01, Flat_loss 0.21, Train_acc 95.44, Test_acc 69.75
2022-05-24 22:21:02,371 [podnet.py] => Task 1, Epoch 108/160 (LR 0.02388) => LSC_loss 0.18, Spatial_loss 1.00, Flat_loss 0.21, Train_acc 95.63, Test_acc 68.40
2022-05-24 22:21:07,883 [podnet.py] => Task 1, Epoch 109/160 (LR 0.02304) => LSC_loss 0.18, Spatial_loss 0.98, Flat_loss 0.21, Train_acc 95.96, Test_acc 71.90
2022-05-24 22:21:13,710 [podnet.py] => Task 1, Epoch 110/160 (LR 0.02222) => LSC_loss 0.16, Spatial_loss 0.98, Flat_loss 0.21, Train_acc 96.37, Test_acc 71.40
2022-05-24 22:21:19,717 [podnet.py] => Task 1, Epoch 111/160 (LR 0.02141) => LSC_loss 0.18, Spatial_loss 0.98, Flat_loss 0.21, Train_acc 95.79, Test_acc 72.85
2022-05-24 22:21:25,523 [podnet.py] => Task 1, Epoch 112/160 (LR 0.02061) => LSC_loss 0.16, Spatial_loss 0.95, Flat_loss 0.21, Train_acc 96.33, Test_acc 69.70
2022-05-24 22:21:31,425 [podnet.py] => Task 1, Epoch 113/160 (LR 0.01982) => LSC_loss 0.16, Spatial_loss 0.95, Flat_loss 0.21, Train_acc 96.29, Test_acc 68.40
2022-05-24 22:21:37,397 [podnet.py] => Task 1, Epoch 114/160 (LR 0.01905) => LSC_loss 0.17, Spatial_loss 0.95, Flat_loss 0.21, Train_acc 96.09, Test_acc 71.25
2022-05-24 22:21:43,001 [podnet.py] => Task 1, Epoch 115/160 (LR 0.01828) => LSC_loss 0.15, Spatial_loss 0.94, Flat_loss 0.21, Train_acc 96.43, Test_acc 71.65
2022-05-24 22:21:48,715 [podnet.py] => Task 1, Epoch 116/160 (LR 0.01753) => LSC_loss 0.14, Spatial_loss 0.94, Flat_loss 0.21, Train_acc 97.14, Test_acc 70.60
2022-05-24 22:21:54,785 [podnet.py] => Task 1, Epoch 117/160 (LR 0.01679) => LSC_loss 0.15, Spatial_loss 0.93, Flat_loss 0.20, Train_acc 96.51, Test_acc 71.70
2022-05-24 22:22:00,734 [podnet.py] => Task 1, Epoch 118/160 (LR 0.01606) => LSC_loss 0.16, Spatial_loss 0.94, Flat_loss 0.21, Train_acc 96.50, Test_acc 72.35
2022-05-24 22:22:06,312 [podnet.py] => Task 1, Epoch 119/160 (LR 0.01535) => LSC_loss 0.15, Spatial_loss 0.94, Flat_loss 0.20, Train_acc 96.77, Test_acc 72.50
2022-05-24 22:22:11,913 [podnet.py] => Task 1, Epoch 120/160 (LR 0.01464) => LSC_loss 0.14, Spatial_loss 0.93, Flat_loss 0.20, Train_acc 96.97, Test_acc 71.05
2022-05-24 22:22:17,831 [podnet.py] => Task 1, Epoch 121/160 (LR 0.01396) => LSC_loss 0.14, Spatial_loss 0.90, Flat_loss 0.20, Train_acc 97.30, Test_acc 72.90
2022-05-24 22:22:23,769 [podnet.py] => Task 1, Epoch 122/160 (LR 0.01328) => LSC_loss 0.14, Spatial_loss 0.90, Flat_loss 0.20, Train_acc 97.01, Test_acc 72.15
2022-05-24 22:22:29,286 [podnet.py] => Task 1, Epoch 123/160 (LR 0.01262) => LSC_loss 0.14, Spatial_loss 0.88, Flat_loss 0.20, Train_acc 97.16, Test_acc 72.05
2022-05-24 22:22:34,921 [podnet.py] => Task 1, Epoch 124/160 (LR 0.01198) => LSC_loss 0.13, Spatial_loss 0.87, Flat_loss 0.20, Train_acc 97.29, Test_acc 73.05
2022-05-24 22:22:41,078 [podnet.py] => Task 1, Epoch 125/160 (LR 0.01135) => LSC_loss 0.13, Spatial_loss 0.87, Flat_loss 0.20, Train_acc 97.70, Test_acc 71.90
2022-05-24 22:22:47,042 [podnet.py] => Task 1, Epoch 126/160 (LR 0.01073) => LSC_loss 0.13, Spatial_loss 0.87, Flat_loss 0.20, Train_acc 97.40, Test_acc 71.60
2022-05-24 22:22:53,319 [podnet.py] => Task 1, Epoch 127/160 (LR 0.01013) => LSC_loss 0.12, Spatial_loss 0.87, Flat_loss 0.20, Train_acc 97.73, Test_acc 71.30
2022-05-24 22:22:59,477 [podnet.py] => Task 1, Epoch 128/160 (LR 0.00955) => LSC_loss 0.13, Spatial_loss 0.86, Flat_loss 0.20, Train_acc 97.54, Test_acc 72.30
2022-05-24 22:23:05,306 [podnet.py] => Task 1, Epoch 129/160 (LR 0.00898) => LSC_loss 0.12, Spatial_loss 0.85, Flat_loss 0.20, Train_acc 97.63, Test_acc 73.30
2022-05-24 22:23:11,084 [podnet.py] => Task 1, Epoch 130/160 (LR 0.00843) => LSC_loss 0.11, Spatial_loss 0.86, Flat_loss 0.19, Train_acc 97.93, Test_acc 73.05
2022-05-24 22:23:16,815 [podnet.py] => Task 1, Epoch 131/160 (LR 0.00789) => LSC_loss 0.12, Spatial_loss 0.86, Flat_loss 0.19, Train_acc 97.83, Test_acc 73.15
2022-05-24 22:23:22,802 [podnet.py] => Task 1, Epoch 132/160 (LR 0.00737) => LSC_loss 0.12, Spatial_loss 0.84, Flat_loss 0.19, Train_acc 97.90, Test_acc 72.95
2022-05-24 22:23:28,900 [podnet.py] => Task 1, Epoch 133/160 (LR 0.00686) => LSC_loss 0.12, Spatial_loss 0.83, Flat_loss 0.19, Train_acc 98.10, Test_acc 73.10
2022-05-24 22:23:34,769 [podnet.py] => Task 1, Epoch 134/160 (LR 0.00638) => LSC_loss 0.11, Spatial_loss 0.84, Flat_loss 0.19, Train_acc 97.99, Test_acc 72.75
2022-05-24 22:23:40,363 [podnet.py] => Task 1, Epoch 135/160 (LR 0.00590) => LSC_loss 0.11, Spatial_loss 0.83, Flat_loss 0.19, Train_acc 98.00, Test_acc 72.20
2022-05-24 22:23:46,186 [podnet.py] => Task 1, Epoch 136/160 (LR 0.00545) => LSC_loss 0.12, Spatial_loss 0.83, Flat_loss 0.19, Train_acc 97.91, Test_acc 72.95
2022-05-24 22:23:52,111 [podnet.py] => Task 1, Epoch 137/160 (LR 0.00501) => LSC_loss 0.12, Spatial_loss 0.83, Flat_loss 0.19, Train_acc 97.74, Test_acc 72.40
2022-05-24 22:23:58,302 [podnet.py] => Task 1, Epoch 138/160 (LR 0.00459) => LSC_loss 0.11, Spatial_loss 0.82, Flat_loss 0.19, Train_acc 97.96, Test_acc 72.55
2022-05-24 22:24:04,296 [podnet.py] => Task 1, Epoch 139/160 (LR 0.00419) => LSC_loss 0.11, Spatial_loss 0.82, Flat_loss 0.19, Train_acc 98.09, Test_acc 72.70
2022-05-24 22:24:10,126 [podnet.py] => Task 1, Epoch 140/160 (LR 0.00381) => LSC_loss 0.11, Spatial_loss 0.81, Flat_loss 0.19, Train_acc 98.29, Test_acc 72.50
2022-05-24 22:24:16,218 [podnet.py] => Task 1, Epoch 141/160 (LR 0.00344) => LSC_loss 0.11, Spatial_loss 0.82, Flat_loss 0.19, Train_acc 98.23, Test_acc 72.60
2022-05-24 22:24:21,788 [podnet.py] => Task 1, Epoch 142/160 (LR 0.00309) => LSC_loss 0.11, Spatial_loss 0.81, Flat_loss 0.19, Train_acc 98.26, Test_acc 72.50
2022-05-24 22:24:27,851 [podnet.py] => Task 1, Epoch 143/160 (LR 0.00276) => LSC_loss 0.10, Spatial_loss 0.80, Flat_loss 0.19, Train_acc 98.34, Test_acc 72.85
2022-05-24 22:24:33,861 [podnet.py] => Task 1, Epoch 144/160 (LR 0.00245) => LSC_loss 0.10, Spatial_loss 0.79, Flat_loss 0.19, Train_acc 98.23, Test_acc 72.65
2022-05-24 22:24:39,600 [podnet.py] => Task 1, Epoch 145/160 (LR 0.00215) => LSC_loss 0.11, Spatial_loss 0.79, Flat_loss 0.19, Train_acc 98.16, Test_acc 73.15
2022-05-24 22:24:45,387 [podnet.py] => Task 1, Epoch 146/160 (LR 0.00188) => LSC_loss 0.10, Spatial_loss 0.79, Flat_loss 0.19, Train_acc 98.33, Test_acc 73.35
2022-05-24 22:24:51,174 [podnet.py] => Task 1, Epoch 147/160 (LR 0.00162) => LSC_loss 0.10, Spatial_loss 0.79, Flat_loss 0.19, Train_acc 98.31, Test_acc 72.95
2022-05-24 22:24:56,709 [podnet.py] => Task 1, Epoch 148/160 (LR 0.00138) => LSC_loss 0.11, Spatial_loss 0.79, Flat_loss 0.19, Train_acc 98.01, Test_acc 73.85
2022-05-24 22:25:02,820 [podnet.py] => Task 1, Epoch 149/160 (LR 0.00116) => LSC_loss 0.11, Spatial_loss 0.78, Flat_loss 0.19, Train_acc 98.31, Test_acc 73.25
2022-05-24 22:25:08,971 [podnet.py] => Task 1, Epoch 150/160 (LR 0.00096) => LSC_loss 0.10, Spatial_loss 0.77, Flat_loss 0.19, Train_acc 98.61, Test_acc 73.25
2022-05-24 22:25:14,733 [podnet.py] => Task 1, Epoch 151/160 (LR 0.00078) => LSC_loss 0.10, Spatial_loss 0.78, Flat_loss 0.18, Train_acc 98.36, Test_acc 73.30
2022-05-24 22:25:20,294 [podnet.py] => Task 1, Epoch 152/160 (LR 0.00062) => LSC_loss 0.10, Spatial_loss 0.78, Flat_loss 0.19, Train_acc 98.46, Test_acc 73.50
2022-05-24 22:25:26,170 [podnet.py] => Task 1, Epoch 153/160 (LR 0.00047) => LSC_loss 0.10, Spatial_loss 0.78, Flat_loss 0.19, Train_acc 98.60, Test_acc 73.65
2022-05-24 22:25:32,166 [podnet.py] => Task 1, Epoch 154/160 (LR 0.00035) => LSC_loss 0.10, Spatial_loss 0.78, Flat_loss 0.19, Train_acc 98.37, Test_acc 73.50
2022-05-24 22:25:38,235 [podnet.py] => Task 1, Epoch 155/160 (LR 0.00024) => LSC_loss 0.10, Spatial_loss 0.77, Flat_loss 0.19, Train_acc 98.49, Test_acc 73.50
2022-05-24 22:25:44,254 [podnet.py] => Task 1, Epoch 156/160 (LR 0.00015) => LSC_loss 0.10, Spatial_loss 0.77, Flat_loss 0.19, Train_acc 98.53, Test_acc 73.25
2022-05-24 22:25:50,079 [podnet.py] => Task 1, Epoch 157/160 (LR 0.00009) => LSC_loss 0.10, Spatial_loss 0.77, Flat_loss 0.19, Train_acc 98.36, Test_acc 73.15
2022-05-24 22:25:55,650 [podnet.py] => Task 1, Epoch 158/160 (LR 0.00004) => LSC_loss 0.10, Spatial_loss 0.78, Flat_loss 0.19, Train_acc 98.39, Test_acc 73.20
2022-05-24 22:26:01,362 [podnet.py] => Task 1, Epoch 159/160 (LR 0.00001) => LSC_loss 0.10, Spatial_loss 0.78, Flat_loss 0.19, Train_acc 98.60, Test_acc 73.10
2022-05-24 22:26:07,526 [podnet.py] => Task 1, Epoch 160/160 (LR 0.00000) => LSC_loss 0.10, Spatial_loss 0.78, Flat_loss 0.19, Train_acc 98.76, Test_acc 72.85
2022-05-24 22:26:07,527 [podnet.py] => Finetune the network (classifier part) with the undersampled dataset!
2022-05-24 22:26:07,527 [base.py] => Reducing exemplars...(200 per classes)
2022-05-24 22:26:10,012 [base.py] => Constructing exemplars...(200 per classes)
2022-05-24 22:26:17,019 [podnet.py] => The size of finetune dataset: 4000
2022-05-24 22:26:20,843 [podnet.py] => Task 1, Epoch 1/20 (LR 0.00497) => LSC_loss 0.11, Spatial_loss 0.77, Flat_loss 0.15, Train_acc 98.40, Test_acc 73.20
2022-05-24 22:26:24,627 [podnet.py] => Task 1, Epoch 2/20 (LR 0.00488) => LSC_loss 0.09, Spatial_loss 0.77, Flat_loss 0.15, Train_acc 98.55, Test_acc 72.65
2022-05-24 22:26:28,218 [podnet.py] => Task 1, Epoch 3/20 (LR 0.00473) => LSC_loss 0.09, Spatial_loss 0.77, Flat_loss 0.15, Train_acc 98.45, Test_acc 72.60
2022-05-24 22:26:32,097 [podnet.py] => Task 1, Epoch 4/20 (LR 0.00452) => LSC_loss 0.10, Spatial_loss 0.76, Flat_loss 0.14, Train_acc 98.22, Test_acc 72.40
2022-05-24 22:26:35,916 [podnet.py] => Task 1, Epoch 5/20 (LR 0.00427) => LSC_loss 0.09, Spatial_loss 0.77, Flat_loss 0.14, Train_acc 98.35, Test_acc 72.60
2022-05-24 22:26:39,609 [podnet.py] => Task 1, Epoch 6/20 (LR 0.00397) => LSC_loss 0.09, Spatial_loss 0.76, Flat_loss 0.14, Train_acc 98.48, Test_acc 72.35
2022-05-24 22:26:43,130 [podnet.py] => Task 1, Epoch 7/20 (LR 0.00363) => LSC_loss 0.09, Spatial_loss 0.76, Flat_loss 0.15, Train_acc 98.35, Test_acc 72.90
2022-05-24 22:26:47,037 [podnet.py] => Task 1, Epoch 8/20 (LR 0.00327) => LSC_loss 0.10, Spatial_loss 0.78, Flat_loss 0.15, Train_acc 97.95, Test_acc 72.55
2022-05-24 22:26:50,841 [podnet.py] => Task 1, Epoch 9/20 (LR 0.00289) => LSC_loss 0.09, Spatial_loss 0.77, Flat_loss 0.15, Train_acc 98.40, Test_acc 72.60
2022-05-24 22:26:55,026 [podnet.py] => Task 1, Epoch 10/20 (LR 0.00250) => LSC_loss 0.09, Spatial_loss 0.77, Flat_loss 0.14, Train_acc 98.45, Test_acc 72.70
2022-05-24 22:26:58,594 [podnet.py] => Task 1, Epoch 11/20 (LR 0.00211) => LSC_loss 0.08, Spatial_loss 0.75, Flat_loss 0.14, Train_acc 98.65, Test_acc 73.05
2022-05-24 22:27:02,364 [podnet.py] => Task 1, Epoch 12/20 (LR 0.00173) => LSC_loss 0.08, Spatial_loss 0.78, Flat_loss 0.14, Train_acc 98.60, Test_acc 72.80
2022-05-24 22:27:05,920 [podnet.py] => Task 1, Epoch 13/20 (LR 0.00137) => LSC_loss 0.09, Spatial_loss 0.76, Flat_loss 0.14, Train_acc 98.35, Test_acc 72.95
2022-05-24 22:27:09,585 [podnet.py] => Task 1, Epoch 14/20 (LR 0.00103) => LSC_loss 0.08, Spatial_loss 0.75, Flat_loss 0.14, Train_acc 98.58, Test_acc 73.35
2022-05-24 22:27:13,254 [podnet.py] => Task 1, Epoch 15/20 (LR 0.00073) => LSC_loss 0.09, Spatial_loss 0.75, Flat_loss 0.14, Train_acc 98.82, Test_acc 73.05
2022-05-24 22:27:16,598 [podnet.py] => Task 1, Epoch 16/20 (LR 0.00048) => LSC_loss 0.08, Spatial_loss 0.75, Flat_loss 0.14, Train_acc 98.50, Test_acc 73.05
2022-05-24 22:27:20,509 [podnet.py] => Task 1, Epoch 17/20 (LR 0.00027) => LSC_loss 0.07, Spatial_loss 0.74, Flat_loss 0.14, Train_acc 99.00, Test_acc 73.35
2022-05-24 22:27:24,385 [podnet.py] => Task 1, Epoch 18/20 (LR 0.00012) => LSC_loss 0.08, Spatial_loss 0.76, Flat_loss 0.14, Train_acc 98.65, Test_acc 73.45
2022-05-24 22:27:28,246 [podnet.py] => Task 1, Epoch 19/20 (LR 0.00003) => LSC_loss 0.08, Spatial_loss 0.75, Flat_loss 0.14, Train_acc 98.95, Test_acc 73.55
2022-05-24 22:27:31,714 [podnet.py] => Task 1, Epoch 20/20 (LR 0.00000) => LSC_loss 0.08, Spatial_loss 0.74, Flat_loss 0.14, Train_acc 98.95, Test_acc 72.95
2022-05-24 22:27:31,716 [base.py] => Reducing exemplars...(100 per classes)
2022-05-24 22:27:34,087 [base.py] => Constructing exemplars...(100 per classes)
2022-05-24 22:27:41,871 [podnet.py] => Exemplar size: 2000
2022-05-24 22:27:41,871 [trainer.py] => CNN: {'total': 72.95, '00-09': 84.0, '10-19': 61.9, 'old': 84.0, 'new': 61.9}
2022-05-24 22:27:41,871 [trainer.py] => NME: {'total': 72.05, '00-09': 83.5, '10-19': 60.6, 'old': 83.5, 'new': 60.6}
2022-05-24 22:27:41,871 [trainer.py] => CNN top1 curve: [90.7, 72.95]
2022-05-24 22:27:41,871 [trainer.py] => CNN top5 curve: [99.2, 93.95]
2022-05-24 22:27:41,871 [trainer.py] => NME top1 curve: [90.8, 72.05]
2022-05-24 22:27:41,871 [trainer.py] => NME top5 curve: [99.3, 92.8]

2022-05-24 22:27:41,872 [trainer.py] => All params: 479057
2022-05-24 22:27:41,872 [trainer.py] => Trainable params: 479057
2022-05-24 22:27:41,873 [podnet.py] => Learning on 20-30
2022-05-24 22:27:41,939 [podnet.py] => Adaptive factor: 1.7320508075688772
2022-05-24 22:27:47,880 [podnet.py] => Task 2, Epoch 1/160 (LR 0.09999) => LSC_loss 2.31, Spatial_loss 2.05, Flat_loss 0.49, Train_acc 45.41, Test_acc 43.90
2022-05-24 22:27:53,718 [podnet.py] => Task 2, Epoch 2/160 (LR 0.09996) => LSC_loss 1.33, Spatial_loss 1.77, Flat_loss 0.25, Train_acc 62.11, Test_acc 48.97
2022-05-24 22:27:59,702 [podnet.py] => Task 2, Epoch 3/160 (LR 0.09991) => LSC_loss 1.18, Spatial_loss 1.73, Flat_loss 0.22, Train_acc 66.01, Test_acc 51.87
2022-05-24 22:28:05,829 [podnet.py] => Task 2, Epoch 4/160 (LR 0.09985) => LSC_loss 1.07, Spatial_loss 1.64, Flat_loss 0.21, Train_acc 68.47, Test_acc 52.83
2022-05-24 22:28:12,133 [podnet.py] => Task 2, Epoch 5/160 (LR 0.09976) => LSC_loss 1.01, Spatial_loss 1.62, Flat_loss 0.21, Train_acc 71.56, Test_acc 54.03
2022-05-24 22:28:18,285 [podnet.py] => Task 2, Epoch 6/160 (LR 0.09965) => LSC_loss 0.97, Spatial_loss 1.61, Flat_loss 0.21, Train_acc 71.80, Test_acc 51.83
2022-05-24 22:28:24,083 [podnet.py] => Task 2, Epoch 7/160 (LR 0.09953) => LSC_loss 0.92, Spatial_loss 1.58, Flat_loss 0.20, Train_acc 74.09, Test_acc 49.77
2022-05-24 22:28:30,009 [podnet.py] => Task 2, Epoch 8/160 (LR 0.09938) => LSC_loss 0.89, Spatial_loss 1.59, Flat_loss 0.20, Train_acc 74.64, Test_acc 54.83
2022-05-24 22:28:36,119 [podnet.py] => Task 2, Epoch 9/160 (LR 0.09922) => LSC_loss 0.84, Spatial_loss 1.57, Flat_loss 0.20, Train_acc 75.86, Test_acc 56.50
2022-05-24 22:28:42,343 [podnet.py] => Task 2, Epoch 10/160 (LR 0.09904) => LSC_loss 0.81, Spatial_loss 1.53, Flat_loss 0.20, Train_acc 76.97, Test_acc 55.87
2022-05-24 22:28:48,669 [podnet.py] => Task 2, Epoch 11/160 (LR 0.09884) => LSC_loss 0.79, Spatial_loss 1.53, Flat_loss 0.20, Train_acc 77.69, Test_acc 56.03
2022-05-24 22:28:54,987 [podnet.py] => Task 2, Epoch 12/160 (LR 0.09862) => LSC_loss 0.75, Spatial_loss 1.55, Flat_loss 0.20, Train_acc 78.81, Test_acc 53.27
2022-05-24 22:29:01,269 [podnet.py] => Task 2, Epoch 13/160 (LR 0.09838) => LSC_loss 0.76, Spatial_loss 1.57, Flat_loss 0.20, Train_acc 78.93, Test_acc 53.23
2022-05-24 22:29:07,270 [podnet.py] => Task 2, Epoch 14/160 (LR 0.09812) => LSC_loss 0.76, Spatial_loss 1.58, Flat_loss 0.21, Train_acc 78.60, Test_acc 56.80
2022-05-24 22:29:13,163 [podnet.py] => Task 2, Epoch 15/160 (LR 0.09785) => LSC_loss 0.69, Spatial_loss 1.53, Flat_loss 0.20, Train_acc 80.33, Test_acc 55.97
2022-05-24 22:29:19,107 [podnet.py] => Task 2, Epoch 16/160 (LR 0.09755) => LSC_loss 0.70, Spatial_loss 1.54, Flat_loss 0.21, Train_acc 80.16, Test_acc 60.07
2022-05-24 22:29:25,003 [podnet.py] => Task 2, Epoch 17/160 (LR 0.09724) => LSC_loss 0.70, Spatial_loss 1.56, Flat_loss 0.21, Train_acc 80.23, Test_acc 55.67
2022-05-24 22:29:31,334 [podnet.py] => Task 2, Epoch 18/160 (LR 0.09691) => LSC_loss 0.69, Spatial_loss 1.53, Flat_loss 0.21, Train_acc 80.00, Test_acc 55.23
2022-05-24 22:29:37,467 [podnet.py] => Task 2, Epoch 19/160 (LR 0.09656) => LSC_loss 0.65, Spatial_loss 1.51, Flat_loss 0.21, Train_acc 81.64, Test_acc 54.60
2022-05-24 22:29:43,283 [podnet.py] => Task 2, Epoch 20/160 (LR 0.09619) => LSC_loss 0.64, Spatial_loss 1.50, Flat_loss 0.21, Train_acc 81.90, Test_acc 57.63
2022-05-24 22:29:49,316 [podnet.py] => Task 2, Epoch 21/160 (LR 0.09581) => LSC_loss 0.62, Spatial_loss 1.50, Flat_loss 0.20, Train_acc 82.36, Test_acc 55.60
2022-05-24 22:29:55,335 [podnet.py] => Task 2, Epoch 22/160 (LR 0.09541) => LSC_loss 0.61, Spatial_loss 1.51, Flat_loss 0.21, Train_acc 82.59, Test_acc 53.80
2022-05-24 22:30:01,674 [podnet.py] => Task 2, Epoch 23/160 (LR 0.09499) => LSC_loss 0.65, Spatial_loss 1.53, Flat_loss 0.21, Train_acc 81.47, Test_acc 54.77
2022-05-24 22:30:07,913 [podnet.py] => Task 2, Epoch 24/160 (LR 0.09455) => LSC_loss 0.62, Spatial_loss 1.53, Flat_loss 0.21, Train_acc 82.29, Test_acc 53.43
2022-05-24 22:30:14,118 [podnet.py] => Task 2, Epoch 25/160 (LR 0.09410) => LSC_loss 0.57, Spatial_loss 1.48, Flat_loss 0.20, Train_acc 84.10, Test_acc 58.47
2022-05-24 22:30:20,164 [podnet.py] => Task 2, Epoch 26/160 (LR 0.09362) => LSC_loss 0.58, Spatial_loss 1.49, Flat_loss 0.21, Train_acc 84.04, Test_acc 57.93
2022-05-24 22:30:25,743 [podnet.py] => Task 2, Epoch 27/160 (LR 0.09314) => LSC_loss 0.56, Spatial_loss 1.48, Flat_loss 0.21, Train_acc 84.37, Test_acc 51.90
2022-05-24 22:30:31,823 [podnet.py] => Task 2, Epoch 28/160 (LR 0.09263) => LSC_loss 0.55, Spatial_loss 1.47, Flat_loss 0.20, Train_acc 84.41, Test_acc 57.27
2022-05-24 22:30:38,096 [podnet.py] => Task 2, Epoch 29/160 (LR 0.09211) => LSC_loss 0.55, Spatial_loss 1.49, Flat_loss 0.21, Train_acc 84.46, Test_acc 54.70
2022-05-24 22:30:44,225 [podnet.py] => Task 2, Epoch 30/160 (LR 0.09157) => LSC_loss 0.54, Spatial_loss 1.47, Flat_loss 0.21, Train_acc 84.93, Test_acc 56.53
2022-05-24 22:30:50,382 [podnet.py] => Task 2, Epoch 31/160 (LR 0.09102) => LSC_loss 0.52, Spatial_loss 1.47, Flat_loss 0.21, Train_acc 85.33, Test_acc 57.03
2022-05-24 22:30:56,293 [podnet.py] => Task 2, Epoch 32/160 (LR 0.09045) => LSC_loss 0.54, Spatial_loss 1.45, Flat_loss 0.21, Train_acc 84.49, Test_acc 56.30
2022-05-24 22:31:01,857 [podnet.py] => Task 2, Epoch 33/160 (LR 0.08987) => LSC_loss 0.51, Spatial_loss 1.48, Flat_loss 0.21, Train_acc 85.49, Test_acc 58.17
2022-05-24 22:31:08,032 [podnet.py] => Task 2, Epoch 34/160 (LR 0.08927) => LSC_loss 0.52, Spatial_loss 1.48, Flat_loss 0.21, Train_acc 85.19, Test_acc 55.80
2022-05-24 22:31:14,150 [podnet.py] => Task 2, Epoch 35/160 (LR 0.08865) => LSC_loss 0.51, Spatial_loss 1.47, Flat_loss 0.21, Train_acc 85.77, Test_acc 58.43
2022-05-24 22:31:20,040 [podnet.py] => Task 2, Epoch 36/160 (LR 0.08802) => LSC_loss 0.52, Spatial_loss 1.49, Flat_loss 0.21, Train_acc 85.53, Test_acc 54.27
2022-05-24 22:31:25,848 [podnet.py] => Task 2, Epoch 37/160 (LR 0.08738) => LSC_loss 0.49, Spatial_loss 1.50, Flat_loss 0.21, Train_acc 87.07, Test_acc 57.83
2022-05-24 22:31:31,813 [podnet.py] => Task 2, Epoch 38/160 (LR 0.08672) => LSC_loss 0.46, Spatial_loss 1.45, Flat_loss 0.20, Train_acc 87.17, Test_acc 57.77
2022-05-24 22:31:37,669 [podnet.py] => Task 2, Epoch 39/160 (LR 0.08604) => LSC_loss 0.50, Spatial_loss 1.47, Flat_loss 0.21, Train_acc 86.30, Test_acc 55.60
2022-05-24 22:31:43,845 [podnet.py] => Task 2, Epoch 40/160 (LR 0.08536) => LSC_loss 0.48, Spatial_loss 1.45, Flat_loss 0.21, Train_acc 86.64, Test_acc 58.87
2022-05-24 22:31:50,155 [podnet.py] => Task 2, Epoch 41/160 (LR 0.08465) => LSC_loss 0.46, Spatial_loss 1.46, Flat_loss 0.21, Train_acc 87.00, Test_acc 58.93
2022-05-24 22:31:56,151 [podnet.py] => Task 2, Epoch 42/160 (LR 0.08394) => LSC_loss 0.45, Spatial_loss 1.43, Flat_loss 0.20, Train_acc 87.96, Test_acc 51.87
2022-05-24 22:32:02,020 [podnet.py] => Task 2, Epoch 43/160 (LR 0.08321) => LSC_loss 0.43, Spatial_loss 1.41, Flat_loss 0.20, Train_acc 88.26, Test_acc 55.70
2022-05-24 22:32:07,574 [podnet.py] => Task 2, Epoch 44/160 (LR 0.08247) => LSC_loss 0.46, Spatial_loss 1.44, Flat_loss 0.21, Train_acc 87.16, Test_acc 59.00
2022-05-24 22:32:13,612 [podnet.py] => Task 2, Epoch 45/160 (LR 0.08172) => LSC_loss 0.44, Spatial_loss 1.41, Flat_loss 0.20, Train_acc 88.10, Test_acc 58.30
2022-05-24 22:32:19,776 [podnet.py] => Task 2, Epoch 46/160 (LR 0.08095) => LSC_loss 0.45, Spatial_loss 1.43, Flat_loss 0.20, Train_acc 87.57, Test_acc 53.87
2022-05-24 22:32:25,711 [podnet.py] => Task 2, Epoch 47/160 (LR 0.08018) => LSC_loss 0.41, Spatial_loss 1.42, Flat_loss 0.20, Train_acc 88.69, Test_acc 59.47
2022-05-24 22:32:31,663 [podnet.py] => Task 2, Epoch 48/160 (LR 0.07939) => LSC_loss 0.41, Spatial_loss 1.41, Flat_loss 0.20, Train_acc 88.64, Test_acc 57.63
2022-05-24 22:32:37,632 [podnet.py] => Task 2, Epoch 49/160 (LR 0.07859) => LSC_loss 0.42, Spatial_loss 1.40, Flat_loss 0.20, Train_acc 88.24, Test_acc 56.70
2022-05-24 22:32:43,248 [podnet.py] => Task 2, Epoch 50/160 (LR 0.07778) => LSC_loss 0.40, Spatial_loss 1.41, Flat_loss 0.21, Train_acc 89.14, Test_acc 60.20
2022-05-24 22:32:49,421 [podnet.py] => Task 2, Epoch 51/160 (LR 0.07696) => LSC_loss 0.40, Spatial_loss 1.41, Flat_loss 0.20, Train_acc 88.99, Test_acc 59.20
2022-05-24 22:32:55,529 [podnet.py] => Task 2, Epoch 52/160 (LR 0.07612) => LSC_loss 0.45, Spatial_loss 1.48, Flat_loss 0.21, Train_acc 87.43, Test_acc 55.87
2022-05-24 22:33:01,723 [podnet.py] => Task 2, Epoch 53/160 (LR 0.07528) => LSC_loss 0.40, Spatial_loss 1.43, Flat_loss 0.20, Train_acc 89.37, Test_acc 55.23
2022-05-24 22:33:07,638 [podnet.py] => Task 2, Epoch 54/160 (LR 0.07443) => LSC_loss 0.37, Spatial_loss 1.38, Flat_loss 0.20, Train_acc 89.93, Test_acc 53.07
2022-05-24 22:33:13,196 [podnet.py] => Task 2, Epoch 55/160 (LR 0.07357) => LSC_loss 0.38, Spatial_loss 1.40, Flat_loss 0.20, Train_acc 89.91, Test_acc 57.40
2022-05-24 22:33:19,142 [podnet.py] => Task 2, Epoch 56/160 (LR 0.07270) => LSC_loss 0.37, Spatial_loss 1.37, Flat_loss 0.20, Train_acc 90.03, Test_acc 58.60
2022-05-24 22:33:25,120 [podnet.py] => Task 2, Epoch 57/160 (LR 0.07182) => LSC_loss 0.38, Spatial_loss 1.40, Flat_loss 0.20, Train_acc 89.89, Test_acc 58.33
2022-05-24 22:33:31,126 [podnet.py] => Task 2, Epoch 58/160 (LR 0.07093) => LSC_loss 0.37, Spatial_loss 1.34, Flat_loss 0.20, Train_acc 90.23, Test_acc 59.17
2022-05-24 22:33:37,341 [podnet.py] => Task 2, Epoch 59/160 (LR 0.07004) => LSC_loss 0.38, Spatial_loss 1.36, Flat_loss 0.20, Train_acc 89.77, Test_acc 59.20
2022-05-24 22:33:43,302 [podnet.py] => Task 2, Epoch 60/160 (LR 0.06913) => LSC_loss 0.38, Spatial_loss 1.38, Flat_loss 0.20, Train_acc 89.51, Test_acc 61.67
2022-05-24 22:33:48,926 [podnet.py] => Task 2, Epoch 61/160 (LR 0.06822) => LSC_loss 0.38, Spatial_loss 1.37, Flat_loss 0.20, Train_acc 89.59, Test_acc 55.60
2022-05-24 22:33:54,687 [podnet.py] => Task 2, Epoch 62/160 (LR 0.06731) => LSC_loss 0.36, Spatial_loss 1.34, Flat_loss 0.20, Train_acc 90.84, Test_acc 60.80
2022-05-24 22:34:00,773 [podnet.py] => Task 2, Epoch 63/160 (LR 0.06638) => LSC_loss 0.34, Spatial_loss 1.34, Flat_loss 0.20, Train_acc 91.53, Test_acc 57.93
2022-05-24 22:34:07,167 [podnet.py] => Task 2, Epoch 64/160 (LR 0.06545) => LSC_loss 0.34, Spatial_loss 1.34, Flat_loss 0.20, Train_acc 91.04, Test_acc 58.23
2022-05-24 22:34:13,142 [podnet.py] => Task 2, Epoch 65/160 (LR 0.06451) => LSC_loss 0.36, Spatial_loss 1.38, Flat_loss 0.20, Train_acc 90.36, Test_acc 59.43
2022-05-24 22:34:18,491 [podnet.py] => Task 2, Epoch 66/160 (LR 0.06357) => LSC_loss 0.35, Spatial_loss 1.36, Flat_loss 0.20, Train_acc 90.67, Test_acc 60.33
2022-05-24 22:34:24,690 [podnet.py] => Task 2, Epoch 67/160 (LR 0.06262) => LSC_loss 0.34, Spatial_loss 1.33, Flat_loss 0.19, Train_acc 90.91, Test_acc 58.17
2022-05-24 22:34:30,994 [podnet.py] => Task 2, Epoch 68/160 (LR 0.06167) => LSC_loss 0.32, Spatial_loss 1.31, Flat_loss 0.19, Train_acc 91.59, Test_acc 58.17
2022-05-24 22:34:36,933 [podnet.py] => Task 2, Epoch 69/160 (LR 0.06072) => LSC_loss 0.33, Spatial_loss 1.35, Flat_loss 0.20, Train_acc 91.56, Test_acc 58.97
2022-05-24 22:34:43,083 [podnet.py] => Task 2, Epoch 70/160 (LR 0.05975) => LSC_loss 0.33, Spatial_loss 1.32, Flat_loss 0.19, Train_acc 91.50, Test_acc 59.67
2022-05-24 22:34:48,842 [podnet.py] => Task 2, Epoch 71/160 (LR 0.05879) => LSC_loss 0.32, Spatial_loss 1.30, Flat_loss 0.20, Train_acc 91.86, Test_acc 61.00
2022-05-24 22:34:54,523 [podnet.py] => Task 2, Epoch 72/160 (LR 0.05782) => LSC_loss 0.30, Spatial_loss 1.29, Flat_loss 0.19, Train_acc 92.60, Test_acc 54.70
2022-05-24 22:35:00,787 [podnet.py] => Task 2, Epoch 73/160 (LR 0.05685) => LSC_loss 0.31, Spatial_loss 1.30, Flat_loss 0.19, Train_acc 91.84, Test_acc 54.87
2022-05-24 22:35:06,836 [podnet.py] => Task 2, Epoch 74/160 (LR 0.05588) => LSC_loss 0.31, Spatial_loss 1.28, Flat_loss 0.19, Train_acc 92.46, Test_acc 59.33
2022-05-24 22:35:13,063 [podnet.py] => Task 2, Epoch 75/160 (LR 0.05490) => LSC_loss 0.32, Spatial_loss 1.31, Flat_loss 0.19, Train_acc 91.39, Test_acc 59.67
2022-05-24 22:35:19,199 [podnet.py] => Task 2, Epoch 76/160 (LR 0.05392) => LSC_loss 0.29, Spatial_loss 1.28, Flat_loss 0.19, Train_acc 92.91, Test_acc 59.13
2022-05-24 22:35:24,824 [podnet.py] => Task 2, Epoch 77/160 (LR 0.05294) => LSC_loss 0.31, Spatial_loss 1.28, Flat_loss 0.19, Train_acc 91.93, Test_acc 59.37
2022-05-24 22:35:30,579 [podnet.py] => Task 2, Epoch 78/160 (LR 0.05196) => LSC_loss 0.28, Spatial_loss 1.26, Flat_loss 0.19, Train_acc 92.89, Test_acc 57.40
2022-05-24 22:35:36,744 [podnet.py] => Task 2, Epoch 79/160 (LR 0.05098) => LSC_loss 0.27, Spatial_loss 1.23, Flat_loss 0.19, Train_acc 93.70, Test_acc 60.87
2022-05-24 22:35:42,711 [podnet.py] => Task 2, Epoch 80/160 (LR 0.05000) => LSC_loss 0.27, Spatial_loss 1.24, Flat_loss 0.19, Train_acc 93.46, Test_acc 62.13
2022-05-24 22:35:48,912 [podnet.py] => Task 2, Epoch 81/160 (LR 0.04902) => LSC_loss 0.29, Spatial_loss 1.22, Flat_loss 0.18, Train_acc 93.01, Test_acc 58.63
2022-05-24 22:35:54,791 [podnet.py] => Task 2, Epoch 82/160 (LR 0.04804) => LSC_loss 0.27, Spatial_loss 1.24, Flat_loss 0.18, Train_acc 93.27, Test_acc 59.10
2022-05-24 22:36:00,428 [podnet.py] => Task 2, Epoch 83/160 (LR 0.04706) => LSC_loss 0.25, Spatial_loss 1.22, Flat_loss 0.18, Train_acc 94.16, Test_acc 61.17
2022-05-24 22:36:06,427 [podnet.py] => Task 2, Epoch 84/160 (LR 0.04608) => LSC_loss 0.25, Spatial_loss 1.22, Flat_loss 0.18, Train_acc 93.87, Test_acc 59.77
2022-05-24 22:36:12,722 [podnet.py] => Task 2, Epoch 85/160 (LR 0.04510) => LSC_loss 0.24, Spatial_loss 1.17, Flat_loss 0.18, Train_acc 94.59, Test_acc 62.83
2022-05-24 22:36:18,962 [podnet.py] => Task 2, Epoch 86/160 (LR 0.04412) => LSC_loss 0.24, Spatial_loss 1.18, Flat_loss 0.18, Train_acc 94.54, Test_acc 61.03
2022-05-24 22:36:25,249 [podnet.py] => Task 2, Epoch 87/160 (LR 0.04315) => LSC_loss 0.26, Spatial_loss 1.20, Flat_loss 0.19, Train_acc 93.69, Test_acc 60.23
2022-05-24 22:36:31,322 [podnet.py] => Task 2, Epoch 88/160 (LR 0.04218) => LSC_loss 0.24, Spatial_loss 1.18, Flat_loss 0.18, Train_acc 94.61, Test_acc 59.53
2022-05-24 22:36:37,150 [podnet.py] => Task 2, Epoch 89/160 (LR 0.04121) => LSC_loss 0.24, Spatial_loss 1.17, Flat_loss 0.18, Train_acc 94.33, Test_acc 60.00
2022-05-24 22:36:43,014 [podnet.py] => Task 2, Epoch 90/160 (LR 0.04025) => LSC_loss 0.24, Spatial_loss 1.18, Flat_loss 0.18, Train_acc 94.14, Test_acc 62.00
2022-05-24 22:36:48,927 [podnet.py] => Task 2, Epoch 91/160 (LR 0.03928) => LSC_loss 0.24, Spatial_loss 1.16, Flat_loss 0.18, Train_acc 94.30, Test_acc 63.27
2022-05-24 22:36:55,004 [podnet.py] => Task 2, Epoch 92/160 (LR 0.03833) => LSC_loss 0.23, Spatial_loss 1.15, Flat_loss 0.18, Train_acc 94.56, Test_acc 61.63
2022-05-24 22:37:01,555 [podnet.py] => Task 2, Epoch 93/160 (LR 0.03738) => LSC_loss 0.22, Spatial_loss 1.14, Flat_loss 0.18, Train_acc 95.36, Test_acc 61.23
2022-05-24 22:37:07,862 [podnet.py] => Task 2, Epoch 94/160 (LR 0.03643) => LSC_loss 0.21, Spatial_loss 1.12, Flat_loss 0.17, Train_acc 95.76, Test_acc 61.53
2022-05-24 22:37:14,268 [podnet.py] => Task 2, Epoch 95/160 (LR 0.03549) => LSC_loss 0.21, Spatial_loss 1.11, Flat_loss 0.17, Train_acc 95.59, Test_acc 62.90
2022-05-24 22:37:20,408 [podnet.py] => Task 2, Epoch 96/160 (LR 0.03455) => LSC_loss 0.21, Spatial_loss 1.11, Flat_loss 0.17, Train_acc 95.21, Test_acc 60.93
2022-05-24 22:37:26,716 [podnet.py] => Task 2, Epoch 97/160 (LR 0.03362) => LSC_loss 0.21, Spatial_loss 1.12, Flat_loss 0.17, Train_acc 95.50, Test_acc 60.77
2022-05-24 22:37:32,839 [podnet.py] => Task 2, Epoch 98/160 (LR 0.03269) => LSC_loss 0.19, Spatial_loss 1.07, Flat_loss 0.17, Train_acc 96.23, Test_acc 63.27
2022-05-24 22:37:38,606 [podnet.py] => Task 2, Epoch 99/160 (LR 0.03178) => LSC_loss 0.20, Spatial_loss 1.09, Flat_loss 0.17, Train_acc 95.89, Test_acc 62.00
2022-05-24 22:37:44,693 [podnet.py] => Task 2, Epoch 100/160 (LR 0.03087) => LSC_loss 0.20, Spatial_loss 1.11, Flat_loss 0.17, Train_acc 95.84, Test_acc 63.17
2022-05-24 22:37:50,569 [podnet.py] => Task 2, Epoch 101/160 (LR 0.02996) => LSC_loss 0.21, Spatial_loss 1.10, Flat_loss 0.17, Train_acc 95.63, Test_acc 63.77
2022-05-24 22:37:56,717 [podnet.py] => Task 2, Epoch 102/160 (LR 0.02907) => LSC_loss 0.18, Spatial_loss 1.07, Flat_loss 0.17, Train_acc 96.57, Test_acc 61.77
2022-05-24 22:38:02,885 [podnet.py] => Task 2, Epoch 103/160 (LR 0.02818) => LSC_loss 0.18, Spatial_loss 1.06, Flat_loss 0.17, Train_acc 96.61, Test_acc 61.50
2022-05-24 22:38:08,913 [podnet.py] => Task 2, Epoch 104/160 (LR 0.02730) => LSC_loss 0.18, Spatial_loss 1.04, Flat_loss 0.17, Train_acc 96.79, Test_acc 62.60
2022-05-24 22:38:14,871 [podnet.py] => Task 2, Epoch 105/160 (LR 0.02643) => LSC_loss 0.18, Spatial_loss 1.03, Flat_loss 0.16, Train_acc 96.61, Test_acc 58.43
2022-05-24 22:38:20,702 [podnet.py] => Task 2, Epoch 106/160 (LR 0.02557) => LSC_loss 0.18, Spatial_loss 1.06, Flat_loss 0.17, Train_acc 96.39, Test_acc 61.27
2022-05-24 22:38:26,489 [podnet.py] => Task 2, Epoch 107/160 (LR 0.02472) => LSC_loss 0.18, Spatial_loss 1.05, Flat_loss 0.17, Train_acc 96.86, Test_acc 62.13
2022-05-24 22:38:32,738 [podnet.py] => Task 2, Epoch 108/160 (LR 0.02388) => LSC_loss 0.18, Spatial_loss 1.05, Flat_loss 0.17, Train_acc 96.59, Test_acc 61.43
2022-05-24 22:38:38,733 [podnet.py] => Task 2, Epoch 109/160 (LR 0.02304) => LSC_loss 0.17, Spatial_loss 1.01, Flat_loss 0.16, Train_acc 97.21, Test_acc 61.33
2022-05-24 22:38:44,797 [podnet.py] => Task 2, Epoch 110/160 (LR 0.02222) => LSC_loss 0.17, Spatial_loss 1.01, Flat_loss 0.16, Train_acc 96.81, Test_acc 62.20
2022-05-24 22:38:50,759 [podnet.py] => Task 2, Epoch 111/160 (LR 0.02141) => LSC_loss 0.16, Spatial_loss 1.01, Flat_loss 0.16, Train_acc 97.27, Test_acc 63.27
2022-05-24 22:38:56,424 [podnet.py] => Task 2, Epoch 112/160 (LR 0.02061) => LSC_loss 0.16, Spatial_loss 0.99, Flat_loss 0.16, Train_acc 97.41, Test_acc 63.03
2022-05-24 22:39:02,374 [podnet.py] => Task 2, Epoch 113/160 (LR 0.01982) => LSC_loss 0.16, Spatial_loss 1.01, Flat_loss 0.16, Train_acc 97.37, Test_acc 62.13
2022-05-24 22:39:08,395 [podnet.py] => Task 2, Epoch 114/160 (LR 0.01905) => LSC_loss 0.16, Spatial_loss 0.98, Flat_loss 0.16, Train_acc 97.23, Test_acc 61.33
2022-05-24 22:39:14,227 [podnet.py] => Task 2, Epoch 115/160 (LR 0.01828) => LSC_loss 0.15, Spatial_loss 0.98, Flat_loss 0.16, Train_acc 97.51, Test_acc 62.90
2022-05-24 22:39:20,784 [podnet.py] => Task 2, Epoch 116/160 (LR 0.01753) => LSC_loss 0.15, Spatial_loss 0.94, Flat_loss 0.16, Train_acc 97.91, Test_acc 63.13
2022-05-24 22:39:27,004 [podnet.py] => Task 2, Epoch 117/160 (LR 0.01679) => LSC_loss 0.15, Spatial_loss 0.96, Flat_loss 0.16, Train_acc 97.60, Test_acc 63.47
2022-05-24 22:39:32,977 [podnet.py] => Task 2, Epoch 118/160 (LR 0.01606) => LSC_loss 0.15, Spatial_loss 0.95, Flat_loss 0.16, Train_acc 97.71, Test_acc 63.33
2022-05-24 22:39:39,005 [podnet.py] => Task 2, Epoch 119/160 (LR 0.01535) => LSC_loss 0.15, Spatial_loss 0.95, Flat_loss 0.16, Train_acc 97.66, Test_acc 63.03
2022-05-24 22:39:44,674 [podnet.py] => Task 2, Epoch 120/160 (LR 0.01464) => LSC_loss 0.13, Spatial_loss 0.93, Flat_loss 0.15, Train_acc 98.46, Test_acc 64.37
2022-05-24 22:39:50,770 [podnet.py] => Task 2, Epoch 121/160 (LR 0.01396) => LSC_loss 0.14, Spatial_loss 0.91, Flat_loss 0.15, Train_acc 97.91, Test_acc 63.10
2022-05-24 22:39:56,955 [podnet.py] => Task 2, Epoch 122/160 (LR 0.01328) => LSC_loss 0.14, Spatial_loss 0.92, Flat_loss 0.15, Train_acc 97.93, Test_acc 63.23
2022-05-24 22:40:02,822 [podnet.py] => Task 2, Epoch 123/160 (LR 0.01262) => LSC_loss 0.14, Spatial_loss 0.92, Flat_loss 0.15, Train_acc 98.06, Test_acc 63.43
2022-05-24 22:40:08,940 [podnet.py] => Task 2, Epoch 124/160 (LR 0.01198) => LSC_loss 0.13, Spatial_loss 0.94, Flat_loss 0.15, Train_acc 98.21, Test_acc 63.80
2022-05-24 22:40:14,905 [podnet.py] => Task 2, Epoch 125/160 (LR 0.01135) => LSC_loss 0.14, Spatial_loss 0.91, Flat_loss 0.15, Train_acc 97.94, Test_acc 63.17
2022-05-24 22:40:20,441 [podnet.py] => Task 2, Epoch 126/160 (LR 0.01073) => LSC_loss 0.13, Spatial_loss 0.89, Flat_loss 0.15, Train_acc 98.49, Test_acc 64.30
2022-05-24 22:40:26,291 [podnet.py] => Task 2, Epoch 127/160 (LR 0.01013) => LSC_loss 0.13, Spatial_loss 0.89, Flat_loss 0.15, Train_acc 98.37, Test_acc 63.97
2022-05-24 22:40:32,316 [podnet.py] => Task 2, Epoch 128/160 (LR 0.00955) => LSC_loss 0.13, Spatial_loss 0.90, Flat_loss 0.15, Train_acc 98.47, Test_acc 63.40
2022-05-24 22:40:38,547 [podnet.py] => Task 2, Epoch 129/160 (LR 0.00898) => LSC_loss 0.13, Spatial_loss 0.89, Flat_loss 0.15, Train_acc 98.33, Test_acc 63.73
2022-05-24 22:40:45,048 [podnet.py] => Task 2, Epoch 130/160 (LR 0.00843) => LSC_loss 0.13, Spatial_loss 0.87, Flat_loss 0.15, Train_acc 98.34, Test_acc 64.23
2022-05-24 22:40:50,911 [podnet.py] => Task 2, Epoch 131/160 (LR 0.00789) => LSC_loss 0.13, Spatial_loss 0.87, Flat_loss 0.15, Train_acc 98.36, Test_acc 63.80
2022-05-24 22:40:56,909 [podnet.py] => Task 2, Epoch 132/160 (LR 0.00737) => LSC_loss 0.13, Spatial_loss 0.88, Flat_loss 0.15, Train_acc 98.43, Test_acc 64.27
2022-05-24 22:41:02,739 [podnet.py] => Task 2, Epoch 133/160 (LR 0.00686) => LSC_loss 0.13, Spatial_loss 0.87, Flat_loss 0.15, Train_acc 98.24, Test_acc 63.93
2022-05-24 22:41:08,241 [podnet.py] => Task 2, Epoch 134/160 (LR 0.00638) => LSC_loss 0.12, Spatial_loss 0.87, Flat_loss 0.15, Train_acc 98.46, Test_acc 63.63
2022-05-24 22:41:14,721 [podnet.py] => Task 2, Epoch 135/160 (LR 0.00590) => LSC_loss 0.12, Spatial_loss 0.86, Flat_loss 0.15, Train_acc 98.51, Test_acc 63.97
2022-05-24 22:41:20,453 [podnet.py] => Task 2, Epoch 136/160 (LR 0.00545) => LSC_loss 0.12, Spatial_loss 0.85, Flat_loss 0.15, Train_acc 98.66, Test_acc 64.57
2022-05-24 22:41:26,174 [podnet.py] => Task 2, Epoch 137/160 (LR 0.00501) => LSC_loss 0.11, Spatial_loss 0.86, Flat_loss 0.15, Train_acc 98.99, Test_acc 64.17
2022-05-24 22:41:32,225 [podnet.py] => Task 2, Epoch 138/160 (LR 0.00459) => LSC_loss 0.12, Spatial_loss 0.85, Flat_loss 0.14, Train_acc 98.67, Test_acc 64.13
2022-05-24 22:41:38,375 [podnet.py] => Task 2, Epoch 139/160 (LR 0.00419) => LSC_loss 0.12, Spatial_loss 0.84, Flat_loss 0.14, Train_acc 98.63, Test_acc 64.20
2022-05-24 22:41:44,246 [podnet.py] => Task 2, Epoch 140/160 (LR 0.00381) => LSC_loss 0.12, Spatial_loss 0.84, Flat_loss 0.14, Train_acc 98.77, Test_acc 64.37
2022-05-24 22:41:50,099 [podnet.py] => Task 2, Epoch 141/160 (LR 0.00344) => LSC_loss 0.12, Spatial_loss 0.84, Flat_loss 0.14, Train_acc 98.74, Test_acc 64.63
2022-05-24 22:41:55,818 [podnet.py] => Task 2, Epoch 142/160 (LR 0.00309) => LSC_loss 0.12, Spatial_loss 0.83, Flat_loss 0.14, Train_acc 98.79, Test_acc 64.33
2022-05-24 22:42:02,102 [podnet.py] => Task 2, Epoch 143/160 (LR 0.00276) => LSC_loss 0.12, Spatial_loss 0.83, Flat_loss 0.14, Train_acc 98.76, Test_acc 64.27
2022-05-24 22:42:08,306 [podnet.py] => Task 2, Epoch 144/160 (LR 0.00245) => LSC_loss 0.12, Spatial_loss 0.83, Flat_loss 0.14, Train_acc 98.83, Test_acc 64.00
2022-05-24 22:42:14,503 [podnet.py] => Task 2, Epoch 145/160 (LR 0.00215) => LSC_loss 0.11, Spatial_loss 0.83, Flat_loss 0.14, Train_acc 99.06, Test_acc 64.30
2022-05-24 22:42:20,368 [podnet.py] => Task 2, Epoch 146/160 (LR 0.00188) => LSC_loss 0.11, Spatial_loss 0.80, Flat_loss 0.14, Train_acc 98.89, Test_acc 64.03
2022-05-24 22:42:26,240 [podnet.py] => Task 2, Epoch 147/160 (LR 0.00162) => LSC_loss 0.12, Spatial_loss 0.81, Flat_loss 0.14, Train_acc 98.83, Test_acc 64.40
2022-05-24 22:42:32,018 [podnet.py] => Task 2, Epoch 148/160 (LR 0.00138) => LSC_loss 0.11, Spatial_loss 0.81, Flat_loss 0.14, Train_acc 99.07, Test_acc 64.30
2022-05-24 22:42:38,152 [podnet.py] => Task 2, Epoch 149/160 (LR 0.00116) => LSC_loss 0.11, Spatial_loss 0.80, Flat_loss 0.14, Train_acc 99.09, Test_acc 64.47
2022-05-24 22:42:44,485 [podnet.py] => Task 2, Epoch 150/160 (LR 0.00096) => LSC_loss 0.12, Spatial_loss 0.81, Flat_loss 0.14, Train_acc 98.83, Test_acc 64.30
2022-05-24 22:42:50,564 [podnet.py] => Task 2, Epoch 151/160 (LR 0.00078) => LSC_loss 0.11, Spatial_loss 0.81, Flat_loss 0.14, Train_acc 98.93, Test_acc 64.47
2022-05-24 22:42:56,194 [podnet.py] => Task 2, Epoch 152/160 (LR 0.00062) => LSC_loss 0.11, Spatial_loss 0.80, Flat_loss 0.14, Train_acc 98.84, Test_acc 64.37
2022-05-24 22:43:01,988 [podnet.py] => Task 2, Epoch 153/160 (LR 0.00047) => LSC_loss 0.11, Spatial_loss 0.78, Flat_loss 0.14, Train_acc 99.04, Test_acc 64.57
2022-05-24 22:43:08,178 [podnet.py] => Task 2, Epoch 154/160 (LR 0.00035) => LSC_loss 0.11, Spatial_loss 0.80, Flat_loss 0.14, Train_acc 99.03, Test_acc 64.20
2022-05-24 22:43:14,414 [podnet.py] => Task 2, Epoch 155/160 (LR 0.00024) => LSC_loss 0.11, Spatial_loss 0.80, Flat_loss 0.14, Train_acc 98.84, Test_acc 64.37
2022-05-24 22:43:20,334 [podnet.py] => Task 2, Epoch 156/160 (LR 0.00015) => LSC_loss 0.11, Spatial_loss 0.78, Flat_loss 0.14, Train_acc 99.14, Test_acc 64.33
2022-05-24 22:43:26,294 [podnet.py] => Task 2, Epoch 157/160 (LR 0.00009) => LSC_loss 0.11, Spatial_loss 0.79, Flat_loss 0.14, Train_acc 98.81, Test_acc 64.23
2022-05-24 22:43:32,141 [podnet.py] => Task 2, Epoch 158/160 (LR 0.00004) => LSC_loss 0.11, Spatial_loss 0.78, Flat_loss 0.14, Train_acc 99.06, Test_acc 64.17
2022-05-24 22:43:37,889 [podnet.py] => Task 2, Epoch 159/160 (LR 0.00001) => LSC_loss 0.11, Spatial_loss 0.79, Flat_loss 0.14, Train_acc 99.06, Test_acc 64.27
2022-05-24 22:43:44,166 [podnet.py] => Task 2, Epoch 160/160 (LR 0.00000) => LSC_loss 0.12, Spatial_loss 0.79, Flat_loss 0.14, Train_acc 98.79, Test_acc 64.23
2022-05-24 22:43:44,167 [podnet.py] => Finetune the network (classifier part) with the undersampled dataset!
2022-05-24 22:43:44,167 [base.py] => Reducing exemplars...(100 per classes)
2022-05-24 22:43:48,670 [base.py] => Constructing exemplars...(100 per classes)
2022-05-24 22:43:54,959 [podnet.py] => The size of finetune dataset: 3000
2022-05-24 22:43:57,937 [podnet.py] => Task 2, Epoch 1/20 (LR 0.00497) => LSC_loss 0.12, Spatial_loss 0.81, Flat_loss 0.10, Train_acc 98.73, Test_acc 65.30
2022-05-24 22:44:00,831 [podnet.py] => Task 2, Epoch 2/20 (LR 0.00488) => LSC_loss 0.10, Spatial_loss 0.80, Flat_loss 0.09, Train_acc 98.80, Test_acc 64.90
2022-05-24 22:44:03,676 [podnet.py] => Task 2, Epoch 3/20 (LR 0.00473) => LSC_loss 0.10, Spatial_loss 0.81, Flat_loss 0.09, Train_acc 98.83, Test_acc 65.30
2022-05-24 22:44:06,935 [podnet.py] => Task 2, Epoch 4/20 (LR 0.00452) => LSC_loss 0.09, Spatial_loss 0.79, Flat_loss 0.09, Train_acc 99.03, Test_acc 64.77
2022-05-24 22:44:10,097 [podnet.py] => Task 2, Epoch 5/20 (LR 0.00427) => LSC_loss 0.09, Spatial_loss 0.81, Flat_loss 0.09, Train_acc 99.23, Test_acc 65.07
2022-05-24 22:44:13,164 [podnet.py] => Task 2, Epoch 6/20 (LR 0.00397) => LSC_loss 0.09, Spatial_loss 0.80, Flat_loss 0.09, Train_acc 99.17, Test_acc 65.80
2022-05-24 22:44:16,135 [podnet.py] => Task 2, Epoch 7/20 (LR 0.00363) => LSC_loss 0.09, Spatial_loss 0.78, Flat_loss 0.09, Train_acc 98.90, Test_acc 65.30
2022-05-24 22:44:19,288 [podnet.py] => Task 2, Epoch 8/20 (LR 0.00327) => LSC_loss 0.09, Spatial_loss 0.78, Flat_loss 0.09, Train_acc 98.93, Test_acc 65.23
2022-05-24 22:44:22,605 [podnet.py] => Task 2, Epoch 9/20 (LR 0.00289) => LSC_loss 0.09, Spatial_loss 0.79, Flat_loss 0.09, Train_acc 98.87, Test_acc 65.40
2022-05-24 22:44:25,934 [podnet.py] => Task 2, Epoch 10/20 (LR 0.00250) => LSC_loss 0.09, Spatial_loss 0.79, Flat_loss 0.09, Train_acc 99.03, Test_acc 64.77
2022-05-24 22:44:29,330 [podnet.py] => Task 2, Epoch 11/20 (LR 0.00211) => LSC_loss 0.09, Spatial_loss 0.78, Flat_loss 0.09, Train_acc 99.03, Test_acc 65.33
2022-05-24 22:44:32,312 [podnet.py] => Task 2, Epoch 12/20 (LR 0.00173) => LSC_loss 0.09, Spatial_loss 0.79, Flat_loss 0.09, Train_acc 99.10, Test_acc 65.50
2022-05-24 22:44:35,213 [podnet.py] => Task 2, Epoch 13/20 (LR 0.00137) => LSC_loss 0.09, Spatial_loss 0.80, Flat_loss 0.09, Train_acc 99.13, Test_acc 65.70
2022-05-24 22:44:38,491 [podnet.py] => Task 2, Epoch 14/20 (LR 0.00103) => LSC_loss 0.08, Spatial_loss 0.77, Flat_loss 0.09, Train_acc 99.10, Test_acc 65.83
2022-05-24 22:44:41,885 [podnet.py] => Task 2, Epoch 15/20 (LR 0.00073) => LSC_loss 0.08, Spatial_loss 0.77, Flat_loss 0.09, Train_acc 99.00, Test_acc 65.87
2022-05-24 22:44:44,911 [podnet.py] => Task 2, Epoch 16/20 (LR 0.00048) => LSC_loss 0.09, Spatial_loss 0.77, Flat_loss 0.09, Train_acc 99.00, Test_acc 65.60
2022-05-24 22:44:48,139 [podnet.py] => Task 2, Epoch 17/20 (LR 0.00027) => LSC_loss 0.09, Spatial_loss 0.76, Flat_loss 0.09, Train_acc 98.87, Test_acc 65.70
2022-05-24 22:44:51,229 [podnet.py] => Task 2, Epoch 18/20 (LR 0.00012) => LSC_loss 0.08, Spatial_loss 0.78, Flat_loss 0.09, Train_acc 99.23, Test_acc 65.60
2022-05-24 22:44:54,372 [podnet.py] => Task 2, Epoch 19/20 (LR 0.00003) => LSC_loss 0.08, Spatial_loss 0.76, Flat_loss 0.09, Train_acc 99.27, Test_acc 65.53
2022-05-24 22:44:57,644 [podnet.py] => Task 2, Epoch 20/20 (LR 0.00000) => LSC_loss 0.09, Spatial_loss 0.76, Flat_loss 0.09, Train_acc 99.10, Test_acc 65.47
2022-05-24 22:44:57,646 [base.py] => Reducing exemplars...(66 per classes)
2022-05-24 22:45:02,297 [base.py] => Constructing exemplars...(66 per classes)
2022-05-24 22:45:10,108 [podnet.py] => Exemplar size: 1980
2022-05-24 22:45:10,108 [trainer.py] => CNN: {'total': 65.47, '00-09': 77.7, '10-19': 47.1, '20-29': 71.6, 'old': 62.4, 'new': 71.6}
2022-05-24 22:45:10,108 [trainer.py] => NME: {'total': 63.37, '00-09': 78.1, '10-19': 43.1, '20-29': 68.9, 'old': 60.6, 'new': 68.9}
2022-05-24 22:45:10,108 [trainer.py] => CNN top1 curve: [90.7, 72.95, 65.47]
2022-05-24 22:45:10,108 [trainer.py] => CNN top5 curve: [99.2, 93.95, 90.1]
2022-05-24 22:45:10,108 [trainer.py] => NME top1 curve: [90.8, 72.05, 63.37]
2022-05-24 22:45:10,108 [trainer.py] => NME top5 curve: [99.3, 92.8, 88.93]

2022-05-24 22:45:10,109 [trainer.py] => All params: 485457
2022-05-24 22:45:10,109 [trainer.py] => Trainable params: 485457
2022-05-24 22:45:10,110 [podnet.py] => Learning on 30-40
2022-05-24 22:45:10,173 [podnet.py] => Adaptive factor: 2.0
2022-05-24 22:45:16,187 [podnet.py] => Task 3, Epoch 1/160 (LR 0.09999) => LSC_loss 2.64, Spatial_loss 2.40, Flat_loss 0.63, Train_acc 40.52, Test_acc 38.15
2022-05-24 22:45:22,103 [podnet.py] => Task 3, Epoch 2/160 (LR 0.09996) => LSC_loss 1.56, Spatial_loss 1.99, Flat_loss 0.31, Train_acc 54.99, Test_acc 34.38
2022-05-24 22:45:28,281 [podnet.py] => Task 3, Epoch 3/160 (LR 0.09991) => LSC_loss 1.38, Spatial_loss 1.85, Flat_loss 0.26, Train_acc 60.26, Test_acc 40.40
2022-05-24 22:45:34,742 [podnet.py] => Task 3, Epoch 4/160 (LR 0.09985) => LSC_loss 1.29, Spatial_loss 1.80, Flat_loss 0.24, Train_acc 62.61, Test_acc 39.45
2022-05-24 22:45:40,665 [podnet.py] => Task 3, Epoch 5/160 (LR 0.09976) => LSC_loss 1.22, Spatial_loss 1.79, Flat_loss 0.23, Train_acc 65.00, Test_acc 47.08
2022-05-24 22:45:46,742 [podnet.py] => Task 3, Epoch 6/160 (LR 0.09965) => LSC_loss 1.15, Spatial_loss 1.73, Flat_loss 0.23, Train_acc 67.44, Test_acc 43.88
2022-05-24 22:45:52,610 [podnet.py] => Task 3, Epoch 7/160 (LR 0.09953) => LSC_loss 1.11, Spatial_loss 1.75, Flat_loss 0.23, Train_acc 67.72, Test_acc 45.40
2022-05-24 22:45:58,983 [podnet.py] => Task 3, Epoch 8/160 (LR 0.09938) => LSC_loss 1.09, Spatial_loss 1.73, Flat_loss 0.22, Train_acc 68.24, Test_acc 45.12
2022-05-24 22:46:05,199 [podnet.py] => Task 3, Epoch 9/160 (LR 0.09922) => LSC_loss 1.04, Spatial_loss 1.70, Flat_loss 0.22, Train_acc 70.04, Test_acc 45.58
2022-05-24 22:46:11,358 [podnet.py] => Task 3, Epoch 10/160 (LR 0.09904) => LSC_loss 1.01, Spatial_loss 1.70, Flat_loss 0.22, Train_acc 70.69, Test_acc 43.05
2022-05-24 22:46:17,448 [podnet.py] => Task 3, Epoch 11/160 (LR 0.09884) => LSC_loss 0.98, Spatial_loss 1.70, Flat_loss 0.22, Train_acc 71.88, Test_acc 49.58
2022-05-24 22:46:23,436 [podnet.py] => Task 3, Epoch 12/160 (LR 0.09862) => LSC_loss 0.97, Spatial_loss 1.67, Flat_loss 0.22, Train_acc 72.18, Test_acc 47.40
2022-05-24 22:46:29,242 [podnet.py] => Task 3, Epoch 13/160 (LR 0.09838) => LSC_loss 0.95, Spatial_loss 1.71, Flat_loss 0.22, Train_acc 72.46, Test_acc 45.08
2022-05-24 22:46:35,387 [podnet.py] => Task 3, Epoch 14/160 (LR 0.09812) => LSC_loss 0.91, Spatial_loss 1.66, Flat_loss 0.22, Train_acc 74.56, Test_acc 48.55
2022-05-24 22:46:41,753 [podnet.py] => Task 3, Epoch 15/160 (LR 0.09785) => LSC_loss 0.89, Spatial_loss 1.66, Flat_loss 0.22, Train_acc 74.60, Test_acc 43.12
2022-05-24 22:46:48,089 [podnet.py] => Task 3, Epoch 16/160 (LR 0.09755) => LSC_loss 0.87, Spatial_loss 1.67, Flat_loss 0.22, Train_acc 74.77, Test_acc 43.40
2022-05-24 22:46:54,651 [podnet.py] => Task 3, Epoch 17/160 (LR 0.09724) => LSC_loss 0.85, Spatial_loss 1.67, Flat_loss 0.22, Train_acc 76.29, Test_acc 45.70
2022-05-24 22:47:00,813 [podnet.py] => Task 3, Epoch 18/160 (LR 0.09691) => LSC_loss 0.84, Spatial_loss 1.64, Flat_loss 0.22, Train_acc 75.86, Test_acc 47.28
2022-05-24 22:47:07,112 [podnet.py] => Task 3, Epoch 19/160 (LR 0.09656) => LSC_loss 0.86, Spatial_loss 1.66, Flat_loss 0.22, Train_acc 76.00, Test_acc 47.90
2022-05-24 22:47:13,665 [podnet.py] => Task 3, Epoch 20/160 (LR 0.09619) => LSC_loss 0.81, Spatial_loss 1.64, Flat_loss 0.23, Train_acc 77.18, Test_acc 42.85
2022-05-24 22:47:19,721 [podnet.py] => Task 3, Epoch 21/160 (LR 0.09581) => LSC_loss 0.79, Spatial_loss 1.62, Flat_loss 0.22, Train_acc 77.91, Test_acc 49.92
2022-05-24 22:47:25,888 [podnet.py] => Task 3, Epoch 22/160 (LR 0.09541) => LSC_loss 0.78, Spatial_loss 1.64, Flat_loss 0.22, Train_acc 78.17, Test_acc 40.17
2022-05-24 22:47:31,606 [podnet.py] => Task 3, Epoch 23/160 (LR 0.09499) => LSC_loss 0.77, Spatial_loss 1.66, Flat_loss 0.22, Train_acc 78.45, Test_acc 46.82
2022-05-24 22:47:37,738 [podnet.py] => Task 3, Epoch 24/160 (LR 0.09455) => LSC_loss 0.77, Spatial_loss 1.64, Flat_loss 0.23, Train_acc 78.81, Test_acc 49.98
2022-05-24 22:47:44,025 [podnet.py] => Task 3, Epoch 25/160 (LR 0.09410) => LSC_loss 0.80, Spatial_loss 1.68, Flat_loss 0.23, Train_acc 76.86, Test_acc 47.12
2022-05-24 22:47:50,104 [podnet.py] => Task 3, Epoch 26/160 (LR 0.09362) => LSC_loss 0.74, Spatial_loss 1.64, Flat_loss 0.23, Train_acc 78.35, Test_acc 48.12
2022-05-24 22:47:56,555 [podnet.py] => Task 3, Epoch 27/160 (LR 0.09314) => LSC_loss 0.73, Spatial_loss 1.61, Flat_loss 0.23, Train_acc 79.10, Test_acc 48.40
2022-05-24 22:48:02,904 [podnet.py] => Task 3, Epoch 28/160 (LR 0.09263) => LSC_loss 0.73, Spatial_loss 1.62, Flat_loss 0.22, Train_acc 79.60, Test_acc 52.30
2022-05-24 22:48:09,255 [podnet.py] => Task 3, Epoch 29/160 (LR 0.09211) => LSC_loss 0.69, Spatial_loss 1.63, Flat_loss 0.22, Train_acc 80.54, Test_acc 48.12
2022-05-24 22:48:15,537 [podnet.py] => Task 3, Epoch 30/160 (LR 0.09157) => LSC_loss 0.70, Spatial_loss 1.62, Flat_loss 0.23, Train_acc 80.24, Test_acc 50.40
2022-05-24 22:48:21,274 [podnet.py] => Task 3, Epoch 31/160 (LR 0.09102) => LSC_loss 0.69, Spatial_loss 1.63, Flat_loss 0.23, Train_acc 80.53, Test_acc 40.45
2022-05-24 22:48:27,341 [podnet.py] => Task 3, Epoch 32/160 (LR 0.09045) => LSC_loss 0.71, Spatial_loss 1.63, Flat_loss 0.23, Train_acc 80.72, Test_acc 46.58
2022-05-24 22:48:33,310 [podnet.py] => Task 3, Epoch 33/160 (LR 0.08987) => LSC_loss 0.71, Spatial_loss 1.65, Flat_loss 0.23, Train_acc 80.00, Test_acc 47.42
2022-05-24 22:48:39,402 [podnet.py] => Task 3, Epoch 34/160 (LR 0.08927) => LSC_loss 0.68, Spatial_loss 1.62, Flat_loss 0.23, Train_acc 80.59, Test_acc 48.80
2022-05-24 22:48:45,890 [podnet.py] => Task 3, Epoch 35/160 (LR 0.08865) => LSC_loss 0.66, Spatial_loss 1.61, Flat_loss 0.23, Train_acc 81.48, Test_acc 46.02
2022-05-24 22:48:52,142 [podnet.py] => Task 3, Epoch 36/160 (LR 0.08802) => LSC_loss 0.66, Spatial_loss 1.62, Flat_loss 0.22, Train_acc 80.93, Test_acc 48.00
2022-05-24 22:48:58,369 [podnet.py] => Task 3, Epoch 37/160 (LR 0.08738) => LSC_loss 0.64, Spatial_loss 1.61, Flat_loss 0.23, Train_acc 82.16, Test_acc 49.05
2022-05-24 22:49:04,301 [podnet.py] => Task 3, Epoch 38/160 (LR 0.08672) => LSC_loss 0.60, Spatial_loss 1.60, Flat_loss 0.23, Train_acc 83.17, Test_acc 50.62
2022-05-24 22:49:10,242 [podnet.py] => Task 3, Epoch 39/160 (LR 0.08604) => LSC_loss 0.64, Spatial_loss 1.64, Flat_loss 0.22, Train_acc 82.03, Test_acc 45.60
2022-05-24 22:49:16,539 [podnet.py] => Task 3, Epoch 40/160 (LR 0.08536) => LSC_loss 0.63, Spatial_loss 1.57, Flat_loss 0.23, Train_acc 82.82, Test_acc 47.10
2022-05-24 22:49:22,917 [podnet.py] => Task 3, Epoch 41/160 (LR 0.08465) => LSC_loss 0.61, Spatial_loss 1.61, Flat_loss 0.23, Train_acc 82.99, Test_acc 45.55
2022-05-24 22:49:29,021 [podnet.py] => Task 3, Epoch 42/160 (LR 0.08394) => LSC_loss 0.57, Spatial_loss 1.52, Flat_loss 0.22, Train_acc 84.40, Test_acc 50.58
2022-05-24 22:49:35,408 [podnet.py] => Task 3, Epoch 43/160 (LR 0.08321) => LSC_loss 0.58, Spatial_loss 1.57, Flat_loss 0.22, Train_acc 83.84, Test_acc 46.30
2022-05-24 22:49:41,546 [podnet.py] => Task 3, Epoch 44/160 (LR 0.08247) => LSC_loss 0.62, Spatial_loss 1.59, Flat_loss 0.23, Train_acc 82.88, Test_acc 46.78
2022-05-24 22:49:47,350 [podnet.py] => Task 3, Epoch 45/160 (LR 0.08172) => LSC_loss 0.58, Spatial_loss 1.56, Flat_loss 0.23, Train_acc 84.07, Test_acc 51.30
2022-05-24 22:49:53,417 [podnet.py] => Task 3, Epoch 46/160 (LR 0.08095) => LSC_loss 0.57, Spatial_loss 1.56, Flat_loss 0.23, Train_acc 84.21, Test_acc 49.45
2022-05-24 22:49:59,268 [podnet.py] => Task 3, Epoch 47/160 (LR 0.08018) => LSC_loss 0.58, Spatial_loss 1.61, Flat_loss 0.22, Train_acc 83.84, Test_acc 50.60
2022-05-24 22:50:05,449 [podnet.py] => Task 3, Epoch 48/160 (LR 0.07939) => LSC_loss 0.56, Spatial_loss 1.57, Flat_loss 0.22, Train_acc 84.90, Test_acc 46.72
2022-05-24 22:50:12,074 [podnet.py] => Task 3, Epoch 49/160 (LR 0.07859) => LSC_loss 0.55, Spatial_loss 1.53, Flat_loss 0.22, Train_acc 85.30, Test_acc 48.50
2022-05-24 22:50:17,993 [podnet.py] => Task 3, Epoch 50/160 (LR 0.07778) => LSC_loss 0.54, Spatial_loss 1.56, Flat_loss 0.22, Train_acc 85.57, Test_acc 44.85
2022-05-24 22:50:23,868 [podnet.py] => Task 3, Epoch 51/160 (LR 0.07696) => LSC_loss 0.53, Spatial_loss 1.53, Flat_loss 0.22, Train_acc 85.62, Test_acc 50.65
2022-05-24 22:50:29,891 [podnet.py] => Task 3, Epoch 52/160 (LR 0.07612) => LSC_loss 0.55, Spatial_loss 1.55, Flat_loss 0.23, Train_acc 84.77, Test_acc 44.60
2022-05-24 22:50:35,734 [podnet.py] => Task 3, Epoch 53/160 (LR 0.07528) => LSC_loss 0.52, Spatial_loss 1.57, Flat_loss 0.23, Train_acc 86.07, Test_acc 47.92
2022-05-24 22:50:42,232 [podnet.py] => Task 3, Epoch 54/160 (LR 0.07443) => LSC_loss 0.51, Spatial_loss 1.57, Flat_loss 0.23, Train_acc 86.42, Test_acc 49.95
2022-05-24 22:50:48,369 [podnet.py] => Task 3, Epoch 55/160 (LR 0.07357) => LSC_loss 0.51, Spatial_loss 1.52, Flat_loss 0.22, Train_acc 86.38, Test_acc 47.90
2022-05-24 22:50:54,740 [podnet.py] => Task 3, Epoch 56/160 (LR 0.07270) => LSC_loss 0.51, Spatial_loss 1.53, Flat_loss 0.22, Train_acc 85.36, Test_acc 49.65
2022-05-24 22:51:01,019 [podnet.py] => Task 3, Epoch 57/160 (LR 0.07182) => LSC_loss 0.51, Spatial_loss 1.53, Flat_loss 0.22, Train_acc 86.43, Test_acc 49.88
2022-05-24 22:51:06,958 [podnet.py] => Task 3, Epoch 58/160 (LR 0.07093) => LSC_loss 0.50, Spatial_loss 1.53, Flat_loss 0.22, Train_acc 86.59, Test_acc 51.98
2022-05-24 22:51:12,860 [podnet.py] => Task 3, Epoch 59/160 (LR 0.07004) => LSC_loss 0.50, Spatial_loss 1.51, Flat_loss 0.22, Train_acc 86.40, Test_acc 51.32
2022-05-24 22:51:18,778 [podnet.py] => Task 3, Epoch 60/160 (LR 0.06913) => LSC_loss 0.49, Spatial_loss 1.51, Flat_loss 0.22, Train_acc 86.68, Test_acc 52.08
2022-05-24 22:51:25,065 [podnet.py] => Task 3, Epoch 61/160 (LR 0.06822) => LSC_loss 0.46, Spatial_loss 1.48, Flat_loss 0.22, Train_acc 87.64, Test_acc 50.30
2022-05-24 22:51:31,539 [podnet.py] => Task 3, Epoch 62/160 (LR 0.06731) => LSC_loss 0.48, Spatial_loss 1.49, Flat_loss 0.22, Train_acc 87.19, Test_acc 49.08
2022-05-24 22:51:37,752 [podnet.py] => Task 3, Epoch 63/160 (LR 0.06638) => LSC_loss 0.47, Spatial_loss 1.49, Flat_loss 0.22, Train_acc 87.44, Test_acc 53.05
2022-05-24 22:51:44,416 [podnet.py] => Task 3, Epoch 64/160 (LR 0.06545) => LSC_loss 0.46, Spatial_loss 1.50, Flat_loss 0.22, Train_acc 88.09, Test_acc 51.85
2022-05-24 22:51:50,918 [podnet.py] => Task 3, Epoch 65/160 (LR 0.06451) => LSC_loss 0.45, Spatial_loss 1.47, Flat_loss 0.22, Train_acc 88.25, Test_acc 48.80
2022-05-24 22:51:56,984 [podnet.py] => Task 3, Epoch 66/160 (LR 0.06357) => LSC_loss 0.47, Spatial_loss 1.52, Flat_loss 0.22, Train_acc 87.38, Test_acc 50.45
2022-05-24 22:52:03,340 [podnet.py] => Task 3, Epoch 67/160 (LR 0.06262) => LSC_loss 0.47, Spatial_loss 1.51, Flat_loss 0.22, Train_acc 87.62, Test_acc 47.60
2022-05-24 22:52:09,908 [podnet.py] => Task 3, Epoch 68/160 (LR 0.06167) => LSC_loss 0.45, Spatial_loss 1.46, Flat_loss 0.22, Train_acc 88.01, Test_acc 50.88
2022-05-24 22:52:16,259 [podnet.py] => Task 3, Epoch 69/160 (LR 0.06072) => LSC_loss 0.43, Spatial_loss 1.46, Flat_loss 0.22, Train_acc 88.47, Test_acc 51.32
2022-05-24 22:52:22,489 [podnet.py] => Task 3, Epoch 70/160 (LR 0.05975) => LSC_loss 0.42, Spatial_loss 1.44, Flat_loss 0.22, Train_acc 89.47, Test_acc 51.90
2022-05-24 22:52:28,565 [podnet.py] => Task 3, Epoch 71/160 (LR 0.05879) => LSC_loss 0.41, Spatial_loss 1.43, Flat_loss 0.22, Train_acc 89.18, Test_acc 51.15
2022-05-24 22:52:34,460 [podnet.py] => Task 3, Epoch 72/160 (LR 0.05782) => LSC_loss 0.43, Spatial_loss 1.44, Flat_loss 0.22, Train_acc 88.78, Test_acc 48.68
2022-05-24 22:52:40,403 [podnet.py] => Task 3, Epoch 73/160 (LR 0.05685) => LSC_loss 0.39, Spatial_loss 1.44, Flat_loss 0.22, Train_acc 90.11, Test_acc 52.20
2022-05-24 22:52:46,407 [podnet.py] => Task 3, Epoch 74/160 (LR 0.05588) => LSC_loss 0.38, Spatial_loss 1.39, Flat_loss 0.21, Train_acc 90.60, Test_acc 52.92
2022-05-24 22:52:52,556 [podnet.py] => Task 3, Epoch 75/160 (LR 0.05490) => LSC_loss 0.38, Spatial_loss 1.38, Flat_loss 0.21, Train_acc 90.34, Test_acc 51.90
2022-05-24 22:52:58,783 [podnet.py] => Task 3, Epoch 76/160 (LR 0.05392) => LSC_loss 0.39, Spatial_loss 1.41, Flat_loss 0.21, Train_acc 89.86, Test_acc 47.42
2022-05-24 22:53:05,410 [podnet.py] => Task 3, Epoch 77/160 (LR 0.05294) => LSC_loss 0.37, Spatial_loss 1.41, Flat_loss 0.21, Train_acc 91.05, Test_acc 52.62
2022-05-24 22:53:11,708 [podnet.py] => Task 3, Epoch 78/160 (LR 0.05196) => LSC_loss 0.37, Spatial_loss 1.36, Flat_loss 0.21, Train_acc 90.57, Test_acc 51.78
2022-05-24 22:53:17,701 [podnet.py] => Task 3, Epoch 79/160 (LR 0.05098) => LSC_loss 0.37, Spatial_loss 1.39, Flat_loss 0.21, Train_acc 90.69, Test_acc 53.02
2022-05-24 22:53:23,808 [podnet.py] => Task 3, Epoch 80/160 (LR 0.05000) => LSC_loss 0.37, Spatial_loss 1.40, Flat_loss 0.21, Train_acc 90.76, Test_acc 50.05
2022-05-24 22:53:29,858 [podnet.py] => Task 3, Epoch 81/160 (LR 0.04902) => LSC_loss 0.37, Spatial_loss 1.37, Flat_loss 0.21, Train_acc 91.15, Test_acc 51.00
2022-05-24 22:53:35,555 [podnet.py] => Task 3, Epoch 82/160 (LR 0.04804) => LSC_loss 0.35, Spatial_loss 1.33, Flat_loss 0.21, Train_acc 91.72, Test_acc 51.18
2022-05-24 22:53:41,657 [podnet.py] => Task 3, Epoch 83/160 (LR 0.04706) => LSC_loss 0.37, Spatial_loss 1.34, Flat_loss 0.21, Train_acc 90.79, Test_acc 49.55
2022-05-24 22:53:47,539 [podnet.py] => Task 3, Epoch 84/160 (LR 0.04608) => LSC_loss 0.35, Spatial_loss 1.38, Flat_loss 0.21, Train_acc 91.42, Test_acc 50.48
2022-05-24 22:53:53,817 [podnet.py] => Task 3, Epoch 85/160 (LR 0.04510) => LSC_loss 0.32, Spatial_loss 1.32, Flat_loss 0.20, Train_acc 92.18, Test_acc 49.90
2022-05-24 22:54:00,199 [podnet.py] => Task 3, Epoch 86/160 (LR 0.04412) => LSC_loss 0.34, Spatial_loss 1.34, Flat_loss 0.21, Train_acc 91.53, Test_acc 51.82
2022-05-24 22:54:06,323 [podnet.py] => Task 3, Epoch 87/160 (LR 0.04315) => LSC_loss 0.33, Spatial_loss 1.33, Flat_loss 0.21, Train_acc 91.88, Test_acc 52.78
2022-05-24 22:54:12,609 [podnet.py] => Task 3, Epoch 88/160 (LR 0.04218) => LSC_loss 0.31, Spatial_loss 1.30, Flat_loss 0.20, Train_acc 93.28, Test_acc 51.32
2022-05-24 22:54:18,900 [podnet.py] => Task 3, Epoch 89/160 (LR 0.04121) => LSC_loss 0.33, Spatial_loss 1.32, Flat_loss 0.21, Train_acc 92.03, Test_acc 51.88
2022-05-24 22:54:25,045 [podnet.py] => Task 3, Epoch 90/160 (LR 0.04025) => LSC_loss 0.30, Spatial_loss 1.31, Flat_loss 0.20, Train_acc 92.97, Test_acc 50.22
2022-05-24 22:54:30,855 [podnet.py] => Task 3, Epoch 91/160 (LR 0.03928) => LSC_loss 0.29, Spatial_loss 1.26, Flat_loss 0.20, Train_acc 93.60, Test_acc 52.72
2022-05-24 22:54:36,794 [podnet.py] => Task 3, Epoch 92/160 (LR 0.03833) => LSC_loss 0.31, Spatial_loss 1.29, Flat_loss 0.20, Train_acc 92.61, Test_acc 52.22
2022-05-24 22:54:43,250 [podnet.py] => Task 3, Epoch 93/160 (LR 0.03738) => LSC_loss 0.30, Spatial_loss 1.28, Flat_loss 0.20, Train_acc 93.09, Test_acc 51.40
2022-05-24 22:54:49,587 [podnet.py] => Task 3, Epoch 94/160 (LR 0.03643) => LSC_loss 0.29, Spatial_loss 1.25, Flat_loss 0.20, Train_acc 93.68, Test_acc 52.88
2022-05-24 22:54:55,625 [podnet.py] => Task 3, Epoch 95/160 (LR 0.03549) => LSC_loss 0.29, Spatial_loss 1.27, Flat_loss 0.20, Train_acc 93.28, Test_acc 54.05
2022-05-24 22:55:01,545 [podnet.py] => Task 3, Epoch 96/160 (LR 0.03455) => LSC_loss 0.28, Spatial_loss 1.22, Flat_loss 0.20, Train_acc 93.57, Test_acc 52.35
2022-05-24 22:55:07,628 [podnet.py] => Task 3, Epoch 97/160 (LR 0.03362) => LSC_loss 0.27, Spatial_loss 1.22, Flat_loss 0.19, Train_acc 94.18, Test_acc 52.25
2022-05-24 22:55:13,506 [podnet.py] => Task 3, Epoch 98/160 (LR 0.03269) => LSC_loss 0.27, Spatial_loss 1.25, Flat_loss 0.20, Train_acc 94.14, Test_acc 52.28
2022-05-24 22:55:19,680 [podnet.py] => Task 3, Epoch 99/160 (LR 0.03178) => LSC_loss 0.28, Spatial_loss 1.23, Flat_loss 0.20, Train_acc 93.80, Test_acc 52.78
2022-05-24 22:55:25,956 [podnet.py] => Task 3, Epoch 100/160 (LR 0.03087) => LSC_loss 0.25, Spatial_loss 1.22, Flat_loss 0.20, Train_acc 94.71, Test_acc 53.35
2022-05-24 22:55:32,509 [podnet.py] => Task 3, Epoch 101/160 (LR 0.02996) => LSC_loss 0.24, Spatial_loss 1.18, Flat_loss 0.19, Train_acc 95.43, Test_acc 53.52
2022-05-24 22:55:38,660 [podnet.py] => Task 3, Epoch 102/160 (LR 0.02907) => LSC_loss 0.25, Spatial_loss 1.18, Flat_loss 0.19, Train_acc 94.74, Test_acc 53.32
2022-05-24 22:55:44,778 [podnet.py] => Task 3, Epoch 103/160 (LR 0.02818) => LSC_loss 0.24, Spatial_loss 1.20, Flat_loss 0.19, Train_acc 95.32, Test_acc 52.15
2022-05-24 22:55:50,956 [podnet.py] => Task 3, Epoch 104/160 (LR 0.02730) => LSC_loss 0.24, Spatial_loss 1.19, Flat_loss 0.19, Train_acc 95.20, Test_acc 51.78
2022-05-24 22:55:56,937 [podnet.py] => Task 3, Epoch 105/160 (LR 0.02643) => LSC_loss 0.23, Spatial_loss 1.16, Flat_loss 0.19, Train_acc 95.50, Test_acc 53.72
2022-05-24 22:56:02,623 [podnet.py] => Task 3, Epoch 106/160 (LR 0.02557) => LSC_loss 0.23, Spatial_loss 1.17, Flat_loss 0.19, Train_acc 95.82, Test_acc 53.55
2022-05-24 22:56:08,656 [podnet.py] => Task 3, Epoch 107/160 (LR 0.02472) => LSC_loss 0.23, Spatial_loss 1.15, Flat_loss 0.19, Train_acc 95.97, Test_acc 54.42
2022-05-24 22:56:15,022 [podnet.py] => Task 3, Epoch 108/160 (LR 0.02388) => LSC_loss 0.22, Spatial_loss 1.14, Flat_loss 0.18, Train_acc 96.06, Test_acc 52.48
2022-05-24 22:56:20,924 [podnet.py] => Task 3, Epoch 109/160 (LR 0.02304) => LSC_loss 0.21, Spatial_loss 1.12, Flat_loss 0.19, Train_acc 96.00, Test_acc 53.92
2022-05-24 22:56:26,884 [podnet.py] => Task 3, Epoch 110/160 (LR 0.02222) => LSC_loss 0.21, Spatial_loss 1.14, Flat_loss 0.18, Train_acc 96.02, Test_acc 53.38
2022-05-24 22:56:32,702 [podnet.py] => Task 3, Epoch 111/160 (LR 0.02141) => LSC_loss 0.21, Spatial_loss 1.12, Flat_loss 0.18, Train_acc 96.53, Test_acc 52.78
2022-05-24 22:56:38,896 [podnet.py] => Task 3, Epoch 112/160 (LR 0.02061) => LSC_loss 0.21, Spatial_loss 1.10, Flat_loss 0.18, Train_acc 96.69, Test_acc 53.40
2022-05-24 22:56:45,003 [podnet.py] => Task 3, Epoch 113/160 (LR 0.01982) => LSC_loss 0.21, Spatial_loss 1.11, Flat_loss 0.18, Train_acc 96.33, Test_acc 52.92
2022-05-24 22:56:51,218 [podnet.py] => Task 3, Epoch 114/160 (LR 0.01905) => LSC_loss 0.21, Spatial_loss 1.08, Flat_loss 0.18, Train_acc 96.32, Test_acc 54.52
2022-05-24 22:56:57,859 [podnet.py] => Task 3, Epoch 115/160 (LR 0.01828) => LSC_loss 0.20, Spatial_loss 1.08, Flat_loss 0.18, Train_acc 96.79, Test_acc 54.02
2022-05-24 22:57:04,185 [podnet.py] => Task 3, Epoch 116/160 (LR 0.01753) => LSC_loss 0.20, Spatial_loss 1.07, Flat_loss 0.18, Train_acc 96.52, Test_acc 52.78
2022-05-24 22:57:10,531 [podnet.py] => Task 3, Epoch 117/160 (LR 0.01679) => LSC_loss 0.20, Spatial_loss 1.06, Flat_loss 0.18, Train_acc 97.03, Test_acc 55.58
2022-05-24 22:57:16,904 [podnet.py] => Task 3, Epoch 118/160 (LR 0.01606) => LSC_loss 0.19, Spatial_loss 1.04, Flat_loss 0.18, Train_acc 97.21, Test_acc 54.32
2022-05-24 22:57:22,671 [podnet.py] => Task 3, Epoch 119/160 (LR 0.01535) => LSC_loss 0.18, Spatial_loss 1.03, Flat_loss 0.17, Train_acc 97.59, Test_acc 53.62
2022-05-24 22:57:28,583 [podnet.py] => Task 3, Epoch 120/160 (LR 0.01464) => LSC_loss 0.19, Spatial_loss 1.05, Flat_loss 0.17, Train_acc 97.16, Test_acc 54.32
2022-05-24 22:57:34,504 [podnet.py] => Task 3, Epoch 121/160 (LR 0.01396) => LSC_loss 0.18, Spatial_loss 1.03, Flat_loss 0.17, Train_acc 97.21, Test_acc 54.08
2022-05-24 22:57:40,441 [podnet.py] => Task 3, Epoch 122/160 (LR 0.01328) => LSC_loss 0.18, Spatial_loss 1.01, Flat_loss 0.17, Train_acc 97.34, Test_acc 54.82
2022-05-24 22:57:46,791 [podnet.py] => Task 3, Epoch 123/160 (LR 0.01262) => LSC_loss 0.18, Spatial_loss 1.02, Flat_loss 0.17, Train_acc 97.18, Test_acc 54.95
2022-05-24 22:57:53,255 [podnet.py] => Task 3, Epoch 124/160 (LR 0.01198) => LSC_loss 0.17, Spatial_loss 1.01, Flat_loss 0.17, Train_acc 97.58, Test_acc 55.82
2022-05-24 22:57:59,587 [podnet.py] => Task 3, Epoch 125/160 (LR 0.01135) => LSC_loss 0.17, Spatial_loss 1.00, Flat_loss 0.17, Train_acc 97.66, Test_acc 56.42
2022-05-24 22:58:06,058 [podnet.py] => Task 3, Epoch 126/160 (LR 0.01073) => LSC_loss 0.17, Spatial_loss 0.99, Flat_loss 0.17, Train_acc 97.65, Test_acc 55.32
2022-05-24 22:58:11,965 [podnet.py] => Task 3, Epoch 127/160 (LR 0.01013) => LSC_loss 0.17, Spatial_loss 1.01, Flat_loss 0.17, Train_acc 97.56, Test_acc 55.08
2022-05-24 22:58:17,941 [podnet.py] => Task 3, Epoch 128/160 (LR 0.00955) => LSC_loss 0.17, Spatial_loss 0.99, Flat_loss 0.17, Train_acc 97.84, Test_acc 54.68
2022-05-24 22:58:23,902 [podnet.py] => Task 3, Epoch 129/160 (LR 0.00898) => LSC_loss 0.16, Spatial_loss 0.98, Flat_loss 0.17, Train_acc 97.94, Test_acc 55.62
2022-05-24 22:58:29,802 [podnet.py] => Task 3, Epoch 130/160 (LR 0.00843) => LSC_loss 0.17, Spatial_loss 0.97, Flat_loss 0.17, Train_acc 97.66, Test_acc 56.55
2022-05-24 22:58:36,149 [podnet.py] => Task 3, Epoch 131/160 (LR 0.00789) => LSC_loss 0.16, Spatial_loss 0.97, Flat_loss 0.17, Train_acc 98.07, Test_acc 55.75
2022-05-24 22:58:42,375 [podnet.py] => Task 3, Epoch 132/160 (LR 0.00737) => LSC_loss 0.16, Spatial_loss 0.96, Flat_loss 0.17, Train_acc 98.01, Test_acc 55.30
2022-05-24 22:58:48,684 [podnet.py] => Task 3, Epoch 133/160 (LR 0.00686) => LSC_loss 0.16, Spatial_loss 0.95, Flat_loss 0.17, Train_acc 98.08, Test_acc 55.40
2022-05-24 22:58:54,964 [podnet.py] => Task 3, Epoch 134/160 (LR 0.00638) => LSC_loss 0.15, Spatial_loss 0.94, Flat_loss 0.16, Train_acc 98.51, Test_acc 56.62
2022-05-24 22:59:01,038 [podnet.py] => Task 3, Epoch 135/160 (LR 0.00590) => LSC_loss 0.16, Spatial_loss 0.94, Flat_loss 0.16, Train_acc 97.95, Test_acc 55.02
2022-05-24 22:59:07,004 [podnet.py] => Task 3, Epoch 136/160 (LR 0.00545) => LSC_loss 0.15, Spatial_loss 0.93, Flat_loss 0.16, Train_acc 98.40, Test_acc 55.58
2022-05-24 22:59:13,000 [podnet.py] => Task 3, Epoch 137/160 (LR 0.00501) => LSC_loss 0.16, Spatial_loss 0.94, Flat_loss 0.16, Train_acc 98.07, Test_acc 56.32
2022-05-24 22:59:18,995 [podnet.py] => Task 3, Epoch 138/160 (LR 0.00459) => LSC_loss 0.15, Spatial_loss 0.94, Flat_loss 0.16, Train_acc 98.24, Test_acc 55.42
2022-05-24 22:59:25,103 [podnet.py] => Task 3, Epoch 139/160 (LR 0.00419) => LSC_loss 0.15, Spatial_loss 0.93, Flat_loss 0.16, Train_acc 98.44, Test_acc 56.50
2022-05-24 22:59:31,557 [podnet.py] => Task 3, Epoch 140/160 (LR 0.00381) => LSC_loss 0.15, Spatial_loss 0.94, Flat_loss 0.16, Train_acc 98.30, Test_acc 56.20
2022-05-24 22:59:37,837 [podnet.py] => Task 3, Epoch 141/160 (LR 0.00344) => LSC_loss 0.15, Spatial_loss 0.92, Flat_loss 0.16, Train_acc 98.42, Test_acc 56.10
2022-05-24 22:59:44,013 [podnet.py] => Task 3, Epoch 142/160 (LR 0.00309) => LSC_loss 0.15, Spatial_loss 0.90, Flat_loss 0.16, Train_acc 98.30, Test_acc 56.42
2022-05-24 22:59:49,881 [podnet.py] => Task 3, Epoch 143/160 (LR 0.00276) => LSC_loss 0.15, Spatial_loss 0.92, Flat_loss 0.16, Train_acc 98.14, Test_acc 56.18
2022-05-24 22:59:55,980 [podnet.py] => Task 3, Epoch 144/160 (LR 0.00245) => LSC_loss 0.15, Spatial_loss 0.90, Flat_loss 0.16, Train_acc 98.55, Test_acc 55.48
2022-05-24 23:00:01,988 [podnet.py] => Task 3, Epoch 145/160 (LR 0.00215) => LSC_loss 0.15, Spatial_loss 0.91, Flat_loss 0.16, Train_acc 98.55, Test_acc 56.32
2022-05-24 23:00:07,884 [podnet.py] => Task 3, Epoch 146/160 (LR 0.00188) => LSC_loss 0.15, Spatial_loss 0.89, Flat_loss 0.16, Train_acc 98.51, Test_acc 55.92
2022-05-24 23:00:14,235 [podnet.py] => Task 3, Epoch 147/160 (LR 0.00162) => LSC_loss 0.14, Spatial_loss 0.90, Flat_loss 0.16, Train_acc 98.64, Test_acc 56.08
2022-05-24 23:00:20,717 [podnet.py] => Task 3, Epoch 148/160 (LR 0.00138) => LSC_loss 0.15, Spatial_loss 0.88, Flat_loss 0.16, Train_acc 98.44, Test_acc 56.30
2022-05-24 23:00:26,970 [podnet.py] => Task 3, Epoch 149/160 (LR 0.00116) => LSC_loss 0.14, Spatial_loss 0.88, Flat_loss 0.16, Train_acc 98.74, Test_acc 56.10
2022-05-24 23:00:33,243 [podnet.py] => Task 3, Epoch 150/160 (LR 0.00096) => LSC_loss 0.15, Spatial_loss 0.88, Flat_loss 0.16, Train_acc 98.47, Test_acc 56.20
2022-05-24 23:00:39,238 [podnet.py] => Task 3, Epoch 151/160 (LR 0.00078) => LSC_loss 0.14, Spatial_loss 0.88, Flat_loss 0.16, Train_acc 98.67, Test_acc 56.10
2022-05-24 23:00:45,220 [podnet.py] => Task 3, Epoch 152/160 (LR 0.00062) => LSC_loss 0.15, Spatial_loss 0.89, Flat_loss 0.16, Train_acc 98.50, Test_acc 56.20
2022-05-24 23:00:51,214 [podnet.py] => Task 3, Epoch 153/160 (LR 0.00047) => LSC_loss 0.14, Spatial_loss 0.88, Flat_loss 0.16, Train_acc 98.72, Test_acc 56.32
2022-05-24 23:00:57,110 [podnet.py] => Task 3, Epoch 154/160 (LR 0.00035) => LSC_loss 0.14, Spatial_loss 0.87, Flat_loss 0.16, Train_acc 98.90, Test_acc 56.15
2022-05-24 23:01:03,353 [podnet.py] => Task 3, Epoch 155/160 (LR 0.00024) => LSC_loss 0.14, Spatial_loss 0.87, Flat_loss 0.16, Train_acc 98.81, Test_acc 56.15
2022-05-24 23:01:09,550 [podnet.py] => Task 3, Epoch 156/160 (LR 0.00015) => LSC_loss 0.14, Spatial_loss 0.89, Flat_loss 0.16, Train_acc 98.58, Test_acc 56.28
2022-05-24 23:01:15,907 [podnet.py] => Task 3, Epoch 157/160 (LR 0.00009) => LSC_loss 0.14, Spatial_loss 0.88, Flat_loss 0.16, Train_acc 98.81, Test_acc 55.98
2022-05-24 23:01:22,172 [podnet.py] => Task 3, Epoch 158/160 (LR 0.00004) => LSC_loss 0.15, Spatial_loss 0.88, Flat_loss 0.16, Train_acc 98.38, Test_acc 56.18
2022-05-24 23:01:27,844 [podnet.py] => Task 3, Epoch 159/160 (LR 0.00001) => LSC_loss 0.14, Spatial_loss 0.87, Flat_loss 0.16, Train_acc 98.83, Test_acc 55.70
2022-05-24 23:01:33,809 [podnet.py] => Task 3, Epoch 160/160 (LR 0.00000) => LSC_loss 0.14, Spatial_loss 0.88, Flat_loss 0.16, Train_acc 98.75, Test_acc 55.98
2022-05-24 23:01:33,810 [podnet.py] => Finetune the network (classifier part) with the undersampled dataset!
2022-05-24 23:01:33,810 [base.py] => Reducing exemplars...(66 per classes)
2022-05-24 23:01:41,334 [base.py] => Constructing exemplars...(66 per classes)
2022-05-24 23:01:47,339 [podnet.py] => The size of finetune dataset: 2640
2022-05-24 23:01:50,506 [podnet.py] => Task 3, Epoch 1/20 (LR 0.00497) => LSC_loss 0.15, Spatial_loss 0.96, Flat_loss 0.12, Train_acc 97.99, Test_acc 57.35
2022-05-24 23:01:53,794 [podnet.py] => Task 3, Epoch 2/20 (LR 0.00488) => LSC_loss 0.11, Spatial_loss 0.92, Flat_loss 0.10, Train_acc 99.09, Test_acc 57.38
2022-05-24 23:01:56,686 [podnet.py] => Task 3, Epoch 3/20 (LR 0.00473) => LSC_loss 0.12, Spatial_loss 0.89, Flat_loss 0.10, Train_acc 98.71, Test_acc 56.80
2022-05-24 23:01:59,636 [podnet.py] => Task 3, Epoch 4/20 (LR 0.00452) => LSC_loss 0.11, Spatial_loss 0.91, Flat_loss 0.10, Train_acc 98.94, Test_acc 57.70
2022-05-24 23:02:02,783 [podnet.py] => Task 3, Epoch 5/20 (LR 0.00427) => LSC_loss 0.11, Spatial_loss 0.87, Flat_loss 0.10, Train_acc 99.13, Test_acc 57.72
2022-05-24 23:02:05,772 [podnet.py] => Task 3, Epoch 6/20 (LR 0.00397) => LSC_loss 0.11, Spatial_loss 0.87, Flat_loss 0.10, Train_acc 98.83, Test_acc 57.72
2022-05-24 23:02:08,843 [podnet.py] => Task 3, Epoch 7/20 (LR 0.00363) => LSC_loss 0.10, Spatial_loss 0.89, Flat_loss 0.10, Train_acc 99.17, Test_acc 57.72
2022-05-24 23:02:11,636 [podnet.py] => Task 3, Epoch 8/20 (LR 0.00327) => LSC_loss 0.10, Spatial_loss 0.89, Flat_loss 0.10, Train_acc 99.28, Test_acc 57.55
2022-05-24 23:02:14,142 [podnet.py] => Task 3, Epoch 9/20 (LR 0.00289) => LSC_loss 0.11, Spatial_loss 0.87, Flat_loss 0.10, Train_acc 99.09, Test_acc 58.12
2022-05-24 23:02:17,081 [podnet.py] => Task 3, Epoch 10/20 (LR 0.00250) => LSC_loss 0.10, Spatial_loss 0.86, Flat_loss 0.09, Train_acc 98.90, Test_acc 57.82
2022-05-24 23:02:20,076 [podnet.py] => Task 3, Epoch 11/20 (LR 0.00211) => LSC_loss 0.10, Spatial_loss 0.88, Flat_loss 0.10, Train_acc 98.90, Test_acc 57.48
2022-05-24 23:02:23,194 [podnet.py] => Task 3, Epoch 12/20 (LR 0.00173) => LSC_loss 0.11, Spatial_loss 0.87, Flat_loss 0.10, Train_acc 99.02, Test_acc 57.68
2022-05-24 23:02:26,278 [podnet.py] => Task 3, Epoch 13/20 (LR 0.00137) => LSC_loss 0.10, Spatial_loss 0.85, Flat_loss 0.10, Train_acc 99.02, Test_acc 57.80
2022-05-24 23:02:29,129 [podnet.py] => Task 3, Epoch 14/20 (LR 0.00103) => LSC_loss 0.11, Spatial_loss 0.87, Flat_loss 0.10, Train_acc 98.94, Test_acc 57.90
2022-05-24 23:02:32,067 [podnet.py] => Task 3, Epoch 15/20 (LR 0.00073) => LSC_loss 0.10, Spatial_loss 0.85, Flat_loss 0.09, Train_acc 99.24, Test_acc 58.05
2022-05-24 23:02:34,836 [podnet.py] => Task 3, Epoch 16/20 (LR 0.00048) => LSC_loss 0.10, Spatial_loss 0.86, Flat_loss 0.10, Train_acc 99.51, Test_acc 57.92
2022-05-24 23:02:37,795 [podnet.py] => Task 3, Epoch 17/20 (LR 0.00027) => LSC_loss 0.10, Spatial_loss 0.82, Flat_loss 0.09, Train_acc 99.24, Test_acc 58.02
2022-05-24 23:02:40,970 [podnet.py] => Task 3, Epoch 18/20 (LR 0.00012) => LSC_loss 0.10, Spatial_loss 0.85, Flat_loss 0.09, Train_acc 99.05, Test_acc 57.88
2022-05-24 23:02:43,668 [podnet.py] => Task 3, Epoch 19/20 (LR 0.00003) => LSC_loss 0.10, Spatial_loss 0.84, Flat_loss 0.09, Train_acc 99.05, Test_acc 57.98
2022-05-24 23:02:46,508 [podnet.py] => Task 3, Epoch 20/20 (LR 0.00000) => LSC_loss 0.10, Spatial_loss 0.84, Flat_loss 0.09, Train_acc 99.02, Test_acc 57.80
2022-05-24 23:02:46,510 [base.py] => Reducing exemplars...(50 per classes)
2022-05-24 23:02:52,846 [base.py] => Constructing exemplars...(50 per classes)
2022-05-24 23:03:00,009 [podnet.py] => Exemplar size: 2000
2022-05-24 23:03:00,009 [trainer.py] => CNN: {'total': 57.8, '00-09': 71.8, '10-19': 39.4, '20-29': 56.1, '30-39': 63.9, 'old': 55.77, 'new': 63.9}
2022-05-24 23:03:00,009 [trainer.py] => NME: {'total': 55.7, '00-09': 74.7, '10-19': 35.5, '20-29': 52.0, '30-39': 60.6, 'old': 54.07, 'new': 60.6}
2022-05-24 23:03:00,010 [trainer.py] => CNN top1 curve: [90.7, 72.95, 65.47, 57.8]
2022-05-24 23:03:00,010 [trainer.py] => CNN top5 curve: [99.2, 93.95, 90.1, 85.15]
2022-05-24 23:03:00,010 [trainer.py] => NME top1 curve: [90.8, 72.05, 63.37, 55.7]
2022-05-24 23:03:00,010 [trainer.py] => NME top5 curve: [99.3, 92.8, 88.93, 83.38]

2022-05-24 23:03:00,011 [trainer.py] => All params: 491857
2022-05-24 23:03:00,011 [trainer.py] => Trainable params: 491857
2022-05-24 23:03:00,013 [podnet.py] => Learning on 40-50
2022-05-24 23:03:00,082 [podnet.py] => Adaptive factor: 2.23606797749979
2022-05-24 23:03:06,381 [podnet.py] => Task 4, Epoch 1/160 (LR 0.09999) => LSC_loss 2.40, Spatial_loss 2.63, Flat_loss 0.76, Train_acc 51.01, Test_acc 24.60
2022-05-24 23:03:12,560 [podnet.py] => Task 4, Epoch 2/160 (LR 0.09996) => LSC_loss 1.33, Spatial_loss 2.11, Flat_loss 0.37, Train_acc 64.44, Test_acc 36.64
2022-05-24 23:03:18,884 [podnet.py] => Task 4, Epoch 3/160 (LR 0.09991) => LSC_loss 1.18, Spatial_loss 2.00, Flat_loss 0.31, Train_acc 68.10, Test_acc 41.32
2022-05-24 23:03:25,106 [podnet.py] => Task 4, Epoch 4/160 (LR 0.09985) => LSC_loss 1.07, Spatial_loss 1.97, Flat_loss 0.28, Train_acc 70.73, Test_acc 37.38
2022-05-24 23:03:30,990 [podnet.py] => Task 4, Epoch 5/160 (LR 0.09976) => LSC_loss 1.01, Spatial_loss 1.94, Flat_loss 0.27, Train_acc 72.41, Test_acc 37.26
2022-05-24 23:03:36,924 [podnet.py] => Task 4, Epoch 6/160 (LR 0.09965) => LSC_loss 0.94, Spatial_loss 1.87, Flat_loss 0.25, Train_acc 74.94, Test_acc 43.42
2022-05-24 23:03:43,195 [podnet.py] => Task 4, Epoch 7/160 (LR 0.09953) => LSC_loss 0.90, Spatial_loss 1.85, Flat_loss 0.25, Train_acc 75.44, Test_acc 39.66
2022-05-24 23:03:49,562 [podnet.py] => Task 4, Epoch 8/160 (LR 0.09938) => LSC_loss 0.87, Spatial_loss 1.81, Flat_loss 0.25, Train_acc 76.33, Test_acc 37.72
2022-05-24 23:03:55,935 [podnet.py] => Task 4, Epoch 9/160 (LR 0.09922) => LSC_loss 0.86, Spatial_loss 1.81, Flat_loss 0.25, Train_acc 76.74, Test_acc 37.98
2022-05-24 23:04:02,067 [podnet.py] => Task 4, Epoch 10/160 (LR 0.09904) => LSC_loss 0.83, Spatial_loss 1.81, Flat_loss 0.25, Train_acc 77.81, Test_acc 41.42
2022-05-24 23:04:08,055 [podnet.py] => Task 4, Epoch 11/160 (LR 0.09884) => LSC_loss 0.79, Spatial_loss 1.81, Flat_loss 0.25, Train_acc 78.39, Test_acc 38.20
2022-05-24 23:04:14,117 [podnet.py] => Task 4, Epoch 12/160 (LR 0.09862) => LSC_loss 0.79, Spatial_loss 1.81, Flat_loss 0.25, Train_acc 78.27, Test_acc 46.30
2022-05-24 23:04:20,294 [podnet.py] => Task 4, Epoch 13/160 (LR 0.09838) => LSC_loss 0.77, Spatial_loss 1.78, Flat_loss 0.24, Train_acc 79.31, Test_acc 45.70
2022-05-24 23:04:26,712 [podnet.py] => Task 4, Epoch 14/160 (LR 0.09812) => LSC_loss 0.75, Spatial_loss 1.78, Flat_loss 0.24, Train_acc 79.96, Test_acc 40.04
2022-05-24 23:04:33,197 [podnet.py] => Task 4, Epoch 15/160 (LR 0.09785) => LSC_loss 0.74, Spatial_loss 1.78, Flat_loss 0.24, Train_acc 80.34, Test_acc 44.76
2022-05-24 23:04:39,556 [podnet.py] => Task 4, Epoch 16/160 (LR 0.09755) => LSC_loss 0.70, Spatial_loss 1.72, Flat_loss 0.24, Train_acc 81.44, Test_acc 47.42
2022-05-24 23:04:45,459 [podnet.py] => Task 4, Epoch 17/160 (LR 0.09724) => LSC_loss 0.71, Spatial_loss 1.79, Flat_loss 0.25, Train_acc 81.16, Test_acc 44.72
2022-05-24 23:04:51,354 [podnet.py] => Task 4, Epoch 18/160 (LR 0.09691) => LSC_loss 0.69, Spatial_loss 1.77, Flat_loss 0.24, Train_acc 81.59, Test_acc 38.62
2022-05-24 23:04:57,704 [podnet.py] => Task 4, Epoch 19/160 (LR 0.09656) => LSC_loss 0.69, Spatial_loss 1.77, Flat_loss 0.24, Train_acc 81.70, Test_acc 46.26
2022-05-24 23:05:03,982 [podnet.py] => Task 4, Epoch 20/160 (LR 0.09619) => LSC_loss 0.66, Spatial_loss 1.71, Flat_loss 0.24, Train_acc 82.41, Test_acc 43.98
2022-05-24 23:05:10,196 [podnet.py] => Task 4, Epoch 21/160 (LR 0.09581) => LSC_loss 0.66, Spatial_loss 1.73, Flat_loss 0.24, Train_acc 82.41, Test_acc 44.22
2022-05-24 23:05:16,503 [podnet.py] => Task 4, Epoch 22/160 (LR 0.09541) => LSC_loss 0.65, Spatial_loss 1.69, Flat_loss 0.24, Train_acc 82.77, Test_acc 44.24
2022-05-24 23:05:22,917 [podnet.py] => Task 4, Epoch 23/160 (LR 0.09499) => LSC_loss 0.67, Spatial_loss 1.75, Flat_loss 0.24, Train_acc 82.03, Test_acc 45.02
2022-05-24 23:05:29,255 [podnet.py] => Task 4, Epoch 24/160 (LR 0.09455) => LSC_loss 0.64, Spatial_loss 1.70, Flat_loss 0.24, Train_acc 82.87, Test_acc 42.28
2022-05-24 23:05:35,951 [podnet.py] => Task 4, Epoch 25/160 (LR 0.09410) => LSC_loss 0.63, Spatial_loss 1.74, Flat_loss 0.24, Train_acc 83.11, Test_acc 44.64
2022-05-24 23:05:42,266 [podnet.py] => Task 4, Epoch 26/160 (LR 0.09362) => LSC_loss 0.63, Spatial_loss 1.73, Flat_loss 0.24, Train_acc 83.37, Test_acc 44.06
2022-05-24 23:05:48,915 [podnet.py] => Task 4, Epoch 27/160 (LR 0.09314) => LSC_loss 0.60, Spatial_loss 1.71, Flat_loss 0.24, Train_acc 83.89, Test_acc 43.40
2022-05-24 23:05:55,367 [podnet.py] => Task 4, Epoch 28/160 (LR 0.09263) => LSC_loss 0.63, Spatial_loss 1.72, Flat_loss 0.24, Train_acc 83.19, Test_acc 46.36
2022-05-24 23:06:01,494 [podnet.py] => Task 4, Epoch 29/160 (LR 0.09211) => LSC_loss 0.61, Spatial_loss 1.74, Flat_loss 0.24, Train_acc 83.74, Test_acc 44.80
2022-05-24 23:06:07,879 [podnet.py] => Task 4, Epoch 30/160 (LR 0.09157) => LSC_loss 0.60, Spatial_loss 1.69, Flat_loss 0.24, Train_acc 83.79, Test_acc 44.18
2022-05-24 23:06:13,738 [podnet.py] => Task 4, Epoch 31/160 (LR 0.09102) => LSC_loss 0.55, Spatial_loss 1.65, Flat_loss 0.24, Train_acc 85.77, Test_acc 45.28
2022-05-24 23:06:20,082 [podnet.py] => Task 4, Epoch 32/160 (LR 0.09045) => LSC_loss 0.56, Spatial_loss 1.67, Flat_loss 0.23, Train_acc 85.19, Test_acc 44.72
2022-05-24 23:06:25,936 [podnet.py] => Task 4, Epoch 33/160 (LR 0.08987) => LSC_loss 0.56, Spatial_loss 1.66, Flat_loss 0.24, Train_acc 85.81, Test_acc 41.12
2022-05-24 23:06:32,397 [podnet.py] => Task 4, Epoch 34/160 (LR 0.08927) => LSC_loss 0.54, Spatial_loss 1.62, Flat_loss 0.23, Train_acc 86.01, Test_acc 48.26
2022-05-24 23:06:38,634 [podnet.py] => Task 4, Epoch 35/160 (LR 0.08865) => LSC_loss 0.56, Spatial_loss 1.69, Flat_loss 0.24, Train_acc 84.91, Test_acc 44.30
2022-05-24 23:06:44,908 [podnet.py] => Task 4, Epoch 36/160 (LR 0.08802) => LSC_loss 0.55, Spatial_loss 1.64, Flat_loss 0.23, Train_acc 85.66, Test_acc 45.50
2022-05-24 23:06:51,559 [podnet.py] => Task 4, Epoch 37/160 (LR 0.08738) => LSC_loss 0.56, Spatial_loss 1.66, Flat_loss 0.24, Train_acc 85.17, Test_acc 45.70
2022-05-24 23:06:57,908 [podnet.py] => Task 4, Epoch 38/160 (LR 0.08672) => LSC_loss 0.54, Spatial_loss 1.69, Flat_loss 0.24, Train_acc 85.63, Test_acc 44.42
2022-05-24 23:07:04,193 [podnet.py] => Task 4, Epoch 39/160 (LR 0.08604) => LSC_loss 0.55, Spatial_loss 1.70, Flat_loss 0.24, Train_acc 85.30, Test_acc 44.18
2022-05-24 23:07:10,640 [podnet.py] => Task 4, Epoch 40/160 (LR 0.08536) => LSC_loss 0.53, Spatial_loss 1.68, Flat_loss 0.24, Train_acc 85.90, Test_acc 45.52
2022-05-24 23:07:17,057 [podnet.py] => Task 4, Epoch 41/160 (LR 0.08465) => LSC_loss 0.52, Spatial_loss 1.69, Flat_loss 0.24, Train_acc 86.40, Test_acc 46.84
2022-05-24 23:07:23,181 [podnet.py] => Task 4, Epoch 42/160 (LR 0.08394) => LSC_loss 0.53, Spatial_loss 1.63, Flat_loss 0.23, Train_acc 86.37, Test_acc 44.18
2022-05-24 23:07:29,500 [podnet.py] => Task 4, Epoch 43/160 (LR 0.08321) => LSC_loss 0.53, Spatial_loss 1.66, Flat_loss 0.24, Train_acc 86.09, Test_acc 42.40
2022-05-24 23:07:35,419 [podnet.py] => Task 4, Epoch 44/160 (LR 0.08247) => LSC_loss 0.50, Spatial_loss 1.61, Flat_loss 0.23, Train_acc 87.03, Test_acc 39.28
2022-05-24 23:07:41,577 [podnet.py] => Task 4, Epoch 45/160 (LR 0.08172) => LSC_loss 0.47, Spatial_loss 1.61, Flat_loss 0.23, Train_acc 88.17, Test_acc 43.38
2022-05-24 23:07:47,919 [podnet.py] => Task 4, Epoch 46/160 (LR 0.08095) => LSC_loss 0.48, Spatial_loss 1.63, Flat_loss 0.23, Train_acc 87.67, Test_acc 43.22
2022-05-24 23:07:54,218 [podnet.py] => Task 4, Epoch 47/160 (LR 0.08018) => LSC_loss 0.51, Spatial_loss 1.63, Flat_loss 0.24, Train_acc 86.87, Test_acc 46.12
2022-05-24 23:08:00,632 [podnet.py] => Task 4, Epoch 48/160 (LR 0.07939) => LSC_loss 0.49, Spatial_loss 1.63, Flat_loss 0.23, Train_acc 87.51, Test_acc 45.78
2022-05-24 23:08:07,024 [podnet.py] => Task 4, Epoch 49/160 (LR 0.07859) => LSC_loss 0.45, Spatial_loss 1.59, Flat_loss 0.23, Train_acc 88.49, Test_acc 45.02
2022-05-24 23:08:13,451 [podnet.py] => Task 4, Epoch 50/160 (LR 0.07778) => LSC_loss 0.48, Spatial_loss 1.62, Flat_loss 0.23, Train_acc 87.60, Test_acc 43.66
2022-05-24 23:08:20,030 [podnet.py] => Task 4, Epoch 51/160 (LR 0.07696) => LSC_loss 0.48, Spatial_loss 1.60, Flat_loss 0.23, Train_acc 87.27, Test_acc 46.08
2022-05-24 23:08:26,282 [podnet.py] => Task 4, Epoch 52/160 (LR 0.07612) => LSC_loss 0.46, Spatial_loss 1.59, Flat_loss 0.23, Train_acc 88.20, Test_acc 45.88
2022-05-24 23:08:32,473 [podnet.py] => Task 4, Epoch 53/160 (LR 0.07528) => LSC_loss 0.47, Spatial_loss 1.64, Flat_loss 0.23, Train_acc 88.24, Test_acc 43.90
2022-05-24 23:08:38,668 [podnet.py] => Task 4, Epoch 54/160 (LR 0.07443) => LSC_loss 0.45, Spatial_loss 1.61, Flat_loss 0.23, Train_acc 88.27, Test_acc 45.02
2022-05-24 23:08:44,980 [podnet.py] => Task 4, Epoch 55/160 (LR 0.07357) => LSC_loss 0.43, Spatial_loss 1.55, Flat_loss 0.23, Train_acc 89.30, Test_acc 39.24
2022-05-24 23:08:51,234 [podnet.py] => Task 4, Epoch 56/160 (LR 0.07270) => LSC_loss 0.45, Spatial_loss 1.58, Flat_loss 0.23, Train_acc 87.94, Test_acc 46.92
2022-05-24 23:08:57,590 [podnet.py] => Task 4, Epoch 57/160 (LR 0.07182) => LSC_loss 0.43, Spatial_loss 1.54, Flat_loss 0.23, Train_acc 89.56, Test_acc 45.76
2022-05-24 23:09:04,019 [podnet.py] => Task 4, Epoch 58/160 (LR 0.07093) => LSC_loss 0.43, Spatial_loss 1.54, Flat_loss 0.23, Train_acc 89.40, Test_acc 47.56
2022-05-24 23:09:10,556 [podnet.py] => Task 4, Epoch 59/160 (LR 0.07004) => LSC_loss 0.43, Spatial_loss 1.59, Flat_loss 0.23, Train_acc 88.76, Test_acc 42.84
2022-05-24 23:09:16,815 [podnet.py] => Task 4, Epoch 60/160 (LR 0.06913) => LSC_loss 0.43, Spatial_loss 1.54, Flat_loss 0.23, Train_acc 89.04, Test_acc 47.56
2022-05-24 23:09:23,245 [podnet.py] => Task 4, Epoch 61/160 (LR 0.06822) => LSC_loss 0.41, Spatial_loss 1.55, Flat_loss 0.22, Train_acc 89.80, Test_acc 45.54
2022-05-24 23:09:29,659 [podnet.py] => Task 4, Epoch 62/160 (LR 0.06731) => LSC_loss 0.42, Spatial_loss 1.56, Flat_loss 0.22, Train_acc 89.61, Test_acc 45.42
2022-05-24 23:09:35,983 [podnet.py] => Task 4, Epoch 63/160 (LR 0.06638) => LSC_loss 0.39, Spatial_loss 1.52, Flat_loss 0.22, Train_acc 90.29, Test_acc 45.34
2022-05-24 23:09:42,120 [podnet.py] => Task 4, Epoch 64/160 (LR 0.06545) => LSC_loss 0.41, Spatial_loss 1.56, Flat_loss 0.23, Train_acc 90.04, Test_acc 45.92
2022-05-24 23:09:48,227 [podnet.py] => Task 4, Epoch 65/160 (LR 0.06451) => LSC_loss 0.37, Spatial_loss 1.51, Flat_loss 0.22, Train_acc 91.39, Test_acc 45.92
2022-05-24 23:09:54,496 [podnet.py] => Task 4, Epoch 66/160 (LR 0.06357) => LSC_loss 0.41, Spatial_loss 1.53, Flat_loss 0.22, Train_acc 89.89, Test_acc 44.28
2022-05-24 23:10:00,765 [podnet.py] => Task 4, Epoch 67/160 (LR 0.06262) => LSC_loss 0.39, Spatial_loss 1.55, Flat_loss 0.23, Train_acc 90.43, Test_acc 48.28
2022-05-24 23:10:06,810 [podnet.py] => Task 4, Epoch 68/160 (LR 0.06167) => LSC_loss 0.38, Spatial_loss 1.54, Flat_loss 0.22, Train_acc 91.23, Test_acc 43.64
2022-05-24 23:10:13,182 [podnet.py] => Task 4, Epoch 69/160 (LR 0.06072) => LSC_loss 0.37, Spatial_loss 1.50, Flat_loss 0.22, Train_acc 90.97, Test_acc 47.46
2022-05-24 23:10:19,881 [podnet.py] => Task 4, Epoch 70/160 (LR 0.05975) => LSC_loss 0.40, Spatial_loss 1.52, Flat_loss 0.23, Train_acc 90.49, Test_acc 47.40
2022-05-24 23:10:26,150 [podnet.py] => Task 4, Epoch 71/160 (LR 0.05879) => LSC_loss 0.35, Spatial_loss 1.47, Flat_loss 0.22, Train_acc 91.41, Test_acc 48.44
2022-05-24 23:10:32,273 [podnet.py] => Task 4, Epoch 72/160 (LR 0.05782) => LSC_loss 0.37, Spatial_loss 1.50, Flat_loss 0.22, Train_acc 91.10, Test_acc 45.76
2022-05-24 23:10:38,217 [podnet.py] => Task 4, Epoch 73/160 (LR 0.05685) => LSC_loss 0.35, Spatial_loss 1.47, Flat_loss 0.22, Train_acc 91.50, Test_acc 43.66
2022-05-24 23:10:44,431 [podnet.py] => Task 4, Epoch 74/160 (LR 0.05588) => LSC_loss 0.35, Spatial_loss 1.48, Flat_loss 0.22, Train_acc 92.10, Test_acc 45.62
2022-05-24 23:10:50,469 [podnet.py] => Task 4, Epoch 75/160 (LR 0.05490) => LSC_loss 0.37, Spatial_loss 1.48, Flat_loss 0.22, Train_acc 90.94, Test_acc 44.02
2022-05-24 23:10:56,588 [podnet.py] => Task 4, Epoch 76/160 (LR 0.05392) => LSC_loss 0.36, Spatial_loss 1.46, Flat_loss 0.22, Train_acc 91.53, Test_acc 46.80
2022-05-24 23:11:03,125 [podnet.py] => Task 4, Epoch 77/160 (LR 0.05294) => LSC_loss 0.36, Spatial_loss 1.46, Flat_loss 0.22, Train_acc 91.67, Test_acc 46.02
2022-05-24 23:11:09,666 [podnet.py] => Task 4, Epoch 78/160 (LR 0.05196) => LSC_loss 0.35, Spatial_loss 1.44, Flat_loss 0.21, Train_acc 92.00, Test_acc 46.70
2022-05-24 23:11:16,319 [podnet.py] => Task 4, Epoch 79/160 (LR 0.05098) => LSC_loss 0.32, Spatial_loss 1.39, Flat_loss 0.21, Train_acc 92.87, Test_acc 47.00
2022-05-24 23:11:22,637 [podnet.py] => Task 4, Epoch 80/160 (LR 0.05000) => LSC_loss 0.32, Spatial_loss 1.44, Flat_loss 0.21, Train_acc 92.91, Test_acc 47.62
2022-05-24 23:11:28,979 [podnet.py] => Task 4, Epoch 81/160 (LR 0.04902) => LSC_loss 0.32, Spatial_loss 1.39, Flat_loss 0.21, Train_acc 92.59, Test_acc 49.42
2022-05-24 23:11:35,314 [podnet.py] => Task 4, Epoch 82/160 (LR 0.04804) => LSC_loss 0.30, Spatial_loss 1.38, Flat_loss 0.21, Train_acc 93.39, Test_acc 47.80
2022-05-24 23:11:41,714 [podnet.py] => Task 4, Epoch 83/160 (LR 0.04706) => LSC_loss 0.29, Spatial_loss 1.37, Flat_loss 0.21, Train_acc 93.80, Test_acc 49.62
2022-05-24 23:11:47,714 [podnet.py] => Task 4, Epoch 84/160 (LR 0.04608) => LSC_loss 0.30, Spatial_loss 1.37, Flat_loss 0.21, Train_acc 93.34, Test_acc 44.92
2022-05-24 23:11:53,807 [podnet.py] => Task 4, Epoch 85/160 (LR 0.04510) => LSC_loss 0.30, Spatial_loss 1.41, Flat_loss 0.21, Train_acc 93.34, Test_acc 48.28
2022-05-24 23:11:59,816 [podnet.py] => Task 4, Epoch 86/160 (LR 0.04412) => LSC_loss 0.29, Spatial_loss 1.34, Flat_loss 0.20, Train_acc 93.77, Test_acc 44.94
2022-05-24 23:12:06,467 [podnet.py] => Task 4, Epoch 87/160 (LR 0.04315) => LSC_loss 0.30, Spatial_loss 1.37, Flat_loss 0.21, Train_acc 93.49, Test_acc 46.06
2022-05-24 23:12:13,186 [podnet.py] => Task 4, Epoch 88/160 (LR 0.04218) => LSC_loss 0.30, Spatial_loss 1.35, Flat_loss 0.21, Train_acc 93.33, Test_acc 50.10
2022-05-24 23:12:19,606 [podnet.py] => Task 4, Epoch 89/160 (LR 0.04121) => LSC_loss 0.29, Spatial_loss 1.34, Flat_loss 0.20, Train_acc 93.84, Test_acc 46.20
2022-05-24 23:12:26,178 [podnet.py] => Task 4, Epoch 90/160 (LR 0.04025) => LSC_loss 0.30, Spatial_loss 1.35, Flat_loss 0.20, Train_acc 93.57, Test_acc 48.44
2022-05-24 23:12:32,536 [podnet.py] => Task 4, Epoch 91/160 (LR 0.03928) => LSC_loss 0.27, Spatial_loss 1.33, Flat_loss 0.20, Train_acc 94.30, Test_acc 49.92
2022-05-24 23:12:38,953 [podnet.py] => Task 4, Epoch 92/160 (LR 0.03833) => LSC_loss 0.28, Spatial_loss 1.33, Flat_loss 0.20, Train_acc 93.94, Test_acc 48.20
2022-05-24 23:12:45,414 [podnet.py] => Task 4, Epoch 93/160 (LR 0.03738) => LSC_loss 0.27, Spatial_loss 1.31, Flat_loss 0.20, Train_acc 94.43, Test_acc 48.72
2022-05-24 23:12:51,648 [podnet.py] => Task 4, Epoch 94/160 (LR 0.03643) => LSC_loss 0.26, Spatial_loss 1.28, Flat_loss 0.20, Train_acc 94.83, Test_acc 49.74
2022-05-24 23:12:57,835 [podnet.py] => Task 4, Epoch 95/160 (LR 0.03549) => LSC_loss 0.25, Spatial_loss 1.27, Flat_loss 0.19, Train_acc 95.36, Test_acc 49.98
2022-05-24 23:13:04,397 [podnet.py] => Task 4, Epoch 96/160 (LR 0.03455) => LSC_loss 0.24, Spatial_loss 1.27, Flat_loss 0.19, Train_acc 95.41, Test_acc 48.74
2022-05-24 23:13:10,554 [podnet.py] => Task 4, Epoch 97/160 (LR 0.03362) => LSC_loss 0.25, Spatial_loss 1.28, Flat_loss 0.19, Train_acc 95.23, Test_acc 48.16
2022-05-24 23:13:16,725 [podnet.py] => Task 4, Epoch 98/160 (LR 0.03269) => LSC_loss 0.25, Spatial_loss 1.26, Flat_loss 0.19, Train_acc 95.49, Test_acc 49.54
2022-05-24 23:13:22,776 [podnet.py] => Task 4, Epoch 99/160 (LR 0.03178) => LSC_loss 0.24, Spatial_loss 1.28, Flat_loss 0.19, Train_acc 95.49, Test_acc 49.18
2022-05-24 23:13:29,175 [podnet.py] => Task 4, Epoch 100/160 (LR 0.03087) => LSC_loss 0.24, Spatial_loss 1.24, Flat_loss 0.19, Train_acc 95.64, Test_acc 48.76
2022-05-24 23:13:35,236 [podnet.py] => Task 4, Epoch 101/160 (LR 0.02996) => LSC_loss 0.23, Spatial_loss 1.23, Flat_loss 0.19, Train_acc 95.81, Test_acc 49.46
2022-05-24 23:13:41,390 [podnet.py] => Task 4, Epoch 102/160 (LR 0.02907) => LSC_loss 0.24, Spatial_loss 1.23, Flat_loss 0.19, Train_acc 95.56, Test_acc 50.16
2022-05-24 23:13:47,812 [podnet.py] => Task 4, Epoch 103/160 (LR 0.02818) => LSC_loss 0.22, Spatial_loss 1.20, Flat_loss 0.19, Train_acc 95.91, Test_acc 49.88
2022-05-24 23:13:54,288 [podnet.py] => Task 4, Epoch 104/160 (LR 0.02730) => LSC_loss 0.23, Spatial_loss 1.23, Flat_loss 0.18, Train_acc 95.50, Test_acc 49.88
2022-05-24 23:14:00,989 [podnet.py] => Task 4, Epoch 105/160 (LR 0.02643) => LSC_loss 0.23, Spatial_loss 1.22, Flat_loss 0.19, Train_acc 95.67, Test_acc 48.70
2022-05-24 23:14:07,601 [podnet.py] => Task 4, Epoch 106/160 (LR 0.02557) => LSC_loss 0.22, Spatial_loss 1.18, Flat_loss 0.18, Train_acc 96.54, Test_acc 49.68
2022-05-24 23:14:13,776 [podnet.py] => Task 4, Epoch 107/160 (LR 0.02472) => LSC_loss 0.22, Spatial_loss 1.22, Flat_loss 0.19, Train_acc 96.29, Test_acc 50.32
2022-05-24 23:14:20,257 [podnet.py] => Task 4, Epoch 108/160 (LR 0.02388) => LSC_loss 0.22, Spatial_loss 1.16, Flat_loss 0.18, Train_acc 96.07, Test_acc 49.42
2022-05-24 23:14:26,786 [podnet.py] => Task 4, Epoch 109/160 (LR 0.02304) => LSC_loss 0.21, Spatial_loss 1.16, Flat_loss 0.18, Train_acc 96.43, Test_acc 48.54
2022-05-24 23:14:33,196 [podnet.py] => Task 4, Epoch 110/160 (LR 0.02222) => LSC_loss 0.21, Spatial_loss 1.17, Flat_loss 0.18, Train_acc 96.87, Test_acc 49.36
2022-05-24 23:14:39,648 [podnet.py] => Task 4, Epoch 111/160 (LR 0.02141) => LSC_loss 0.20, Spatial_loss 1.12, Flat_loss 0.18, Train_acc 96.86, Test_acc 49.80
2022-05-24 23:14:45,886 [podnet.py] => Task 4, Epoch 112/160 (LR 0.02061) => LSC_loss 0.20, Spatial_loss 1.11, Flat_loss 0.18, Train_acc 96.87, Test_acc 49.92
2022-05-24 23:14:51,828 [podnet.py] => Task 4, Epoch 113/160 (LR 0.01982) => LSC_loss 0.20, Spatial_loss 1.12, Flat_loss 0.17, Train_acc 96.86, Test_acc 48.32
2022-05-24 23:14:57,806 [podnet.py] => Task 4, Epoch 114/160 (LR 0.01905) => LSC_loss 0.20, Spatial_loss 1.13, Flat_loss 0.18, Train_acc 97.01, Test_acc 50.42
2022-05-24 23:15:03,733 [podnet.py] => Task 4, Epoch 115/160 (LR 0.01828) => LSC_loss 0.20, Spatial_loss 1.15, Flat_loss 0.18, Train_acc 96.67, Test_acc 46.74
2022-05-24 23:15:10,343 [podnet.py] => Task 4, Epoch 116/160 (LR 0.01753) => LSC_loss 0.19, Spatial_loss 1.10, Flat_loss 0.17, Train_acc 97.41, Test_acc 52.06
2022-05-24 23:15:16,584 [podnet.py] => Task 4, Epoch 117/160 (LR 0.01679) => LSC_loss 0.18, Spatial_loss 1.09, Flat_loss 0.17, Train_acc 97.46, Test_acc 50.34
2022-05-24 23:15:22,976 [podnet.py] => Task 4, Epoch 118/160 (LR 0.01606) => LSC_loss 0.19, Spatial_loss 1.09, Flat_loss 0.17, Train_acc 97.50, Test_acc 50.12
2022-05-24 23:15:29,446 [podnet.py] => Task 4, Epoch 119/160 (LR 0.01535) => LSC_loss 0.18, Spatial_loss 1.06, Flat_loss 0.17, Train_acc 97.66, Test_acc 50.40
2022-05-24 23:15:35,689 [podnet.py] => Task 4, Epoch 120/160 (LR 0.01464) => LSC_loss 0.18, Spatial_loss 1.09, Flat_loss 0.17, Train_acc 97.51, Test_acc 51.16
2022-05-24 23:15:41,755 [podnet.py] => Task 4, Epoch 121/160 (LR 0.01396) => LSC_loss 0.18, Spatial_loss 1.07, Flat_loss 0.17, Train_acc 97.41, Test_acc 49.60
2022-05-24 23:15:47,787 [podnet.py] => Task 4, Epoch 122/160 (LR 0.01328) => LSC_loss 0.18, Spatial_loss 1.07, Flat_loss 0.17, Train_acc 97.37, Test_acc 50.50
2022-05-24 23:15:53,611 [podnet.py] => Task 4, Epoch 123/160 (LR 0.01262) => LSC_loss 0.18, Spatial_loss 1.06, Flat_loss 0.17, Train_acc 97.79, Test_acc 49.28
2022-05-24 23:16:00,020 [podnet.py] => Task 4, Epoch 124/160 (LR 0.01198) => LSC_loss 0.18, Spatial_loss 1.05, Flat_loss 0.17, Train_acc 97.70, Test_acc 50.54
2022-05-24 23:16:06,139 [podnet.py] => Task 4, Epoch 125/160 (LR 0.01135) => LSC_loss 0.17, Spatial_loss 1.03, Flat_loss 0.16, Train_acc 97.97, Test_acc 50.26
2022-05-24 23:16:12,579 [podnet.py] => Task 4, Epoch 126/160 (LR 0.01073) => LSC_loss 0.17, Spatial_loss 1.01, Flat_loss 0.16, Train_acc 97.93, Test_acc 49.42
2022-05-24 23:16:19,077 [podnet.py] => Task 4, Epoch 127/160 (LR 0.01013) => LSC_loss 0.17, Spatial_loss 1.04, Flat_loss 0.16, Train_acc 97.53, Test_acc 51.04
2022-05-24 23:16:25,290 [podnet.py] => Task 4, Epoch 128/160 (LR 0.00955) => LSC_loss 0.16, Spatial_loss 0.98, Flat_loss 0.16, Train_acc 98.07, Test_acc 50.32
2022-05-24 23:16:31,753 [podnet.py] => Task 4, Epoch 129/160 (LR 0.00898) => LSC_loss 0.17, Spatial_loss 1.00, Flat_loss 0.16, Train_acc 98.11, Test_acc 51.12
2022-05-24 23:16:38,286 [podnet.py] => Task 4, Epoch 130/160 (LR 0.00843) => LSC_loss 0.16, Spatial_loss 1.01, Flat_loss 0.16, Train_acc 98.11, Test_acc 50.62
2022-05-24 23:16:44,548 [podnet.py] => Task 4, Epoch 131/160 (LR 0.00789) => LSC_loss 0.17, Spatial_loss 0.98, Flat_loss 0.16, Train_acc 98.06, Test_acc 50.64
2022-05-24 23:16:50,645 [podnet.py] => Task 4, Epoch 132/160 (LR 0.00737) => LSC_loss 0.16, Spatial_loss 0.99, Flat_loss 0.16, Train_acc 98.09, Test_acc 51.50
2022-05-24 23:16:56,306 [podnet.py] => Task 4, Epoch 133/160 (LR 0.00686) => LSC_loss 0.16, Spatial_loss 0.97, Flat_loss 0.16, Train_acc 98.31, Test_acc 50.68
2022-05-24 23:17:02,635 [podnet.py] => Task 4, Epoch 134/160 (LR 0.00638) => LSC_loss 0.16, Spatial_loss 0.96, Flat_loss 0.16, Train_acc 98.27, Test_acc 51.40
2022-05-24 23:17:08,750 [podnet.py] => Task 4, Epoch 135/160 (LR 0.00590) => LSC_loss 0.16, Spatial_loss 0.98, Flat_loss 0.16, Train_acc 98.21, Test_acc 51.58
2022-05-24 23:17:14,880 [podnet.py] => Task 4, Epoch 136/160 (LR 0.00545) => LSC_loss 0.16, Spatial_loss 0.97, Flat_loss 0.16, Train_acc 98.20, Test_acc 51.26
2022-05-24 23:17:21,277 [podnet.py] => Task 4, Epoch 137/160 (LR 0.00501) => LSC_loss 0.16, Spatial_loss 0.97, Flat_loss 0.16, Train_acc 98.21, Test_acc 51.34
2022-05-24 23:17:27,675 [podnet.py] => Task 4, Epoch 138/160 (LR 0.00459) => LSC_loss 0.15, Spatial_loss 0.96, Flat_loss 0.16, Train_acc 98.53, Test_acc 51.28
2022-05-24 23:17:34,060 [podnet.py] => Task 4, Epoch 139/160 (LR 0.00419) => LSC_loss 0.16, Spatial_loss 0.95, Flat_loss 0.16, Train_acc 98.34, Test_acc 51.26
2022-05-24 23:17:40,480 [podnet.py] => Task 4, Epoch 140/160 (LR 0.00381) => LSC_loss 0.15, Spatial_loss 0.94, Flat_loss 0.16, Train_acc 98.44, Test_acc 51.36
2022-05-24 23:17:46,479 [podnet.py] => Task 4, Epoch 141/160 (LR 0.00344) => LSC_loss 0.16, Spatial_loss 0.96, Flat_loss 0.15, Train_acc 98.24, Test_acc 50.90
2022-05-24 23:17:52,565 [podnet.py] => Task 4, Epoch 142/160 (LR 0.00309) => LSC_loss 0.16, Spatial_loss 0.95, Flat_loss 0.16, Train_acc 98.47, Test_acc 51.22
2022-05-24 23:17:58,636 [podnet.py] => Task 4, Epoch 143/160 (LR 0.00276) => LSC_loss 0.15, Spatial_loss 0.95, Flat_loss 0.15, Train_acc 98.51, Test_acc 51.54
2022-05-24 23:18:04,672 [podnet.py] => Task 4, Epoch 144/160 (LR 0.00245) => LSC_loss 0.15, Spatial_loss 0.93, Flat_loss 0.16, Train_acc 98.57, Test_acc 51.60
2022-05-24 23:18:11,048 [podnet.py] => Task 4, Epoch 145/160 (LR 0.00215) => LSC_loss 0.15, Spatial_loss 0.93, Flat_loss 0.15, Train_acc 98.40, Test_acc 51.76
2022-05-24 23:18:17,339 [podnet.py] => Task 4, Epoch 146/160 (LR 0.00188) => LSC_loss 0.15, Spatial_loss 0.90, Flat_loss 0.15, Train_acc 98.63, Test_acc 51.86
2022-05-24 23:18:23,813 [podnet.py] => Task 4, Epoch 147/160 (LR 0.00162) => LSC_loss 0.15, Spatial_loss 0.92, Flat_loss 0.15, Train_acc 98.60, Test_acc 51.50
2022-05-24 23:18:30,209 [podnet.py] => Task 4, Epoch 148/160 (LR 0.00138) => LSC_loss 0.15, Spatial_loss 0.92, Flat_loss 0.15, Train_acc 98.60, Test_acc 51.80
2022-05-24 23:18:36,558 [podnet.py] => Task 4, Epoch 149/160 (LR 0.00116) => LSC_loss 0.15, Spatial_loss 0.89, Flat_loss 0.15, Train_acc 98.77, Test_acc 51.50
2022-05-24 23:18:42,955 [podnet.py] => Task 4, Epoch 150/160 (LR 0.00096) => LSC_loss 0.15, Spatial_loss 0.92, Flat_loss 0.15, Train_acc 98.76, Test_acc 51.50
2022-05-24 23:18:49,320 [podnet.py] => Task 4, Epoch 151/160 (LR 0.00078) => LSC_loss 0.15, Spatial_loss 0.88, Flat_loss 0.15, Train_acc 98.70, Test_acc 51.66
2022-05-24 23:18:55,266 [podnet.py] => Task 4, Epoch 152/160 (LR 0.00062) => LSC_loss 0.15, Spatial_loss 0.91, Flat_loss 0.15, Train_acc 98.70, Test_acc 51.64
2022-05-24 23:19:01,478 [podnet.py] => Task 4, Epoch 153/160 (LR 0.00047) => LSC_loss 0.15, Spatial_loss 0.89, Flat_loss 0.15, Train_acc 98.56, Test_acc 51.72
2022-05-24 23:19:07,585 [podnet.py] => Task 4, Epoch 154/160 (LR 0.00035) => LSC_loss 0.15, Spatial_loss 0.88, Flat_loss 0.15, Train_acc 98.67, Test_acc 51.76
2022-05-24 23:19:13,864 [podnet.py] => Task 4, Epoch 155/160 (LR 0.00024) => LSC_loss 0.15, Spatial_loss 0.89, Flat_loss 0.15, Train_acc 98.63, Test_acc 51.62
2022-05-24 23:19:20,209 [podnet.py] => Task 4, Epoch 156/160 (LR 0.00015) => LSC_loss 0.15, Spatial_loss 0.88, Flat_loss 0.15, Train_acc 98.94, Test_acc 51.56
2022-05-24 23:19:26,573 [podnet.py] => Task 4, Epoch 157/160 (LR 0.00009) => LSC_loss 0.15, Spatial_loss 0.89, Flat_loss 0.15, Train_acc 98.74, Test_acc 51.50
2022-05-24 23:19:33,237 [podnet.py] => Task 4, Epoch 158/160 (LR 0.00004) => LSC_loss 0.15, Spatial_loss 0.89, Flat_loss 0.15, Train_acc 98.73, Test_acc 51.94
2022-05-24 23:19:39,505 [podnet.py] => Task 4, Epoch 159/160 (LR 0.00001) => LSC_loss 0.15, Spatial_loss 0.88, Flat_loss 0.15, Train_acc 98.70, Test_acc 51.62
2022-05-24 23:19:45,897 [podnet.py] => Task 4, Epoch 160/160 (LR 0.00000) => LSC_loss 0.15, Spatial_loss 0.90, Flat_loss 0.15, Train_acc 98.70, Test_acc 51.62
2022-05-24 23:19:45,898 [podnet.py] => Finetune the network (classifier part) with the undersampled dataset!
2022-05-24 23:19:45,899 [base.py] => Reducing exemplars...(50 per classes)
2022-05-24 23:19:54,819 [base.py] => Constructing exemplars...(50 per classes)
2022-05-24 23:20:00,711 [podnet.py] => The size of finetune dataset: 2500
2022-05-24 23:20:03,674 [podnet.py] => Task 4, Epoch 1/20 (LR 0.00497) => LSC_loss 0.16, Spatial_loss 0.94, Flat_loss 0.11, Train_acc 98.12, Test_acc 52.98
2022-05-24 23:20:06,826 [podnet.py] => Task 4, Epoch 2/20 (LR 0.00488) => LSC_loss 0.13, Spatial_loss 0.94, Flat_loss 0.10, Train_acc 98.52, Test_acc 53.02
2022-05-24 23:20:09,882 [podnet.py] => Task 4, Epoch 3/20 (LR 0.00473) => LSC_loss 0.12, Spatial_loss 0.92, Flat_loss 0.09, Train_acc 98.92, Test_acc 53.50
2022-05-24 23:20:12,763 [podnet.py] => Task 4, Epoch 4/20 (LR 0.00452) => LSC_loss 0.12, Spatial_loss 0.95, Flat_loss 0.09, Train_acc 99.20, Test_acc 53.60
2022-05-24 23:20:15,678 [podnet.py] => Task 4, Epoch 5/20 (LR 0.00427) => LSC_loss 0.12, Spatial_loss 0.90, Flat_loss 0.09, Train_acc 98.76, Test_acc 53.20
2022-05-24 23:20:18,461 [podnet.py] => Task 4, Epoch 6/20 (LR 0.00397) => LSC_loss 0.11, Spatial_loss 0.94, Flat_loss 0.09, Train_acc 99.28, Test_acc 54.00
2022-05-24 23:20:21,175 [podnet.py] => Task 4, Epoch 7/20 (LR 0.00363) => LSC_loss 0.12, Spatial_loss 0.92, Flat_loss 0.09, Train_acc 98.88, Test_acc 53.62
2022-05-24 23:20:24,046 [podnet.py] => Task 4, Epoch 8/20 (LR 0.00327) => LSC_loss 0.12, Spatial_loss 0.88, Flat_loss 0.09, Train_acc 99.00, Test_acc 53.66
2022-05-24 23:20:27,235 [podnet.py] => Task 4, Epoch 9/20 (LR 0.00289) => LSC_loss 0.11, Spatial_loss 0.89, Flat_loss 0.09, Train_acc 99.00, Test_acc 53.80
2022-05-24 23:20:30,252 [podnet.py] => Task 4, Epoch 10/20 (LR 0.00250) => LSC_loss 0.11, Spatial_loss 0.88, Flat_loss 0.09, Train_acc 98.80, Test_acc 53.68
2022-05-24 23:20:33,399 [podnet.py] => Task 4, Epoch 11/20 (LR 0.00211) => LSC_loss 0.11, Spatial_loss 0.90, Flat_loss 0.09, Train_acc 99.36, Test_acc 53.90
2022-05-24 23:20:36,545 [podnet.py] => Task 4, Epoch 12/20 (LR 0.00173) => LSC_loss 0.10, Spatial_loss 0.87, Flat_loss 0.09, Train_acc 99.44, Test_acc 53.78
2022-05-24 23:20:39,613 [podnet.py] => Task 4, Epoch 13/20 (LR 0.00137) => LSC_loss 0.11, Spatial_loss 0.87, Flat_loss 0.09, Train_acc 99.20, Test_acc 53.96
2022-05-24 23:20:42,625 [podnet.py] => Task 4, Epoch 14/20 (LR 0.00103) => LSC_loss 0.10, Spatial_loss 0.88, Flat_loss 0.09, Train_acc 99.60, Test_acc 53.92
2022-05-24 23:20:45,578 [podnet.py] => Task 4, Epoch 15/20 (LR 0.00073) => LSC_loss 0.11, Spatial_loss 0.87, Flat_loss 0.09, Train_acc 99.24, Test_acc 54.02
2022-05-24 23:20:48,560 [podnet.py] => Task 4, Epoch 16/20 (LR 0.00048) => LSC_loss 0.11, Spatial_loss 0.84, Flat_loss 0.09, Train_acc 99.28, Test_acc 53.96
2022-05-24 23:20:51,596 [podnet.py] => Task 4, Epoch 17/20 (LR 0.00027) => LSC_loss 0.11, Spatial_loss 0.85, Flat_loss 0.08, Train_acc 98.84, Test_acc 53.86
2022-05-24 23:20:54,737 [podnet.py] => Task 4, Epoch 18/20 (LR 0.00012) => LSC_loss 0.10, Spatial_loss 0.83, Flat_loss 0.08, Train_acc 99.48, Test_acc 53.92
2022-05-24 23:20:57,577 [podnet.py] => Task 4, Epoch 19/20 (LR 0.00003) => LSC_loss 0.11, Spatial_loss 0.85, Flat_loss 0.09, Train_acc 99.28, Test_acc 53.98
2022-05-24 23:21:00,585 [podnet.py] => Task 4, Epoch 20/20 (LR 0.00000) => LSC_loss 0.11, Spatial_loss 0.85, Flat_loss 0.08, Train_acc 99.20, Test_acc 53.90
2022-05-24 23:21:00,587 [base.py] => Reducing exemplars...(40 per classes)
2022-05-24 23:21:08,788 [base.py] => Constructing exemplars...(40 per classes)
2022-05-24 23:21:16,327 [podnet.py] => Exemplar size: 2000
2022-05-24 23:21:16,328 [trainer.py] => CNN: {'total': 53.9, '00-09': 66.9, '10-19': 31.8, '20-29': 49.6, '30-39': 48.1, '40-49': 73.1, 'old': 49.1, 'new': 73.1}
2022-05-24 23:21:16,328 [trainer.py] => NME: {'total': 52.92, '00-09': 71.6, '10-19': 28.8, '20-29': 48.4, '30-39': 47.3, '40-49': 68.5, 'old': 49.02, 'new': 68.5}
2022-05-24 23:21:16,328 [trainer.py] => CNN top1 curve: [90.7, 72.95, 65.47, 57.8, 53.9]
2022-05-24 23:21:16,328 [trainer.py] => CNN top5 curve: [99.2, 93.95, 90.1, 85.15, 81.78]
2022-05-24 23:21:16,328 [trainer.py] => NME top1 curve: [90.8, 72.05, 63.37, 55.7, 52.92]
2022-05-24 23:21:16,328 [trainer.py] => NME top5 curve: [99.3, 92.8, 88.93, 83.38, 81.2]

2022-05-24 23:21:16,329 [trainer.py] => All params: 498257
2022-05-24 23:21:16,330 [trainer.py] => Trainable params: 498257
2022-05-24 23:21:16,331 [podnet.py] => Learning on 50-60
2022-05-24 23:21:16,412 [podnet.py] => Adaptive factor: 2.449489742783178
2022-05-24 23:21:22,953 [podnet.py] => Task 5, Epoch 1/160 (LR 0.09999) => LSC_loss 2.65, Spatial_loss 2.74, Flat_loss 0.84, Train_acc 43.01, Test_acc 23.13
2022-05-24 23:21:29,221 [podnet.py] => Task 5, Epoch 2/160 (LR 0.09996) => LSC_loss 1.55, Spatial_loss 2.26, Flat_loss 0.44, Train_acc 56.00, Test_acc 29.47
2022-05-24 23:21:35,686 [podnet.py] => Task 5, Epoch 3/160 (LR 0.09991) => LSC_loss 1.39, Spatial_loss 2.12, Flat_loss 0.35, Train_acc 60.89, Test_acc 33.95
2022-05-24 23:21:41,994 [podnet.py] => Task 5, Epoch 4/160 (LR 0.09985) => LSC_loss 1.26, Spatial_loss 2.11, Flat_loss 0.32, Train_acc 64.57, Test_acc 36.13
2022-05-24 23:21:48,288 [podnet.py] => Task 5, Epoch 5/160 (LR 0.09976) => LSC_loss 1.20, Spatial_loss 2.04, Flat_loss 0.30, Train_acc 66.79, Test_acc 33.28
2022-05-24 23:21:54,471 [podnet.py] => Task 5, Epoch 6/160 (LR 0.09965) => LSC_loss 1.16, Spatial_loss 2.01, Flat_loss 0.29, Train_acc 67.26, Test_acc 35.50
2022-05-24 23:22:00,743 [podnet.py] => Task 5, Epoch 7/160 (LR 0.09953) => LSC_loss 1.07, Spatial_loss 1.96, Flat_loss 0.29, Train_acc 69.70, Test_acc 36.83
2022-05-24 23:22:07,178 [podnet.py] => Task 5, Epoch 8/160 (LR 0.09938) => LSC_loss 1.05, Spatial_loss 1.90, Flat_loss 0.28, Train_acc 71.21, Test_acc 37.98
2022-05-24 23:22:13,660 [podnet.py] => Task 5, Epoch 9/160 (LR 0.09922) => LSC_loss 1.05, Spatial_loss 2.00, Flat_loss 0.29, Train_acc 71.47, Test_acc 32.73
2022-05-24 23:22:19,693 [podnet.py] => Task 5, Epoch 10/160 (LR 0.09904) => LSC_loss 1.01, Spatial_loss 1.96, Flat_loss 0.28, Train_acc 72.31, Test_acc 36.95
2022-05-24 23:22:26,025 [podnet.py] => Task 5, Epoch 11/160 (LR 0.09884) => LSC_loss 0.97, Spatial_loss 1.95, Flat_loss 0.28, Train_acc 73.99, Test_acc 34.95
2022-05-24 23:22:32,144 [podnet.py] => Task 5, Epoch 12/160 (LR 0.09862) => LSC_loss 0.95, Spatial_loss 1.95, Flat_loss 0.28, Train_acc 74.03, Test_acc 39.17
2022-05-24 23:22:38,564 [podnet.py] => Task 5, Epoch 13/160 (LR 0.09838) => LSC_loss 0.93, Spatial_loss 1.91, Flat_loss 0.28, Train_acc 74.40, Test_acc 38.40
2022-05-24 23:22:45,209 [podnet.py] => Task 5, Epoch 14/160 (LR 0.09812) => LSC_loss 0.89, Spatial_loss 1.88, Flat_loss 0.27, Train_acc 76.33, Test_acc 37.63
2022-05-24 23:22:51,540 [podnet.py] => Task 5, Epoch 15/160 (LR 0.09785) => LSC_loss 0.90, Spatial_loss 1.93, Flat_loss 0.28, Train_acc 75.16, Test_acc 36.20
2022-05-24 23:22:58,007 [podnet.py] => Task 5, Epoch 16/160 (LR 0.09755) => LSC_loss 0.87, Spatial_loss 1.88, Flat_loss 0.28, Train_acc 75.96, Test_acc 38.95
2022-05-24 23:23:04,666 [podnet.py] => Task 5, Epoch 17/160 (LR 0.09724) => LSC_loss 0.86, Spatial_loss 1.89, Flat_loss 0.28, Train_acc 76.36, Test_acc 37.73
2022-05-24 23:23:10,774 [podnet.py] => Task 5, Epoch 18/160 (LR 0.09691) => LSC_loss 0.85, Spatial_loss 1.90, Flat_loss 0.28, Train_acc 76.57, Test_acc 36.73
2022-05-24 23:23:16,904 [podnet.py] => Task 5, Epoch 19/160 (LR 0.09656) => LSC_loss 0.81, Spatial_loss 1.84, Flat_loss 0.27, Train_acc 78.73, Test_acc 38.40
2022-05-24 23:23:22,962 [podnet.py] => Task 5, Epoch 20/160 (LR 0.09619) => LSC_loss 0.78, Spatial_loss 1.81, Flat_loss 0.27, Train_acc 78.81, Test_acc 41.47
2022-05-24 23:23:29,629 [podnet.py] => Task 5, Epoch 21/160 (LR 0.09581) => LSC_loss 0.79, Spatial_loss 1.87, Flat_loss 0.28, Train_acc 78.01, Test_acc 40.08
2022-05-24 23:23:35,811 [podnet.py] => Task 5, Epoch 22/160 (LR 0.09541) => LSC_loss 0.76, Spatial_loss 1.80, Flat_loss 0.27, Train_acc 79.60, Test_acc 40.00
2022-05-24 23:23:42,064 [podnet.py] => Task 5, Epoch 23/160 (LR 0.09499) => LSC_loss 0.77, Spatial_loss 1.87, Flat_loss 0.28, Train_acc 79.40, Test_acc 39.88
2022-05-24 23:23:48,708 [podnet.py] => Task 5, Epoch 24/160 (LR 0.09455) => LSC_loss 0.76, Spatial_loss 1.86, Flat_loss 0.28, Train_acc 79.70, Test_acc 36.58
2022-05-24 23:23:55,548 [podnet.py] => Task 5, Epoch 25/160 (LR 0.09410) => LSC_loss 0.78, Spatial_loss 1.86, Flat_loss 0.28, Train_acc 79.00, Test_acc 40.18
2022-05-24 23:24:01,902 [podnet.py] => Task 5, Epoch 26/160 (LR 0.09362) => LSC_loss 0.74, Spatial_loss 1.88, Flat_loss 0.28, Train_acc 79.93, Test_acc 41.35
2022-05-24 23:24:08,632 [podnet.py] => Task 5, Epoch 27/160 (LR 0.09314) => LSC_loss 0.73, Spatial_loss 1.82, Flat_loss 0.28, Train_acc 80.33, Test_acc 36.45
2022-05-24 23:24:14,983 [podnet.py] => Task 5, Epoch 28/160 (LR 0.09263) => LSC_loss 0.68, Spatial_loss 1.85, Flat_loss 0.27, Train_acc 81.99, Test_acc 38.43
2022-05-24 23:24:21,460 [podnet.py] => Task 5, Epoch 29/160 (LR 0.09211) => LSC_loss 0.70, Spatial_loss 1.82, Flat_loss 0.28, Train_acc 81.24, Test_acc 41.10
2022-05-24 23:24:27,929 [podnet.py] => Task 5, Epoch 30/160 (LR 0.09157) => LSC_loss 0.69, Spatial_loss 1.79, Flat_loss 0.27, Train_acc 81.46, Test_acc 37.63
2022-05-24 23:24:34,427 [podnet.py] => Task 5, Epoch 31/160 (LR 0.09102) => LSC_loss 0.68, Spatial_loss 1.83, Flat_loss 0.28, Train_acc 81.91, Test_acc 39.30
2022-05-24 23:24:40,672 [podnet.py] => Task 5, Epoch 32/160 (LR 0.09045) => LSC_loss 0.69, Spatial_loss 1.81, Flat_loss 0.28, Train_acc 81.60, Test_acc 38.95
2022-05-24 23:24:46,668 [podnet.py] => Task 5, Epoch 33/160 (LR 0.08987) => LSC_loss 0.69, Spatial_loss 1.83, Flat_loss 0.28, Train_acc 81.41, Test_acc 37.95
2022-05-24 23:24:53,146 [podnet.py] => Task 5, Epoch 34/160 (LR 0.08927) => LSC_loss 0.66, Spatial_loss 1.81, Flat_loss 0.27, Train_acc 82.41, Test_acc 40.75
2022-05-24 23:24:59,226 [podnet.py] => Task 5, Epoch 35/160 (LR 0.08865) => LSC_loss 0.65, Spatial_loss 1.85, Flat_loss 0.28, Train_acc 82.61, Test_acc 33.98
2022-05-24 23:25:05,771 [podnet.py] => Task 5, Epoch 36/160 (LR 0.08802) => LSC_loss 0.66, Spatial_loss 1.80, Flat_loss 0.28, Train_acc 82.67, Test_acc 38.17
2022-05-24 23:25:12,064 [podnet.py] => Task 5, Epoch 37/160 (LR 0.08738) => LSC_loss 0.64, Spatial_loss 1.83, Flat_loss 0.28, Train_acc 83.79, Test_acc 39.45
2022-05-24 23:25:18,578 [podnet.py] => Task 5, Epoch 38/160 (LR 0.08672) => LSC_loss 0.65, Spatial_loss 1.81, Flat_loss 0.27, Train_acc 82.79, Test_acc 35.20
2022-05-24 23:25:25,271 [podnet.py] => Task 5, Epoch 39/160 (LR 0.08604) => LSC_loss 0.65, Spatial_loss 1.79, Flat_loss 0.27, Train_acc 83.37, Test_acc 38.80
2022-05-24 23:25:31,850 [podnet.py] => Task 5, Epoch 40/160 (LR 0.08536) => LSC_loss 0.61, Spatial_loss 1.78, Flat_loss 0.27, Train_acc 84.13, Test_acc 38.70
2022-05-24 23:25:37,951 [podnet.py] => Task 5, Epoch 41/160 (LR 0.08465) => LSC_loss 0.61, Spatial_loss 1.79, Flat_loss 0.27, Train_acc 84.19, Test_acc 35.78
2022-05-24 23:25:44,363 [podnet.py] => Task 5, Epoch 42/160 (LR 0.08394) => LSC_loss 0.59, Spatial_loss 1.74, Flat_loss 0.27, Train_acc 85.06, Test_acc 43.02
2022-05-24 23:25:50,932 [podnet.py] => Task 5, Epoch 43/160 (LR 0.08321) => LSC_loss 0.59, Spatial_loss 1.79, Flat_loss 0.27, Train_acc 83.93, Test_acc 41.38
2022-05-24 23:25:57,034 [podnet.py] => Task 5, Epoch 44/160 (LR 0.08247) => LSC_loss 0.60, Spatial_loss 1.75, Flat_loss 0.28, Train_acc 83.91, Test_acc 40.48
2022-05-24 23:26:03,177 [podnet.py] => Task 5, Epoch 45/160 (LR 0.08172) => LSC_loss 0.61, Spatial_loss 1.78, Flat_loss 0.27, Train_acc 84.24, Test_acc 43.55
2022-05-24 23:26:09,231 [podnet.py] => Task 5, Epoch 46/160 (LR 0.08095) => LSC_loss 0.58, Spatial_loss 1.78, Flat_loss 0.28, Train_acc 84.56, Test_acc 41.23
2022-05-24 23:26:15,808 [podnet.py] => Task 5, Epoch 47/160 (LR 0.08018) => LSC_loss 0.57, Spatial_loss 1.72, Flat_loss 0.27, Train_acc 85.23, Test_acc 39.42
2022-05-24 23:26:22,088 [podnet.py] => Task 5, Epoch 48/160 (LR 0.07939) => LSC_loss 0.56, Spatial_loss 1.74, Flat_loss 0.27, Train_acc 85.74, Test_acc 42.00
2022-05-24 23:26:28,460 [podnet.py] => Task 5, Epoch 49/160 (LR 0.07859) => LSC_loss 0.57, Spatial_loss 1.75, Flat_loss 0.27, Train_acc 84.60, Test_acc 42.02
2022-05-24 23:26:35,249 [podnet.py] => Task 5, Epoch 50/160 (LR 0.07778) => LSC_loss 0.57, Spatial_loss 1.75, Flat_loss 0.27, Train_acc 85.13, Test_acc 42.75
2022-05-24 23:26:42,003 [podnet.py] => Task 5, Epoch 51/160 (LR 0.07696) => LSC_loss 0.55, Spatial_loss 1.70, Flat_loss 0.26, Train_acc 86.23, Test_acc 40.63
2022-05-24 23:26:48,312 [podnet.py] => Task 5, Epoch 52/160 (LR 0.07612) => LSC_loss 0.54, Spatial_loss 1.70, Flat_loss 0.26, Train_acc 86.00, Test_acc 38.85
2022-05-24 23:26:54,364 [podnet.py] => Task 5, Epoch 53/160 (LR 0.07528) => LSC_loss 0.55, Spatial_loss 1.72, Flat_loss 0.26, Train_acc 85.89, Test_acc 40.63
2022-05-24 23:27:00,419 [podnet.py] => Task 5, Epoch 54/160 (LR 0.07443) => LSC_loss 0.51, Spatial_loss 1.73, Flat_loss 0.27, Train_acc 87.01, Test_acc 41.07
2022-05-24 23:27:06,724 [podnet.py] => Task 5, Epoch 55/160 (LR 0.07357) => LSC_loss 0.50, Spatial_loss 1.66, Flat_loss 0.26, Train_acc 88.06, Test_acc 39.10
2022-05-24 23:27:12,970 [podnet.py] => Task 5, Epoch 56/160 (LR 0.07270) => LSC_loss 0.50, Spatial_loss 1.73, Flat_loss 0.27, Train_acc 87.24, Test_acc 41.25
2022-05-24 23:27:19,121 [podnet.py] => Task 5, Epoch 57/160 (LR 0.07182) => LSC_loss 0.51, Spatial_loss 1.68, Flat_loss 0.27, Train_acc 86.50, Test_acc 41.37
2022-05-24 23:27:25,758 [podnet.py] => Task 5, Epoch 58/160 (LR 0.07093) => LSC_loss 0.48, Spatial_loss 1.66, Flat_loss 0.26, Train_acc 88.21, Test_acc 39.85
2022-05-24 23:27:32,390 [podnet.py] => Task 5, Epoch 59/160 (LR 0.07004) => LSC_loss 0.51, Spatial_loss 1.64, Flat_loss 0.27, Train_acc 86.71, Test_acc 40.03
2022-05-24 23:27:38,849 [podnet.py] => Task 5, Epoch 60/160 (LR 0.06913) => LSC_loss 0.49, Spatial_loss 1.65, Flat_loss 0.26, Train_acc 88.23, Test_acc 39.38
2022-05-24 23:27:45,288 [podnet.py] => Task 5, Epoch 61/160 (LR 0.06822) => LSC_loss 0.48, Spatial_loss 1.65, Flat_loss 0.26, Train_acc 88.00, Test_acc 44.58
2022-05-24 23:27:51,571 [podnet.py] => Task 5, Epoch 62/160 (LR 0.06731) => LSC_loss 0.50, Spatial_loss 1.68, Flat_loss 0.27, Train_acc 87.79, Test_acc 41.35
2022-05-24 23:27:57,968 [podnet.py] => Task 5, Epoch 63/160 (LR 0.06638) => LSC_loss 0.49, Spatial_loss 1.67, Flat_loss 0.26, Train_acc 87.47, Test_acc 40.22
2022-05-24 23:28:04,378 [podnet.py] => Task 5, Epoch 64/160 (LR 0.06545) => LSC_loss 0.47, Spatial_loss 1.67, Flat_loss 0.26, Train_acc 88.46, Test_acc 39.47
2022-05-24 23:28:10,416 [podnet.py] => Task 5, Epoch 65/160 (LR 0.06451) => LSC_loss 0.44, Spatial_loss 1.62, Flat_loss 0.26, Train_acc 89.09, Test_acc 40.05
2022-05-24 23:28:16,940 [podnet.py] => Task 5, Epoch 66/160 (LR 0.06357) => LSC_loss 0.45, Spatial_loss 1.66, Flat_loss 0.26, Train_acc 88.89, Test_acc 41.12
2022-05-24 23:28:23,142 [podnet.py] => Task 5, Epoch 67/160 (LR 0.06262) => LSC_loss 0.44, Spatial_loss 1.64, Flat_loss 0.26, Train_acc 89.40, Test_acc 41.55
2022-05-24 23:28:29,825 [podnet.py] => Task 5, Epoch 68/160 (LR 0.06167) => LSC_loss 0.45, Spatial_loss 1.58, Flat_loss 0.26, Train_acc 89.26, Test_acc 40.18
2022-05-24 23:28:36,146 [podnet.py] => Task 5, Epoch 69/160 (LR 0.06072) => LSC_loss 0.44, Spatial_loss 1.57, Flat_loss 0.26, Train_acc 89.54, Test_acc 38.70
2022-05-24 23:28:42,478 [podnet.py] => Task 5, Epoch 70/160 (LR 0.05975) => LSC_loss 0.43, Spatial_loss 1.60, Flat_loss 0.25, Train_acc 89.54, Test_acc 42.02
2022-05-24 23:28:49,163 [podnet.py] => Task 5, Epoch 71/160 (LR 0.05879) => LSC_loss 0.45, Spatial_loss 1.60, Flat_loss 0.26, Train_acc 88.64, Test_acc 38.92
2022-05-24 23:28:55,650 [podnet.py] => Task 5, Epoch 72/160 (LR 0.05782) => LSC_loss 0.42, Spatial_loss 1.62, Flat_loss 0.26, Train_acc 90.17, Test_acc 41.35
2022-05-24 23:29:02,348 [podnet.py] => Task 5, Epoch 73/160 (LR 0.05685) => LSC_loss 0.40, Spatial_loss 1.58, Flat_loss 0.25, Train_acc 90.57, Test_acc 40.87
2022-05-24 23:29:09,070 [podnet.py] => Task 5, Epoch 74/160 (LR 0.05588) => LSC_loss 0.41, Spatial_loss 1.58, Flat_loss 0.25, Train_acc 90.00, Test_acc 39.18
2022-05-24 23:29:15,483 [podnet.py] => Task 5, Epoch 75/160 (LR 0.05490) => LSC_loss 0.43, Spatial_loss 1.58, Flat_loss 0.26, Train_acc 90.10, Test_acc 42.07
2022-05-24 23:29:22,059 [podnet.py] => Task 5, Epoch 76/160 (LR 0.05392) => LSC_loss 0.41, Spatial_loss 1.55, Flat_loss 0.25, Train_acc 90.07, Test_acc 39.30
2022-05-24 23:29:28,671 [podnet.py] => Task 5, Epoch 77/160 (LR 0.05294) => LSC_loss 0.38, Spatial_loss 1.55, Flat_loss 0.25, Train_acc 91.34, Test_acc 41.52
2022-05-24 23:29:35,231 [podnet.py] => Task 5, Epoch 78/160 (LR 0.05196) => LSC_loss 0.41, Spatial_loss 1.57, Flat_loss 0.25, Train_acc 90.39, Test_acc 45.15
2022-05-24 23:29:42,005 [podnet.py] => Task 5, Epoch 79/160 (LR 0.05098) => LSC_loss 0.38, Spatial_loss 1.52, Flat_loss 0.25, Train_acc 91.31, Test_acc 39.02
2022-05-24 23:29:48,425 [podnet.py] => Task 5, Epoch 80/160 (LR 0.05000) => LSC_loss 0.34, Spatial_loss 1.51, Flat_loss 0.24, Train_acc 92.66, Test_acc 43.30
2022-05-24 23:29:54,935 [podnet.py] => Task 5, Epoch 81/160 (LR 0.04902) => LSC_loss 0.39, Spatial_loss 1.51, Flat_loss 0.25, Train_acc 90.91, Test_acc 43.25
2022-05-24 23:30:01,412 [podnet.py] => Task 5, Epoch 82/160 (LR 0.04804) => LSC_loss 0.37, Spatial_loss 1.51, Flat_loss 0.25, Train_acc 91.53, Test_acc 40.35
2022-05-24 23:30:07,897 [podnet.py] => Task 5, Epoch 83/160 (LR 0.04706) => LSC_loss 0.38, Spatial_loss 1.49, Flat_loss 0.25, Train_acc 91.50, Test_acc 42.88
2022-05-24 23:30:14,363 [podnet.py] => Task 5, Epoch 84/160 (LR 0.04608) => LSC_loss 0.35, Spatial_loss 1.49, Flat_loss 0.25, Train_acc 91.86, Test_acc 43.13
2022-05-24 23:30:20,535 [podnet.py] => Task 5, Epoch 85/160 (LR 0.04510) => LSC_loss 0.35, Spatial_loss 1.47, Flat_loss 0.24, Train_acc 92.19, Test_acc 39.07
2022-05-24 23:30:26,942 [podnet.py] => Task 5, Epoch 86/160 (LR 0.04412) => LSC_loss 0.36, Spatial_loss 1.46, Flat_loss 0.24, Train_acc 92.14, Test_acc 40.48
2022-05-24 23:30:32,958 [podnet.py] => Task 5, Epoch 87/160 (LR 0.04315) => LSC_loss 0.33, Spatial_loss 1.44, Flat_loss 0.24, Train_acc 93.01, Test_acc 42.67
2022-05-24 23:30:39,436 [podnet.py] => Task 5, Epoch 88/160 (LR 0.04218) => LSC_loss 0.33, Spatial_loss 1.45, Flat_loss 0.24, Train_acc 92.74, Test_acc 42.57
2022-05-24 23:30:45,846 [podnet.py] => Task 5, Epoch 89/160 (LR 0.04121) => LSC_loss 0.33, Spatial_loss 1.44, Flat_loss 0.24, Train_acc 93.24, Test_acc 43.88
2022-05-24 23:30:52,102 [podnet.py] => Task 5, Epoch 90/160 (LR 0.04025) => LSC_loss 0.34, Spatial_loss 1.46, Flat_loss 0.24, Train_acc 92.17, Test_acc 44.32
2022-05-24 23:30:58,832 [podnet.py] => Task 5, Epoch 91/160 (LR 0.03928) => LSC_loss 0.33, Spatial_loss 1.45, Flat_loss 0.24, Train_acc 92.63, Test_acc 41.88
2022-05-24 23:31:05,482 [podnet.py] => Task 5, Epoch 92/160 (LR 0.03833) => LSC_loss 0.32, Spatial_loss 1.42, Flat_loss 0.24, Train_acc 93.37, Test_acc 40.18
2022-05-24 23:31:11,821 [podnet.py] => Task 5, Epoch 93/160 (LR 0.03738) => LSC_loss 0.31, Spatial_loss 1.40, Flat_loss 0.23, Train_acc 93.63, Test_acc 43.17
2022-05-24 23:31:18,754 [podnet.py] => Task 5, Epoch 94/160 (LR 0.03643) => LSC_loss 0.31, Spatial_loss 1.38, Flat_loss 0.23, Train_acc 93.61, Test_acc 40.48
2022-05-24 23:31:25,156 [podnet.py] => Task 5, Epoch 95/160 (LR 0.03549) => LSC_loss 0.30, Spatial_loss 1.37, Flat_loss 0.23, Train_acc 93.54, Test_acc 40.95
2022-05-24 23:31:31,777 [podnet.py] => Task 5, Epoch 96/160 (LR 0.03455) => LSC_loss 0.31, Spatial_loss 1.42, Flat_loss 0.23, Train_acc 93.54, Test_acc 40.80
2022-05-24 23:31:38,604 [podnet.py] => Task 5, Epoch 97/160 (LR 0.03362) => LSC_loss 0.30, Spatial_loss 1.41, Flat_loss 0.23, Train_acc 94.30, Test_acc 44.67
2022-05-24 23:31:45,094 [podnet.py] => Task 5, Epoch 98/160 (LR 0.03269) => LSC_loss 0.28, Spatial_loss 1.40, Flat_loss 0.23, Train_acc 94.50, Test_acc 40.78
2022-05-24 23:31:51,539 [podnet.py] => Task 5, Epoch 99/160 (LR 0.03178) => LSC_loss 0.29, Spatial_loss 1.36, Flat_loss 0.23, Train_acc 94.34, Test_acc 44.95
2022-05-24 23:31:58,161 [podnet.py] => Task 5, Epoch 100/160 (LR 0.03087) => LSC_loss 0.29, Spatial_loss 1.36, Flat_loss 0.23, Train_acc 93.99, Test_acc 44.10
2022-05-24 23:32:04,608 [podnet.py] => Task 5, Epoch 101/160 (LR 0.02996) => LSC_loss 0.29, Spatial_loss 1.32, Flat_loss 0.23, Train_acc 94.40, Test_acc 44.05
2022-05-24 23:32:11,092 [podnet.py] => Task 5, Epoch 102/160 (LR 0.02907) => LSC_loss 0.27, Spatial_loss 1.28, Flat_loss 0.22, Train_acc 95.07, Test_acc 43.18
2022-05-24 23:32:17,387 [podnet.py] => Task 5, Epoch 103/160 (LR 0.02818) => LSC_loss 0.26, Spatial_loss 1.31, Flat_loss 0.22, Train_acc 95.24, Test_acc 44.00
2022-05-24 23:32:23,607 [podnet.py] => Task 5, Epoch 104/160 (LR 0.02730) => LSC_loss 0.25, Spatial_loss 1.29, Flat_loss 0.22, Train_acc 95.70, Test_acc 43.78
2022-05-24 23:32:30,075 [podnet.py] => Task 5, Epoch 105/160 (LR 0.02643) => LSC_loss 0.27, Spatial_loss 1.31, Flat_loss 0.22, Train_acc 95.23, Test_acc 44.13
2022-05-24 23:32:36,224 [podnet.py] => Task 5, Epoch 106/160 (LR 0.02557) => LSC_loss 0.26, Spatial_loss 1.31, Flat_loss 0.22, Train_acc 95.26, Test_acc 42.15
2022-05-24 23:32:42,501 [podnet.py] => Task 5, Epoch 107/160 (LR 0.02472) => LSC_loss 0.25, Spatial_loss 1.24, Flat_loss 0.22, Train_acc 95.17, Test_acc 45.27
2022-05-24 23:32:48,888 [podnet.py] => Task 5, Epoch 108/160 (LR 0.02388) => LSC_loss 0.25, Spatial_loss 1.28, Flat_loss 0.22, Train_acc 95.79, Test_acc 45.98
2022-05-24 23:32:55,581 [podnet.py] => Task 5, Epoch 109/160 (LR 0.02304) => LSC_loss 0.24, Spatial_loss 1.25, Flat_loss 0.21, Train_acc 95.89, Test_acc 45.65
2022-05-24 23:33:02,058 [podnet.py] => Task 5, Epoch 110/160 (LR 0.02222) => LSC_loss 0.24, Spatial_loss 1.23, Flat_loss 0.21, Train_acc 96.24, Test_acc 44.32
2022-05-24 23:33:08,313 [podnet.py] => Task 5, Epoch 111/160 (LR 0.02141) => LSC_loss 0.23, Spatial_loss 1.25, Flat_loss 0.21, Train_acc 96.29, Test_acc 45.92
2022-05-24 23:33:14,917 [podnet.py] => Task 5, Epoch 112/160 (LR 0.02061) => LSC_loss 0.24, Spatial_loss 1.26, Flat_loss 0.22, Train_acc 95.91, Test_acc 44.23
2022-05-24 23:33:21,650 [podnet.py] => Task 5, Epoch 113/160 (LR 0.01982) => LSC_loss 0.23, Spatial_loss 1.21, Flat_loss 0.21, Train_acc 96.43, Test_acc 44.45
2022-05-24 23:33:28,130 [podnet.py] => Task 5, Epoch 114/160 (LR 0.01905) => LSC_loss 0.23, Spatial_loss 1.20, Flat_loss 0.21, Train_acc 96.24, Test_acc 45.10
2022-05-24 23:33:34,721 [podnet.py] => Task 5, Epoch 115/160 (LR 0.01828) => LSC_loss 0.23, Spatial_loss 1.17, Flat_loss 0.21, Train_acc 96.09, Test_acc 43.48
2022-05-24 23:33:41,216 [podnet.py] => Task 5, Epoch 116/160 (LR 0.01753) => LSC_loss 0.21, Spatial_loss 1.16, Flat_loss 0.21, Train_acc 96.90, Test_acc 46.20
2022-05-24 23:33:47,661 [podnet.py] => Task 5, Epoch 117/160 (LR 0.01679) => LSC_loss 0.22, Spatial_loss 1.18, Flat_loss 0.20, Train_acc 96.76, Test_acc 45.73
2022-05-24 23:33:54,476 [podnet.py] => Task 5, Epoch 118/160 (LR 0.01606) => LSC_loss 0.21, Spatial_loss 1.17, Flat_loss 0.20, Train_acc 97.10, Test_acc 46.23
2022-05-24 23:34:00,801 [podnet.py] => Task 5, Epoch 119/160 (LR 0.01535) => LSC_loss 0.21, Spatial_loss 1.16, Flat_loss 0.20, Train_acc 96.93, Test_acc 45.17
2022-05-24 23:34:07,274 [podnet.py] => Task 5, Epoch 120/160 (LR 0.01464) => LSC_loss 0.21, Spatial_loss 1.16, Flat_loss 0.20, Train_acc 96.81, Test_acc 44.42
2022-05-24 23:34:13,372 [podnet.py] => Task 5, Epoch 121/160 (LR 0.01396) => LSC_loss 0.21, Spatial_loss 1.17, Flat_loss 0.20, Train_acc 96.91, Test_acc 46.17
2022-05-24 23:34:19,638 [podnet.py] => Task 5, Epoch 122/160 (LR 0.01328) => LSC_loss 0.21, Spatial_loss 1.14, Flat_loss 0.20, Train_acc 97.10, Test_acc 47.22
2022-05-24 23:34:26,146 [podnet.py] => Task 5, Epoch 123/160 (LR 0.01262) => LSC_loss 0.20, Spatial_loss 1.14, Flat_loss 0.20, Train_acc 97.60, Test_acc 46.60
2022-05-24 23:34:32,297 [podnet.py] => Task 5, Epoch 124/160 (LR 0.01198) => LSC_loss 0.20, Spatial_loss 1.11, Flat_loss 0.20, Train_acc 97.47, Test_acc 46.18
2022-05-24 23:34:38,551 [podnet.py] => Task 5, Epoch 125/160 (LR 0.01135) => LSC_loss 0.20, Spatial_loss 1.11, Flat_loss 0.20, Train_acc 97.46, Test_acc 46.75
2022-05-24 23:34:44,669 [podnet.py] => Task 5, Epoch 126/160 (LR 0.01073) => LSC_loss 0.20, Spatial_loss 1.10, Flat_loss 0.19, Train_acc 97.46, Test_acc 46.40
2022-05-24 23:34:51,302 [podnet.py] => Task 5, Epoch 127/160 (LR 0.01013) => LSC_loss 0.19, Spatial_loss 1.08, Flat_loss 0.20, Train_acc 97.63, Test_acc 46.50
2022-05-24 23:34:57,826 [podnet.py] => Task 5, Epoch 128/160 (LR 0.00955) => LSC_loss 0.20, Spatial_loss 1.08, Flat_loss 0.20, Train_acc 97.31, Test_acc 45.17
2022-05-24 23:35:04,101 [podnet.py] => Task 5, Epoch 129/160 (LR 0.00898) => LSC_loss 0.18, Spatial_loss 1.06, Flat_loss 0.19, Train_acc 98.09, Test_acc 47.43
2022-05-24 23:35:10,524 [podnet.py] => Task 5, Epoch 130/160 (LR 0.00843) => LSC_loss 0.19, Spatial_loss 1.09, Flat_loss 0.19, Train_acc 97.77, Test_acc 46.97
2022-05-24 23:35:17,134 [podnet.py] => Task 5, Epoch 131/160 (LR 0.00789) => LSC_loss 0.18, Spatial_loss 1.05, Flat_loss 0.19, Train_acc 97.96, Test_acc 46.07
2022-05-24 23:35:23,432 [podnet.py] => Task 5, Epoch 132/160 (LR 0.00737) => LSC_loss 0.19, Spatial_loss 1.06, Flat_loss 0.19, Train_acc 97.73, Test_acc 45.77
2022-05-24 23:35:29,600 [podnet.py] => Task 5, Epoch 133/160 (LR 0.00686) => LSC_loss 0.18, Spatial_loss 1.06, Flat_loss 0.19, Train_acc 97.93, Test_acc 47.02
2022-05-24 23:35:35,635 [podnet.py] => Task 5, Epoch 134/160 (LR 0.00638) => LSC_loss 0.18, Spatial_loss 1.03, Flat_loss 0.19, Train_acc 98.01, Test_acc 46.60
2022-05-24 23:35:41,833 [podnet.py] => Task 5, Epoch 135/160 (LR 0.00590) => LSC_loss 0.18, Spatial_loss 1.05, Flat_loss 0.19, Train_acc 97.87, Test_acc 47.18
2022-05-24 23:35:48,116 [podnet.py] => Task 5, Epoch 136/160 (LR 0.00545) => LSC_loss 0.18, Spatial_loss 1.02, Flat_loss 0.19, Train_acc 98.29, Test_acc 46.27
2022-05-24 23:35:54,351 [podnet.py] => Task 5, Epoch 137/160 (LR 0.00501) => LSC_loss 0.18, Spatial_loss 1.02, Flat_loss 0.19, Train_acc 98.14, Test_acc 45.98
2022-05-24 23:36:00,509 [podnet.py] => Task 5, Epoch 138/160 (LR 0.00459) => LSC_loss 0.18, Spatial_loss 1.03, Flat_loss 0.19, Train_acc 98.09, Test_acc 46.25
2022-05-24 23:36:06,675 [podnet.py] => Task 5, Epoch 139/160 (LR 0.00419) => LSC_loss 0.18, Spatial_loss 1.03, Flat_loss 0.19, Train_acc 98.20, Test_acc 47.00
2022-05-24 23:36:13,043 [podnet.py] => Task 5, Epoch 140/160 (LR 0.00381) => LSC_loss 0.17, Spatial_loss 1.02, Flat_loss 0.19, Train_acc 98.14, Test_acc 46.93
2022-05-24 23:36:19,512 [podnet.py] => Task 5, Epoch 141/160 (LR 0.00344) => LSC_loss 0.17, Spatial_loss 1.00, Flat_loss 0.19, Train_acc 98.16, Test_acc 47.25
2022-05-24 23:36:25,977 [podnet.py] => Task 5, Epoch 142/160 (LR 0.00309) => LSC_loss 0.18, Spatial_loss 1.00, Flat_loss 0.19, Train_acc 98.27, Test_acc 47.12
2022-05-24 23:36:32,466 [podnet.py] => Task 5, Epoch 143/160 (LR 0.00276) => LSC_loss 0.18, Spatial_loss 1.01, Flat_loss 0.19, Train_acc 98.06, Test_acc 47.18
2022-05-24 23:36:39,015 [podnet.py] => Task 5, Epoch 144/160 (LR 0.00245) => LSC_loss 0.17, Spatial_loss 0.99, Flat_loss 0.19, Train_acc 98.43, Test_acc 46.67
2022-05-24 23:36:45,467 [podnet.py] => Task 5, Epoch 145/160 (LR 0.00215) => LSC_loss 0.17, Spatial_loss 0.95, Flat_loss 0.18, Train_acc 98.30, Test_acc 47.50
2022-05-24 23:36:51,824 [podnet.py] => Task 5, Epoch 146/160 (LR 0.00188) => LSC_loss 0.18, Spatial_loss 0.99, Flat_loss 0.19, Train_acc 98.36, Test_acc 47.05
2022-05-24 23:36:58,203 [podnet.py] => Task 5, Epoch 147/160 (LR 0.00162) => LSC_loss 0.17, Spatial_loss 0.97, Flat_loss 0.18, Train_acc 98.39, Test_acc 47.53
2022-05-24 23:37:04,599 [podnet.py] => Task 5, Epoch 148/160 (LR 0.00138) => LSC_loss 0.17, Spatial_loss 0.96, Flat_loss 0.18, Train_acc 98.30, Test_acc 47.50
2022-05-24 23:37:10,771 [podnet.py] => Task 5, Epoch 149/160 (LR 0.00116) => LSC_loss 0.17, Spatial_loss 0.96, Flat_loss 0.18, Train_acc 98.34, Test_acc 47.38
2022-05-24 23:37:16,946 [podnet.py] => Task 5, Epoch 150/160 (LR 0.00096) => LSC_loss 0.16, Spatial_loss 0.98, Flat_loss 0.18, Train_acc 98.53, Test_acc 47.43
2022-05-24 23:37:23,368 [podnet.py] => Task 5, Epoch 151/160 (LR 0.00078) => LSC_loss 0.17, Spatial_loss 0.96, Flat_loss 0.18, Train_acc 98.44, Test_acc 47.50
2022-05-24 23:37:29,587 [podnet.py] => Task 5, Epoch 152/160 (LR 0.00062) => LSC_loss 0.17, Spatial_loss 0.98, Flat_loss 0.18, Train_acc 98.13, Test_acc 46.95
2022-05-24 23:37:35,872 [podnet.py] => Task 5, Epoch 153/160 (LR 0.00047) => LSC_loss 0.17, Spatial_loss 0.96, Flat_loss 0.18, Train_acc 98.24, Test_acc 47.43
2022-05-24 23:37:42,300 [podnet.py] => Task 5, Epoch 154/160 (LR 0.00035) => LSC_loss 0.17, Spatial_loss 0.95, Flat_loss 0.18, Train_acc 98.39, Test_acc 47.48
2022-05-24 23:37:48,787 [podnet.py] => Task 5, Epoch 155/160 (LR 0.00024) => LSC_loss 0.17, Spatial_loss 0.95, Flat_loss 0.18, Train_acc 98.64, Test_acc 47.48
2022-05-24 23:37:55,144 [podnet.py] => Task 5, Epoch 156/160 (LR 0.00015) => LSC_loss 0.17, Spatial_loss 0.96, Flat_loss 0.18, Train_acc 98.41, Test_acc 47.35
2022-05-24 23:38:01,286 [podnet.py] => Task 5, Epoch 157/160 (LR 0.00009) => LSC_loss 0.17, Spatial_loss 0.94, Flat_loss 0.18, Train_acc 98.44, Test_acc 47.47
2022-05-24 23:38:07,415 [podnet.py] => Task 5, Epoch 158/160 (LR 0.00004) => LSC_loss 0.17, Spatial_loss 0.93, Flat_loss 0.18, Train_acc 98.50, Test_acc 47.43
2022-05-24 23:38:13,883 [podnet.py] => Task 5, Epoch 159/160 (LR 0.00001) => LSC_loss 0.17, Spatial_loss 0.97, Flat_loss 0.18, Train_acc 98.63, Test_acc 47.40
2022-05-24 23:38:20,266 [podnet.py] => Task 5, Epoch 160/160 (LR 0.00000) => LSC_loss 0.17, Spatial_loss 0.95, Flat_loss 0.18, Train_acc 98.59, Test_acc 47.30
2022-05-24 23:38:20,267 [podnet.py] => Finetune the network (classifier part) with the undersampled dataset!
2022-05-24 23:38:20,267 [base.py] => Reducing exemplars...(40 per classes)
2022-05-24 23:38:31,693 [base.py] => Constructing exemplars...(40 per classes)
2022-05-24 23:38:38,080 [podnet.py] => The size of finetune dataset: 2400
2022-05-24 23:38:40,881 [podnet.py] => Task 5, Epoch 1/20 (LR 0.00497) => LSC_loss 0.18, Spatial_loss 1.01, Flat_loss 0.12, Train_acc 97.62, Test_acc 49.83
2022-05-24 23:38:43,824 [podnet.py] => Task 5, Epoch 2/20 (LR 0.00488) => LSC_loss 0.14, Spatial_loss 0.97, Flat_loss 0.11, Train_acc 98.42, Test_acc 48.75
2022-05-24 23:38:46,601 [podnet.py] => Task 5, Epoch 3/20 (LR 0.00473) => LSC_loss 0.13, Spatial_loss 0.97, Flat_loss 0.10, Train_acc 98.92, Test_acc 48.73
2022-05-24 23:38:49,341 [podnet.py] => Task 5, Epoch 4/20 (LR 0.00452) => LSC_loss 0.13, Spatial_loss 0.98, Flat_loss 0.10, Train_acc 98.92, Test_acc 49.37
2022-05-24 23:38:52,568 [podnet.py] => Task 5, Epoch 5/20 (LR 0.00427) => LSC_loss 0.13, Spatial_loss 0.98, Flat_loss 0.11, Train_acc 98.96, Test_acc 49.30
2022-05-24 23:38:55,828 [podnet.py] => Task 5, Epoch 6/20 (LR 0.00397) => LSC_loss 0.13, Spatial_loss 0.97, Flat_loss 0.10, Train_acc 99.08, Test_acc 48.90
2022-05-24 23:38:58,922 [podnet.py] => Task 5, Epoch 7/20 (LR 0.00363) => LSC_loss 0.13, Spatial_loss 0.99, Flat_loss 0.10, Train_acc 98.88, Test_acc 49.28
2022-05-24 23:39:01,987 [podnet.py] => Task 5, Epoch 8/20 (LR 0.00327) => LSC_loss 0.13, Spatial_loss 0.97, Flat_loss 0.10, Train_acc 98.79, Test_acc 49.78
2022-05-24 23:39:05,330 [podnet.py] => Task 5, Epoch 9/20 (LR 0.00289) => LSC_loss 0.12, Spatial_loss 0.95, Flat_loss 0.10, Train_acc 98.75, Test_acc 49.55
2022-05-24 23:39:08,442 [podnet.py] => Task 5, Epoch 10/20 (LR 0.00250) => LSC_loss 0.12, Spatial_loss 0.94, Flat_loss 0.10, Train_acc 99.08, Test_acc 49.40
2022-05-24 23:39:11,522 [podnet.py] => Task 5, Epoch 11/20 (LR 0.00211) => LSC_loss 0.12, Spatial_loss 0.94, Flat_loss 0.10, Train_acc 99.04, Test_acc 49.68
2022-05-24 23:39:14,688 [podnet.py] => Task 5, Epoch 12/20 (LR 0.00173) => LSC_loss 0.13, Spatial_loss 0.96, Flat_loss 0.10, Train_acc 98.83, Test_acc 49.38
2022-05-24 23:39:17,705 [podnet.py] => Task 5, Epoch 13/20 (LR 0.00137) => LSC_loss 0.12, Spatial_loss 0.92, Flat_loss 0.10, Train_acc 99.04, Test_acc 49.60
2022-05-24 23:39:20,633 [podnet.py] => Task 5, Epoch 14/20 (LR 0.00103) => LSC_loss 0.11, Spatial_loss 0.95, Flat_loss 0.10, Train_acc 99.38, Test_acc 49.62
2022-05-24 23:39:23,415 [podnet.py] => Task 5, Epoch 15/20 (LR 0.00073) => LSC_loss 0.12, Spatial_loss 0.94, Flat_loss 0.10, Train_acc 99.08, Test_acc 49.72
2022-05-24 23:39:26,365 [podnet.py] => Task 5, Epoch 16/20 (LR 0.00048) => LSC_loss 0.12, Spatial_loss 0.89, Flat_loss 0.10, Train_acc 99.21, Test_acc 49.67
2022-05-24 23:39:29,438 [podnet.py] => Task 5, Epoch 17/20 (LR 0.00027) => LSC_loss 0.11, Spatial_loss 0.91, Flat_loss 0.10, Train_acc 99.12, Test_acc 49.48
2022-05-24 23:39:32,466 [podnet.py] => Task 5, Epoch 18/20 (LR 0.00012) => LSC_loss 0.11, Spatial_loss 0.92, Flat_loss 0.10, Train_acc 98.96, Test_acc 49.62
2022-05-24 23:39:35,559 [podnet.py] => Task 5, Epoch 19/20 (LR 0.00003) => LSC_loss 0.11, Spatial_loss 0.88, Flat_loss 0.10, Train_acc 99.33, Test_acc 49.68
2022-05-24 23:39:38,767 [podnet.py] => Task 5, Epoch 20/20 (LR 0.00000) => LSC_loss 0.12, Spatial_loss 0.91, Flat_loss 0.10, Train_acc 99.00, Test_acc 49.75
2022-05-24 23:39:38,768 [base.py] => Reducing exemplars...(33 per classes)
2022-05-24 23:39:50,151 [base.py] => Constructing exemplars...(33 per classes)
2022-05-24 23:39:58,213 [podnet.py] => Exemplar size: 1980
2022-05-24 23:39:58,213 [trainer.py] => CNN: {'total': 49.75, '00-09': 63.8, '10-19': 27.3, '20-29': 45.0, '30-39': 40.5, '40-49': 57.2, '50-59': 64.7, 'old': 46.76, 'new': 64.7}
2022-05-24 23:39:58,213 [trainer.py] => NME: {'total': 48.87, '00-09': 68.7, '10-19': 26.2, '20-29': 45.6, '30-39': 39.6, '40-49': 54.5, '50-59': 58.6, 'old': 46.92, 'new': 58.6}
2022-05-24 23:39:58,214 [trainer.py] => CNN top1 curve: [90.7, 72.95, 65.47, 57.8, 53.9, 49.75]
2022-05-24 23:39:58,214 [trainer.py] => CNN top5 curve: [99.2, 93.95, 90.1, 85.15, 81.78, 78.42]
2022-05-24 23:39:58,214 [trainer.py] => NME top1 curve: [90.8, 72.05, 63.37, 55.7, 52.92, 48.87]
2022-05-24 23:39:58,214 [trainer.py] => NME top5 curve: [99.3, 92.8, 88.93, 83.38, 81.2, 77.87]

2022-05-24 23:39:58,214 [trainer.py] => All params: 504657
2022-05-24 23:39:58,215 [trainer.py] => Trainable params: 504657
2022-05-24 23:39:58,215 [podnet.py] => Learning on 60-70
2022-05-24 23:39:58,275 [podnet.py] => Adaptive factor: 2.6457513110645907
2022-05-24 23:40:04,846 [podnet.py] => Task 6, Epoch 1/160 (LR 0.09999) => LSC_loss 2.74, Spatial_loss 3.01, Flat_loss 0.99, Train_acc 44.56, Test_acc 27.69
2022-05-24 23:40:11,658 [podnet.py] => Task 6, Epoch 2/160 (LR 0.09996) => LSC_loss 1.55, Spatial_loss 2.45, Flat_loss 0.49, Train_acc 59.73, Test_acc 29.03
2022-05-24 23:40:18,180 [podnet.py] => Task 6, Epoch 3/160 (LR 0.09991) => LSC_loss 1.33, Spatial_loss 2.20, Flat_loss 0.38, Train_acc 64.58, Test_acc 29.26
2022-05-24 23:40:24,589 [podnet.py] => Task 6, Epoch 4/160 (LR 0.09985) => LSC_loss 1.22, Spatial_loss 2.15, Flat_loss 0.35, Train_acc 66.76, Test_acc 33.11
2022-05-24 23:40:30,960 [podnet.py] => Task 6, Epoch 5/160 (LR 0.09976) => LSC_loss 1.17, Spatial_loss 2.07, Flat_loss 0.33, Train_acc 68.27, Test_acc 30.59
2022-05-24 23:40:37,465 [podnet.py] => Task 6, Epoch 6/160 (LR 0.09965) => LSC_loss 1.10, Spatial_loss 2.06, Flat_loss 0.32, Train_acc 71.10, Test_acc 36.94
2022-05-24 23:40:43,838 [podnet.py] => Task 6, Epoch 7/160 (LR 0.09953) => LSC_loss 1.06, Spatial_loss 2.04, Flat_loss 0.30, Train_acc 72.22, Test_acc 34.21
2022-05-24 23:40:50,093 [podnet.py] => Task 6, Epoch 8/160 (LR 0.09938) => LSC_loss 1.04, Spatial_loss 2.03, Flat_loss 0.31, Train_acc 72.03, Test_acc 33.46
2022-05-24 23:40:56,490 [podnet.py] => Task 6, Epoch 9/160 (LR 0.09922) => LSC_loss 0.97, Spatial_loss 1.97, Flat_loss 0.30, Train_acc 74.68, Test_acc 37.73
2022-05-24 23:41:02,982 [podnet.py] => Task 6, Epoch 10/160 (LR 0.09904) => LSC_loss 0.96, Spatial_loss 2.02, Flat_loss 0.30, Train_acc 74.46, Test_acc 38.39
2022-05-24 23:41:09,467 [podnet.py] => Task 6, Epoch 11/160 (LR 0.09884) => LSC_loss 0.96, Spatial_loss 1.98, Flat_loss 0.30, Train_acc 74.43, Test_acc 39.41
2022-05-24 23:41:15,642 [podnet.py] => Task 6, Epoch 12/160 (LR 0.09862) => LSC_loss 0.89, Spatial_loss 1.94, Flat_loss 0.30, Train_acc 76.69, Test_acc 37.79
2022-05-24 23:41:22,447 [podnet.py] => Task 6, Epoch 13/160 (LR 0.09838) => LSC_loss 0.88, Spatial_loss 1.99, Flat_loss 0.30, Train_acc 77.21, Test_acc 34.10
2022-05-24 23:41:29,323 [podnet.py] => Task 6, Epoch 14/160 (LR 0.09812) => LSC_loss 0.87, Spatial_loss 1.95, Flat_loss 0.30, Train_acc 77.49, Test_acc 36.13
2022-05-24 23:41:35,752 [podnet.py] => Task 6, Epoch 15/160 (LR 0.09785) => LSC_loss 0.84, Spatial_loss 1.91, Flat_loss 0.29, Train_acc 78.40, Test_acc 37.11
2022-05-24 23:41:42,570 [podnet.py] => Task 6, Epoch 16/160 (LR 0.09755) => LSC_loss 0.81, Spatial_loss 1.87, Flat_loss 0.29, Train_acc 78.81, Test_acc 33.36
2022-05-24 23:41:48,888 [podnet.py] => Task 6, Epoch 17/160 (LR 0.09724) => LSC_loss 0.82, Spatial_loss 1.94, Flat_loss 0.29, Train_acc 78.80, Test_acc 33.87
2022-05-24 23:41:55,178 [podnet.py] => Task 6, Epoch 18/160 (LR 0.09691) => LSC_loss 0.80, Spatial_loss 1.89, Flat_loss 0.29, Train_acc 80.01, Test_acc 33.00
2022-05-24 23:42:01,683 [podnet.py] => Task 6, Epoch 19/160 (LR 0.09656) => LSC_loss 0.78, Spatial_loss 1.92, Flat_loss 0.29, Train_acc 79.61, Test_acc 38.14
2022-05-24 23:42:07,981 [podnet.py] => Task 6, Epoch 20/160 (LR 0.09619) => LSC_loss 0.77, Spatial_loss 1.85, Flat_loss 0.29, Train_acc 79.57, Test_acc 31.99
2022-05-24 23:42:14,549 [podnet.py] => Task 6, Epoch 21/160 (LR 0.09581) => LSC_loss 0.76, Spatial_loss 1.91, Flat_loss 0.29, Train_acc 80.42, Test_acc 35.86
2022-05-24 23:42:20,663 [podnet.py] => Task 6, Epoch 22/160 (LR 0.09541) => LSC_loss 0.77, Spatial_loss 1.89, Flat_loss 0.29, Train_acc 80.01, Test_acc 36.77
2022-05-24 23:42:27,124 [podnet.py] => Task 6, Epoch 23/160 (LR 0.09499) => LSC_loss 0.72, Spatial_loss 1.88, Flat_loss 0.29, Train_acc 81.38, Test_acc 37.21
2022-05-24 23:42:33,627 [podnet.py] => Task 6, Epoch 24/160 (LR 0.09455) => LSC_loss 0.72, Spatial_loss 1.85, Flat_loss 0.29, Train_acc 81.45, Test_acc 34.54
2022-05-24 23:42:39,918 [podnet.py] => Task 6, Epoch 25/160 (LR 0.09410) => LSC_loss 0.71, Spatial_loss 1.88, Flat_loss 0.29, Train_acc 81.05, Test_acc 35.43
2022-05-24 23:42:46,709 [podnet.py] => Task 6, Epoch 26/160 (LR 0.09362) => LSC_loss 0.71, Spatial_loss 1.85, Flat_loss 0.29, Train_acc 81.88, Test_acc 35.91
2022-05-24 23:42:53,505 [podnet.py] => Task 6, Epoch 27/160 (LR 0.09314) => LSC_loss 0.68, Spatial_loss 1.87, Flat_loss 0.29, Train_acc 82.61, Test_acc 36.70
2022-05-24 23:42:59,962 [podnet.py] => Task 6, Epoch 28/160 (LR 0.09263) => LSC_loss 0.68, Spatial_loss 1.88, Flat_loss 0.29, Train_acc 82.77, Test_acc 35.97
2022-05-24 23:43:06,672 [podnet.py] => Task 6, Epoch 29/160 (LR 0.09211) => LSC_loss 0.69, Spatial_loss 1.84, Flat_loss 0.29, Train_acc 81.99, Test_acc 36.20
2022-05-24 23:43:12,947 [podnet.py] => Task 6, Epoch 30/160 (LR 0.09157) => LSC_loss 0.69, Spatial_loss 1.85, Flat_loss 0.29, Train_acc 82.08, Test_acc 36.61
2022-05-24 23:43:19,056 [podnet.py] => Task 6, Epoch 31/160 (LR 0.09102) => LSC_loss 0.68, Spatial_loss 1.89, Flat_loss 0.29, Train_acc 81.92, Test_acc 37.50
2022-05-24 23:43:25,445 [podnet.py] => Task 6, Epoch 32/160 (LR 0.09045) => LSC_loss 0.68, Spatial_loss 1.84, Flat_loss 0.29, Train_acc 82.71, Test_acc 33.76
2022-05-24 23:43:31,582 [podnet.py] => Task 6, Epoch 33/160 (LR 0.08987) => LSC_loss 0.64, Spatial_loss 1.84, Flat_loss 0.29, Train_acc 82.97, Test_acc 37.04
2022-05-24 23:43:38,045 [podnet.py] => Task 6, Epoch 34/160 (LR 0.08927) => LSC_loss 0.65, Spatial_loss 1.82, Flat_loss 0.29, Train_acc 83.45, Test_acc 39.07
2022-05-24 23:43:44,497 [podnet.py] => Task 6, Epoch 35/160 (LR 0.08865) => LSC_loss 0.63, Spatial_loss 1.80, Flat_loss 0.29, Train_acc 84.34, Test_acc 36.99
2022-05-24 23:43:51,169 [podnet.py] => Task 6, Epoch 36/160 (LR 0.08802) => LSC_loss 0.60, Spatial_loss 1.78, Flat_loss 0.28, Train_acc 84.60, Test_acc 38.29
2022-05-24 23:43:57,658 [podnet.py] => Task 6, Epoch 37/160 (LR 0.08738) => LSC_loss 0.61, Spatial_loss 1.83, Flat_loss 0.29, Train_acc 84.37, Test_acc 37.29
2022-05-24 23:44:03,946 [podnet.py] => Task 6, Epoch 38/160 (LR 0.08672) => LSC_loss 0.60, Spatial_loss 1.80, Flat_loss 0.29, Train_acc 84.94, Test_acc 39.76
2022-05-24 23:44:10,577 [podnet.py] => Task 6, Epoch 39/160 (LR 0.08604) => LSC_loss 0.58, Spatial_loss 1.81, Flat_loss 0.28, Train_acc 85.32, Test_acc 34.54
2022-05-24 23:44:17,475 [podnet.py] => Task 6, Epoch 40/160 (LR 0.08536) => LSC_loss 0.61, Spatial_loss 1.91, Flat_loss 0.29, Train_acc 84.83, Test_acc 35.53
2022-05-24 23:44:23,891 [podnet.py] => Task 6, Epoch 41/160 (LR 0.08465) => LSC_loss 0.59, Spatial_loss 1.75, Flat_loss 0.28, Train_acc 85.07, Test_acc 36.53
2022-05-24 23:44:30,545 [podnet.py] => Task 6, Epoch 42/160 (LR 0.08394) => LSC_loss 0.58, Spatial_loss 1.77, Flat_loss 0.29, Train_acc 85.36, Test_acc 38.03
2022-05-24 23:44:36,744 [podnet.py] => Task 6, Epoch 43/160 (LR 0.08321) => LSC_loss 0.56, Spatial_loss 1.80, Flat_loss 0.29, Train_acc 85.83, Test_acc 39.10
2022-05-24 23:44:43,041 [podnet.py] => Task 6, Epoch 44/160 (LR 0.08247) => LSC_loss 0.55, Spatial_loss 1.74, Flat_loss 0.28, Train_acc 86.45, Test_acc 32.93
2022-05-24 23:44:49,313 [podnet.py] => Task 6, Epoch 45/160 (LR 0.08172) => LSC_loss 0.56, Spatial_loss 1.77, Flat_loss 0.28, Train_acc 85.59, Test_acc 39.11
2022-05-24 23:44:55,681 [podnet.py] => Task 6, Epoch 46/160 (LR 0.08095) => LSC_loss 0.54, Spatial_loss 1.79, Flat_loss 0.28, Train_acc 86.55, Test_acc 37.10
2022-05-24 23:45:01,915 [podnet.py] => Task 6, Epoch 47/160 (LR 0.08018) => LSC_loss 0.53, Spatial_loss 1.79, Flat_loss 0.28, Train_acc 86.73, Test_acc 37.50
2022-05-24 23:45:08,010 [podnet.py] => Task 6, Epoch 48/160 (LR 0.07939) => LSC_loss 0.57, Spatial_loss 1.80, Flat_loss 0.29, Train_acc 85.39, Test_acc 35.87
2022-05-24 23:45:14,776 [podnet.py] => Task 6, Epoch 49/160 (LR 0.07859) => LSC_loss 0.57, Spatial_loss 1.82, Flat_loss 0.29, Train_acc 85.43, Test_acc 37.01
2022-05-24 23:45:21,476 [podnet.py] => Task 6, Epoch 50/160 (LR 0.07778) => LSC_loss 0.54, Spatial_loss 1.75, Flat_loss 0.28, Train_acc 86.32, Test_acc 37.91
2022-05-24 23:45:28,197 [podnet.py] => Task 6, Epoch 51/160 (LR 0.07696) => LSC_loss 0.52, Spatial_loss 1.72, Flat_loss 0.28, Train_acc 87.09, Test_acc 39.94
2022-05-24 23:45:34,639 [podnet.py] => Task 6, Epoch 52/160 (LR 0.07612) => LSC_loss 0.53, Spatial_loss 1.73, Flat_loss 0.28, Train_acc 86.81, Test_acc 37.14
2022-05-24 23:45:41,120 [podnet.py] => Task 6, Epoch 53/160 (LR 0.07528) => LSC_loss 0.49, Spatial_loss 1.75, Flat_loss 0.28, Train_acc 88.07, Test_acc 36.10
2022-05-24 23:45:47,510 [podnet.py] => Task 6, Epoch 54/160 (LR 0.07443) => LSC_loss 0.50, Spatial_loss 1.75, Flat_loss 0.28, Train_acc 87.38, Test_acc 37.26
2022-05-24 23:45:54,274 [podnet.py] => Task 6, Epoch 55/160 (LR 0.07357) => LSC_loss 0.52, Spatial_loss 1.71, Flat_loss 0.28, Train_acc 87.18, Test_acc 34.39
2022-05-24 23:46:00,685 [podnet.py] => Task 6, Epoch 56/160 (LR 0.07270) => LSC_loss 0.51, Spatial_loss 1.72, Flat_loss 0.28, Train_acc 87.58, Test_acc 36.59
2022-05-24 23:46:07,177 [podnet.py] => Task 6, Epoch 57/160 (LR 0.07182) => LSC_loss 0.47, Spatial_loss 1.72, Flat_loss 0.28, Train_acc 88.50, Test_acc 39.01
2022-05-24 23:46:13,823 [podnet.py] => Task 6, Epoch 58/160 (LR 0.07093) => LSC_loss 0.48, Spatial_loss 1.69, Flat_loss 0.27, Train_acc 88.70, Test_acc 35.51
2022-05-24 23:46:20,563 [podnet.py] => Task 6, Epoch 59/160 (LR 0.07004) => LSC_loss 0.49, Spatial_loss 1.70, Flat_loss 0.28, Train_acc 87.91, Test_acc 39.36
2022-05-24 23:46:27,169 [podnet.py] => Task 6, Epoch 60/160 (LR 0.06913) => LSC_loss 0.47, Spatial_loss 1.72, Flat_loss 0.28, Train_acc 88.65, Test_acc 38.40
2022-05-24 23:46:33,664 [podnet.py] => Task 6, Epoch 61/160 (LR 0.06822) => LSC_loss 0.47, Spatial_loss 1.71, Flat_loss 0.28, Train_acc 88.58, Test_acc 37.59
2022-05-24 23:46:39,957 [podnet.py] => Task 6, Epoch 62/160 (LR 0.06731) => LSC_loss 0.49, Spatial_loss 1.68, Flat_loss 0.27, Train_acc 87.78, Test_acc 34.30
2022-05-24 23:46:46,555 [podnet.py] => Task 6, Epoch 63/160 (LR 0.06638) => LSC_loss 0.46, Spatial_loss 1.68, Flat_loss 0.27, Train_acc 88.70, Test_acc 40.50
2022-05-24 23:46:52,868 [podnet.py] => Task 6, Epoch 64/160 (LR 0.06545) => LSC_loss 0.43, Spatial_loss 1.62, Flat_loss 0.27, Train_acc 89.63, Test_acc 38.29
2022-05-24 23:46:59,225 [podnet.py] => Task 6, Epoch 65/160 (LR 0.06451) => LSC_loss 0.43, Spatial_loss 1.61, Flat_loss 0.27, Train_acc 89.97, Test_acc 36.36
2022-05-24 23:47:05,469 [podnet.py] => Task 6, Epoch 66/160 (LR 0.06357) => LSC_loss 0.45, Spatial_loss 1.68, Flat_loss 0.27, Train_acc 89.44, Test_acc 39.09
2022-05-24 23:47:12,033 [podnet.py] => Task 6, Epoch 67/160 (LR 0.06262) => LSC_loss 0.47, Spatial_loss 1.69, Flat_loss 0.28, Train_acc 88.62, Test_acc 34.89
2022-05-24 23:47:18,547 [podnet.py] => Task 6, Epoch 68/160 (LR 0.06167) => LSC_loss 0.47, Spatial_loss 1.70, Flat_loss 0.28, Train_acc 88.81, Test_acc 36.77
2022-05-24 23:47:24,864 [podnet.py] => Task 6, Epoch 69/160 (LR 0.06072) => LSC_loss 0.43, Spatial_loss 1.68, Flat_loss 0.28, Train_acc 89.61, Test_acc 39.91
2022-05-24 23:47:31,392 [podnet.py] => Task 6, Epoch 70/160 (LR 0.05975) => LSC_loss 0.42, Spatial_loss 1.63, Flat_loss 0.27, Train_acc 90.11, Test_acc 39.33
2022-05-24 23:47:38,129 [podnet.py] => Task 6, Epoch 71/160 (LR 0.05879) => LSC_loss 0.45, Spatial_loss 1.69, Flat_loss 0.28, Train_acc 88.87, Test_acc 34.37
2022-05-24 23:47:44,796 [podnet.py] => Task 6, Epoch 72/160 (LR 0.05782) => LSC_loss 0.44, Spatial_loss 1.65, Flat_loss 0.27, Train_acc 89.56, Test_acc 38.49
2022-05-24 23:47:51,318 [podnet.py] => Task 6, Epoch 73/160 (LR 0.05685) => LSC_loss 0.41, Spatial_loss 1.58, Flat_loss 0.26, Train_acc 90.76, Test_acc 39.76
2022-05-24 23:47:57,768 [podnet.py] => Task 6, Epoch 74/160 (LR 0.05588) => LSC_loss 0.40, Spatial_loss 1.61, Flat_loss 0.27, Train_acc 90.85, Test_acc 39.97
2022-05-24 23:48:03,787 [podnet.py] => Task 6, Epoch 75/160 (LR 0.05490) => LSC_loss 0.42, Spatial_loss 1.62, Flat_loss 0.27, Train_acc 90.29, Test_acc 39.04
2022-05-24 23:48:09,979 [podnet.py] => Task 6, Epoch 76/160 (LR 0.05392) => LSC_loss 0.39, Spatial_loss 1.57, Flat_loss 0.26, Train_acc 90.83, Test_acc 40.29
2022-05-24 23:48:16,173 [podnet.py] => Task 6, Epoch 77/160 (LR 0.05294) => LSC_loss 0.37, Spatial_loss 1.54, Flat_loss 0.26, Train_acc 92.01, Test_acc 43.09
2022-05-24 23:48:22,682 [podnet.py] => Task 6, Epoch 78/160 (LR 0.05196) => LSC_loss 0.37, Spatial_loss 1.55, Flat_loss 0.26, Train_acc 91.83, Test_acc 37.73
2022-05-24 23:48:29,078 [podnet.py] => Task 6, Epoch 79/160 (LR 0.05098) => LSC_loss 0.36, Spatial_loss 1.53, Flat_loss 0.26, Train_acc 92.12, Test_acc 37.53
2022-05-24 23:48:36,022 [podnet.py] => Task 6, Epoch 80/160 (LR 0.05000) => LSC_loss 0.40, Spatial_loss 1.56, Flat_loss 0.27, Train_acc 90.76, Test_acc 41.04
2022-05-24 23:48:42,641 [podnet.py] => Task 6, Epoch 81/160 (LR 0.04902) => LSC_loss 0.35, Spatial_loss 1.54, Flat_loss 0.26, Train_acc 92.56, Test_acc 39.21
2022-05-24 23:48:49,075 [podnet.py] => Task 6, Epoch 82/160 (LR 0.04804) => LSC_loss 0.34, Spatial_loss 1.49, Flat_loss 0.26, Train_acc 92.72, Test_acc 41.20
2022-05-24 23:48:55,803 [podnet.py] => Task 6, Epoch 83/160 (LR 0.04706) => LSC_loss 0.35, Spatial_loss 1.49, Flat_loss 0.26, Train_acc 92.26, Test_acc 39.27
2022-05-24 23:49:02,316 [podnet.py] => Task 6, Epoch 84/160 (LR 0.04608) => LSC_loss 0.34, Spatial_loss 1.46, Flat_loss 0.25, Train_acc 93.02, Test_acc 38.93
2022-05-24 23:49:08,765 [podnet.py] => Task 6, Epoch 85/160 (LR 0.04510) => LSC_loss 0.33, Spatial_loss 1.50, Flat_loss 0.25, Train_acc 93.22, Test_acc 41.47
2022-05-24 23:49:15,457 [podnet.py] => Task 6, Epoch 86/160 (LR 0.04412) => LSC_loss 0.35, Spatial_loss 1.46, Flat_loss 0.25, Train_acc 92.48, Test_acc 39.67
2022-05-24 23:49:21,846 [podnet.py] => Task 6, Epoch 87/160 (LR 0.04315) => LSC_loss 0.34, Spatial_loss 1.44, Flat_loss 0.25, Train_acc 92.44, Test_acc 40.83
2022-05-24 23:49:28,282 [podnet.py] => Task 6, Epoch 88/160 (LR 0.04218) => LSC_loss 0.33, Spatial_loss 1.45, Flat_loss 0.25, Train_acc 93.09, Test_acc 36.39
2022-05-24 23:49:34,502 [podnet.py] => Task 6, Epoch 89/160 (LR 0.04121) => LSC_loss 0.35, Spatial_loss 1.49, Flat_loss 0.26, Train_acc 92.38, Test_acc 40.99
2022-05-24 23:49:40,871 [podnet.py] => Task 6, Epoch 90/160 (LR 0.04025) => LSC_loss 0.33, Spatial_loss 1.47, Flat_loss 0.25, Train_acc 93.30, Test_acc 39.69
2022-05-24 23:49:47,371 [podnet.py] => Task 6, Epoch 91/160 (LR 0.03928) => LSC_loss 0.32, Spatial_loss 1.46, Flat_loss 0.24, Train_acc 93.68, Test_acc 39.59
2022-05-24 23:49:54,112 [podnet.py] => Task 6, Epoch 92/160 (LR 0.03833) => LSC_loss 0.30, Spatial_loss 1.38, Flat_loss 0.24, Train_acc 94.10, Test_acc 42.26
2022-05-24 23:50:00,438 [podnet.py] => Task 6, Epoch 93/160 (LR 0.03738) => LSC_loss 0.32, Spatial_loss 1.43, Flat_loss 0.25, Train_acc 93.34, Test_acc 40.31
2022-05-24 23:50:06,696 [podnet.py] => Task 6, Epoch 94/160 (LR 0.03643) => LSC_loss 0.31, Spatial_loss 1.37, Flat_loss 0.24, Train_acc 93.60, Test_acc 39.27
2022-05-24 23:50:12,858 [podnet.py] => Task 6, Epoch 95/160 (LR 0.03549) => LSC_loss 0.30, Spatial_loss 1.39, Flat_loss 0.24, Train_acc 94.17, Test_acc 39.30
2022-05-24 23:50:19,436 [podnet.py] => Task 6, Epoch 96/160 (LR 0.03455) => LSC_loss 0.28, Spatial_loss 1.36, Flat_loss 0.24, Train_acc 94.58, Test_acc 41.67
2022-05-24 23:50:25,721 [podnet.py] => Task 6, Epoch 97/160 (LR 0.03362) => LSC_loss 0.28, Spatial_loss 1.34, Flat_loss 0.23, Train_acc 95.09, Test_acc 42.03
2022-05-24 23:50:32,130 [podnet.py] => Task 6, Epoch 98/160 (LR 0.03269) => LSC_loss 0.28, Spatial_loss 1.36, Flat_loss 0.24, Train_acc 94.90, Test_acc 43.37
2022-05-24 23:50:39,106 [podnet.py] => Task 6, Epoch 99/160 (LR 0.03178) => LSC_loss 0.27, Spatial_loss 1.34, Flat_loss 0.23, Train_acc 95.40, Test_acc 40.51
2022-05-24 23:50:45,769 [podnet.py] => Task 6, Epoch 100/160 (LR 0.03087) => LSC_loss 0.27, Spatial_loss 1.31, Flat_loss 0.23, Train_acc 95.06, Test_acc 39.71
2022-05-24 23:50:52,589 [podnet.py] => Task 6, Epoch 101/160 (LR 0.02996) => LSC_loss 0.28, Spatial_loss 1.33, Flat_loss 0.23, Train_acc 95.19, Test_acc 41.89
2022-05-24 23:50:59,379 [podnet.py] => Task 6, Epoch 102/160 (LR 0.02907) => LSC_loss 0.27, Spatial_loss 1.34, Flat_loss 0.23, Train_acc 94.90, Test_acc 40.51
2022-05-24 23:51:05,839 [podnet.py] => Task 6, Epoch 103/160 (LR 0.02818) => LSC_loss 0.27, Spatial_loss 1.33, Flat_loss 0.23, Train_acc 95.29, Test_acc 41.31
2022-05-24 23:51:12,518 [podnet.py] => Task 6, Epoch 104/160 (LR 0.02730) => LSC_loss 0.26, Spatial_loss 1.33, Flat_loss 0.23, Train_acc 95.39, Test_acc 41.30
2022-05-24 23:51:19,226 [podnet.py] => Task 6, Epoch 105/160 (LR 0.02643) => LSC_loss 0.26, Spatial_loss 1.30, Flat_loss 0.23, Train_acc 95.70, Test_acc 41.33
2022-05-24 23:51:26,263 [podnet.py] => Task 6, Epoch 106/160 (LR 0.02557) => LSC_loss 0.24, Spatial_loss 1.28, Flat_loss 0.23, Train_acc 96.00, Test_acc 43.04
2022-05-24 23:51:32,904 [podnet.py] => Task 6, Epoch 107/160 (LR 0.02472) => LSC_loss 0.26, Spatial_loss 1.30, Flat_loss 0.23, Train_acc 95.46, Test_acc 40.87
2022-05-24 23:51:39,335 [podnet.py] => Task 6, Epoch 108/160 (LR 0.02388) => LSC_loss 0.25, Spatial_loss 1.26, Flat_loss 0.22, Train_acc 95.93, Test_acc 40.74
2022-05-24 23:51:45,965 [podnet.py] => Task 6, Epoch 109/160 (LR 0.02304) => LSC_loss 0.24, Spatial_loss 1.25, Flat_loss 0.22, Train_acc 96.15, Test_acc 42.81
2022-05-24 23:51:52,871 [podnet.py] => Task 6, Epoch 110/160 (LR 0.02222) => LSC_loss 0.24, Spatial_loss 1.25, Flat_loss 0.22, Train_acc 96.09, Test_acc 39.97
2022-05-24 23:51:59,503 [podnet.py] => Task 6, Epoch 111/160 (LR 0.02141) => LSC_loss 0.24, Spatial_loss 1.23, Flat_loss 0.22, Train_acc 96.02, Test_acc 41.20
2022-05-24 23:52:06,210 [podnet.py] => Task 6, Epoch 112/160 (LR 0.02061) => LSC_loss 0.23, Spatial_loss 1.25, Flat_loss 0.22, Train_acc 96.69, Test_acc 43.19
2022-05-24 23:52:12,948 [podnet.py] => Task 6, Epoch 113/160 (LR 0.01982) => LSC_loss 0.23, Spatial_loss 1.24, Flat_loss 0.22, Train_acc 96.52, Test_acc 41.14
2022-05-24 23:52:19,486 [podnet.py] => Task 6, Epoch 114/160 (LR 0.01905) => LSC_loss 0.22, Spatial_loss 1.23, Flat_loss 0.22, Train_acc 97.05, Test_acc 42.97
2022-05-24 23:52:26,250 [podnet.py] => Task 6, Epoch 115/160 (LR 0.01828) => LSC_loss 0.22, Spatial_loss 1.20, Flat_loss 0.21, Train_acc 97.02, Test_acc 41.74
2022-05-24 23:52:32,883 [podnet.py] => Task 6, Epoch 116/160 (LR 0.01753) => LSC_loss 0.22, Spatial_loss 1.19, Flat_loss 0.21, Train_acc 96.79, Test_acc 41.96
2022-05-24 23:52:39,248 [podnet.py] => Task 6, Epoch 117/160 (LR 0.01679) => LSC_loss 0.21, Spatial_loss 1.20, Flat_loss 0.21, Train_acc 97.19, Test_acc 41.37
2022-05-24 23:52:45,539 [podnet.py] => Task 6, Epoch 118/160 (LR 0.01606) => LSC_loss 0.22, Spatial_loss 1.21, Flat_loss 0.21, Train_acc 96.83, Test_acc 39.99
2022-05-24 23:52:51,963 [podnet.py] => Task 6, Epoch 119/160 (LR 0.01535) => LSC_loss 0.21, Spatial_loss 1.17, Flat_loss 0.21, Train_acc 97.34, Test_acc 43.44
2022-05-24 23:52:58,637 [podnet.py] => Task 6, Epoch 120/160 (LR 0.01464) => LSC_loss 0.21, Spatial_loss 1.15, Flat_loss 0.21, Train_acc 97.13, Test_acc 42.56
2022-05-24 23:53:04,999 [podnet.py] => Task 6, Epoch 121/160 (LR 0.01396) => LSC_loss 0.20, Spatial_loss 1.20, Flat_loss 0.21, Train_acc 97.39, Test_acc 43.40
2022-05-24 23:53:11,585 [podnet.py] => Task 6, Epoch 122/160 (LR 0.01328) => LSC_loss 0.21, Spatial_loss 1.17, Flat_loss 0.21, Train_acc 97.21, Test_acc 42.19
2022-05-24 23:53:18,328 [podnet.py] => Task 6, Epoch 123/160 (LR 0.01262) => LSC_loss 0.20, Spatial_loss 1.14, Flat_loss 0.20, Train_acc 97.36, Test_acc 41.23
2022-05-24 23:53:25,059 [podnet.py] => Task 6, Epoch 124/160 (LR 0.01198) => LSC_loss 0.19, Spatial_loss 1.12, Flat_loss 0.20, Train_acc 97.71, Test_acc 43.67
2022-05-24 23:53:31,619 [podnet.py] => Task 6, Epoch 125/160 (LR 0.01135) => LSC_loss 0.20, Spatial_loss 1.12, Flat_loss 0.20, Train_acc 97.72, Test_acc 42.74
2022-05-24 23:53:38,226 [podnet.py] => Task 6, Epoch 126/160 (LR 0.01073) => LSC_loss 0.20, Spatial_loss 1.12, Flat_loss 0.20, Train_acc 97.85, Test_acc 41.41
2022-05-24 23:53:44,619 [podnet.py] => Task 6, Epoch 127/160 (LR 0.01013) => LSC_loss 0.19, Spatial_loss 1.09, Flat_loss 0.20, Train_acc 97.98, Test_acc 42.09
2022-05-24 23:53:51,054 [podnet.py] => Task 6, Epoch 128/160 (LR 0.00955) => LSC_loss 0.19, Spatial_loss 1.07, Flat_loss 0.20, Train_acc 97.87, Test_acc 43.44
2022-05-24 23:53:57,525 [podnet.py] => Task 6, Epoch 129/160 (LR 0.00898) => LSC_loss 0.20, Spatial_loss 1.11, Flat_loss 0.20, Train_acc 97.62, Test_acc 42.89
2022-05-24 23:54:04,177 [podnet.py] => Task 6, Epoch 130/160 (LR 0.00843) => LSC_loss 0.18, Spatial_loss 1.08, Flat_loss 0.20, Train_acc 98.08, Test_acc 44.20
2022-05-24 23:54:10,526 [podnet.py] => Task 6, Epoch 131/160 (LR 0.00789) => LSC_loss 0.19, Spatial_loss 1.07, Flat_loss 0.20, Train_acc 97.92, Test_acc 42.47
2022-05-24 23:54:16,960 [podnet.py] => Task 6, Epoch 132/160 (LR 0.00737) => LSC_loss 0.18, Spatial_loss 1.04, Flat_loss 0.20, Train_acc 98.28, Test_acc 43.59
2022-05-24 23:54:23,397 [podnet.py] => Task 6, Epoch 133/160 (LR 0.00686) => LSC_loss 0.18, Spatial_loss 1.02, Flat_loss 0.19, Train_acc 98.37, Test_acc 43.17
2022-05-24 23:54:29,810 [podnet.py] => Task 6, Epoch 134/160 (LR 0.00638) => LSC_loss 0.18, Spatial_loss 1.04, Flat_loss 0.19, Train_acc 98.11, Test_acc 43.01
2022-05-24 23:54:36,531 [podnet.py] => Task 6, Epoch 135/160 (LR 0.00590) => LSC_loss 0.18, Spatial_loss 1.05, Flat_loss 0.19, Train_acc 98.19, Test_acc 42.94
2022-05-24 23:54:43,117 [podnet.py] => Task 6, Epoch 136/160 (LR 0.00545) => LSC_loss 0.18, Spatial_loss 1.03, Flat_loss 0.19, Train_acc 98.21, Test_acc 43.49
2022-05-24 23:54:49,650 [podnet.py] => Task 6, Epoch 137/160 (LR 0.00501) => LSC_loss 0.18, Spatial_loss 1.02, Flat_loss 0.19, Train_acc 98.34, Test_acc 43.24
2022-05-24 23:54:56,597 [podnet.py] => Task 6, Epoch 138/160 (LR 0.00459) => LSC_loss 0.18, Spatial_loss 1.01, Flat_loss 0.19, Train_acc 98.21, Test_acc 43.76
2022-05-24 23:55:03,164 [podnet.py] => Task 6, Epoch 139/160 (LR 0.00419) => LSC_loss 0.18, Spatial_loss 1.02, Flat_loss 0.19, Train_acc 98.31, Test_acc 43.84
2022-05-24 23:55:09,956 [podnet.py] => Task 6, Epoch 140/160 (LR 0.00381) => LSC_loss 0.17, Spatial_loss 1.02, Flat_loss 0.19, Train_acc 98.44, Test_acc 44.21
2022-05-24 23:55:16,695 [podnet.py] => Task 6, Epoch 141/160 (LR 0.00344) => LSC_loss 0.18, Spatial_loss 1.01, Flat_loss 0.19, Train_acc 98.12, Test_acc 43.89
2022-05-24 23:55:23,169 [podnet.py] => Task 6, Epoch 142/160 (LR 0.00309) => LSC_loss 0.17, Spatial_loss 1.00, Flat_loss 0.19, Train_acc 98.52, Test_acc 43.79
2022-05-24 23:55:29,993 [podnet.py] => Task 6, Epoch 143/160 (LR 0.00276) => LSC_loss 0.17, Spatial_loss 1.01, Flat_loss 0.19, Train_acc 98.42, Test_acc 43.64
2022-05-24 23:55:36,495 [podnet.py] => Task 6, Epoch 144/160 (LR 0.00245) => LSC_loss 0.17, Spatial_loss 0.99, Flat_loss 0.19, Train_acc 98.44, Test_acc 44.03
2022-05-24 23:55:42,894 [podnet.py] => Task 6, Epoch 145/160 (LR 0.00215) => LSC_loss 0.17, Spatial_loss 0.97, Flat_loss 0.19, Train_acc 98.22, Test_acc 43.86
2022-05-24 23:55:49,511 [podnet.py] => Task 6, Epoch 146/160 (LR 0.00188) => LSC_loss 0.17, Spatial_loss 0.98, Flat_loss 0.19, Train_acc 98.44, Test_acc 44.29
2022-05-24 23:55:55,978 [podnet.py] => Task 6, Epoch 147/160 (LR 0.00162) => LSC_loss 0.17, Spatial_loss 0.97, Flat_loss 0.19, Train_acc 98.67, Test_acc 44.20
2022-05-24 23:56:02,298 [podnet.py] => Task 6, Epoch 148/160 (LR 0.00138) => LSC_loss 0.17, Spatial_loss 0.97, Flat_loss 0.19, Train_acc 98.55, Test_acc 44.26
2022-05-24 23:56:08,620 [podnet.py] => Task 6, Epoch 149/160 (LR 0.00116) => LSC_loss 0.17, Spatial_loss 0.97, Flat_loss 0.19, Train_acc 98.64, Test_acc 44.06
2022-05-24 23:56:15,029 [podnet.py] => Task 6, Epoch 150/160 (LR 0.00096) => LSC_loss 0.17, Spatial_loss 0.98, Flat_loss 0.19, Train_acc 98.83, Test_acc 44.04
2022-05-24 23:56:21,453 [podnet.py] => Task 6, Epoch 151/160 (LR 0.00078) => LSC_loss 0.17, Spatial_loss 0.97, Flat_loss 0.19, Train_acc 98.64, Test_acc 44.21
2022-05-24 23:56:27,595 [podnet.py] => Task 6, Epoch 152/160 (LR 0.00062) => LSC_loss 0.17, Spatial_loss 0.97, Flat_loss 0.19, Train_acc 98.67, Test_acc 44.24
2022-05-24 23:56:34,014 [podnet.py] => Task 6, Epoch 153/160 (LR 0.00047) => LSC_loss 0.17, Spatial_loss 0.98, Flat_loss 0.19, Train_acc 98.80, Test_acc 44.27
2022-05-24 23:56:40,724 [podnet.py] => Task 6, Epoch 154/160 (LR 0.00035) => LSC_loss 0.17, Spatial_loss 0.95, Flat_loss 0.19, Train_acc 98.65, Test_acc 43.61
2022-05-24 23:56:47,170 [podnet.py] => Task 6, Epoch 155/160 (LR 0.00024) => LSC_loss 0.16, Spatial_loss 0.94, Flat_loss 0.19, Train_acc 98.71, Test_acc 44.31
2022-05-24 23:56:53,237 [podnet.py] => Task 6, Epoch 156/160 (LR 0.00015) => LSC_loss 0.16, Spatial_loss 0.93, Flat_loss 0.19, Train_acc 98.74, Test_acc 44.19
2022-05-24 23:56:59,389 [podnet.py] => Task 6, Epoch 157/160 (LR 0.00009) => LSC_loss 0.17, Spatial_loss 0.96, Flat_loss 0.19, Train_acc 98.41, Test_acc 44.20
2022-05-24 23:57:06,160 [podnet.py] => Task 6, Epoch 158/160 (LR 0.00004) => LSC_loss 0.17, Spatial_loss 0.95, Flat_loss 0.19, Train_acc 98.87, Test_acc 44.37
2022-05-24 23:57:12,670 [podnet.py] => Task 6, Epoch 159/160 (LR 0.00001) => LSC_loss 0.16, Spatial_loss 0.95, Flat_loss 0.19, Train_acc 98.68, Test_acc 43.97
2022-05-24 23:57:19,048 [podnet.py] => Task 6, Epoch 160/160 (LR 0.00000) => LSC_loss 0.17, Spatial_loss 0.94, Flat_loss 0.19, Train_acc 98.62, Test_acc 44.36
2022-05-24 23:57:19,049 [podnet.py] => Finetune the network (classifier part) with the undersampled dataset!
2022-05-24 23:57:19,049 [base.py] => Reducing exemplars...(33 per classes)
2022-05-24 23:57:32,233 [base.py] => Constructing exemplars...(33 per classes)
2022-05-24 23:57:38,375 [podnet.py] => The size of finetune dataset: 2310
2022-05-24 23:57:41,516 [podnet.py] => Task 6, Epoch 1/20 (LR 0.00497) => LSC_loss 0.25, Spatial_loss 1.17, Flat_loss 0.14, Train_acc 97.40, Test_acc 46.57
2022-05-24 23:57:44,854 [podnet.py] => Task 6, Epoch 2/20 (LR 0.00488) => LSC_loss 0.37, Spatial_loss 1.30, Flat_loss 0.17, Train_acc 94.55, Test_acc 45.13
2022-05-24 23:57:48,167 [podnet.py] => Task 6, Epoch 3/20 (LR 0.00473) => LSC_loss 0.25, Spatial_loss 1.24, Flat_loss 0.16, Train_acc 96.36, Test_acc 43.56
2022-05-24 23:57:51,409 [podnet.py] => Task 6, Epoch 4/20 (LR 0.00452) => LSC_loss 0.20, Spatial_loss 1.19, Flat_loss 0.14, Train_acc 96.88, Test_acc 45.46
2022-05-24 23:57:54,435 [podnet.py] => Task 6, Epoch 5/20 (LR 0.00427) => LSC_loss 0.19, Spatial_loss 1.15, Flat_loss 0.14, Train_acc 98.10, Test_acc 45.64
2022-05-24 23:57:57,610 [podnet.py] => Task 6, Epoch 6/20 (LR 0.00397) => LSC_loss 0.20, Spatial_loss 1.15, Flat_loss 0.14, Train_acc 98.10, Test_acc 45.30
2022-05-24 23:58:01,027 [podnet.py] => Task 6, Epoch 7/20 (LR 0.00363) => LSC_loss 0.17, Spatial_loss 1.16, Flat_loss 0.14, Train_acc 98.14, Test_acc 46.19
2022-05-24 23:58:04,213 [podnet.py] => Task 6, Epoch 8/20 (LR 0.00327) => LSC_loss 0.17, Spatial_loss 1.09, Flat_loss 0.13, Train_acc 98.18, Test_acc 46.20
2022-05-24 23:58:07,626 [podnet.py] => Task 6, Epoch 9/20 (LR 0.00289) => LSC_loss 0.18, Spatial_loss 1.20, Flat_loss 0.14, Train_acc 98.79, Test_acc 45.47
2022-05-24 23:58:10,789 [podnet.py] => Task 6, Epoch 10/20 (LR 0.00250) => LSC_loss 0.17, Spatial_loss 1.08, Flat_loss 0.14, Train_acc 97.92, Test_acc 46.60
2022-05-24 23:58:14,150 [podnet.py] => Task 6, Epoch 11/20 (LR 0.00211) => LSC_loss 0.16, Spatial_loss 1.08, Flat_loss 0.13, Train_acc 98.74, Test_acc 46.51
2022-05-24 23:58:17,543 [podnet.py] => Task 6, Epoch 12/20 (LR 0.00173) => LSC_loss 0.16, Spatial_loss 1.10, Flat_loss 0.13, Train_acc 98.92, Test_acc 46.53
2022-05-24 23:58:20,665 [podnet.py] => Task 6, Epoch 13/20 (LR 0.00137) => LSC_loss 0.19, Spatial_loss 1.10, Flat_loss 0.13, Train_acc 98.66, Test_acc 46.59
2022-05-24 23:58:23,834 [podnet.py] => Task 6, Epoch 14/20 (LR 0.00103) => LSC_loss 0.16, Spatial_loss 1.16, Flat_loss 0.14, Train_acc 98.83, Test_acc 47.01
2022-05-24 23:58:27,075 [podnet.py] => Task 6, Epoch 15/20 (LR 0.00073) => LSC_loss 0.16, Spatial_loss 1.13, Flat_loss 0.13, Train_acc 98.83, Test_acc 46.93
2022-05-24 23:58:30,373 [podnet.py] => Task 6, Epoch 16/20 (LR 0.00048) => LSC_loss 0.15, Spatial_loss 1.12, Flat_loss 0.13, Train_acc 98.92, Test_acc 47.24
2022-05-24 23:58:33,203 [podnet.py] => Task 6, Epoch 17/20 (LR 0.00027) => LSC_loss 0.20, Spatial_loss 1.08, Flat_loss 0.13, Train_acc 98.83, Test_acc 46.74
2022-05-24 23:58:36,131 [podnet.py] => Task 6, Epoch 18/20 (LR 0.00012) => LSC_loss 0.18, Spatial_loss 1.08, Flat_loss 0.12, Train_acc 99.09, Test_acc 46.97
2022-05-24 23:58:39,346 [podnet.py] => Task 6, Epoch 19/20 (LR 0.00003) => LSC_loss 0.21, Spatial_loss 1.02, Flat_loss 0.13, Train_acc 99.05, Test_acc 46.76
2022-05-24 23:58:42,359 [podnet.py] => Task 6, Epoch 20/20 (LR 0.00000) => LSC_loss 0.17, Spatial_loss 1.07, Flat_loss 0.13, Train_acc 98.83, Test_acc 47.14
2022-05-24 23:58:42,360 [base.py] => Reducing exemplars...(28 per classes)
2022-05-24 23:58:55,419 [base.py] => Constructing exemplars...(28 per classes)
2022-05-24 23:59:03,978 [podnet.py] => Exemplar size: 1960
2022-05-24 23:59:03,979 [trainer.py] => CNN: {'total': 47.14, '00-09': 60.4, '10-19': 25.4, '20-29': 42.2, '30-39': 34.8, '40-49': 52.9, '50-59': 45.4, '60-69': 68.9, 'old': 43.52, 'new': 68.9}
2022-05-24 23:59:03,979 [trainer.py] => NME: {'total': 45.64, '00-09': 66.3, '10-19': 22.5, '20-29': 42.6, '30-39': 34.1, '40-49': 48.5, '50-59': 40.1, '60-69': 65.4, 'old': 42.35, 'new': 65.4}
2022-05-24 23:59:03,979 [trainer.py] => CNN top1 curve: [90.7, 72.95, 65.47, 57.8, 53.9, 49.75, 47.14]
2022-05-24 23:59:03,979 [trainer.py] => CNN top5 curve: [99.2, 93.95, 90.1, 85.15, 81.78, 78.42, 76.86]
2022-05-24 23:59:03,979 [trainer.py] => NME top1 curve: [90.8, 72.05, 63.37, 55.7, 52.92, 48.87, 45.64]
2022-05-24 23:59:03,979 [trainer.py] => NME top5 curve: [99.3, 92.8, 88.93, 83.38, 81.2, 77.87, 75.76]

2022-05-24 23:59:03,980 [trainer.py] => All params: 511057
2022-05-24 23:59:03,980 [trainer.py] => Trainable params: 511057
2022-05-24 23:59:03,981 [podnet.py] => Learning on 70-80
2022-05-24 23:59:04,051 [podnet.py] => Adaptive factor: 2.8284271247461903
2022-05-24 23:59:10,512 [podnet.py] => Task 7, Epoch 1/160 (LR 0.09999) => LSC_loss 2.82, Spatial_loss 3.29, Flat_loss 1.07, Train_acc 44.37, Test_acc 15.82
2022-05-24 23:59:17,292 [podnet.py] => Task 7, Epoch 2/160 (LR 0.09996) => LSC_loss 1.63, Spatial_loss 2.69, Flat_loss 0.62, Train_acc 57.39, Test_acc 28.69
2022-05-24 23:59:24,129 [podnet.py] => Task 7, Epoch 3/160 (LR 0.09991) => LSC_loss 1.41, Spatial_loss 2.44, Flat_loss 0.47, Train_acc 62.03, Test_acc 32.59
2022-05-24 23:59:30,768 [podnet.py] => Task 7, Epoch 4/160 (LR 0.09985) => LSC_loss 1.30, Spatial_loss 2.37, Flat_loss 0.42, Train_acc 64.09, Test_acc 31.45
2022-05-24 23:59:37,792 [podnet.py] => Task 7, Epoch 5/160 (LR 0.09976) => LSC_loss 1.23, Spatial_loss 2.27, Flat_loss 0.39, Train_acc 65.76, Test_acc 28.84
2022-05-24 23:59:44,269 [podnet.py] => Task 7, Epoch 6/160 (LR 0.09965) => LSC_loss 1.18, Spatial_loss 2.20, Flat_loss 0.37, Train_acc 67.24, Test_acc 30.45
2022-05-24 23:59:50,800 [podnet.py] => Task 7, Epoch 7/160 (LR 0.09953) => LSC_loss 1.15, Spatial_loss 2.23, Flat_loss 0.36, Train_acc 68.64, Test_acc 31.44
2022-05-24 23:59:57,503 [podnet.py] => Task 7, Epoch 8/160 (LR 0.09938) => LSC_loss 1.10, Spatial_loss 2.12, Flat_loss 0.35, Train_acc 69.86, Test_acc 31.09
2022-05-25 00:00:04,192 [podnet.py] => Task 7, Epoch 9/160 (LR 0.09922) => LSC_loss 1.07, Spatial_loss 2.19, Flat_loss 0.35, Train_acc 71.18, Test_acc 32.96
2022-05-25 00:00:11,214 [podnet.py] => Task 7, Epoch 10/160 (LR 0.09904) => LSC_loss 1.05, Spatial_loss 2.08, Flat_loss 0.34, Train_acc 71.24, Test_acc 30.54
2022-05-25 00:00:17,958 [podnet.py] => Task 7, Epoch 11/160 (LR 0.09884) => LSC_loss 1.03, Spatial_loss 2.13, Flat_loss 0.34, Train_acc 71.34, Test_acc 31.16
2022-05-25 00:00:24,413 [podnet.py] => Task 7, Epoch 12/160 (LR 0.09862) => LSC_loss 1.02, Spatial_loss 2.09, Flat_loss 0.34, Train_acc 72.51, Test_acc 33.49
2022-05-25 00:00:31,278 [podnet.py] => Task 7, Epoch 13/160 (LR 0.09838) => LSC_loss 0.98, Spatial_loss 2.06, Flat_loss 0.34, Train_acc 73.20, Test_acc 31.55
2022-05-25 00:00:38,052 [podnet.py] => Task 7, Epoch 14/160 (LR 0.09812) => LSC_loss 0.93, Spatial_loss 2.04, Flat_loss 0.33, Train_acc 74.54, Test_acc 36.74
2022-05-25 00:00:44,765 [podnet.py] => Task 7, Epoch 15/160 (LR 0.09785) => LSC_loss 0.96, Spatial_loss 2.06, Flat_loss 0.33, Train_acc 73.49, Test_acc 29.00
2022-05-25 00:00:51,673 [podnet.py] => Task 7, Epoch 16/160 (LR 0.09755) => LSC_loss 0.94, Spatial_loss 2.07, Flat_loss 0.33, Train_acc 74.37, Test_acc 29.89
2022-05-25 00:00:58,273 [podnet.py] => Task 7, Epoch 17/160 (LR 0.09724) => LSC_loss 0.92, Spatial_loss 2.07, Flat_loss 0.33, Train_acc 75.14, Test_acc 34.78
2022-05-25 00:01:05,171 [podnet.py] => Task 7, Epoch 18/160 (LR 0.09691) => LSC_loss 0.91, Spatial_loss 2.08, Flat_loss 0.33, Train_acc 75.75, Test_acc 34.20
2022-05-25 00:01:11,963 [podnet.py] => Task 7, Epoch 19/160 (LR 0.09656) => LSC_loss 0.87, Spatial_loss 1.99, Flat_loss 0.32, Train_acc 76.35, Test_acc 32.29
2022-05-25 00:01:18,702 [podnet.py] => Task 7, Epoch 20/160 (LR 0.09619) => LSC_loss 0.87, Spatial_loss 2.02, Flat_loss 0.33, Train_acc 75.70, Test_acc 31.18
2022-05-25 00:01:25,640 [podnet.py] => Task 7, Epoch 21/160 (LR 0.09581) => LSC_loss 0.87, Spatial_loss 2.05, Flat_loss 0.33, Train_acc 75.62, Test_acc 29.70
2022-05-25 00:01:32,039 [podnet.py] => Task 7, Epoch 22/160 (LR 0.09541) => LSC_loss 0.84, Spatial_loss 2.01, Flat_loss 0.33, Train_acc 76.95, Test_acc 33.14
2022-05-25 00:01:39,197 [podnet.py] => Task 7, Epoch 23/160 (LR 0.09499) => LSC_loss 0.84, Spatial_loss 2.02, Flat_loss 0.33, Train_acc 76.67, Test_acc 34.75
2022-05-25 00:01:45,639 [podnet.py] => Task 7, Epoch 24/160 (LR 0.09455) => LSC_loss 0.84, Spatial_loss 2.03, Flat_loss 0.33, Train_acc 76.84, Test_acc 32.26
2022-05-25 00:01:52,351 [podnet.py] => Task 7, Epoch 25/160 (LR 0.09410) => LSC_loss 0.85, Spatial_loss 2.05, Flat_loss 0.33, Train_acc 76.85, Test_acc 31.92
2022-05-25 00:01:59,095 [podnet.py] => Task 7, Epoch 26/160 (LR 0.09362) => LSC_loss 0.82, Spatial_loss 2.01, Flat_loss 0.33, Train_acc 77.34, Test_acc 29.04
2022-05-25 00:02:05,506 [podnet.py] => Task 7, Epoch 27/160 (LR 0.09314) => LSC_loss 0.83, Spatial_loss 2.01, Flat_loss 0.33, Train_acc 77.46, Test_acc 31.01
2022-05-25 00:02:12,353 [podnet.py] => Task 7, Epoch 28/160 (LR 0.09263) => LSC_loss 0.79, Spatial_loss 2.02, Flat_loss 0.32, Train_acc 78.94, Test_acc 28.86
2022-05-25 00:02:19,090 [podnet.py] => Task 7, Epoch 29/160 (LR 0.09211) => LSC_loss 0.76, Spatial_loss 1.95, Flat_loss 0.32, Train_acc 79.37, Test_acc 35.17
2022-05-25 00:02:25,805 [podnet.py] => Task 7, Epoch 30/160 (LR 0.09157) => LSC_loss 0.75, Spatial_loss 1.92, Flat_loss 0.32, Train_acc 79.38, Test_acc 34.04
2022-05-25 00:02:32,622 [podnet.py] => Task 7, Epoch 31/160 (LR 0.09102) => LSC_loss 0.74, Spatial_loss 1.93, Flat_loss 0.32, Train_acc 79.91, Test_acc 34.62
2022-05-25 00:02:38,995 [podnet.py] => Task 7, Epoch 32/160 (LR 0.09045) => LSC_loss 0.75, Spatial_loss 1.96, Flat_loss 0.33, Train_acc 79.54, Test_acc 33.66
2022-05-25 00:02:45,714 [podnet.py] => Task 7, Epoch 33/160 (LR 0.08987) => LSC_loss 0.73, Spatial_loss 1.94, Flat_loss 0.33, Train_acc 80.09, Test_acc 32.78
2022-05-25 00:02:52,634 [podnet.py] => Task 7, Epoch 34/160 (LR 0.08927) => LSC_loss 0.73, Spatial_loss 1.97, Flat_loss 0.33, Train_acc 80.22, Test_acc 30.39
2022-05-25 00:02:59,262 [podnet.py] => Task 7, Epoch 35/160 (LR 0.08865) => LSC_loss 0.75, Spatial_loss 2.00, Flat_loss 0.32, Train_acc 79.35, Test_acc 33.69
2022-05-25 00:03:06,429 [podnet.py] => Task 7, Epoch 36/160 (LR 0.08802) => LSC_loss 0.74, Spatial_loss 1.99, Flat_loss 0.33, Train_acc 80.00, Test_acc 35.10
2022-05-25 00:03:12,705 [podnet.py] => Task 7, Epoch 37/160 (LR 0.08738) => LSC_loss 0.74, Spatial_loss 2.01, Flat_loss 0.32, Train_acc 80.10, Test_acc 32.83
2022-05-25 00:03:19,201 [podnet.py] => Task 7, Epoch 38/160 (LR 0.08672) => LSC_loss 0.73, Spatial_loss 2.00, Flat_loss 0.33, Train_acc 80.47, Test_acc 31.02
2022-05-25 00:03:25,461 [podnet.py] => Task 7, Epoch 39/160 (LR 0.08604) => LSC_loss 0.72, Spatial_loss 1.96, Flat_loss 0.33, Train_acc 80.07, Test_acc 34.52
2022-05-25 00:03:31,847 [podnet.py] => Task 7, Epoch 40/160 (LR 0.08536) => LSC_loss 0.70, Spatial_loss 1.98, Flat_loss 0.32, Train_acc 81.57, Test_acc 31.56
2022-05-25 00:03:38,576 [podnet.py] => Task 7, Epoch 41/160 (LR 0.08465) => LSC_loss 0.70, Spatial_loss 1.94, Flat_loss 0.33, Train_acc 81.03, Test_acc 34.08
2022-05-25 00:03:45,218 [podnet.py] => Task 7, Epoch 42/160 (LR 0.08394) => LSC_loss 0.69, Spatial_loss 1.92, Flat_loss 0.32, Train_acc 81.45, Test_acc 29.15
2022-05-25 00:03:51,978 [podnet.py] => Task 7, Epoch 43/160 (LR 0.08321) => LSC_loss 0.70, Spatial_loss 1.96, Flat_loss 0.33, Train_acc 80.69, Test_acc 35.10
2022-05-25 00:03:58,807 [podnet.py] => Task 7, Epoch 44/160 (LR 0.08247) => LSC_loss 0.69, Spatial_loss 1.94, Flat_loss 0.32, Train_acc 81.77, Test_acc 34.49
2022-05-25 00:04:05,469 [podnet.py] => Task 7, Epoch 45/160 (LR 0.08172) => LSC_loss 0.65, Spatial_loss 1.91, Flat_loss 0.32, Train_acc 82.43, Test_acc 37.17
2022-05-25 00:04:12,261 [podnet.py] => Task 7, Epoch 46/160 (LR 0.08095) => LSC_loss 0.66, Spatial_loss 1.90, Flat_loss 0.32, Train_acc 82.28, Test_acc 31.11
2022-05-25 00:04:19,004 [podnet.py] => Task 7, Epoch 47/160 (LR 0.08018) => LSC_loss 0.65, Spatial_loss 1.89, Flat_loss 0.32, Train_acc 82.40, Test_acc 33.84
2022-05-25 00:04:25,857 [podnet.py] => Task 7, Epoch 48/160 (LR 0.07939) => LSC_loss 0.68, Spatial_loss 1.93, Flat_loss 0.32, Train_acc 81.34, Test_acc 34.52
2022-05-25 00:04:32,490 [podnet.py] => Task 7, Epoch 49/160 (LR 0.07859) => LSC_loss 0.63, Spatial_loss 1.87, Flat_loss 0.32, Train_acc 83.52, Test_acc 33.61
2022-05-25 00:04:39,010 [podnet.py] => Task 7, Epoch 50/160 (LR 0.07778) => LSC_loss 0.66, Spatial_loss 1.94, Flat_loss 0.32, Train_acc 82.00, Test_acc 28.05
2022-05-25 00:04:45,448 [podnet.py] => Task 7, Epoch 51/160 (LR 0.07696) => LSC_loss 0.64, Spatial_loss 1.92, Flat_loss 0.32, Train_acc 83.05, Test_acc 33.31
2022-05-25 00:04:52,018 [podnet.py] => Task 7, Epoch 52/160 (LR 0.07612) => LSC_loss 0.63, Spatial_loss 1.91, Flat_loss 0.32, Train_acc 83.69, Test_acc 33.26
2022-05-25 00:04:58,665 [podnet.py] => Task 7, Epoch 53/160 (LR 0.07528) => LSC_loss 0.63, Spatial_loss 1.88, Flat_loss 0.32, Train_acc 83.00, Test_acc 29.95
2022-05-25 00:05:05,093 [podnet.py] => Task 7, Epoch 54/160 (LR 0.07443) => LSC_loss 0.62, Spatial_loss 1.88, Flat_loss 0.32, Train_acc 83.71, Test_acc 34.70
2022-05-25 00:05:11,482 [podnet.py] => Task 7, Epoch 55/160 (LR 0.07357) => LSC_loss 0.62, Spatial_loss 1.86, Flat_loss 0.32, Train_acc 83.76, Test_acc 34.92
2022-05-25 00:05:18,055 [podnet.py] => Task 7, Epoch 56/160 (LR 0.07270) => LSC_loss 0.61, Spatial_loss 1.89, Flat_loss 0.32, Train_acc 83.86, Test_acc 31.74
2022-05-25 00:05:24,407 [podnet.py] => Task 7, Epoch 57/160 (LR 0.07182) => LSC_loss 0.60, Spatial_loss 1.87, Flat_loss 0.32, Train_acc 84.32, Test_acc 33.09
2022-05-25 00:05:30,993 [podnet.py] => Task 7, Epoch 58/160 (LR 0.07093) => LSC_loss 0.59, Spatial_loss 1.87, Flat_loss 0.31, Train_acc 84.84, Test_acc 34.26
2022-05-25 00:05:37,893 [podnet.py] => Task 7, Epoch 59/160 (LR 0.07004) => LSC_loss 0.60, Spatial_loss 1.84, Flat_loss 0.31, Train_acc 84.27, Test_acc 31.71
2022-05-25 00:05:44,488 [podnet.py] => Task 7, Epoch 60/160 (LR 0.06913) => LSC_loss 0.58, Spatial_loss 1.81, Flat_loss 0.31, Train_acc 84.77, Test_acc 35.22
2022-05-25 00:05:51,199 [podnet.py] => Task 7, Epoch 61/160 (LR 0.06822) => LSC_loss 0.57, Spatial_loss 1.85, Flat_loss 0.32, Train_acc 85.16, Test_acc 33.25
2022-05-25 00:05:57,977 [podnet.py] => Task 7, Epoch 62/160 (LR 0.06731) => LSC_loss 0.57, Spatial_loss 1.80, Flat_loss 0.31, Train_acc 84.97, Test_acc 34.15
2022-05-25 00:06:04,565 [podnet.py] => Task 7, Epoch 63/160 (LR 0.06638) => LSC_loss 0.58, Spatial_loss 1.83, Flat_loss 0.32, Train_acc 84.63, Test_acc 32.88
2022-05-25 00:06:11,405 [podnet.py] => Task 7, Epoch 64/160 (LR 0.06545) => LSC_loss 0.57, Spatial_loss 1.79, Flat_loss 0.31, Train_acc 86.02, Test_acc 35.31
2022-05-25 00:06:18,119 [podnet.py] => Task 7, Epoch 65/160 (LR 0.06451) => LSC_loss 0.55, Spatial_loss 1.82, Flat_loss 0.31, Train_acc 85.82, Test_acc 34.79
2022-05-25 00:06:24,690 [podnet.py] => Task 7, Epoch 66/160 (LR 0.06357) => LSC_loss 0.56, Spatial_loss 1.83, Flat_loss 0.31, Train_acc 85.59, Test_acc 31.48
2022-05-25 00:06:31,214 [podnet.py] => Task 7, Epoch 67/160 (LR 0.06262) => LSC_loss 0.57, Spatial_loss 1.86, Flat_loss 0.32, Train_acc 85.20, Test_acc 31.40
2022-05-25 00:06:37,582 [podnet.py] => Task 7, Epoch 68/160 (LR 0.06167) => LSC_loss 0.52, Spatial_loss 1.75, Flat_loss 0.31, Train_acc 87.00, Test_acc 34.86
2022-05-25 00:06:44,232 [podnet.py] => Task 7, Epoch 69/160 (LR 0.06072) => LSC_loss 0.51, Spatial_loss 1.75, Flat_loss 0.30, Train_acc 87.04, Test_acc 30.90
2022-05-25 00:06:50,735 [podnet.py] => Task 7, Epoch 70/160 (LR 0.05975) => LSC_loss 0.52, Spatial_loss 1.77, Flat_loss 0.30, Train_acc 86.93, Test_acc 31.68
2022-05-25 00:06:57,272 [podnet.py] => Task 7, Epoch 71/160 (LR 0.05879) => LSC_loss 0.52, Spatial_loss 1.74, Flat_loss 0.30, Train_acc 86.54, Test_acc 34.48
2022-05-25 00:07:03,726 [podnet.py] => Task 7, Epoch 72/160 (LR 0.05782) => LSC_loss 0.50, Spatial_loss 1.75, Flat_loss 0.30, Train_acc 87.72, Test_acc 36.84
2022-05-25 00:07:10,530 [podnet.py] => Task 7, Epoch 73/160 (LR 0.05685) => LSC_loss 0.50, Spatial_loss 1.73, Flat_loss 0.30, Train_acc 87.66, Test_acc 33.88
2022-05-25 00:07:17,441 [podnet.py] => Task 7, Epoch 74/160 (LR 0.05588) => LSC_loss 0.51, Spatial_loss 1.73, Flat_loss 0.31, Train_acc 87.00, Test_acc 32.45
2022-05-25 00:07:24,009 [podnet.py] => Task 7, Epoch 75/160 (LR 0.05490) => LSC_loss 0.50, Spatial_loss 1.75, Flat_loss 0.31, Train_acc 87.50, Test_acc 37.22
2022-05-25 00:07:30,432 [podnet.py] => Task 7, Epoch 76/160 (LR 0.05392) => LSC_loss 0.45, Spatial_loss 1.72, Flat_loss 0.30, Train_acc 88.94, Test_acc 35.38
2022-05-25 00:07:37,391 [podnet.py] => Task 7, Epoch 77/160 (LR 0.05294) => LSC_loss 0.46, Spatial_loss 1.68, Flat_loss 0.29, Train_acc 88.97, Test_acc 33.67
2022-05-25 00:07:44,047 [podnet.py] => Task 7, Epoch 78/160 (LR 0.05196) => LSC_loss 0.46, Spatial_loss 1.69, Flat_loss 0.30, Train_acc 89.04, Test_acc 33.55
2022-05-25 00:07:50,594 [podnet.py] => Task 7, Epoch 79/160 (LR 0.05098) => LSC_loss 0.46, Spatial_loss 1.68, Flat_loss 0.30, Train_acc 88.94, Test_acc 36.99
2022-05-25 00:07:57,192 [podnet.py] => Task 7, Epoch 80/160 (LR 0.05000) => LSC_loss 0.47, Spatial_loss 1.70, Flat_loss 0.30, Train_acc 88.22, Test_acc 35.10
2022-05-25 00:08:03,612 [podnet.py] => Task 7, Epoch 81/160 (LR 0.04902) => LSC_loss 0.45, Spatial_loss 1.67, Flat_loss 0.30, Train_acc 88.91, Test_acc 36.21
2022-05-25 00:08:10,110 [podnet.py] => Task 7, Epoch 82/160 (LR 0.04804) => LSC_loss 0.44, Spatial_loss 1.62, Flat_loss 0.29, Train_acc 89.51, Test_acc 36.91
2022-05-25 00:08:16,545 [podnet.py] => Task 7, Epoch 83/160 (LR 0.04706) => LSC_loss 0.44, Spatial_loss 1.66, Flat_loss 0.30, Train_acc 89.35, Test_acc 38.14
2022-05-25 00:08:23,012 [podnet.py] => Task 7, Epoch 84/160 (LR 0.04608) => LSC_loss 0.43, Spatial_loss 1.65, Flat_loss 0.30, Train_acc 89.86, Test_acc 33.70
2022-05-25 00:08:29,527 [podnet.py] => Task 7, Epoch 85/160 (LR 0.04510) => LSC_loss 0.43, Spatial_loss 1.58, Flat_loss 0.29, Train_acc 90.00, Test_acc 31.66
2022-05-25 00:08:35,937 [podnet.py] => Task 7, Epoch 86/160 (LR 0.04412) => LSC_loss 0.44, Spatial_loss 1.62, Flat_loss 0.29, Train_acc 89.57, Test_acc 31.95
2022-05-25 00:08:42,743 [podnet.py] => Task 7, Epoch 87/160 (LR 0.04315) => LSC_loss 0.41, Spatial_loss 1.61, Flat_loss 0.29, Train_acc 90.96, Test_acc 37.96
2022-05-25 00:08:49,634 [podnet.py] => Task 7, Epoch 88/160 (LR 0.04218) => LSC_loss 0.42, Spatial_loss 1.61, Flat_loss 0.29, Train_acc 89.97, Test_acc 34.16
2022-05-25 00:08:56,336 [podnet.py] => Task 7, Epoch 89/160 (LR 0.04121) => LSC_loss 0.41, Spatial_loss 1.56, Flat_loss 0.29, Train_acc 90.50, Test_acc 35.96
2022-05-25 00:09:03,097 [podnet.py] => Task 7, Epoch 90/160 (LR 0.04025) => LSC_loss 0.39, Spatial_loss 1.56, Flat_loss 0.28, Train_acc 91.15, Test_acc 35.26
2022-05-25 00:09:09,957 [podnet.py] => Task 7, Epoch 91/160 (LR 0.03928) => LSC_loss 0.37, Spatial_loss 1.53, Flat_loss 0.28, Train_acc 91.62, Test_acc 36.39
2022-05-25 00:09:17,047 [podnet.py] => Task 7, Epoch 92/160 (LR 0.03833) => LSC_loss 0.38, Spatial_loss 1.54, Flat_loss 0.28, Train_acc 91.65, Test_acc 38.12
2022-05-25 00:09:23,863 [podnet.py] => Task 7, Epoch 93/160 (LR 0.03738) => LSC_loss 0.35, Spatial_loss 1.51, Flat_loss 0.27, Train_acc 92.49, Test_acc 39.46
2022-05-25 00:09:30,596 [podnet.py] => Task 7, Epoch 94/160 (LR 0.03643) => LSC_loss 0.39, Spatial_loss 1.54, Flat_loss 0.28, Train_acc 90.72, Test_acc 39.06
2022-05-25 00:09:37,505 [podnet.py] => Task 7, Epoch 95/160 (LR 0.03549) => LSC_loss 0.37, Spatial_loss 1.53, Flat_loss 0.28, Train_acc 91.91, Test_acc 36.42
2022-05-25 00:09:44,123 [podnet.py] => Task 7, Epoch 96/160 (LR 0.03455) => LSC_loss 0.37, Spatial_loss 1.56, Flat_loss 0.28, Train_acc 91.61, Test_acc 33.54
2022-05-25 00:09:51,177 [podnet.py] => Task 7, Epoch 97/160 (LR 0.03362) => LSC_loss 0.37, Spatial_loss 1.54, Flat_loss 0.28, Train_acc 92.00, Test_acc 34.19
2022-05-25 00:09:57,761 [podnet.py] => Task 7, Epoch 98/160 (LR 0.03269) => LSC_loss 0.36, Spatial_loss 1.47, Flat_loss 0.27, Train_acc 92.05, Test_acc 34.00
2022-05-25 00:10:04,182 [podnet.py] => Task 7, Epoch 99/160 (LR 0.03178) => LSC_loss 0.35, Spatial_loss 1.54, Flat_loss 0.27, Train_acc 92.20, Test_acc 37.52
2022-05-25 00:10:11,210 [podnet.py] => Task 7, Epoch 100/160 (LR 0.03087) => LSC_loss 0.33, Spatial_loss 1.47, Flat_loss 0.27, Train_acc 93.45, Test_acc 38.95
2022-05-25 00:10:18,063 [podnet.py] => Task 7, Epoch 101/160 (LR 0.02996) => LSC_loss 0.35, Spatial_loss 1.48, Flat_loss 0.27, Train_acc 92.63, Test_acc 35.84
2022-05-25 00:10:24,834 [podnet.py] => Task 7, Epoch 102/160 (LR 0.02907) => LSC_loss 0.35, Spatial_loss 1.50, Flat_loss 0.27, Train_acc 92.57, Test_acc 35.60
2022-05-25 00:10:31,684 [podnet.py] => Task 7, Epoch 103/160 (LR 0.02818) => LSC_loss 0.34, Spatial_loss 1.46, Flat_loss 0.27, Train_acc 92.72, Test_acc 33.62
2022-05-25 00:10:38,491 [podnet.py] => Task 7, Epoch 104/160 (LR 0.02730) => LSC_loss 0.33, Spatial_loss 1.48, Flat_loss 0.27, Train_acc 93.23, Test_acc 37.15
2022-05-25 00:10:45,499 [podnet.py] => Task 7, Epoch 105/160 (LR 0.02643) => LSC_loss 0.32, Spatial_loss 1.41, Flat_loss 0.27, Train_acc 93.46, Test_acc 36.94
2022-05-25 00:10:52,123 [podnet.py] => Task 7, Epoch 106/160 (LR 0.02557) => LSC_loss 0.32, Spatial_loss 1.41, Flat_loss 0.27, Train_acc 93.52, Test_acc 36.91
2022-05-25 00:10:58,906 [podnet.py] => Task 7, Epoch 107/160 (LR 0.02472) => LSC_loss 0.32, Spatial_loss 1.45, Flat_loss 0.27, Train_acc 93.62, Test_acc 36.55
2022-05-25 00:11:05,767 [podnet.py] => Task 7, Epoch 108/160 (LR 0.02388) => LSC_loss 0.29, Spatial_loss 1.41, Flat_loss 0.26, Train_acc 94.66, Test_acc 35.45
2022-05-25 00:11:12,283 [podnet.py] => Task 7, Epoch 109/160 (LR 0.02304) => LSC_loss 0.29, Spatial_loss 1.37, Flat_loss 0.26, Train_acc 94.66, Test_acc 35.48
2022-05-25 00:11:18,980 [podnet.py] => Task 7, Epoch 110/160 (LR 0.02222) => LSC_loss 0.30, Spatial_loss 1.36, Flat_loss 0.26, Train_acc 94.54, Test_acc 37.21
2022-05-25 00:11:25,828 [podnet.py] => Task 7, Epoch 111/160 (LR 0.02141) => LSC_loss 0.28, Spatial_loss 1.37, Flat_loss 0.26, Train_acc 95.06, Test_acc 38.10
2022-05-25 00:11:32,528 [podnet.py] => Task 7, Epoch 112/160 (LR 0.02061) => LSC_loss 0.27, Spatial_loss 1.32, Flat_loss 0.25, Train_acc 95.26, Test_acc 38.45
2022-05-25 00:11:39,309 [podnet.py] => Task 7, Epoch 113/160 (LR 0.01982) => LSC_loss 0.29, Spatial_loss 1.36, Flat_loss 0.26, Train_acc 94.45, Test_acc 36.59
2022-05-25 00:11:45,990 [podnet.py] => Task 7, Epoch 114/160 (LR 0.01905) => LSC_loss 0.28, Spatial_loss 1.32, Flat_loss 0.25, Train_acc 95.04, Test_acc 38.99
2022-05-25 00:11:52,917 [podnet.py] => Task 7, Epoch 115/160 (LR 0.01828) => LSC_loss 0.27, Spatial_loss 1.34, Flat_loss 0.25, Train_acc 95.04, Test_acc 35.34
2022-05-25 00:11:59,812 [podnet.py] => Task 7, Epoch 116/160 (LR 0.01753) => LSC_loss 0.27, Spatial_loss 1.33, Flat_loss 0.25, Train_acc 95.32, Test_acc 37.39
2022-05-25 00:12:06,544 [podnet.py] => Task 7, Epoch 117/160 (LR 0.01679) => LSC_loss 0.26, Spatial_loss 1.31, Flat_loss 0.25, Train_acc 95.59, Test_acc 38.40
2022-05-25 00:12:13,213 [podnet.py] => Task 7, Epoch 118/160 (LR 0.01606) => LSC_loss 0.26, Spatial_loss 1.30, Flat_loss 0.25, Train_acc 95.83, Test_acc 37.95
2022-05-25 00:12:19,523 [podnet.py] => Task 7, Epoch 119/160 (LR 0.01535) => LSC_loss 0.25, Spatial_loss 1.28, Flat_loss 0.24, Train_acc 95.99, Test_acc 36.40
2022-05-25 00:12:26,336 [podnet.py] => Task 7, Epoch 120/160 (LR 0.01464) => LSC_loss 0.25, Spatial_loss 1.27, Flat_loss 0.25, Train_acc 95.60, Test_acc 40.66
2022-05-25 00:12:33,176 [podnet.py] => Task 7, Epoch 121/160 (LR 0.01396) => LSC_loss 0.25, Spatial_loss 1.22, Flat_loss 0.24, Train_acc 95.85, Test_acc 39.09
2022-05-25 00:12:39,803 [podnet.py] => Task 7, Epoch 122/160 (LR 0.01328) => LSC_loss 0.24, Spatial_loss 1.29, Flat_loss 0.24, Train_acc 96.09, Test_acc 39.55
2022-05-25 00:12:46,416 [podnet.py] => Task 7, Epoch 123/160 (LR 0.01262) => LSC_loss 0.25, Spatial_loss 1.23, Flat_loss 0.24, Train_acc 95.93, Test_acc 37.85
2022-05-25 00:12:53,122 [podnet.py] => Task 7, Epoch 124/160 (LR 0.01198) => LSC_loss 0.24, Spatial_loss 1.26, Flat_loss 0.24, Train_acc 96.41, Test_acc 38.79
2022-05-25 00:12:59,861 [podnet.py] => Task 7, Epoch 125/160 (LR 0.01135) => LSC_loss 0.23, Spatial_loss 1.21, Flat_loss 0.24, Train_acc 96.67, Test_acc 38.15
2022-05-25 00:13:06,662 [podnet.py] => Task 7, Epoch 126/160 (LR 0.01073) => LSC_loss 0.24, Spatial_loss 1.20, Flat_loss 0.24, Train_acc 96.36, Test_acc 39.33
2022-05-25 00:13:13,221 [podnet.py] => Task 7, Epoch 127/160 (LR 0.01013) => LSC_loss 0.23, Spatial_loss 1.25, Flat_loss 0.24, Train_acc 96.34, Test_acc 40.29
2022-05-25 00:13:19,573 [podnet.py] => Task 7, Epoch 128/160 (LR 0.00955) => LSC_loss 0.23, Spatial_loss 1.21, Flat_loss 0.24, Train_acc 96.75, Test_acc 39.81
2022-05-25 00:13:26,177 [podnet.py] => Task 7, Epoch 129/160 (LR 0.00898) => LSC_loss 0.23, Spatial_loss 1.19, Flat_loss 0.24, Train_acc 96.93, Test_acc 38.65
2022-05-25 00:13:32,743 [podnet.py] => Task 7, Epoch 130/160 (LR 0.00843) => LSC_loss 0.22, Spatial_loss 1.15, Flat_loss 0.23, Train_acc 97.05, Test_acc 40.17
2022-05-25 00:13:39,314 [podnet.py] => Task 7, Epoch 131/160 (LR 0.00789) => LSC_loss 0.22, Spatial_loss 1.16, Flat_loss 0.23, Train_acc 97.05, Test_acc 38.91
2022-05-25 00:13:45,665 [podnet.py] => Task 7, Epoch 132/160 (LR 0.00737) => LSC_loss 0.22, Spatial_loss 1.17, Flat_loss 0.23, Train_acc 96.91, Test_acc 40.22
2022-05-25 00:13:52,166 [podnet.py] => Task 7, Epoch 133/160 (LR 0.00686) => LSC_loss 0.22, Spatial_loss 1.14, Flat_loss 0.23, Train_acc 97.17, Test_acc 39.14
2022-05-25 00:13:58,859 [podnet.py] => Task 7, Epoch 134/160 (LR 0.00638) => LSC_loss 0.22, Spatial_loss 1.15, Flat_loss 0.23, Train_acc 97.07, Test_acc 40.81
2022-05-25 00:14:05,818 [podnet.py] => Task 7, Epoch 135/160 (LR 0.00590) => LSC_loss 0.22, Spatial_loss 1.16, Flat_loss 0.23, Train_acc 96.88, Test_acc 40.01
2022-05-25 00:14:12,447 [podnet.py] => Task 7, Epoch 136/160 (LR 0.00545) => LSC_loss 0.22, Spatial_loss 1.14, Flat_loss 0.23, Train_acc 97.16, Test_acc 40.06
2022-05-25 00:14:19,224 [podnet.py] => Task 7, Epoch 137/160 (LR 0.00501) => LSC_loss 0.21, Spatial_loss 1.13, Flat_loss 0.23, Train_acc 97.30, Test_acc 39.79
2022-05-25 00:14:25,771 [podnet.py] => Task 7, Epoch 138/160 (LR 0.00459) => LSC_loss 0.21, Spatial_loss 1.12, Flat_loss 0.23, Train_acc 97.14, Test_acc 39.11
2022-05-25 00:14:32,373 [podnet.py] => Task 7, Epoch 139/160 (LR 0.00419) => LSC_loss 0.21, Spatial_loss 1.12, Flat_loss 0.23, Train_acc 97.51, Test_acc 40.25
2022-05-25 00:14:39,345 [podnet.py] => Task 7, Epoch 140/160 (LR 0.00381) => LSC_loss 0.21, Spatial_loss 1.09, Flat_loss 0.23, Train_acc 97.61, Test_acc 40.99
2022-05-25 00:14:45,943 [podnet.py] => Task 7, Epoch 141/160 (LR 0.00344) => LSC_loss 0.21, Spatial_loss 1.11, Flat_loss 0.23, Train_acc 97.51, Test_acc 40.85
2022-05-25 00:14:52,497 [podnet.py] => Task 7, Epoch 142/160 (LR 0.00309) => LSC_loss 0.21, Spatial_loss 1.10, Flat_loss 0.23, Train_acc 97.40, Test_acc 40.24
2022-05-25 00:14:59,398 [podnet.py] => Task 7, Epoch 143/160 (LR 0.00276) => LSC_loss 0.21, Spatial_loss 1.10, Flat_loss 0.22, Train_acc 97.82, Test_acc 39.80
2022-05-25 00:15:06,188 [podnet.py] => Task 7, Epoch 144/160 (LR 0.00245) => LSC_loss 0.21, Spatial_loss 1.10, Flat_loss 0.23, Train_acc 97.61, Test_acc 40.11
2022-05-25 00:15:13,484 [podnet.py] => Task 7, Epoch 145/160 (LR 0.00215) => LSC_loss 0.21, Spatial_loss 1.10, Flat_loss 0.23, Train_acc 97.50, Test_acc 40.55
2022-05-25 00:15:19,992 [podnet.py] => Task 7, Epoch 146/160 (LR 0.00188) => LSC_loss 0.20, Spatial_loss 1.08, Flat_loss 0.22, Train_acc 97.63, Test_acc 40.24
2022-05-25 00:15:26,500 [podnet.py] => Task 7, Epoch 147/160 (LR 0.00162) => LSC_loss 0.20, Spatial_loss 1.09, Flat_loss 0.22, Train_acc 97.76, Test_acc 40.50
2022-05-25 00:15:32,979 [podnet.py] => Task 7, Epoch 148/160 (LR 0.00138) => LSC_loss 0.20, Spatial_loss 1.08, Flat_loss 0.22, Train_acc 97.57, Test_acc 40.45
2022-05-25 00:15:40,110 [podnet.py] => Task 7, Epoch 149/160 (LR 0.00116) => LSC_loss 0.20, Spatial_loss 1.06, Flat_loss 0.22, Train_acc 97.95, Test_acc 40.81
2022-05-25 00:15:46,713 [podnet.py] => Task 7, Epoch 150/160 (LR 0.00096) => LSC_loss 0.20, Spatial_loss 1.07, Flat_loss 0.22, Train_acc 97.67, Test_acc 40.48
2022-05-25 00:15:53,678 [podnet.py] => Task 7, Epoch 151/160 (LR 0.00078) => LSC_loss 0.20, Spatial_loss 1.05, Flat_loss 0.22, Train_acc 97.79, Test_acc 40.38
2022-05-25 00:16:00,466 [podnet.py] => Task 7, Epoch 152/160 (LR 0.00062) => LSC_loss 0.19, Spatial_loss 1.04, Flat_loss 0.22, Train_acc 97.99, Test_acc 40.51
2022-05-25 00:16:07,058 [podnet.py] => Task 7, Epoch 153/160 (LR 0.00047) => LSC_loss 0.20, Spatial_loss 1.06, Flat_loss 0.22, Train_acc 97.84, Test_acc 40.26
2022-05-25 00:16:13,920 [podnet.py] => Task 7, Epoch 154/160 (LR 0.00035) => LSC_loss 0.20, Spatial_loss 1.06, Flat_loss 0.22, Train_acc 97.83, Test_acc 40.58
2022-05-25 00:16:20,742 [podnet.py] => Task 7, Epoch 155/160 (LR 0.00024) => LSC_loss 0.19, Spatial_loss 1.04, Flat_loss 0.22, Train_acc 98.20, Test_acc 40.51
2022-05-25 00:16:27,544 [podnet.py] => Task 7, Epoch 156/160 (LR 0.00015) => LSC_loss 0.20, Spatial_loss 1.02, Flat_loss 0.22, Train_acc 97.73, Test_acc 40.48
2022-05-25 00:16:34,086 [podnet.py] => Task 7, Epoch 157/160 (LR 0.00009) => LSC_loss 0.20, Spatial_loss 1.06, Flat_loss 0.22, Train_acc 97.99, Test_acc 40.44
2022-05-25 00:16:40,608 [podnet.py] => Task 7, Epoch 158/160 (LR 0.00004) => LSC_loss 0.20, Spatial_loss 1.04, Flat_loss 0.22, Train_acc 97.86, Test_acc 40.39
2022-05-25 00:16:47,312 [podnet.py] => Task 7, Epoch 159/160 (LR 0.00001) => LSC_loss 0.20, Spatial_loss 1.04, Flat_loss 0.22, Train_acc 97.76, Test_acc 40.42
2022-05-25 00:16:53,751 [podnet.py] => Task 7, Epoch 160/160 (LR 0.00000) => LSC_loss 0.20, Spatial_loss 1.04, Flat_loss 0.22, Train_acc 97.72, Test_acc 40.31
2022-05-25 00:16:53,752 [podnet.py] => Finetune the network (classifier part) with the undersampled dataset!
2022-05-25 00:16:53,753 [base.py] => Reducing exemplars...(28 per classes)
2022-05-25 00:17:09,192 [base.py] => Constructing exemplars...(28 per classes)
2022-05-25 00:17:15,705 [podnet.py] => The size of finetune dataset: 2240
2022-05-25 00:17:18,950 [podnet.py] => Task 7, Epoch 1/20 (LR 0.00497) => LSC_loss 0.25, Spatial_loss 1.10, Flat_loss 0.16, Train_acc 95.71, Test_acc 43.68
2022-05-25 00:17:22,023 [podnet.py] => Task 7, Epoch 2/20 (LR 0.00488) => LSC_loss 0.18, Spatial_loss 1.13, Flat_loss 0.13, Train_acc 98.17, Test_acc 42.85
2022-05-25 00:17:25,126 [podnet.py] => Task 7, Epoch 3/20 (LR 0.00473) => LSC_loss 0.17, Spatial_loss 1.06, Flat_loss 0.13, Train_acc 98.17, Test_acc 43.24
2022-05-25 00:17:27,992 [podnet.py] => Task 7, Epoch 4/20 (LR 0.00452) => LSC_loss 0.16, Spatial_loss 1.05, Flat_loss 0.12, Train_acc 98.08, Test_acc 43.31
2022-05-25 00:17:30,232 [podnet.py] => Task 7, Epoch 5/20 (LR 0.00427) => LSC_loss 0.16, Spatial_loss 1.07, Flat_loss 0.12, Train_acc 98.66, Test_acc 43.35
2022-05-25 00:17:32,580 [podnet.py] => Task 7, Epoch 6/20 (LR 0.00397) => LSC_loss 0.16, Spatial_loss 1.05, Flat_loss 0.12, Train_acc 98.44, Test_acc 43.54
2022-05-25 00:17:34,734 [podnet.py] => Task 7, Epoch 7/20 (LR 0.00363) => LSC_loss 0.16, Spatial_loss 1.01, Flat_loss 0.12, Train_acc 98.35, Test_acc 43.25
2022-05-25 00:17:36,866 [podnet.py] => Task 7, Epoch 8/20 (LR 0.00327) => LSC_loss 0.15, Spatial_loss 1.05, Flat_loss 0.12, Train_acc 98.71, Test_acc 43.01
2022-05-25 00:17:38,836 [podnet.py] => Task 7, Epoch 9/20 (LR 0.00289) => LSC_loss 0.15, Spatial_loss 1.04, Flat_loss 0.12, Train_acc 98.75, Test_acc 43.42
2022-05-25 00:17:40,815 [podnet.py] => Task 7, Epoch 10/20 (LR 0.00250) => LSC_loss 0.15, Spatial_loss 1.06, Flat_loss 0.12, Train_acc 98.66, Test_acc 43.88
2022-05-25 00:17:43,007 [podnet.py] => Task 7, Epoch 11/20 (LR 0.00211) => LSC_loss 0.14, Spatial_loss 1.02, Flat_loss 0.12, Train_acc 98.97, Test_acc 43.55
2022-05-25 00:17:45,292 [podnet.py] => Task 7, Epoch 12/20 (LR 0.00173) => LSC_loss 0.15, Spatial_loss 1.04, Flat_loss 0.11, Train_acc 98.39, Test_acc 43.76
2022-05-25 00:17:47,581 [podnet.py] => Task 7, Epoch 13/20 (LR 0.00137) => LSC_loss 0.15, Spatial_loss 1.00, Flat_loss 0.11, Train_acc 99.20, Test_acc 43.56
2022-05-25 00:17:49,760 [podnet.py] => Task 7, Epoch 14/20 (LR 0.00103) => LSC_loss 0.14, Spatial_loss 1.00, Flat_loss 0.11, Train_acc 99.15, Test_acc 43.70
2022-05-25 00:17:51,863 [podnet.py] => Task 7, Epoch 15/20 (LR 0.00073) => LSC_loss 0.15, Spatial_loss 1.04, Flat_loss 0.12, Train_acc 98.75, Test_acc 43.80
2022-05-25 00:17:53,913 [podnet.py] => Task 7, Epoch 16/20 (LR 0.00048) => LSC_loss 0.15, Spatial_loss 1.00, Flat_loss 0.11, Train_acc 98.88, Test_acc 43.66
2022-05-25 00:17:56,128 [podnet.py] => Task 7, Epoch 17/20 (LR 0.00027) => LSC_loss 0.15, Spatial_loss 1.01, Flat_loss 0.11, Train_acc 98.75, Test_acc 43.66
2022-05-25 00:17:58,276 [podnet.py] => Task 7, Epoch 18/20 (LR 0.00012) => LSC_loss 0.13, Spatial_loss 0.99, Flat_loss 0.11, Train_acc 98.97, Test_acc 43.61
2022-05-25 00:18:00,399 [podnet.py] => Task 7, Epoch 19/20 (LR 0.00003) => LSC_loss 0.14, Spatial_loss 0.99, Flat_loss 0.11, Train_acc 98.93, Test_acc 43.68
2022-05-25 00:18:02,685 [podnet.py] => Task 7, Epoch 20/20 (LR 0.00000) => LSC_loss 0.14, Spatial_loss 0.98, Flat_loss 0.11, Train_acc 98.79, Test_acc 43.70
2022-05-25 00:18:02,687 [base.py] => Reducing exemplars...(25 per classes)
2022-05-25 00:18:17,339 [base.py] => Constructing exemplars...(25 per classes)
2022-05-25 00:18:25,731 [podnet.py] => Exemplar size: 2000
2022-05-25 00:18:25,731 [trainer.py] => CNN: {'total': 43.7, '00-09': 57.5, '10-19': 22.0, '20-29': 40.3, '30-39': 31.0, '40-49': 47.0, '50-59': 36.3, '60-69': 56.3, '70-79': 59.2, 'old': 41.49, 'new': 59.2}
2022-05-25 00:18:25,731 [trainer.py] => NME: {'total': 42.5, '00-09': 64.0, '10-19': 19.5, '20-29': 40.1, '30-39': 32.0, '40-49': 43.4, '50-59': 32.0, '60-69': 51.2, '70-79': 57.8, 'old': 40.31, 'new': 57.8}
2022-05-25 00:18:25,731 [trainer.py] => CNN top1 curve: [90.7, 72.95, 65.47, 57.8, 53.9, 49.75, 47.14, 43.7]
2022-05-25 00:18:25,731 [trainer.py] => CNN top5 curve: [99.2, 93.95, 90.1, 85.15, 81.78, 78.42, 76.86, 73.58]
2022-05-25 00:18:25,731 [trainer.py] => NME top1 curve: [90.8, 72.05, 63.37, 55.7, 52.92, 48.87, 45.64, 42.5]
2022-05-25 00:18:25,731 [trainer.py] => NME top5 curve: [99.3, 92.8, 88.93, 83.38, 81.2, 77.87, 75.76, 72.41]

2022-05-25 00:18:25,732 [trainer.py] => All params: 517457
2022-05-25 00:18:25,732 [trainer.py] => Trainable params: 517457
2022-05-25 00:18:25,733 [podnet.py] => Learning on 80-90
2022-05-25 00:18:25,808 [podnet.py] => Adaptive factor: 3.0
2022-05-25 00:18:29,781 [podnet.py] => Task 8, Epoch 1/160 (LR 0.09999) => LSC_loss 2.69, Spatial_loss 3.01, Flat_loss 1.05, Train_acc 45.60, Test_acc 26.41
2022-05-25 00:18:33,787 [podnet.py] => Task 8, Epoch 2/160 (LR 0.09996) => LSC_loss 1.54, Spatial_loss 2.53, Flat_loss 0.57, Train_acc 59.41, Test_acc 27.97
2022-05-25 00:18:37,765 [podnet.py] => Task 8, Epoch 3/160 (LR 0.09991) => LSC_loss 1.41, Spatial_loss 2.46, Flat_loss 0.47, Train_acc 62.34, Test_acc 26.11
2022-05-25 00:18:41,869 [podnet.py] => Task 8, Epoch 4/160 (LR 0.09985) => LSC_loss 1.28, Spatial_loss 2.23, Flat_loss 0.41, Train_acc 65.86, Test_acc 22.72
2022-05-25 00:18:45,925 [podnet.py] => Task 8, Epoch 5/160 (LR 0.09976) => LSC_loss 1.22, Spatial_loss 2.25, Flat_loss 0.40, Train_acc 67.49, Test_acc 23.93
2022-05-25 00:18:49,877 [podnet.py] => Task 8, Epoch 6/160 (LR 0.09965) => LSC_loss 1.15, Spatial_loss 2.21, Flat_loss 0.38, Train_acc 69.36, Test_acc 32.81
2022-05-25 00:18:53,798 [podnet.py] => Task 8, Epoch 7/160 (LR 0.09953) => LSC_loss 1.09, Spatial_loss 2.16, Flat_loss 0.37, Train_acc 70.91, Test_acc 24.36
2022-05-25 00:18:57,737 [podnet.py] => Task 8, Epoch 8/160 (LR 0.09938) => LSC_loss 1.09, Spatial_loss 2.23, Flat_loss 0.37, Train_acc 71.40, Test_acc 25.18
2022-05-25 00:19:01,802 [podnet.py] => Task 8, Epoch 9/160 (LR 0.09922) => LSC_loss 1.05, Spatial_loss 2.14, Flat_loss 0.37, Train_acc 72.01, Test_acc 31.74
2022-05-25 00:19:05,820 [podnet.py] => Task 8, Epoch 10/160 (LR 0.09904) => LSC_loss 1.00, Spatial_loss 2.13, Flat_loss 0.36, Train_acc 73.44, Test_acc 32.90
2022-05-25 00:19:09,823 [podnet.py] => Task 8, Epoch 11/160 (LR 0.09884) => LSC_loss 1.00, Spatial_loss 2.18, Flat_loss 0.36, Train_acc 74.21, Test_acc 31.47
2022-05-25 00:19:13,908 [podnet.py] => Task 8, Epoch 12/160 (LR 0.09862) => LSC_loss 0.96, Spatial_loss 2.13, Flat_loss 0.36, Train_acc 74.34, Test_acc 28.22
2022-05-25 00:19:17,886 [podnet.py] => Task 8, Epoch 13/160 (LR 0.09838) => LSC_loss 0.95, Spatial_loss 2.09, Flat_loss 0.36, Train_acc 74.63, Test_acc 31.21
2022-05-25 00:19:21,860 [podnet.py] => Task 8, Epoch 14/160 (LR 0.09812) => LSC_loss 0.95, Spatial_loss 2.12, Flat_loss 0.36, Train_acc 74.79, Test_acc 26.73
2022-05-25 00:19:25,912 [podnet.py] => Task 8, Epoch 15/160 (LR 0.09785) => LSC_loss 0.91, Spatial_loss 2.14, Flat_loss 0.36, Train_acc 76.36, Test_acc 29.77
2022-05-25 00:19:30,033 [podnet.py] => Task 8, Epoch 16/160 (LR 0.09755) => LSC_loss 0.88, Spatial_loss 2.03, Flat_loss 0.35, Train_acc 76.66, Test_acc 31.71
2022-05-25 00:19:34,180 [podnet.py] => Task 8, Epoch 17/160 (LR 0.09724) => LSC_loss 0.88, Spatial_loss 2.03, Flat_loss 0.35, Train_acc 76.93, Test_acc 28.60
2022-05-25 00:19:38,229 [podnet.py] => Task 8, Epoch 18/160 (LR 0.09691) => LSC_loss 0.87, Spatial_loss 2.06, Flat_loss 0.36, Train_acc 77.33, Test_acc 27.67
2022-05-25 00:19:42,303 [podnet.py] => Task 8, Epoch 19/160 (LR 0.09656) => LSC_loss 0.85, Spatial_loss 2.05, Flat_loss 0.35, Train_acc 78.04, Test_acc 27.40
2022-05-25 00:19:46,461 [podnet.py] => Task 8, Epoch 20/160 (LR 0.09619) => LSC_loss 0.87, Spatial_loss 2.11, Flat_loss 0.36, Train_acc 76.44, Test_acc 30.32
2022-05-25 00:19:50,410 [podnet.py] => Task 8, Epoch 21/160 (LR 0.09581) => LSC_loss 0.83, Spatial_loss 2.04, Flat_loss 0.35, Train_acc 78.44, Test_acc 30.60
2022-05-25 00:19:54,518 [podnet.py] => Task 8, Epoch 22/160 (LR 0.09541) => LSC_loss 0.82, Spatial_loss 2.07, Flat_loss 0.35, Train_acc 78.11, Test_acc 28.86
2022-05-25 00:19:58,646 [podnet.py] => Task 8, Epoch 23/160 (LR 0.09499) => LSC_loss 0.79, Spatial_loss 2.05, Flat_loss 0.35, Train_acc 79.66, Test_acc 29.29
2022-05-25 00:20:02,808 [podnet.py] => Task 8, Epoch 24/160 (LR 0.09455) => LSC_loss 0.78, Spatial_loss 2.02, Flat_loss 0.35, Train_acc 79.84, Test_acc 28.37
2022-05-25 00:20:06,982 [podnet.py] => Task 8, Epoch 25/160 (LR 0.09410) => LSC_loss 0.76, Spatial_loss 1.99, Flat_loss 0.35, Train_acc 80.23, Test_acc 28.72
2022-05-25 00:20:11,138 [podnet.py] => Task 8, Epoch 26/160 (LR 0.09362) => LSC_loss 0.81, Spatial_loss 2.01, Flat_loss 0.36, Train_acc 78.69, Test_acc 22.93
2022-05-25 00:20:15,463 [podnet.py] => Task 8, Epoch 27/160 (LR 0.09314) => LSC_loss 0.79, Spatial_loss 2.10, Flat_loss 0.36, Train_acc 78.97, Test_acc 27.63
2022-05-25 00:20:19,517 [podnet.py] => Task 8, Epoch 28/160 (LR 0.09263) => LSC_loss 0.77, Spatial_loss 2.04, Flat_loss 0.35, Train_acc 80.23, Test_acc 32.26
2022-05-25 00:20:23,487 [podnet.py] => Task 8, Epoch 29/160 (LR 0.09211) => LSC_loss 0.73, Spatial_loss 1.99, Flat_loss 0.34, Train_acc 80.76, Test_acc 26.62
2022-05-25 00:20:27,602 [podnet.py] => Task 8, Epoch 30/160 (LR 0.09157) => LSC_loss 0.72, Spatial_loss 1.95, Flat_loss 0.35, Train_acc 81.66, Test_acc 31.09
2022-05-25 00:20:31,769 [podnet.py] => Task 8, Epoch 31/160 (LR 0.09102) => LSC_loss 0.76, Spatial_loss 2.08, Flat_loss 0.36, Train_acc 79.80, Test_acc 31.46
2022-05-25 00:20:36,070 [podnet.py] => Task 8, Epoch 32/160 (LR 0.09045) => LSC_loss 0.72, Spatial_loss 1.99, Flat_loss 0.35, Train_acc 81.11, Test_acc 29.53
2022-05-25 00:20:40,104 [podnet.py] => Task 8, Epoch 33/160 (LR 0.08987) => LSC_loss 0.73, Spatial_loss 2.09, Flat_loss 0.36, Train_acc 80.83, Test_acc 28.98
2022-05-25 00:20:44,327 [podnet.py] => Task 8, Epoch 34/160 (LR 0.08927) => LSC_loss 0.71, Spatial_loss 2.02, Flat_loss 0.35, Train_acc 81.20, Test_acc 26.34
2022-05-25 00:20:48,704 [podnet.py] => Task 8, Epoch 35/160 (LR 0.08865) => LSC_loss 0.71, Spatial_loss 1.93, Flat_loss 0.35, Train_acc 81.43, Test_acc 32.21
2022-05-25 00:20:52,871 [podnet.py] => Task 8, Epoch 36/160 (LR 0.08802) => LSC_loss 0.69, Spatial_loss 1.98, Flat_loss 0.34, Train_acc 82.26, Test_acc 25.67
2022-05-25 00:20:57,126 [podnet.py] => Task 8, Epoch 37/160 (LR 0.08738) => LSC_loss 0.68, Spatial_loss 2.02, Flat_loss 0.35, Train_acc 81.79, Test_acc 26.19
2022-05-25 00:21:01,173 [podnet.py] => Task 8, Epoch 38/160 (LR 0.08672) => LSC_loss 0.67, Spatial_loss 1.91, Flat_loss 0.34, Train_acc 82.80, Test_acc 32.70
2022-05-25 00:21:05,159 [podnet.py] => Task 8, Epoch 39/160 (LR 0.08604) => LSC_loss 0.65, Spatial_loss 1.90, Flat_loss 0.34, Train_acc 83.73, Test_acc 27.04
2022-05-25 00:21:09,106 [podnet.py] => Task 8, Epoch 40/160 (LR 0.08536) => LSC_loss 0.65, Spatial_loss 1.96, Flat_loss 0.34, Train_acc 83.01, Test_acc 33.46
2022-05-25 00:21:13,351 [podnet.py] => Task 8, Epoch 41/160 (LR 0.08465) => LSC_loss 0.62, Spatial_loss 1.96, Flat_loss 0.34, Train_acc 84.23, Test_acc 30.04
2022-05-25 00:21:17,360 [podnet.py] => Task 8, Epoch 42/160 (LR 0.08394) => LSC_loss 0.65, Spatial_loss 1.92, Flat_loss 0.34, Train_acc 83.54, Test_acc 30.72
2022-05-25 00:21:21,356 [podnet.py] => Task 8, Epoch 43/160 (LR 0.08321) => LSC_loss 0.63, Spatial_loss 1.94, Flat_loss 0.34, Train_acc 83.83, Test_acc 30.00
2022-05-25 00:21:25,464 [podnet.py] => Task 8, Epoch 44/160 (LR 0.08247) => LSC_loss 0.63, Spatial_loss 1.92, Flat_loss 0.34, Train_acc 83.84, Test_acc 32.61
2022-05-25 00:21:29,444 [podnet.py] => Task 8, Epoch 45/160 (LR 0.08172) => LSC_loss 0.66, Spatial_loss 1.92, Flat_loss 0.35, Train_acc 82.71, Test_acc 32.31
2022-05-25 00:21:33,640 [podnet.py] => Task 8, Epoch 46/160 (LR 0.08095) => LSC_loss 0.66, Spatial_loss 1.98, Flat_loss 0.35, Train_acc 83.00, Test_acc 31.88
2022-05-25 00:21:37,886 [podnet.py] => Task 8, Epoch 47/160 (LR 0.08018) => LSC_loss 0.63, Spatial_loss 1.97, Flat_loss 0.34, Train_acc 84.36, Test_acc 31.41
2022-05-25 00:21:41,891 [podnet.py] => Task 8, Epoch 48/160 (LR 0.07939) => LSC_loss 0.59, Spatial_loss 1.90, Flat_loss 0.34, Train_acc 84.99, Test_acc 31.57
2022-05-25 00:21:46,141 [podnet.py] => Task 8, Epoch 49/160 (LR 0.07859) => LSC_loss 0.61, Spatial_loss 1.91, Flat_loss 0.34, Train_acc 84.30, Test_acc 30.66
2022-05-25 00:21:50,122 [podnet.py] => Task 8, Epoch 50/160 (LR 0.07778) => LSC_loss 0.60, Spatial_loss 1.91, Flat_loss 0.34, Train_acc 85.36, Test_acc 31.77
2022-05-25 00:21:54,266 [podnet.py] => Task 8, Epoch 51/160 (LR 0.07696) => LSC_loss 0.61, Spatial_loss 1.90, Flat_loss 0.34, Train_acc 84.63, Test_acc 28.92
2022-05-25 00:21:58,352 [podnet.py] => Task 8, Epoch 52/160 (LR 0.07612) => LSC_loss 0.57, Spatial_loss 1.86, Flat_loss 0.33, Train_acc 85.49, Test_acc 30.20
2022-05-25 00:22:02,392 [podnet.py] => Task 8, Epoch 53/160 (LR 0.07528) => LSC_loss 0.58, Spatial_loss 1.85, Flat_loss 0.33, Train_acc 85.29, Test_acc 32.59
2022-05-25 00:22:06,569 [podnet.py] => Task 8, Epoch 54/160 (LR 0.07443) => LSC_loss 0.57, Spatial_loss 1.87, Flat_loss 0.33, Train_acc 85.30, Test_acc 26.71
2022-05-25 00:22:10,721 [podnet.py] => Task 8, Epoch 55/160 (LR 0.07357) => LSC_loss 0.60, Spatial_loss 1.88, Flat_loss 0.33, Train_acc 84.83, Test_acc 29.87
2022-05-25 00:22:14,873 [podnet.py] => Task 8, Epoch 56/160 (LR 0.07270) => LSC_loss 0.55, Spatial_loss 1.86, Flat_loss 0.33, Train_acc 86.61, Test_acc 30.97
2022-05-25 00:22:19,053 [podnet.py] => Task 8, Epoch 57/160 (LR 0.07182) => LSC_loss 0.54, Spatial_loss 1.85, Flat_loss 0.33, Train_acc 86.29, Test_acc 32.00
2022-05-25 00:22:23,064 [podnet.py] => Task 8, Epoch 58/160 (LR 0.07093) => LSC_loss 0.56, Spatial_loss 1.85, Flat_loss 0.34, Train_acc 86.11, Test_acc 27.17
2022-05-25 00:22:27,081 [podnet.py] => Task 8, Epoch 59/160 (LR 0.07004) => LSC_loss 0.54, Spatial_loss 1.84, Flat_loss 0.33, Train_acc 86.54, Test_acc 27.42
2022-05-25 00:22:31,169 [podnet.py] => Task 8, Epoch 60/160 (LR 0.06913) => LSC_loss 0.54, Spatial_loss 1.84, Flat_loss 0.33, Train_acc 86.37, Test_acc 28.47
2022-05-25 00:22:35,121 [podnet.py] => Task 8, Epoch 61/160 (LR 0.06822) => LSC_loss 0.55, Spatial_loss 1.86, Flat_loss 0.34, Train_acc 86.21, Test_acc 27.02
2022-05-25 00:22:39,175 [podnet.py] => Task 8, Epoch 62/160 (LR 0.06731) => LSC_loss 0.51, Spatial_loss 1.83, Flat_loss 0.33, Train_acc 87.74, Test_acc 33.87
2022-05-25 00:22:43,416 [podnet.py] => Task 8, Epoch 63/160 (LR 0.06638) => LSC_loss 0.49, Spatial_loss 1.78, Flat_loss 0.33, Train_acc 88.20, Test_acc 29.14
2022-05-25 00:22:47,743 [podnet.py] => Task 8, Epoch 64/160 (LR 0.06545) => LSC_loss 0.51, Spatial_loss 1.82, Flat_loss 0.33, Train_acc 87.96, Test_acc 26.77
2022-05-25 00:22:51,760 [podnet.py] => Task 8, Epoch 65/160 (LR 0.06451) => LSC_loss 0.54, Spatial_loss 1.84, Flat_loss 0.33, Train_acc 86.57, Test_acc 28.66
2022-05-25 00:22:56,006 [podnet.py] => Task 8, Epoch 66/160 (LR 0.06357) => LSC_loss 0.53, Spatial_loss 1.81, Flat_loss 0.34, Train_acc 86.94, Test_acc 32.68
2022-05-25 00:23:00,355 [podnet.py] => Task 8, Epoch 67/160 (LR 0.06262) => LSC_loss 0.48, Spatial_loss 1.78, Flat_loss 0.33, Train_acc 88.54, Test_acc 32.21
2022-05-25 00:23:04,352 [podnet.py] => Task 8, Epoch 68/160 (LR 0.06167) => LSC_loss 0.49, Spatial_loss 1.79, Flat_loss 0.33, Train_acc 87.96, Test_acc 32.09
2022-05-25 00:23:08,593 [podnet.py] => Task 8, Epoch 69/160 (LR 0.06072) => LSC_loss 0.50, Spatial_loss 1.74, Flat_loss 0.32, Train_acc 87.67, Test_acc 35.20
2022-05-25 00:23:12,815 [podnet.py] => Task 8, Epoch 70/160 (LR 0.05975) => LSC_loss 0.46, Spatial_loss 1.77, Flat_loss 0.32, Train_acc 88.96, Test_acc 29.71
2022-05-25 00:23:16,816 [podnet.py] => Task 8, Epoch 71/160 (LR 0.05879) => LSC_loss 0.46, Spatial_loss 1.75, Flat_loss 0.32, Train_acc 89.54, Test_acc 30.12
2022-05-25 00:23:20,833 [podnet.py] => Task 8, Epoch 72/160 (LR 0.05782) => LSC_loss 0.48, Spatial_loss 1.75, Flat_loss 0.32, Train_acc 88.26, Test_acc 30.97
2022-05-25 00:23:24,854 [podnet.py] => Task 8, Epoch 73/160 (LR 0.05685) => LSC_loss 0.47, Spatial_loss 1.76, Flat_loss 0.32, Train_acc 88.63, Test_acc 33.34
2022-05-25 00:23:28,966 [podnet.py] => Task 8, Epoch 74/160 (LR 0.05588) => LSC_loss 0.45, Spatial_loss 1.73, Flat_loss 0.32, Train_acc 89.80, Test_acc 28.81
2022-05-25 00:23:33,107 [podnet.py] => Task 8, Epoch 75/160 (LR 0.05490) => LSC_loss 0.46, Spatial_loss 1.70, Flat_loss 0.31, Train_acc 89.04, Test_acc 34.12
2022-05-25 00:23:37,446 [podnet.py] => Task 8, Epoch 76/160 (LR 0.05392) => LSC_loss 0.45, Spatial_loss 1.70, Flat_loss 0.31, Train_acc 89.54, Test_acc 31.13
2022-05-25 00:23:41,386 [podnet.py] => Task 8, Epoch 77/160 (LR 0.05294) => LSC_loss 0.46, Spatial_loss 1.76, Flat_loss 0.32, Train_acc 89.21, Test_acc 31.70
2022-05-25 00:23:45,399 [podnet.py] => Task 8, Epoch 78/160 (LR 0.05196) => LSC_loss 0.42, Spatial_loss 1.71, Flat_loss 0.31, Train_acc 90.31, Test_acc 32.88
2022-05-25 00:23:49,366 [podnet.py] => Task 8, Epoch 79/160 (LR 0.05098) => LSC_loss 0.43, Spatial_loss 1.69, Flat_loss 0.31, Train_acc 90.17, Test_acc 30.71
2022-05-25 00:23:53,301 [podnet.py] => Task 8, Epoch 80/160 (LR 0.05000) => LSC_loss 0.42, Spatial_loss 1.69, Flat_loss 0.31, Train_acc 90.57, Test_acc 32.70
2022-05-25 00:23:57,356 [podnet.py] => Task 8, Epoch 81/160 (LR 0.04902) => LSC_loss 0.41, Spatial_loss 1.67, Flat_loss 0.31, Train_acc 90.89, Test_acc 29.76
2022-05-25 00:24:01,350 [podnet.py] => Task 8, Epoch 82/160 (LR 0.04804) => LSC_loss 0.40, Spatial_loss 1.63, Flat_loss 0.30, Train_acc 91.30, Test_acc 35.18
2022-05-25 00:24:05,658 [podnet.py] => Task 8, Epoch 83/160 (LR 0.04706) => LSC_loss 0.41, Spatial_loss 1.66, Flat_loss 0.30, Train_acc 90.77, Test_acc 32.82
2022-05-25 00:24:09,726 [podnet.py] => Task 8, Epoch 84/160 (LR 0.04608) => LSC_loss 0.38, Spatial_loss 1.61, Flat_loss 0.30, Train_acc 91.57, Test_acc 35.50
2022-05-25 00:24:13,950 [podnet.py] => Task 8, Epoch 85/160 (LR 0.04510) => LSC_loss 0.39, Spatial_loss 1.66, Flat_loss 0.31, Train_acc 91.46, Test_acc 30.19
2022-05-25 00:24:18,118 [podnet.py] => Task 8, Epoch 86/160 (LR 0.04412) => LSC_loss 0.38, Spatial_loss 1.57, Flat_loss 0.30, Train_acc 91.73, Test_acc 32.03
2022-05-25 00:24:22,210 [podnet.py] => Task 8, Epoch 87/160 (LR 0.04315) => LSC_loss 0.39, Spatial_loss 1.58, Flat_loss 0.30, Train_acc 91.44, Test_acc 32.06
2022-05-25 00:24:26,489 [podnet.py] => Task 8, Epoch 88/160 (LR 0.04218) => LSC_loss 0.35, Spatial_loss 1.58, Flat_loss 0.30, Train_acc 92.94, Test_acc 35.60
2022-05-25 00:24:30,559 [podnet.py] => Task 8, Epoch 89/160 (LR 0.04121) => LSC_loss 0.36, Spatial_loss 1.52, Flat_loss 0.29, Train_acc 92.46, Test_acc 33.80
2022-05-25 00:24:34,814 [podnet.py] => Task 8, Epoch 90/160 (LR 0.04025) => LSC_loss 0.34, Spatial_loss 1.55, Flat_loss 0.30, Train_acc 93.19, Test_acc 32.99
2022-05-25 00:24:38,775 [podnet.py] => Task 8, Epoch 91/160 (LR 0.03928) => LSC_loss 0.36, Spatial_loss 1.54, Flat_loss 0.30, Train_acc 92.49, Test_acc 30.46
2022-05-25 00:24:42,744 [podnet.py] => Task 8, Epoch 92/160 (LR 0.03833) => LSC_loss 0.36, Spatial_loss 1.57, Flat_loss 0.29, Train_acc 92.31, Test_acc 31.88
2022-05-25 00:24:46,785 [podnet.py] => Task 8, Epoch 93/160 (LR 0.03738) => LSC_loss 0.36, Spatial_loss 1.54, Flat_loss 0.29, Train_acc 92.79, Test_acc 33.40
2022-05-25 00:24:50,792 [podnet.py] => Task 8, Epoch 94/160 (LR 0.03643) => LSC_loss 0.34, Spatial_loss 1.51, Flat_loss 0.29, Train_acc 93.07, Test_acc 35.92
2022-05-25 00:24:54,745 [podnet.py] => Task 8, Epoch 95/160 (LR 0.03549) => LSC_loss 0.33, Spatial_loss 1.51, Flat_loss 0.29, Train_acc 93.53, Test_acc 35.16
2022-05-25 00:24:58,927 [podnet.py] => Task 8, Epoch 96/160 (LR 0.03455) => LSC_loss 0.32, Spatial_loss 1.48, Flat_loss 0.28, Train_acc 93.89, Test_acc 37.02
2022-05-25 00:25:03,005 [podnet.py] => Task 8, Epoch 97/160 (LR 0.03362) => LSC_loss 0.32, Spatial_loss 1.49, Flat_loss 0.29, Train_acc 93.56, Test_acc 32.23
2022-05-25 00:25:07,277 [podnet.py] => Task 8, Epoch 98/160 (LR 0.03269) => LSC_loss 0.33, Spatial_loss 1.47, Flat_loss 0.28, Train_acc 93.41, Test_acc 31.03
2022-05-25 00:25:11,366 [podnet.py] => Task 8, Epoch 99/160 (LR 0.03178) => LSC_loss 0.32, Spatial_loss 1.44, Flat_loss 0.28, Train_acc 94.21, Test_acc 32.83
2022-05-25 00:25:15,616 [podnet.py] => Task 8, Epoch 100/160 (LR 0.03087) => LSC_loss 0.31, Spatial_loss 1.47, Flat_loss 0.28, Train_acc 94.14, Test_acc 35.32
2022-05-25 00:25:19,916 [podnet.py] => Task 8, Epoch 101/160 (LR 0.02996) => LSC_loss 0.30, Spatial_loss 1.46, Flat_loss 0.28, Train_acc 94.64, Test_acc 33.27
2022-05-25 00:25:23,931 [podnet.py] => Task 8, Epoch 102/160 (LR 0.02907) => LSC_loss 0.31, Spatial_loss 1.42, Flat_loss 0.28, Train_acc 94.07, Test_acc 35.69
2022-05-25 00:25:28,060 [podnet.py] => Task 8, Epoch 103/160 (LR 0.02818) => LSC_loss 0.30, Spatial_loss 1.46, Flat_loss 0.28, Train_acc 94.19, Test_acc 35.78
2022-05-25 00:25:32,257 [podnet.py] => Task 8, Epoch 104/160 (LR 0.02730) => LSC_loss 0.30, Spatial_loss 1.41, Flat_loss 0.27, Train_acc 94.53, Test_acc 35.60
2022-05-25 00:25:36,343 [podnet.py] => Task 8, Epoch 105/160 (LR 0.02643) => LSC_loss 0.27, Spatial_loss 1.39, Flat_loss 0.27, Train_acc 95.40, Test_acc 35.53
2022-05-25 00:25:40,398 [podnet.py] => Task 8, Epoch 106/160 (LR 0.02557) => LSC_loss 0.27, Spatial_loss 1.35, Flat_loss 0.27, Train_acc 95.40, Test_acc 37.18
2022-05-25 00:25:44,419 [podnet.py] => Task 8, Epoch 107/160 (LR 0.02472) => LSC_loss 0.27, Spatial_loss 1.34, Flat_loss 0.27, Train_acc 95.40, Test_acc 36.02
2022-05-25 00:25:48,413 [podnet.py] => Task 8, Epoch 108/160 (LR 0.02388) => LSC_loss 0.27, Spatial_loss 1.38, Flat_loss 0.27, Train_acc 95.03, Test_acc 35.43
2022-05-25 00:25:52,451 [podnet.py] => Task 8, Epoch 109/160 (LR 0.02304) => LSC_loss 0.27, Spatial_loss 1.36, Flat_loss 0.26, Train_acc 95.23, Test_acc 34.92
2022-05-25 00:25:56,565 [podnet.py] => Task 8, Epoch 110/160 (LR 0.02222) => LSC_loss 0.27, Spatial_loss 1.38, Flat_loss 0.27, Train_acc 95.29, Test_acc 33.06
2022-05-25 00:26:00,578 [podnet.py] => Task 8, Epoch 111/160 (LR 0.02141) => LSC_loss 0.27, Spatial_loss 1.35, Flat_loss 0.26, Train_acc 95.27, Test_acc 35.49
2022-05-25 00:26:04,642 [podnet.py] => Task 8, Epoch 112/160 (LR 0.02061) => LSC_loss 0.25, Spatial_loss 1.32, Flat_loss 0.26, Train_acc 95.89, Test_acc 35.22
2022-05-25 00:26:08,716 [podnet.py] => Task 8, Epoch 113/160 (LR 0.01982) => LSC_loss 0.25, Spatial_loss 1.33, Flat_loss 0.26, Train_acc 96.27, Test_acc 33.76
2022-05-25 00:26:12,854 [podnet.py] => Task 8, Epoch 114/160 (LR 0.01905) => LSC_loss 0.26, Spatial_loss 1.32, Flat_loss 0.26, Train_acc 95.93, Test_acc 33.24
2022-05-25 00:26:17,098 [podnet.py] => Task 8, Epoch 115/160 (LR 0.01828) => LSC_loss 0.25, Spatial_loss 1.30, Flat_loss 0.26, Train_acc 96.03, Test_acc 35.19
2022-05-25 00:26:21,107 [podnet.py] => Task 8, Epoch 116/160 (LR 0.01753) => LSC_loss 0.25, Spatial_loss 1.27, Flat_loss 0.25, Train_acc 96.10, Test_acc 33.41
2022-05-25 00:26:25,217 [podnet.py] => Task 8, Epoch 117/160 (LR 0.01679) => LSC_loss 0.25, Spatial_loss 1.30, Flat_loss 0.26, Train_acc 96.19, Test_acc 34.69
2022-05-25 00:26:29,337 [podnet.py] => Task 8, Epoch 118/160 (LR 0.01606) => LSC_loss 0.24, Spatial_loss 1.26, Flat_loss 0.25, Train_acc 96.23, Test_acc 34.87
2022-05-25 00:26:33,325 [podnet.py] => Task 8, Epoch 119/160 (LR 0.01535) => LSC_loss 0.23, Spatial_loss 1.25, Flat_loss 0.25, Train_acc 97.06, Test_acc 35.70
2022-05-25 00:26:37,363 [podnet.py] => Task 8, Epoch 120/160 (LR 0.01464) => LSC_loss 0.23, Spatial_loss 1.25, Flat_loss 0.25, Train_acc 96.54, Test_acc 35.18
2022-05-25 00:26:41,385 [podnet.py] => Task 8, Epoch 121/160 (LR 0.01396) => LSC_loss 0.23, Spatial_loss 1.25, Flat_loss 0.25, Train_acc 96.89, Test_acc 36.47
2022-05-25 00:26:45,385 [podnet.py] => Task 8, Epoch 122/160 (LR 0.01328) => LSC_loss 0.23, Spatial_loss 1.21, Flat_loss 0.24, Train_acc 96.57, Test_acc 36.86
2022-05-25 00:26:49,379 [podnet.py] => Task 8, Epoch 123/160 (LR 0.01262) => LSC_loss 0.23, Spatial_loss 1.22, Flat_loss 0.25, Train_acc 96.96, Test_acc 36.92
2022-05-25 00:26:53,543 [podnet.py] => Task 8, Epoch 124/160 (LR 0.01198) => LSC_loss 0.22, Spatial_loss 1.21, Flat_loss 0.24, Train_acc 97.23, Test_acc 36.03
2022-05-25 00:26:57,604 [podnet.py] => Task 8, Epoch 125/160 (LR 0.01135) => LSC_loss 0.22, Spatial_loss 1.19, Flat_loss 0.24, Train_acc 97.53, Test_acc 36.29
2022-05-25 00:27:01,730 [podnet.py] => Task 8, Epoch 126/160 (LR 0.01073) => LSC_loss 0.23, Spatial_loss 1.22, Flat_loss 0.24, Train_acc 96.81, Test_acc 38.17
2022-05-25 00:27:05,758 [podnet.py] => Task 8, Epoch 127/160 (LR 0.01013) => LSC_loss 0.21, Spatial_loss 1.18, Flat_loss 0.24, Train_acc 97.34, Test_acc 36.04
2022-05-25 00:27:09,860 [podnet.py] => Task 8, Epoch 128/160 (LR 0.00955) => LSC_loss 0.22, Spatial_loss 1.13, Flat_loss 0.24, Train_acc 97.41, Test_acc 36.82
2022-05-25 00:27:13,870 [podnet.py] => Task 8, Epoch 129/160 (LR 0.00898) => LSC_loss 0.21, Spatial_loss 1.16, Flat_loss 0.24, Train_acc 97.69, Test_acc 36.66
2022-05-25 00:27:17,950 [podnet.py] => Task 8, Epoch 130/160 (LR 0.00843) => LSC_loss 0.21, Spatial_loss 1.14, Flat_loss 0.23, Train_acc 97.71, Test_acc 37.33
2022-05-25 00:27:22,111 [podnet.py] => Task 8, Epoch 131/160 (LR 0.00789) => LSC_loss 0.21, Spatial_loss 1.14, Flat_loss 0.24, Train_acc 97.50, Test_acc 36.92
2022-05-25 00:27:26,129 [podnet.py] => Task 8, Epoch 132/160 (LR 0.00737) => LSC_loss 0.21, Spatial_loss 1.17, Flat_loss 0.24, Train_acc 97.66, Test_acc 36.39
2022-05-25 00:27:30,365 [podnet.py] => Task 8, Epoch 133/160 (LR 0.00686) => LSC_loss 0.21, Spatial_loss 1.13, Flat_loss 0.23, Train_acc 97.59, Test_acc 35.32
2022-05-25 00:27:34,456 [podnet.py] => Task 8, Epoch 134/160 (LR 0.00638) => LSC_loss 0.21, Spatial_loss 1.12, Flat_loss 0.23, Train_acc 97.63, Test_acc 37.43
2022-05-25 00:27:38,465 [podnet.py] => Task 8, Epoch 135/160 (LR 0.00590) => LSC_loss 0.21, Spatial_loss 1.11, Flat_loss 0.23, Train_acc 97.70, Test_acc 37.24
2022-05-25 00:27:42,630 [podnet.py] => Task 8, Epoch 136/160 (LR 0.00545) => LSC_loss 0.20, Spatial_loss 1.07, Flat_loss 0.23, Train_acc 97.94, Test_acc 36.71
2022-05-25 00:27:46,965 [podnet.py] => Task 8, Epoch 137/160 (LR 0.00501) => LSC_loss 0.19, Spatial_loss 1.09, Flat_loss 0.23, Train_acc 98.37, Test_acc 37.36
2022-05-25 00:27:51,247 [podnet.py] => Task 8, Epoch 138/160 (LR 0.00459) => LSC_loss 0.20, Spatial_loss 1.08, Flat_loss 0.23, Train_acc 97.89, Test_acc 36.20
2022-05-25 00:27:55,337 [podnet.py] => Task 8, Epoch 139/160 (LR 0.00419) => LSC_loss 0.20, Spatial_loss 1.10, Flat_loss 0.23, Train_acc 97.71, Test_acc 37.03
2022-05-25 00:27:59,518 [podnet.py] => Task 8, Epoch 140/160 (LR 0.00381) => LSC_loss 0.20, Spatial_loss 1.07, Flat_loss 0.23, Train_acc 98.00, Test_acc 37.22
2022-05-25 00:28:03,702 [podnet.py] => Task 8, Epoch 141/160 (LR 0.00344) => LSC_loss 0.20, Spatial_loss 1.08, Flat_loss 0.23, Train_acc 97.94, Test_acc 37.42
2022-05-25 00:28:07,909 [podnet.py] => Task 8, Epoch 142/160 (LR 0.00309) => LSC_loss 0.19, Spatial_loss 1.05, Flat_loss 0.22, Train_acc 98.16, Test_acc 37.48
2022-05-25 00:28:12,062 [podnet.py] => Task 8, Epoch 143/160 (LR 0.00276) => LSC_loss 0.20, Spatial_loss 1.03, Flat_loss 0.22, Train_acc 98.04, Test_acc 36.13
2022-05-25 00:28:16,153 [podnet.py] => Task 8, Epoch 144/160 (LR 0.00245) => LSC_loss 0.19, Spatial_loss 1.04, Flat_loss 0.22, Train_acc 98.39, Test_acc 36.54
2022-05-25 00:28:20,337 [podnet.py] => Task 8, Epoch 145/160 (LR 0.00215) => LSC_loss 0.20, Spatial_loss 1.05, Flat_loss 0.22, Train_acc 98.14, Test_acc 37.16
2022-05-25 00:28:24,516 [podnet.py] => Task 8, Epoch 146/160 (LR 0.00188) => LSC_loss 0.19, Spatial_loss 1.04, Flat_loss 0.22, Train_acc 98.04, Test_acc 37.52
2022-05-25 00:28:28,743 [podnet.py] => Task 8, Epoch 147/160 (LR 0.00162) => LSC_loss 0.19, Spatial_loss 1.04, Flat_loss 0.22, Train_acc 98.30, Test_acc 37.79
2022-05-25 00:28:33,046 [podnet.py] => Task 8, Epoch 148/160 (LR 0.00138) => LSC_loss 0.19, Spatial_loss 1.03, Flat_loss 0.22, Train_acc 98.31, Test_acc 36.97
2022-05-25 00:28:37,265 [podnet.py] => Task 8, Epoch 149/160 (LR 0.00116) => LSC_loss 0.19, Spatial_loss 1.02, Flat_loss 0.22, Train_acc 98.21, Test_acc 37.11
2022-05-25 00:28:41,709 [podnet.py] => Task 8, Epoch 150/160 (LR 0.00096) => LSC_loss 0.18, Spatial_loss 1.02, Flat_loss 0.22, Train_acc 98.56, Test_acc 37.21
2022-05-25 00:28:45,927 [podnet.py] => Task 8, Epoch 151/160 (LR 0.00078) => LSC_loss 0.19, Spatial_loss 0.99, Flat_loss 0.22, Train_acc 98.16, Test_acc 37.32
2022-05-25 00:28:49,949 [podnet.py] => Task 8, Epoch 152/160 (LR 0.00062) => LSC_loss 0.19, Spatial_loss 1.00, Flat_loss 0.22, Train_acc 98.29, Test_acc 37.23
2022-05-25 00:28:54,055 [podnet.py] => Task 8, Epoch 153/160 (LR 0.00047) => LSC_loss 0.18, Spatial_loss 1.00, Flat_loss 0.22, Train_acc 98.56, Test_acc 37.30
2022-05-25 00:28:58,105 [podnet.py] => Task 8, Epoch 154/160 (LR 0.00035) => LSC_loss 0.19, Spatial_loss 1.01, Flat_loss 0.22, Train_acc 98.11, Test_acc 37.12
2022-05-25 00:29:02,343 [podnet.py] => Task 8, Epoch 155/160 (LR 0.00024) => LSC_loss 0.18, Spatial_loss 1.00, Flat_loss 0.22, Train_acc 98.47, Test_acc 37.30
2022-05-25 00:29:06,398 [podnet.py] => Task 8, Epoch 156/160 (LR 0.00015) => LSC_loss 0.18, Spatial_loss 1.01, Flat_loss 0.22, Train_acc 98.44, Test_acc 37.20
2022-05-25 00:29:10,686 [podnet.py] => Task 8, Epoch 157/160 (LR 0.00009) => LSC_loss 0.19, Spatial_loss 1.01, Flat_loss 0.22, Train_acc 98.14, Test_acc 37.06
2022-05-25 00:29:14,984 [podnet.py] => Task 8, Epoch 158/160 (LR 0.00004) => LSC_loss 0.19, Spatial_loss 0.99, Flat_loss 0.22, Train_acc 98.14, Test_acc 37.24
2022-05-25 00:29:19,318 [podnet.py] => Task 8, Epoch 159/160 (LR 0.00001) => LSC_loss 0.18, Spatial_loss 1.01, Flat_loss 0.22, Train_acc 98.60, Test_acc 37.07
2022-05-25 00:29:23,561 [podnet.py] => Task 8, Epoch 160/160 (LR 0.00000) => LSC_loss 0.19, Spatial_loss 1.00, Flat_loss 0.22, Train_acc 98.56, Test_acc 37.23
2022-05-25 00:29:23,561 [podnet.py] => Finetune the network (classifier part) with the undersampled dataset!
2022-05-25 00:29:23,561 [base.py] => Reducing exemplars...(25 per classes)
2022-05-25 00:29:42,165 [base.py] => Constructing exemplars...(25 per classes)
2022-05-25 00:29:48,688 [podnet.py] => The size of finetune dataset: 2250
2022-05-25 00:29:51,067 [podnet.py] => Task 8, Epoch 1/20 (LR 0.00497) => LSC_loss 0.23, Spatial_loss 1.11, Flat_loss 0.15, Train_acc 96.62, Test_acc 40.94
2022-05-25 00:29:53,378 [podnet.py] => Task 8, Epoch 2/20 (LR 0.00488) => LSC_loss 0.15, Spatial_loss 1.08, Flat_loss 0.13, Train_acc 98.84, Test_acc 39.66
2022-05-25 00:29:55,910 [podnet.py] => Task 8, Epoch 3/20 (LR 0.00473) => LSC_loss 0.15, Spatial_loss 1.08, Flat_loss 0.12, Train_acc 98.89, Test_acc 40.06
2022-05-25 00:29:58,425 [podnet.py] => Task 8, Epoch 4/20 (LR 0.00452) => LSC_loss 0.15, Spatial_loss 1.06, Flat_loss 0.12, Train_acc 99.07, Test_acc 39.61
2022-05-25 00:30:00,668 [podnet.py] => Task 8, Epoch 5/20 (LR 0.00427) => LSC_loss 0.14, Spatial_loss 1.04, Flat_loss 0.12, Train_acc 99.11, Test_acc 39.71
2022-05-25 00:30:02,901 [podnet.py] => Task 8, Epoch 6/20 (LR 0.00397) => LSC_loss 0.14, Spatial_loss 1.03, Flat_loss 0.12, Train_acc 98.98, Test_acc 39.46
2022-05-25 00:30:05,250 [podnet.py] => Task 8, Epoch 7/20 (LR 0.00363) => LSC_loss 0.14, Spatial_loss 1.05, Flat_loss 0.12, Train_acc 99.07, Test_acc 40.46
2022-05-25 00:30:07,527 [podnet.py] => Task 8, Epoch 8/20 (LR 0.00327) => LSC_loss 0.14, Spatial_loss 1.04, Flat_loss 0.11, Train_acc 99.11, Test_acc 39.93
2022-05-25 00:30:09,908 [podnet.py] => Task 8, Epoch 9/20 (LR 0.00289) => LSC_loss 0.14, Spatial_loss 1.03, Flat_loss 0.11, Train_acc 99.11, Test_acc 40.04
2022-05-25 00:30:12,213 [podnet.py] => Task 8, Epoch 10/20 (LR 0.00250) => LSC_loss 0.14, Spatial_loss 1.03, Flat_loss 0.11, Train_acc 99.16, Test_acc 40.46
2022-05-25 00:30:14,676 [podnet.py] => Task 8, Epoch 11/20 (LR 0.00211) => LSC_loss 0.13, Spatial_loss 1.03, Flat_loss 0.11, Train_acc 99.07, Test_acc 40.38
2022-05-25 00:30:17,071 [podnet.py] => Task 8, Epoch 12/20 (LR 0.00173) => LSC_loss 0.14, Spatial_loss 1.05, Flat_loss 0.11, Train_acc 99.11, Test_acc 40.06
2022-05-25 00:30:19,559 [podnet.py] => Task 8, Epoch 13/20 (LR 0.00137) => LSC_loss 0.13, Spatial_loss 1.02, Flat_loss 0.11, Train_acc 99.29, Test_acc 40.43
2022-05-25 00:30:21,882 [podnet.py] => Task 8, Epoch 14/20 (LR 0.00103) => LSC_loss 0.13, Spatial_loss 0.99, Flat_loss 0.11, Train_acc 99.33, Test_acc 40.11
2022-05-25 00:30:24,171 [podnet.py] => Task 8, Epoch 15/20 (LR 0.00073) => LSC_loss 0.13, Spatial_loss 0.96, Flat_loss 0.11, Train_acc 99.20, Test_acc 40.26
2022-05-25 00:30:26,507 [podnet.py] => Task 8, Epoch 16/20 (LR 0.00048) => LSC_loss 0.14, Spatial_loss 0.99, Flat_loss 0.11, Train_acc 99.11, Test_acc 40.03
2022-05-25 00:30:28,807 [podnet.py] => Task 8, Epoch 17/20 (LR 0.00027) => LSC_loss 0.13, Spatial_loss 0.97, Flat_loss 0.11, Train_acc 99.42, Test_acc 40.28
2022-05-25 00:30:31,124 [podnet.py] => Task 8, Epoch 18/20 (LR 0.00012) => LSC_loss 0.13, Spatial_loss 0.99, Flat_loss 0.11, Train_acc 99.56, Test_acc 40.32
2022-05-25 00:30:33,334 [podnet.py] => Task 8, Epoch 19/20 (LR 0.00003) => LSC_loss 0.13, Spatial_loss 0.93, Flat_loss 0.11, Train_acc 99.24, Test_acc 40.21
2022-05-25 00:30:35,640 [podnet.py] => Task 8, Epoch 20/20 (LR 0.00000) => LSC_loss 0.14, Spatial_loss 0.99, Flat_loss 0.11, Train_acc 99.33, Test_acc 40.18
2022-05-25 00:30:35,643 [base.py] => Reducing exemplars...(22 per classes)
2022-05-25 00:30:52,957 [base.py] => Constructing exemplars...(22 per classes)
2022-05-25 00:31:01,699 [podnet.py] => Exemplar size: 1980
2022-05-25 00:31:01,699 [trainer.py] => CNN: {'total': 40.18, '00-09': 55.1, '10-19': 19.5, '20-29': 34.6, '30-39': 28.5, '40-49': 43.0, '50-59': 30.6, '60-69': 41.4, '70-79': 43.6, '80-89': 65.3, 'old': 37.04, 'new': 65.3}
2022-05-25 00:31:01,699 [trainer.py] => NME: {'total': 39.83, '00-09': 61.7, '10-19': 18.3, '20-29': 34.5, '30-39': 29.9, '40-49': 41.6, '50-59': 28.5, '60-69': 41.7, '70-79': 43.5, '80-89': 58.8, 'old': 37.46, 'new': 58.8}
2022-05-25 00:31:01,699 [trainer.py] => CNN top1 curve: [90.7, 72.95, 65.47, 57.8, 53.9, 49.75, 47.14, 43.7, 40.18]
2022-05-25 00:31:01,699 [trainer.py] => CNN top5 curve: [99.2, 93.95, 90.1, 85.15, 81.78, 78.42, 76.86, 73.58, 70.63]
2022-05-25 00:31:01,700 [trainer.py] => NME top1 curve: [90.8, 72.05, 63.37, 55.7, 52.92, 48.87, 45.64, 42.5, 39.83]
2022-05-25 00:31:01,700 [trainer.py] => NME top5 curve: [99.3, 92.8, 88.93, 83.38, 81.2, 77.87, 75.76, 72.41, 69.54]

2022-05-25 00:31:01,700 [trainer.py] => All params: 523857
2022-05-25 00:31:01,700 [trainer.py] => Trainable params: 523857
2022-05-25 00:31:01,701 [podnet.py] => Learning on 90-100
2022-05-25 00:31:01,765 [podnet.py] => Adaptive factor: 3.1622776601683795
2022-05-25 00:31:06,089 [podnet.py] => Task 9, Epoch 1/160 (LR 0.09999) => LSC_loss 2.87, Spatial_loss 3.35, Flat_loss 1.16, Train_acc 43.21, Test_acc 17.40
2022-05-25 00:31:10,320 [podnet.py] => Task 9, Epoch 2/160 (LR 0.09996) => LSC_loss 1.68, Spatial_loss 2.88, Flat_loss 0.69, Train_acc 55.39, Test_acc 26.88
2022-05-25 00:31:14,772 [podnet.py] => Task 9, Epoch 3/160 (LR 0.09991) => LSC_loss 1.47, Spatial_loss 2.70, Flat_loss 0.56, Train_acc 60.52, Test_acc 22.02
2022-05-25 00:31:19,038 [podnet.py] => Task 9, Epoch 4/160 (LR 0.09985) => LSC_loss 1.39, Spatial_loss 2.55, Flat_loss 0.50, Train_acc 62.01, Test_acc 29.85
2022-05-25 00:31:23,285 [podnet.py] => Task 9, Epoch 5/160 (LR 0.09976) => LSC_loss 1.28, Spatial_loss 2.47, Flat_loss 0.47, Train_acc 65.62, Test_acc 27.99
2022-05-25 00:31:27,493 [podnet.py] => Task 9, Epoch 6/160 (LR 0.09965) => LSC_loss 1.25, Spatial_loss 2.45, Flat_loss 0.45, Train_acc 65.82, Test_acc 26.60
2022-05-25 00:31:31,708 [podnet.py] => Task 9, Epoch 7/160 (LR 0.09953) => LSC_loss 1.20, Spatial_loss 2.44, Flat_loss 0.44, Train_acc 67.45, Test_acc 25.28
2022-05-25 00:31:35,841 [podnet.py] => Task 9, Epoch 8/160 (LR 0.09938) => LSC_loss 1.17, Spatial_loss 2.41, Flat_loss 0.44, Train_acc 68.37, Test_acc 28.27
2022-05-25 00:31:40,299 [podnet.py] => Task 9, Epoch 9/160 (LR 0.09922) => LSC_loss 1.11, Spatial_loss 2.36, Flat_loss 0.42, Train_acc 70.23, Test_acc 27.50
2022-05-25 00:31:44,788 [podnet.py] => Task 9, Epoch 10/160 (LR 0.09904) => LSC_loss 1.11, Spatial_loss 2.29, Flat_loss 0.42, Train_acc 70.32, Test_acc 23.64
2022-05-25 00:31:48,926 [podnet.py] => Task 9, Epoch 11/160 (LR 0.09884) => LSC_loss 1.06, Spatial_loss 2.27, Flat_loss 0.41, Train_acc 71.76, Test_acc 24.84
2022-05-25 00:31:53,132 [podnet.py] => Task 9, Epoch 12/160 (LR 0.09862) => LSC_loss 1.08, Spatial_loss 2.37, Flat_loss 0.42, Train_acc 70.80, Test_acc 29.07
2022-05-25 00:31:57,529 [podnet.py] => Task 9, Epoch 13/160 (LR 0.09838) => LSC_loss 1.01, Spatial_loss 2.35, Flat_loss 0.41, Train_acc 73.72, Test_acc 30.31
2022-05-25 00:32:01,870 [podnet.py] => Task 9, Epoch 14/160 (LR 0.09812) => LSC_loss 0.97, Spatial_loss 2.22, Flat_loss 0.40, Train_acc 74.26, Test_acc 25.32
2022-05-25 00:32:06,091 [podnet.py] => Task 9, Epoch 15/160 (LR 0.09785) => LSC_loss 1.02, Spatial_loss 2.31, Flat_loss 0.41, Train_acc 72.45, Test_acc 24.22
2022-05-25 00:32:10,356 [podnet.py] => Task 9, Epoch 16/160 (LR 0.09755) => LSC_loss 0.95, Spatial_loss 2.22, Flat_loss 0.40, Train_acc 74.77, Test_acc 31.27
2022-05-25 00:32:14,808 [podnet.py] => Task 9, Epoch 17/160 (LR 0.09724) => LSC_loss 0.95, Spatial_loss 2.26, Flat_loss 0.40, Train_acc 74.96, Test_acc 30.04
2022-05-25 00:32:18,908 [podnet.py] => Task 9, Epoch 18/160 (LR 0.09691) => LSC_loss 0.93, Spatial_loss 2.27, Flat_loss 0.40, Train_acc 75.09, Test_acc 29.48
2022-05-25 00:32:23,236 [podnet.py] => Task 9, Epoch 19/160 (LR 0.09656) => LSC_loss 0.91, Spatial_loss 2.25, Flat_loss 0.40, Train_acc 75.90, Test_acc 26.15
2022-05-25 00:32:27,604 [podnet.py] => Task 9, Epoch 20/160 (LR 0.09619) => LSC_loss 0.91, Spatial_loss 2.27, Flat_loss 0.40, Train_acc 75.57, Test_acc 25.92
2022-05-25 00:32:31,812 [podnet.py] => Task 9, Epoch 21/160 (LR 0.09581) => LSC_loss 0.98, Spatial_loss 2.34, Flat_loss 0.42, Train_acc 74.74, Test_acc 23.75
2022-05-25 00:32:35,993 [podnet.py] => Task 9, Epoch 22/160 (LR 0.09541) => LSC_loss 0.91, Spatial_loss 2.23, Flat_loss 0.40, Train_acc 76.39, Test_acc 27.55
2022-05-25 00:32:40,373 [podnet.py] => Task 9, Epoch 23/160 (LR 0.09499) => LSC_loss 0.86, Spatial_loss 2.26, Flat_loss 0.40, Train_acc 77.51, Test_acc 27.95
2022-05-25 00:32:44,757 [podnet.py] => Task 9, Epoch 24/160 (LR 0.09455) => LSC_loss 0.90, Spatial_loss 2.32, Flat_loss 0.40, Train_acc 75.90, Test_acc 27.83
2022-05-25 00:32:49,047 [podnet.py] => Task 9, Epoch 25/160 (LR 0.09410) => LSC_loss 0.86, Spatial_loss 2.20, Flat_loss 0.40, Train_acc 77.74, Test_acc 30.20
2022-05-25 00:32:53,277 [podnet.py] => Task 9, Epoch 26/160 (LR 0.09362) => LSC_loss 0.85, Spatial_loss 2.22, Flat_loss 0.39, Train_acc 76.93, Test_acc 26.74
2022-05-25 00:32:57,713 [podnet.py] => Task 9, Epoch 27/160 (LR 0.09314) => LSC_loss 0.80, Spatial_loss 2.15, Flat_loss 0.39, Train_acc 79.40, Test_acc 20.57
2022-05-25 00:33:02,155 [podnet.py] => Task 9, Epoch 28/160 (LR 0.09263) => LSC_loss 0.85, Spatial_loss 2.20, Flat_loss 0.40, Train_acc 77.34, Test_acc 29.88
2022-05-25 00:33:06,418 [podnet.py] => Task 9, Epoch 29/160 (LR 0.09211) => LSC_loss 0.79, Spatial_loss 2.14, Flat_loss 0.38, Train_acc 78.74, Test_acc 29.24
2022-05-25 00:33:10,551 [podnet.py] => Task 9, Epoch 30/160 (LR 0.09157) => LSC_loss 0.82, Spatial_loss 2.19, Flat_loss 0.40, Train_acc 78.45, Test_acc 26.44
2022-05-25 00:33:14,778 [podnet.py] => Task 9, Epoch 31/160 (LR 0.09102) => LSC_loss 0.81, Spatial_loss 2.20, Flat_loss 0.39, Train_acc 78.28, Test_acc 28.40
2022-05-25 00:33:19,058 [podnet.py] => Task 9, Epoch 32/160 (LR 0.09045) => LSC_loss 0.80, Spatial_loss 2.20, Flat_loss 0.40, Train_acc 79.01, Test_acc 26.97
2022-05-25 00:33:23,412 [podnet.py] => Task 9, Epoch 33/160 (LR 0.08987) => LSC_loss 0.80, Spatial_loss 2.18, Flat_loss 0.40, Train_acc 78.94, Test_acc 30.98
2022-05-25 00:33:27,674 [podnet.py] => Task 9, Epoch 34/160 (LR 0.08927) => LSC_loss 0.76, Spatial_loss 2.13, Flat_loss 0.39, Train_acc 79.74, Test_acc 31.01
2022-05-25 00:33:31,696 [podnet.py] => Task 9, Epoch 35/160 (LR 0.08865) => LSC_loss 0.75, Spatial_loss 2.11, Flat_loss 0.38, Train_acc 80.97, Test_acc 30.43
2022-05-25 00:33:35,895 [podnet.py] => Task 9, Epoch 36/160 (LR 0.08802) => LSC_loss 0.76, Spatial_loss 2.12, Flat_loss 0.38, Train_acc 79.63, Test_acc 27.61
2022-05-25 00:33:40,250 [podnet.py] => Task 9, Epoch 37/160 (LR 0.08738) => LSC_loss 0.75, Spatial_loss 2.16, Flat_loss 0.39, Train_acc 80.54, Test_acc 30.23
2022-05-25 00:33:44,548 [podnet.py] => Task 9, Epoch 38/160 (LR 0.08672) => LSC_loss 0.75, Spatial_loss 2.14, Flat_loss 0.39, Train_acc 80.80, Test_acc 24.80
2022-05-25 00:33:48,623 [podnet.py] => Task 9, Epoch 39/160 (LR 0.08604) => LSC_loss 0.73, Spatial_loss 2.13, Flat_loss 0.39, Train_acc 80.96, Test_acc 27.26
2022-05-25 00:33:52,823 [podnet.py] => Task 9, Epoch 40/160 (LR 0.08536) => LSC_loss 0.73, Spatial_loss 2.12, Flat_loss 0.39, Train_acc 81.43, Test_acc 26.83
2022-05-25 00:33:57,184 [podnet.py] => Task 9, Epoch 41/160 (LR 0.08465) => LSC_loss 0.73, Spatial_loss 2.17, Flat_loss 0.39, Train_acc 81.13, Test_acc 27.19
2022-05-25 00:34:01,243 [podnet.py] => Task 9, Epoch 42/160 (LR 0.08394) => LSC_loss 0.70, Spatial_loss 2.10, Flat_loss 0.39, Train_acc 81.60, Test_acc 25.77
2022-05-25 00:34:05,239 [podnet.py] => Task 9, Epoch 43/160 (LR 0.08321) => LSC_loss 0.70, Spatial_loss 2.13, Flat_loss 0.39, Train_acc 81.35, Test_acc 28.62
2022-05-25 00:34:09,429 [podnet.py] => Task 9, Epoch 44/160 (LR 0.08247) => LSC_loss 0.70, Spatial_loss 2.11, Flat_loss 0.39, Train_acc 81.88, Test_acc 26.65
2022-05-25 00:34:13,711 [podnet.py] => Task 9, Epoch 45/160 (LR 0.08172) => LSC_loss 0.74, Spatial_loss 2.16, Flat_loss 0.39, Train_acc 80.52, Test_acc 28.42
2022-05-25 00:34:17,777 [podnet.py] => Task 9, Epoch 46/160 (LR 0.08095) => LSC_loss 0.71, Spatial_loss 2.16, Flat_loss 0.39, Train_acc 81.45, Test_acc 29.73
2022-05-25 00:34:22,057 [podnet.py] => Task 9, Epoch 47/160 (LR 0.08018) => LSC_loss 0.72, Spatial_loss 2.11, Flat_loss 0.39, Train_acc 80.85, Test_acc 29.72
2022-05-25 00:34:26,228 [podnet.py] => Task 9, Epoch 48/160 (LR 0.07939) => LSC_loss 0.66, Spatial_loss 2.07, Flat_loss 0.38, Train_acc 83.02, Test_acc 29.76
2022-05-25 00:34:30,390 [podnet.py] => Task 9, Epoch 49/160 (LR 0.07859) => LSC_loss 0.66, Spatial_loss 2.09, Flat_loss 0.38, Train_acc 82.97, Test_acc 27.88
2022-05-25 00:34:34,704 [podnet.py] => Task 9, Epoch 50/160 (LR 0.07778) => LSC_loss 0.68, Spatial_loss 2.14, Flat_loss 0.39, Train_acc 82.38, Test_acc 27.04
2022-05-25 00:34:38,825 [podnet.py] => Task 9, Epoch 51/160 (LR 0.07696) => LSC_loss 0.69, Spatial_loss 2.08, Flat_loss 0.38, Train_acc 82.41, Test_acc 28.19
2022-05-25 00:34:43,026 [podnet.py] => Task 9, Epoch 52/160 (LR 0.07612) => LSC_loss 0.66, Spatial_loss 2.14, Flat_loss 0.38, Train_acc 83.37, Test_acc 31.05
2022-05-25 00:34:47,200 [podnet.py] => Task 9, Epoch 53/160 (LR 0.07528) => LSC_loss 0.61, Spatial_loss 2.05, Flat_loss 0.37, Train_acc 83.94, Test_acc 26.20
2022-05-25 00:34:51,265 [podnet.py] => Task 9, Epoch 54/160 (LR 0.07443) => LSC_loss 0.67, Spatial_loss 2.09, Flat_loss 0.38, Train_acc 82.26, Test_acc 30.76
2022-05-25 00:34:55,429 [podnet.py] => Task 9, Epoch 55/160 (LR 0.07357) => LSC_loss 0.64, Spatial_loss 2.07, Flat_loss 0.38, Train_acc 83.21, Test_acc 26.94
2022-05-25 00:34:59,682 [podnet.py] => Task 9, Epoch 56/160 (LR 0.07270) => LSC_loss 0.64, Spatial_loss 2.07, Flat_loss 0.38, Train_acc 82.95, Test_acc 29.85
2022-05-25 00:35:03,774 [podnet.py] => Task 9, Epoch 57/160 (LR 0.07182) => LSC_loss 0.62, Spatial_loss 2.05, Flat_loss 0.38, Train_acc 83.94, Test_acc 29.57
2022-05-25 00:35:07,837 [podnet.py] => Task 9, Epoch 58/160 (LR 0.07093) => LSC_loss 0.58, Spatial_loss 2.03, Flat_loss 0.38, Train_acc 85.20, Test_acc 27.69
2022-05-25 00:35:11,929 [podnet.py] => Task 9, Epoch 59/160 (LR 0.07004) => LSC_loss 0.61, Spatial_loss 2.07, Flat_loss 0.38, Train_acc 84.64, Test_acc 26.62
2022-05-25 00:35:16,067 [podnet.py] => Task 9, Epoch 60/160 (LR 0.06913) => LSC_loss 0.58, Spatial_loss 1.97, Flat_loss 0.37, Train_acc 85.24, Test_acc 26.15
2022-05-25 00:35:20,299 [podnet.py] => Task 9, Epoch 61/160 (LR 0.06822) => LSC_loss 0.59, Spatial_loss 1.99, Flat_loss 0.37, Train_acc 84.66, Test_acc 29.06
2022-05-25 00:35:24,514 [podnet.py] => Task 9, Epoch 62/160 (LR 0.06731) => LSC_loss 0.56, Spatial_loss 1.95, Flat_loss 0.37, Train_acc 85.80, Test_acc 28.85
2022-05-25 00:35:28,664 [podnet.py] => Task 9, Epoch 63/160 (LR 0.06638) => LSC_loss 0.57, Spatial_loss 2.03, Flat_loss 0.37, Train_acc 85.69, Test_acc 28.90
2022-05-25 00:35:32,890 [podnet.py] => Task 9, Epoch 64/160 (LR 0.06545) => LSC_loss 0.58, Spatial_loss 1.99, Flat_loss 0.37, Train_acc 85.54, Test_acc 28.53
2022-05-25 00:35:36,925 [podnet.py] => Task 9, Epoch 65/160 (LR 0.06451) => LSC_loss 0.58, Spatial_loss 1.97, Flat_loss 0.37, Train_acc 84.51, Test_acc 29.08
2022-05-25 00:35:40,931 [podnet.py] => Task 9, Epoch 66/160 (LR 0.06357) => LSC_loss 0.56, Spatial_loss 1.98, Flat_loss 0.37, Train_acc 85.89, Test_acc 31.84
2022-05-25 00:35:45,193 [podnet.py] => Task 9, Epoch 67/160 (LR 0.06262) => LSC_loss 0.57, Spatial_loss 2.00, Flat_loss 0.37, Train_acc 85.70, Test_acc 31.23
2022-05-25 00:35:49,384 [podnet.py] => Task 9, Epoch 68/160 (LR 0.06167) => LSC_loss 0.58, Spatial_loss 1.99, Flat_loss 0.38, Train_acc 85.27, Test_acc 25.53
2022-05-25 00:35:53,568 [podnet.py] => Task 9, Epoch 69/160 (LR 0.06072) => LSC_loss 0.54, Spatial_loss 1.95, Flat_loss 0.36, Train_acc 86.88, Test_acc 30.09
2022-05-25 00:35:57,936 [podnet.py] => Task 9, Epoch 70/160 (LR 0.05975) => LSC_loss 0.53, Spatial_loss 1.92, Flat_loss 0.36, Train_acc 87.03, Test_acc 26.03
2022-05-25 00:36:02,214 [podnet.py] => Task 9, Epoch 71/160 (LR 0.05879) => LSC_loss 0.53, Spatial_loss 1.97, Flat_loss 0.37, Train_acc 86.91, Test_acc 31.49
2022-05-25 00:36:06,481 [podnet.py] => Task 9, Epoch 72/160 (LR 0.05782) => LSC_loss 0.49, Spatial_loss 1.89, Flat_loss 0.35, Train_acc 87.84, Test_acc 30.06
2022-05-25 00:36:10,645 [podnet.py] => Task 9, Epoch 73/160 (LR 0.05685) => LSC_loss 0.53, Spatial_loss 1.94, Flat_loss 0.36, Train_acc 86.72, Test_acc 23.26
2022-05-25 00:36:15,025 [podnet.py] => Task 9, Epoch 74/160 (LR 0.05588) => LSC_loss 0.50, Spatial_loss 1.87, Flat_loss 0.36, Train_acc 88.12, Test_acc 27.46
2022-05-25 00:36:19,223 [podnet.py] => Task 9, Epoch 75/160 (LR 0.05490) => LSC_loss 0.51, Spatial_loss 1.89, Flat_loss 0.36, Train_acc 86.99, Test_acc 30.46
2022-05-25 00:36:23,404 [podnet.py] => Task 9, Epoch 76/160 (LR 0.05392) => LSC_loss 0.48, Spatial_loss 1.86, Flat_loss 0.35, Train_acc 88.55, Test_acc 31.90
2022-05-25 00:36:27,475 [podnet.py] => Task 9, Epoch 77/160 (LR 0.05294) => LSC_loss 0.49, Spatial_loss 1.90, Flat_loss 0.36, Train_acc 88.25, Test_acc 31.98
2022-05-25 00:36:31,753 [podnet.py] => Task 9, Epoch 78/160 (LR 0.05196) => LSC_loss 0.47, Spatial_loss 1.81, Flat_loss 0.35, Train_acc 88.70, Test_acc 29.65
2022-05-25 00:36:35,866 [podnet.py] => Task 9, Epoch 79/160 (LR 0.05098) => LSC_loss 0.46, Spatial_loss 1.80, Flat_loss 0.34, Train_acc 89.20, Test_acc 29.29
2022-05-25 00:36:39,984 [podnet.py] => Task 9, Epoch 80/160 (LR 0.05000) => LSC_loss 0.47, Spatial_loss 1.80, Flat_loss 0.35, Train_acc 88.80, Test_acc 27.48
2022-05-25 00:36:44,173 [podnet.py] => Task 9, Epoch 81/160 (LR 0.04902) => LSC_loss 0.47, Spatial_loss 1.83, Flat_loss 0.35, Train_acc 88.71, Test_acc 32.26
2022-05-25 00:36:48,386 [podnet.py] => Task 9, Epoch 82/160 (LR 0.04804) => LSC_loss 0.46, Spatial_loss 1.87, Flat_loss 0.35, Train_acc 88.84, Test_acc 34.23
2022-05-25 00:36:52,654 [podnet.py] => Task 9, Epoch 83/160 (LR 0.04706) => LSC_loss 0.45, Spatial_loss 1.83, Flat_loss 0.35, Train_acc 89.17, Test_acc 30.41
2022-05-25 00:36:56,790 [podnet.py] => Task 9, Epoch 84/160 (LR 0.04608) => LSC_loss 0.44, Spatial_loss 1.81, Flat_loss 0.34, Train_acc 89.48, Test_acc 31.74
2022-05-25 00:37:01,077 [podnet.py] => Task 9, Epoch 85/160 (LR 0.04510) => LSC_loss 0.43, Spatial_loss 1.79, Flat_loss 0.34, Train_acc 90.01, Test_acc 27.18
2022-05-25 00:37:05,459 [podnet.py] => Task 9, Epoch 86/160 (LR 0.04412) => LSC_loss 0.42, Spatial_loss 1.79, Flat_loss 0.34, Train_acc 90.06, Test_acc 32.27
2022-05-25 00:37:09,685 [podnet.py] => Task 9, Epoch 87/160 (LR 0.04315) => LSC_loss 0.44, Spatial_loss 1.81, Flat_loss 0.34, Train_acc 89.53, Test_acc 27.57
2022-05-25 00:37:13,889 [podnet.py] => Task 9, Epoch 88/160 (LR 0.04218) => LSC_loss 0.42, Spatial_loss 1.79, Flat_loss 0.34, Train_acc 90.42, Test_acc 29.79
2022-05-25 00:37:18,013 [podnet.py] => Task 9, Epoch 89/160 (LR 0.04121) => LSC_loss 0.43, Spatial_loss 1.82, Flat_loss 0.35, Train_acc 90.21, Test_acc 31.43
2022-05-25 00:37:22,341 [podnet.py] => Task 9, Epoch 90/160 (LR 0.04025) => LSC_loss 0.41, Spatial_loss 1.76, Flat_loss 0.34, Train_acc 90.63, Test_acc 29.81
2022-05-25 00:37:26,508 [podnet.py] => Task 9, Epoch 91/160 (LR 0.03928) => LSC_loss 0.39, Spatial_loss 1.73, Flat_loss 0.33, Train_acc 91.40, Test_acc 33.47
2022-05-25 00:37:31,032 [podnet.py] => Task 9, Epoch 92/160 (LR 0.03833) => LSC_loss 0.40, Spatial_loss 1.70, Flat_loss 0.33, Train_acc 91.29, Test_acc 35.08
2022-05-25 00:37:35,352 [podnet.py] => Task 9, Epoch 93/160 (LR 0.03738) => LSC_loss 0.39, Spatial_loss 1.74, Flat_loss 0.33, Train_acc 91.29, Test_acc 30.19
2022-05-25 00:37:39,437 [podnet.py] => Task 9, Epoch 94/160 (LR 0.03643) => LSC_loss 0.37, Spatial_loss 1.69, Flat_loss 0.33, Train_acc 92.11, Test_acc 30.44
2022-05-25 00:37:43,750 [podnet.py] => Task 9, Epoch 95/160 (LR 0.03549) => LSC_loss 0.38, Spatial_loss 1.69, Flat_loss 0.33, Train_acc 91.93, Test_acc 31.88
2022-05-25 00:37:47,951 [podnet.py] => Task 9, Epoch 96/160 (LR 0.03455) => LSC_loss 0.37, Spatial_loss 1.64, Flat_loss 0.32, Train_acc 91.63, Test_acc 32.79
2022-05-25 00:37:52,181 [podnet.py] => Task 9, Epoch 97/160 (LR 0.03362) => LSC_loss 0.38, Spatial_loss 1.69, Flat_loss 0.33, Train_acc 91.73, Test_acc 28.22
2022-05-25 00:37:56,333 [podnet.py] => Task 9, Epoch 98/160 (LR 0.03269) => LSC_loss 0.36, Spatial_loss 1.70, Flat_loss 0.32, Train_acc 92.19, Test_acc 30.56
2022-05-25 00:38:00,413 [podnet.py] => Task 9, Epoch 99/160 (LR 0.03178) => LSC_loss 0.36, Spatial_loss 1.63, Flat_loss 0.32, Train_acc 92.21, Test_acc 30.05
2022-05-25 00:38:04,761 [podnet.py] => Task 9, Epoch 100/160 (LR 0.03087) => LSC_loss 0.34, Spatial_loss 1.63, Flat_loss 0.32, Train_acc 93.05, Test_acc 28.58
2022-05-25 00:38:08,907 [podnet.py] => Task 9, Epoch 101/160 (LR 0.02996) => LSC_loss 0.33, Spatial_loss 1.61, Flat_loss 0.31, Train_acc 93.27, Test_acc 33.76
2022-05-25 00:38:13,176 [podnet.py] => Task 9, Epoch 102/160 (LR 0.02907) => LSC_loss 0.35, Spatial_loss 1.61, Flat_loss 0.32, Train_acc 92.79, Test_acc 32.54
2022-05-25 00:38:17,501 [podnet.py] => Task 9, Epoch 103/160 (LR 0.02818) => LSC_loss 0.34, Spatial_loss 1.65, Flat_loss 0.32, Train_acc 93.04, Test_acc 30.77
2022-05-25 00:38:21,823 [podnet.py] => Task 9, Epoch 104/160 (LR 0.02730) => LSC_loss 0.32, Spatial_loss 1.61, Flat_loss 0.31, Train_acc 93.71, Test_acc 33.04
2022-05-25 00:38:25,933 [podnet.py] => Task 9, Epoch 105/160 (LR 0.02643) => LSC_loss 0.30, Spatial_loss 1.55, Flat_loss 0.31, Train_acc 94.21, Test_acc 31.92
2022-05-25 00:38:30,258 [podnet.py] => Task 9, Epoch 106/160 (LR 0.02557) => LSC_loss 0.32, Spatial_loss 1.56, Flat_loss 0.31, Train_acc 93.58, Test_acc 30.30
2022-05-25 00:38:34,407 [podnet.py] => Task 9, Epoch 107/160 (LR 0.02472) => LSC_loss 0.30, Spatial_loss 1.55, Flat_loss 0.30, Train_acc 94.43, Test_acc 32.73
2022-05-25 00:38:38,386 [podnet.py] => Task 9, Epoch 108/160 (LR 0.02388) => LSC_loss 0.30, Spatial_loss 1.49, Flat_loss 0.30, Train_acc 94.47, Test_acc 31.05
2022-05-25 00:38:42,617 [podnet.py] => Task 9, Epoch 109/160 (LR 0.02304) => LSC_loss 0.29, Spatial_loss 1.47, Flat_loss 0.30, Train_acc 94.54, Test_acc 32.46
2022-05-25 00:38:46,835 [podnet.py] => Task 9, Epoch 110/160 (LR 0.02222) => LSC_loss 0.29, Spatial_loss 1.49, Flat_loss 0.30, Train_acc 94.57, Test_acc 30.45
2022-05-25 00:38:51,034 [podnet.py] => Task 9, Epoch 111/160 (LR 0.02141) => LSC_loss 0.29, Spatial_loss 1.50, Flat_loss 0.30, Train_acc 94.68, Test_acc 33.67
2022-05-25 00:38:55,362 [podnet.py] => Task 9, Epoch 112/160 (LR 0.02061) => LSC_loss 0.30, Spatial_loss 1.47, Flat_loss 0.29, Train_acc 94.33, Test_acc 31.43
2022-05-25 00:38:59,611 [podnet.py] => Task 9, Epoch 113/160 (LR 0.01982) => LSC_loss 0.28, Spatial_loss 1.48, Flat_loss 0.29, Train_acc 95.11, Test_acc 32.04
2022-05-25 00:39:03,893 [podnet.py] => Task 9, Epoch 114/160 (LR 0.01905) => LSC_loss 0.28, Spatial_loss 1.47, Flat_loss 0.30, Train_acc 95.14, Test_acc 32.87
2022-05-25 00:39:08,160 [podnet.py] => Task 9, Epoch 115/160 (LR 0.01828) => LSC_loss 0.28, Spatial_loss 1.48, Flat_loss 0.29, Train_acc 95.04, Test_acc 33.48
2022-05-25 00:39:12,379 [podnet.py] => Task 9, Epoch 116/160 (LR 0.01753) => LSC_loss 0.28, Spatial_loss 1.43, Flat_loss 0.29, Train_acc 94.80, Test_acc 33.04
2022-05-25 00:39:16,547 [podnet.py] => Task 9, Epoch 117/160 (LR 0.01679) => LSC_loss 0.27, Spatial_loss 1.43, Flat_loss 0.29, Train_acc 95.49, Test_acc 34.43
2022-05-25 00:39:20,773 [podnet.py] => Task 9, Epoch 118/160 (LR 0.01606) => LSC_loss 0.28, Spatial_loss 1.44, Flat_loss 0.29, Train_acc 95.00, Test_acc 31.51
2022-05-25 00:39:24,942 [podnet.py] => Task 9, Epoch 119/160 (LR 0.01535) => LSC_loss 0.26, Spatial_loss 1.45, Flat_loss 0.28, Train_acc 95.70, Test_acc 34.68
2022-05-25 00:39:29,068 [podnet.py] => Task 9, Epoch 120/160 (LR 0.01464) => LSC_loss 0.25, Spatial_loss 1.40, Flat_loss 0.28, Train_acc 95.97, Test_acc 34.27
2022-05-25 00:39:33,237 [podnet.py] => Task 9, Epoch 121/160 (LR 0.01396) => LSC_loss 0.25, Spatial_loss 1.42, Flat_loss 0.28, Train_acc 95.85, Test_acc 34.11
2022-05-25 00:39:37,367 [podnet.py] => Task 9, Epoch 122/160 (LR 0.01328) => LSC_loss 0.25, Spatial_loss 1.35, Flat_loss 0.28, Train_acc 96.15, Test_acc 33.92
2022-05-25 00:39:41,525 [podnet.py] => Task 9, Epoch 123/160 (LR 0.01262) => LSC_loss 0.25, Spatial_loss 1.37, Flat_loss 0.28, Train_acc 96.20, Test_acc 34.08
2022-05-25 00:39:45,668 [podnet.py] => Task 9, Epoch 124/160 (LR 0.01198) => LSC_loss 0.24, Spatial_loss 1.36, Flat_loss 0.28, Train_acc 96.13, Test_acc 35.15
2022-05-25 00:39:49,923 [podnet.py] => Task 9, Epoch 125/160 (LR 0.01135) => LSC_loss 0.25, Spatial_loss 1.35, Flat_loss 0.27, Train_acc 96.20, Test_acc 36.08
2022-05-25 00:39:54,049 [podnet.py] => Task 9, Epoch 126/160 (LR 0.01073) => LSC_loss 0.24, Spatial_loss 1.36, Flat_loss 0.27, Train_acc 96.40, Test_acc 34.02
2022-05-25 00:39:58,325 [podnet.py] => Task 9, Epoch 127/160 (LR 0.01013) => LSC_loss 0.23, Spatial_loss 1.35, Flat_loss 0.27, Train_acc 96.68, Test_acc 33.28
2022-05-25 00:40:02,442 [podnet.py] => Task 9, Epoch 128/160 (LR 0.00955) => LSC_loss 0.23, Spatial_loss 1.36, Flat_loss 0.27, Train_acc 96.53, Test_acc 35.03
2022-05-25 00:40:06,779 [podnet.py] => Task 9, Epoch 129/160 (LR 0.00898) => LSC_loss 0.24, Spatial_loss 1.31, Flat_loss 0.27, Train_acc 96.56, Test_acc 33.72
2022-05-25 00:40:10,892 [podnet.py] => Task 9, Epoch 130/160 (LR 0.00843) => LSC_loss 0.22, Spatial_loss 1.28, Flat_loss 0.26, Train_acc 97.13, Test_acc 35.54
2022-05-25 00:40:15,193 [podnet.py] => Task 9, Epoch 131/160 (LR 0.00789) => LSC_loss 0.23, Spatial_loss 1.29, Flat_loss 0.27, Train_acc 97.01, Test_acc 34.01
2022-05-25 00:40:19,460 [podnet.py] => Task 9, Epoch 132/160 (LR 0.00737) => LSC_loss 0.22, Spatial_loss 1.29, Flat_loss 0.27, Train_acc 97.05, Test_acc 33.09
2022-05-25 00:40:23,667 [podnet.py] => Task 9, Epoch 133/160 (LR 0.00686) => LSC_loss 0.23, Spatial_loss 1.25, Flat_loss 0.26, Train_acc 97.06, Test_acc 35.69
2022-05-25 00:40:27,863 [podnet.py] => Task 9, Epoch 134/160 (LR 0.00638) => LSC_loss 0.22, Spatial_loss 1.27, Flat_loss 0.26, Train_acc 96.83, Test_acc 35.98
2022-05-25 00:40:32,188 [podnet.py] => Task 9, Epoch 135/160 (LR 0.00590) => LSC_loss 0.22, Spatial_loss 1.28, Flat_loss 0.26, Train_acc 97.11, Test_acc 34.86
2022-05-25 00:40:36,616 [podnet.py] => Task 9, Epoch 136/160 (LR 0.00545) => LSC_loss 0.22, Spatial_loss 1.26, Flat_loss 0.26, Train_acc 97.26, Test_acc 34.30
2022-05-25 00:40:40,682 [podnet.py] => Task 9, Epoch 137/160 (LR 0.00501) => LSC_loss 0.22, Spatial_loss 1.25, Flat_loss 0.26, Train_acc 97.08, Test_acc 35.08
2022-05-25 00:40:45,032 [podnet.py] => Task 9, Epoch 138/160 (LR 0.00459) => LSC_loss 0.21, Spatial_loss 1.22, Flat_loss 0.26, Train_acc 97.41, Test_acc 35.76
2022-05-25 00:40:49,197 [podnet.py] => Task 9, Epoch 139/160 (LR 0.00419) => LSC_loss 0.21, Spatial_loss 1.23, Flat_loss 0.26, Train_acc 97.42, Test_acc 35.51
2022-05-25 00:40:53,264 [podnet.py] => Task 9, Epoch 140/160 (LR 0.00381) => LSC_loss 0.21, Spatial_loss 1.20, Flat_loss 0.26, Train_acc 97.42, Test_acc 35.29
2022-05-25 00:40:57,561 [podnet.py] => Task 9, Epoch 141/160 (LR 0.00344) => LSC_loss 0.22, Spatial_loss 1.22, Flat_loss 0.26, Train_acc 97.13, Test_acc 35.60
2022-05-25 00:41:01,973 [podnet.py] => Task 9, Epoch 142/160 (LR 0.00309) => LSC_loss 0.21, Spatial_loss 1.17, Flat_loss 0.25, Train_acc 97.49, Test_acc 35.77
2022-05-25 00:41:06,131 [podnet.py] => Task 9, Epoch 143/160 (LR 0.00276) => LSC_loss 0.20, Spatial_loss 1.19, Flat_loss 0.26, Train_acc 97.56, Test_acc 35.42
2022-05-25 00:41:10,318 [podnet.py] => Task 9, Epoch 144/160 (LR 0.00245) => LSC_loss 0.21, Spatial_loss 1.16, Flat_loss 0.25, Train_acc 97.61, Test_acc 35.80
2022-05-25 00:41:14,439 [podnet.py] => Task 9, Epoch 145/160 (LR 0.00215) => LSC_loss 0.20, Spatial_loss 1.19, Flat_loss 0.25, Train_acc 97.62, Test_acc 35.72
2022-05-25 00:41:18,657 [podnet.py] => Task 9, Epoch 146/160 (LR 0.00188) => LSC_loss 0.20, Spatial_loss 1.18, Flat_loss 0.25, Train_acc 97.66, Test_acc 35.13
2022-05-25 00:41:22,897 [podnet.py] => Task 9, Epoch 147/160 (LR 0.00162) => LSC_loss 0.20, Spatial_loss 1.19, Flat_loss 0.25, Train_acc 97.62, Test_acc 35.60
2022-05-25 00:41:27,128 [podnet.py] => Task 9, Epoch 148/160 (LR 0.00138) => LSC_loss 0.20, Spatial_loss 1.16, Flat_loss 0.25, Train_acc 97.82, Test_acc 35.50
2022-05-25 00:41:31,249 [podnet.py] => Task 9, Epoch 149/160 (LR 0.00116) => LSC_loss 0.20, Spatial_loss 1.15, Flat_loss 0.25, Train_acc 97.44, Test_acc 35.43
2022-05-25 00:41:35,501 [podnet.py] => Task 9, Epoch 150/160 (LR 0.00096) => LSC_loss 0.20, Spatial_loss 1.17, Flat_loss 0.25, Train_acc 97.81, Test_acc 35.41
2022-05-25 00:41:39,667 [podnet.py] => Task 9, Epoch 151/160 (LR 0.00078) => LSC_loss 0.20, Spatial_loss 1.18, Flat_loss 0.25, Train_acc 97.82, Test_acc 35.58
2022-05-25 00:41:43,787 [podnet.py] => Task 9, Epoch 152/160 (LR 0.00062) => LSC_loss 0.20, Spatial_loss 1.19, Flat_loss 0.25, Train_acc 97.97, Test_acc 35.76
2022-05-25 00:41:47,969 [podnet.py] => Task 9, Epoch 153/160 (LR 0.00047) => LSC_loss 0.20, Spatial_loss 1.16, Flat_loss 0.25, Train_acc 97.95, Test_acc 35.88
2022-05-25 00:41:52,210 [podnet.py] => Task 9, Epoch 154/160 (LR 0.00035) => LSC_loss 0.20, Spatial_loss 1.15, Flat_loss 0.25, Train_acc 97.61, Test_acc 35.31
2022-05-25 00:41:56,481 [podnet.py] => Task 9, Epoch 155/160 (LR 0.00024) => LSC_loss 0.20, Spatial_loss 1.17, Flat_loss 0.25, Train_acc 97.82, Test_acc 36.03
2022-05-25 00:42:00,675 [podnet.py] => Task 9, Epoch 156/160 (LR 0.00015) => LSC_loss 0.19, Spatial_loss 1.15, Flat_loss 0.25, Train_acc 97.92, Test_acc 35.82
2022-05-25 00:42:04,963 [podnet.py] => Task 9, Epoch 157/160 (LR 0.00009) => LSC_loss 0.20, Spatial_loss 1.14, Flat_loss 0.25, Train_acc 97.71, Test_acc 35.77
2022-05-25 00:42:09,002 [podnet.py] => Task 9, Epoch 158/160 (LR 0.00004) => LSC_loss 0.20, Spatial_loss 1.15, Flat_loss 0.25, Train_acc 97.97, Test_acc 35.66
2022-05-25 00:42:13,258 [podnet.py] => Task 9, Epoch 159/160 (LR 0.00001) => LSC_loss 0.20, Spatial_loss 1.12, Flat_loss 0.25, Train_acc 97.98, Test_acc 35.81
2022-05-25 00:42:17,361 [podnet.py] => Task 9, Epoch 160/160 (LR 0.00000) => LSC_loss 0.20, Spatial_loss 1.12, Flat_loss 0.25, Train_acc 97.78, Test_acc 35.54
2022-05-25 00:42:17,362 [podnet.py] => Finetune the network (classifier part) with the undersampled dataset!
2022-05-25 00:42:17,362 [base.py] => Reducing exemplars...(22 per classes)
2022-05-25 00:42:36,447 [base.py] => Constructing exemplars...(22 per classes)
2022-05-25 00:42:42,987 [podnet.py] => The size of finetune dataset: 2200
2022-05-25 00:42:45,376 [podnet.py] => Task 9, Epoch 1/20 (LR 0.00497) => LSC_loss 0.27, Spatial_loss 1.35, Flat_loss 0.18, Train_acc 96.09, Test_acc 37.96
2022-05-25 00:42:47,562 [podnet.py] => Task 9, Epoch 2/20 (LR 0.00488) => LSC_loss 0.17, Spatial_loss 1.20, Flat_loss 0.14, Train_acc 98.59, Test_acc 37.85
2022-05-25 00:42:49,869 [podnet.py] => Task 9, Epoch 3/20 (LR 0.00473) => LSC_loss 0.18, Spatial_loss 1.16, Flat_loss 0.14, Train_acc 98.05, Test_acc 36.88
2022-05-25 00:42:52,117 [podnet.py] => Task 9, Epoch 4/20 (LR 0.00452) => LSC_loss 0.17, Spatial_loss 1.21, Flat_loss 0.14, Train_acc 98.64, Test_acc 37.91
2022-05-25 00:42:54,363 [podnet.py] => Task 9, Epoch 5/20 (LR 0.00427) => LSC_loss 0.17, Spatial_loss 1.19, Flat_loss 0.14, Train_acc 99.18, Test_acc 38.35
2022-05-25 00:42:56,721 [podnet.py] => Task 9, Epoch 6/20 (LR 0.00397) => LSC_loss 0.16, Spatial_loss 1.15, Flat_loss 0.14, Train_acc 98.73, Test_acc 37.34
2022-05-25 00:42:58,941 [podnet.py] => Task 9, Epoch 7/20 (LR 0.00363) => LSC_loss 0.15, Spatial_loss 1.19, Flat_loss 0.14, Train_acc 98.73, Test_acc 38.04
2022-05-25 00:43:01,268 [podnet.py] => Task 9, Epoch 8/20 (LR 0.00327) => LSC_loss 0.15, Spatial_loss 1.10, Flat_loss 0.14, Train_acc 99.14, Test_acc 37.95
2022-05-25 00:43:03,448 [podnet.py] => Task 9, Epoch 9/20 (LR 0.00289) => LSC_loss 0.15, Spatial_loss 1.17, Flat_loss 0.13, Train_acc 98.77, Test_acc 37.75
2022-05-25 00:43:05,929 [podnet.py] => Task 9, Epoch 10/20 (LR 0.00250) => LSC_loss 0.16, Spatial_loss 1.13, Flat_loss 0.13, Train_acc 98.91, Test_acc 37.99
2022-05-25 00:43:08,194 [podnet.py] => Task 9, Epoch 11/20 (LR 0.00211) => LSC_loss 0.15, Spatial_loss 1.15, Flat_loss 0.13, Train_acc 99.05, Test_acc 38.31
2022-05-25 00:43:10,567 [podnet.py] => Task 9, Epoch 12/20 (LR 0.00173) => LSC_loss 0.16, Spatial_loss 1.15, Flat_loss 0.14, Train_acc 99.05, Test_acc 37.95
2022-05-25 00:43:12,838 [podnet.py] => Task 9, Epoch 13/20 (LR 0.00137) => LSC_loss 0.15, Spatial_loss 1.11, Flat_loss 0.13, Train_acc 99.18, Test_acc 37.85
2022-05-25 00:43:15,166 [podnet.py] => Task 9, Epoch 14/20 (LR 0.00103) => LSC_loss 0.15, Spatial_loss 1.14, Flat_loss 0.13, Train_acc 99.18, Test_acc 38.03
2022-05-25 00:43:17,415 [podnet.py] => Task 9, Epoch 15/20 (LR 0.00073) => LSC_loss 0.16, Spatial_loss 1.09, Flat_loss 0.13, Train_acc 98.95, Test_acc 37.75
2022-05-25 00:43:19,722 [podnet.py] => Task 9, Epoch 16/20 (LR 0.00048) => LSC_loss 0.14, Spatial_loss 1.09, Flat_loss 0.13, Train_acc 99.18, Test_acc 38.12
2022-05-25 00:43:22,153 [podnet.py] => Task 9, Epoch 17/20 (LR 0.00027) => LSC_loss 0.14, Spatial_loss 1.08, Flat_loss 0.13, Train_acc 99.18, Test_acc 38.08
2022-05-25 00:43:24,663 [podnet.py] => Task 9, Epoch 18/20 (LR 0.00012) => LSC_loss 0.14, Spatial_loss 1.09, Flat_loss 0.13, Train_acc 99.27, Test_acc 38.13
2022-05-25 00:43:27,060 [podnet.py] => Task 9, Epoch 19/20 (LR 0.00003) => LSC_loss 0.14, Spatial_loss 1.09, Flat_loss 0.13, Train_acc 99.23, Test_acc 37.75
2022-05-25 00:43:29,254 [podnet.py] => Task 9, Epoch 20/20 (LR 0.00000) => LSC_loss 0.14, Spatial_loss 1.13, Flat_loss 0.13, Train_acc 99.41, Test_acc 38.10
2022-05-25 00:43:29,256 [base.py] => Reducing exemplars...(20 per classes)
2022-05-25 00:43:47,888 [base.py] => Constructing exemplars...(20 per classes)
2022-05-25 00:43:55,976 [podnet.py] => Exemplar size: 2000
2022-05-25 00:43:55,977 [trainer.py] => CNN: {'total': 38.1, '00-09': 51.9, '10-19': 17.2, '20-29': 31.0, '30-39': 24.9, '40-49': 41.4, '50-59': 27.6, '60-69': 40.6, '70-79': 38.0, '80-89': 48.7, '90-99': 59.7, 'old': 35.7, 'new': 59.7}
2022-05-25 00:43:55,977 [trainer.py] => NME: {'total': 37.82, '00-09': 60.4, '10-19': 16.1, '20-29': 31.2, '30-39': 27.4, '40-49': 38.9, '50-59': 27.5, '60-69': 38.5, '70-79': 39.4, '80-89': 44.9, '90-99': 53.9, 'old': 36.03, 'new': 53.9}
2022-05-25 00:43:55,977 [trainer.py] => CNN top1 curve: [90.7, 72.95, 65.47, 57.8, 53.9, 49.75, 47.14, 43.7, 40.18, 38.1]
2022-05-25 00:43:55,977 [trainer.py] => CNN top5 curve: [99.2, 93.95, 90.1, 85.15, 81.78, 78.42, 76.86, 73.58, 70.63, 68.0]
2022-05-25 00:43:55,977 [trainer.py] => NME top1 curve: [90.8, 72.05, 63.37, 55.7, 52.92, 48.87, 45.64, 42.5, 39.83, 37.82]
2022-05-25 00:43:55,977 [trainer.py] => NME top5 curve: [99.3, 92.8, 88.93, 83.38, 81.2, 77.87, 75.76, 72.41, 69.54, 66.77]

