2022-05-25 10:09:01,578 [trainer.py] => config: options/icarl.yaml
2022-05-25 10:09:01,578 [trainer.py] => prefix: reproduce
2022-05-25 10:09:01,579 [trainer.py] => device: [device(type='cuda', index=3)]
2022-05-25 10:09:01,579 [trainer.py] => seed: 1993
2022-05-25 10:09:01,579 [trainer.py] => num_workers: 8
2022-05-25 10:09:01,579 [trainer.py] => dataset: cifar100
2022-05-25 10:09:01,579 [trainer.py] => shuffle: False
2022-05-25 10:09:01,579 [trainer.py] => method: icarl
2022-05-25 10:09:01,579 [trainer.py] => eval_metric: acc
2022-05-25 10:09:01,579 [trainer.py] => backbone: resnet32
2022-05-25 10:09:01,579 [trainer.py] => pretrained: True
2022-05-25 10:09:01,579 [trainer.py] => save_models: False
2022-05-25 10:09:01,579 [trainer.py] => memory_size: 2000
2022-05-25 10:09:01,579 [trainer.py] => fixed_memory: False
2022-05-25 10:09:01,579 [trainer.py] => sampling_method: icarl
2022-05-25 10:09:01,579 [trainer.py] => init_cls: 10
2022-05-25 10:09:01,579 [trainer.py] => increment: 10
2022-05-25 10:09:01,579 [trainer.py] => incre_type: cil
2022-05-25 10:09:01,579 [trainer.py] => T: 2
2022-05-25 10:09:01,579 [trainer.py] => init_epoch: 200
2022-05-25 10:09:01,580 [trainer.py] => init_lr: 0.1
2022-05-25 10:09:01,580 [trainer.py] => init_milestones: [60, 120, 170]
2022-05-25 10:09:01,580 [trainer.py] => init_lr_decay: 0.1
2022-05-25 10:09:01,580 [trainer.py] => init_weight_decay: 0.0005
2022-05-25 10:09:01,580 [trainer.py] => epochs: 170
2022-05-25 10:09:01,580 [trainer.py] => lrate: 0.1
2022-05-25 10:09:01,580 [trainer.py] => milestones: [80, 120]
2022-05-25 10:09:01,580 [trainer.py] => lrate_decay: 0.1
2022-05-25 10:09:01,580 [trainer.py] => batch_size: 128
2022-05-25 10:09:01,580 [trainer.py] => weight_decay: 0.0002
2022-05-25 10:09:03,384 [data_manager.py] => class order: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]
2022-05-25 10:09:03,747 [trainer.py] => All params: 464154
2022-05-25 10:09:03,748 [trainer.py] => Trainable params: 464154
2022-05-25 10:09:03,758 [icarl.py] => Learning on 0-10
2022-05-25 10:16:38,711 [icarl.py] => Task 0, Epoch 200/200 => Loss 0.043, Train_accy 99.44, Test_accy 84.60
2022-05-25 10:16:38,712 [base.py] => Reducing exemplars...(200 per classes)
2022-05-25 10:16:38,712 [base.py] => Constructing exemplars...(200 per classes)
2022-05-25 10:16:46,239 [icarl.py] => Exemplar size: 2000
2022-05-25 10:16:46,239 [trainer.py] => CNN: {'total': 84.6, '00-09': 84.6, 'old': 0, 'new': 84.6}
2022-05-25 10:16:46,239 [trainer.py] => NME: {'total': 84.5, '00-09': 84.5, 'old': 0, 'new': 84.5}
2022-05-25 10:16:46,239 [trainer.py] => CNN top1 curve: [84.6]
2022-05-25 10:16:46,239 [trainer.py] => CNN top5 curve: [99.2]
2022-05-25 10:16:46,239 [trainer.py] => NME top1 curve: [84.5]
2022-05-25 10:16:46,239 [trainer.py] => NME top5 curve: [99.3]

2022-05-25 10:16:46,240 [trainer.py] => All params: 464804
2022-05-25 10:16:46,240 [trainer.py] => Trainable params: 464804
2022-05-25 10:16:46,241 [icarl.py] => Learning on 10-20
2022-05-25 10:24:42,511 [icarl.py] => Task 1, Epoch 170/170 => Loss 1.126, Train_accy 99.93
2022-05-25 10:24:42,512 [base.py] => Reducing exemplars...(100 per classes)
2022-05-25 10:24:45,002 [base.py] => Constructing exemplars...(100 per classes)
2022-05-25 10:24:53,056 [icarl.py] => Exemplar size: 2000
2022-05-25 10:24:53,056 [trainer.py] => CNN: {'total': 74.55, '00-09': 71.5, '10-19': 77.6, 'old': 71.5, 'new': 77.6}
2022-05-25 10:24:53,057 [trainer.py] => NME: {'total': 75.55, '00-09': 77.5, '10-19': 73.6, 'old': 77.5, 'new': 73.6}
2022-05-25 10:24:53,057 [trainer.py] => CNN top1 curve: [84.6, 74.55]
2022-05-25 10:24:53,057 [trainer.py] => CNN top5 curve: [99.2, 96.35]
2022-05-25 10:24:53,057 [trainer.py] => NME top1 curve: [84.5, 75.55]
2022-05-25 10:24:53,057 [trainer.py] => NME top5 curve: [99.3, 96.5]

2022-05-25 10:24:53,057 [trainer.py] => All params: 465454
2022-05-25 10:24:53,058 [trainer.py] => Trainable params: 465454
2022-05-25 10:24:53,059 [icarl.py] => Learning on 20-30
2022-05-25 10:33:05,545 [icarl.py] => Task 2, Epoch 170/170 => Loss 1.433, Train_accy 99.84
2022-05-25 10:33:05,545 [base.py] => Reducing exemplars...(66 per classes)
2022-05-25 10:33:10,779 [base.py] => Constructing exemplars...(66 per classes)
2022-05-25 10:33:19,538 [icarl.py] => Exemplar size: 1980
2022-05-25 10:33:19,538 [trainer.py] => CNN: {'total': 68.1, '00-09': 59.8, '10-19': 61.6, '20-29': 82.9, 'old': 60.7, 'new': 82.9}
2022-05-25 10:33:19,538 [trainer.py] => NME: {'total': 70.27, '00-09': 68.1, '10-19': 68.2, '20-29': 74.5, 'old': 68.15, 'new': 74.5}
2022-05-25 10:33:19,539 [trainer.py] => CNN top1 curve: [84.6, 74.55, 68.1]
2022-05-25 10:33:19,539 [trainer.py] => CNN top5 curve: [99.2, 96.35, 93.2]
2022-05-25 10:33:19,539 [trainer.py] => NME top1 curve: [84.5, 75.55, 70.27]
2022-05-25 10:33:19,539 [trainer.py] => NME top5 curve: [99.3, 96.5, 93.77]

2022-05-25 10:33:19,539 [trainer.py] => All params: 466104
2022-05-25 10:33:19,540 [trainer.py] => Trainable params: 466104
2022-05-25 10:33:19,541 [icarl.py] => Learning on 30-40
