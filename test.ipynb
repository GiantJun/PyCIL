{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.9431, 0.1140, 0.4176,  ..., 0.1386, 0.7548, 0.5712],\n",
      "          [0.0877, 0.4247, 0.5589,  ..., 0.8116, 0.6912, 0.5512],\n",
      "          [0.5777, 0.8973, 0.2589,  ..., 0.8527, 0.5948, 0.3601],\n",
      "          ...,\n",
      "          [0.9394, 0.5695, 0.7038,  ..., 0.0965, 0.7059, 0.4840],\n",
      "          [0.4910, 0.0861, 0.3547,  ..., 0.5956, 0.0295, 0.1847],\n",
      "          [0.0694, 0.6936, 0.1049,  ..., 0.0324, 0.0087, 0.6257]],\n",
      "\n",
      "         [[0.5618, 0.7147, 0.9100,  ..., 0.3959, 0.2173, 0.7926],\n",
      "          [0.1905, 0.0186, 0.7911,  ..., 0.3425, 0.8479, 0.0650],\n",
      "          [0.1925, 0.2673, 0.2980,  ..., 0.5951, 0.6644, 0.2091],\n",
      "          ...,\n",
      "          [0.3178, 0.0025, 0.5104,  ..., 0.8617, 0.9164, 0.4366],\n",
      "          [0.0404, 0.5511, 0.1685,  ..., 0.1696, 0.2602, 0.4719],\n",
      "          [0.8863, 0.9895, 0.1654,  ..., 0.4979, 0.3122, 0.4018]],\n",
      "\n",
      "         [[0.6137, 0.7177, 0.8440,  ..., 0.2369, 0.0539, 0.1532],\n",
      "          [0.8892, 0.6606, 0.9929,  ..., 0.6740, 0.1686, 0.3901],\n",
      "          [0.6641, 0.2304, 0.3987,  ..., 0.2223, 0.5076, 0.3140],\n",
      "          ...,\n",
      "          [0.4091, 0.3894, 0.2390,  ..., 0.0999, 0.7008, 0.9292],\n",
      "          [0.6844, 0.5260, 0.2858,  ..., 0.5743, 0.4651, 0.2421],\n",
      "          [0.8112, 0.8015, 0.3081,  ..., 0.4855, 0.5368, 0.8787]]],\n",
      "\n",
      "\n",
      "        [[[0.4661, 0.4661, 0.8363,  ..., 0.1321, 0.6178, 0.4353],\n",
      "          [0.3205, 0.6863, 0.1168,  ..., 0.0980, 0.2193, 0.5188],\n",
      "          [0.4666, 0.4274, 0.1143,  ..., 0.5215, 0.9328, 0.1071],\n",
      "          ...,\n",
      "          [0.5436, 0.4049, 0.9396,  ..., 0.2430, 0.6150, 0.8707],\n",
      "          [0.4700, 0.4516, 0.0357,  ..., 0.3580, 0.7504, 0.3568],\n",
      "          [0.6909, 0.0064, 0.3066,  ..., 0.7621, 0.9085, 0.9855]],\n",
      "\n",
      "         [[0.8778, 0.5210, 0.7778,  ..., 0.7409, 0.7180, 0.6598],\n",
      "          [0.0657, 0.1824, 0.2843,  ..., 0.9868, 0.9715, 0.4434],\n",
      "          [0.7205, 0.4891, 0.1477,  ..., 0.5810, 0.6479, 0.5265],\n",
      "          ...,\n",
      "          [0.2633, 0.9338, 0.5219,  ..., 0.7247, 0.7142, 0.2629],\n",
      "          [0.1377, 0.0966, 0.6959,  ..., 0.6364, 0.6123, 0.6022],\n",
      "          [0.6472, 0.0859, 0.4483,  ..., 0.7673, 0.2044, 0.7803]],\n",
      "\n",
      "         [[0.0016, 0.8393, 0.7487,  ..., 0.5747, 0.7112, 0.9880],\n",
      "          [0.7514, 0.2447, 0.4648,  ..., 0.8740, 0.4658, 0.0645],\n",
      "          [0.3806, 0.5138, 0.6903,  ..., 0.9560, 0.5192, 0.6786],\n",
      "          ...,\n",
      "          [0.5659, 0.1936, 0.6572,  ..., 0.3633, 0.0216, 0.6537],\n",
      "          [0.3001, 0.3994, 0.9991,  ..., 0.3203, 0.5676, 0.8424],\n",
      "          [0.4785, 0.1391, 0.8627,  ..., 0.4590, 0.5719, 0.7959]]]])\n"
     ]
    }
   ],
   "source": [
    "from typing import Callable\n",
    "from torchvision import models\n",
    "import torch\n",
    "input = torch.rand((2,3,224,224))\n",
    "print(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = models.resnet18()\n",
    "output_features = {layer: torch.empty(0) for layer in ['layer1','layer2','layer3','layer4', 'fc']}\n",
    "\n",
    "def save_input_features(layer_id: str) -> Callable:\n",
    "    def func(module, input, output):\n",
    "        output_features[layer_id] = input\n",
    "    return func\n",
    "\n",
    "def process_intput_features(module, input):\n",
    "    print(input[0].shape)\n",
    "    print(len(input))\n",
    "    print(input)\n",
    "    return input[0]*2\n",
    "\n",
    "model_layer_dict = dict([*a.named_modules()])\n",
    "for layer_id in ['layer1','layer2','layer3','layer4']:\n",
    "    layer = model_layer_dict[layer_id]\n",
    "    layer.register_forward_hook(save_input_features(layer_id))\n",
    "\n",
    "# model_layer_dict['fc'].register_forward_hook(save_intput_features('fc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[0.2971, 0.2971, 0.6203,  ..., 1.2538, 0.4511, 1.0557],\n",
       "           [0.3483, 0.7073, 1.3407,  ..., 1.1123, 1.4339, 1.4339],\n",
       "           [0.9148, 0.6451, 1.2985,  ..., 2.0140, 2.0140, 1.4339],\n",
       "           ...,\n",
       "           [0.6411, 0.8014, 1.6078,  ..., 0.9235, 2.2598, 2.8920],\n",
       "           [0.8541, 0.9542, 1.6586,  ..., 0.9186, 0.9856, 1.5364],\n",
       "           [0.8285, 1.4148, 1.6586,  ..., 1.6803, 1.5788, 1.5364]],\n",
       " \n",
       "          [[0.7493, 0.7420, 0.7283,  ..., 1.6258, 2.1694, 1.2786],\n",
       "           [1.9083, 0.8327, 1.3374,  ..., 1.5484, 1.4262, 1.4262],\n",
       "           [1.4483, 0.8327, 2.3026,  ..., 0.8237, 1.5628, 1.5628],\n",
       "           ...,\n",
       "           [0.9347, 1.0370, 1.3015,  ..., 1.4786, 1.4659, 1.4659],\n",
       "           [0.9347, 1.0110, 1.0110,  ..., 2.3552, 2.3552, 1.4659],\n",
       "           [1.0326, 1.8997, 1.6859,  ..., 2.3552, 2.3552, 1.0477]],\n",
       " \n",
       "          [[0.0000, 0.0000, 0.1095,  ..., 0.0000, 0.0000, 0.8742],\n",
       "           [0.3402, 0.7300, 1.1236,  ..., 2.8353, 1.1132, 0.8742],\n",
       "           [0.0000, 0.4890, 0.4890,  ..., 2.8353, 0.4364, 0.4831],\n",
       "           ...,\n",
       "           [0.1042, 1.1650, 1.1650,  ..., 2.1897, 1.4485, 0.4554],\n",
       "           [0.1042, 0.9627, 1.9394,  ..., 2.1897, 1.4485, 1.3387],\n",
       "           [0.0000, 0.6719, 1.9394,  ..., 1.4913, 1.3387, 1.3387]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[0.4003, 0.6174, 0.6174,  ..., 0.0000, 0.0000, 0.6751],\n",
       "           [0.4373, 0.6174, 0.8870,  ..., 1.4335, 0.9980, 0.9371],\n",
       "           [0.2796, 0.5552, 0.2419,  ..., 1.1749, 1.2010, 1.2010],\n",
       "           ...,\n",
       "           [0.9348, 0.9348, 1.1565,  ..., 0.9101, 0.9535, 1.7788],\n",
       "           [0.6775, 0.6775, 1.2535,  ..., 1.2502, 1.8540, 2.5722],\n",
       "           [0.0275, 0.0275, 1.2535,  ..., 1.2502, 0.9175, 1.3195]],\n",
       " \n",
       "          [[0.0000, 0.0000, 0.0000,  ..., 0.1469, 0.2717, 0.2717],\n",
       "           [0.2729, 0.2729, 2.4291,  ..., 1.9843, 0.8553, 0.7105],\n",
       "           [1.6773, 1.6773, 1.1860,  ..., 0.2138, 0.8553, 0.7105],\n",
       "           ...,\n",
       "           [0.6780, 0.8168, 1.5287,  ..., 1.5545, 1.5545, 1.2037],\n",
       "           [0.3394, 0.8168, 0.6131,  ..., 2.7363, 1.7516, 1.7516],\n",
       "           [0.9165, 1.6449, 1.7218,  ..., 1.1156, 2.0193, 1.7516]],\n",
       " \n",
       "          [[0.8261, 0.6065, 0.8936,  ..., 0.0176, 2.4643, 2.4643],\n",
       "           [1.9107, 0.6065, 1.6636,  ..., 1.0199, 2.4643, 2.4643],\n",
       "           [1.3005, 1.3005, 1.9070,  ..., 1.0199, 1.0199, 1.1557],\n",
       "           ...,\n",
       "           [1.0329, 1.5128, 1.6250,  ..., 1.8950, 0.0000, 2.5591],\n",
       "           [1.0329, 1.5128, 1.5128,  ..., 1.1861, 0.9451, 0.8679],\n",
       "           [1.0047, 1.0047, 1.1299,  ..., 1.1861, 1.0075, 1.4268]]],\n",
       " \n",
       " \n",
       "         [[[0.5324, 1.0378, 0.3601,  ..., 0.1770, 0.8367, 1.0982],\n",
       "           [0.6094, 0.9635, 1.7793,  ..., 0.9761, 0.9761, 1.0982],\n",
       "           [0.6094, 1.1032, 2.2061,  ..., 1.2918, 0.9009, 2.0304],\n",
       "           ...,\n",
       "           [1.5158, 1.6447, 0.9028,  ..., 2.3829, 0.7049, 2.5168],\n",
       "           [1.1475, 1.6122, 1.6122,  ..., 2.3829, 0.7049, 1.7475],\n",
       "           [1.1475, 1.1539, 1.4134,  ..., 1.0363, 1.2365, 2.3247]],\n",
       " \n",
       "          [[0.9247, 1.2515, 1.7009,  ..., 1.2533, 2.9284, 1.8066],\n",
       "           [0.8783, 1.3021, 1.0703,  ..., 1.2801, 1.6181, 0.8672],\n",
       "           [2.3513, 1.5877, 1.5877,  ..., 2.0612, 1.4169, 0.8672],\n",
       "           ...,\n",
       "           [1.4222, 1.4222, 1.6795,  ..., 0.9196, 1.1849, 1.0145],\n",
       "           [2.5259, 2.5259, 1.9548,  ..., 1.7874, 1.6667, 1.6667],\n",
       "           [2.5259, 2.5259, 1.9548,  ..., 2.6494, 2.0980, 1.4349]],\n",
       " \n",
       "          [[0.0000, 0.0000, 0.0944,  ..., 0.6023, 0.0000, 0.0000],\n",
       "           [0.0000, 1.9233, 1.9233,  ..., 1.6256, 0.7718, 0.0000],\n",
       "           [0.0000, 1.9233, 1.9233,  ..., 1.6256, 1.3072, 0.8974],\n",
       "           ...,\n",
       "           [0.0000, 1.2851, 1.2851,  ..., 1.0709, 2.6590, 2.6590],\n",
       "           [0.0265, 1.3807, 1.1104,  ..., 0.8398, 1.8315, 1.4625],\n",
       "           [0.0265, 0.3322, 1.3250,  ..., 1.6257, 1.6257, 1.4625]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[0.0000, 0.4033, 0.4033,  ..., 0.9207, 0.9207, 0.7173],\n",
       "           [0.5422, 0.9564, 0.9564,  ..., 1.2665, 2.0536, 2.0536],\n",
       "           [1.4939, 1.4939, 1.4467,  ..., 1.2665, 2.3125, 2.3125],\n",
       "           ...,\n",
       "           [0.5519, 1.8164, 1.8164,  ..., 1.0011, 1.0982, 1.8922],\n",
       "           [0.0000, 1.0446, 1.5630,  ..., 0.4656, 0.4736, 1.6192],\n",
       "           [2.0175, 2.0175, 1.5630,  ..., 2.3077, 0.4736, 1.6192]],\n",
       " \n",
       "          [[0.1561, 1.1523, 0.6351,  ..., 0.1586, 0.0000, 0.5492],\n",
       "           [0.4240, 1.1523, 0.6351,  ..., 0.9009, 0.4202, 2.0637],\n",
       "           [0.5948, 1.7662, 1.0445,  ..., 0.9188, 0.9565, 1.7515],\n",
       "           ...,\n",
       "           [1.5814, 1.2580, 1.3213,  ..., 0.3017, 1.1431, 1.7363],\n",
       "           [0.9398, 2.8702, 2.8702,  ..., 1.0753, 1.0753, 1.7363],\n",
       "           [0.8357, 2.8702, 2.8702,  ..., 1.4540, 1.4540, 1.4203]],\n",
       " \n",
       "          [[0.0000, 1.0305, 1.0305,  ..., 0.0000, 0.2385, 0.1370],\n",
       "           [1.8630, 1.8630, 2.1988,  ..., 0.8634, 1.6507, 1.6507],\n",
       "           [1.8630, 1.8630, 2.1988,  ..., 1.0241, 1.6507, 1.6507],\n",
       "           ...,\n",
       "           [0.7488, 1.2639, 1.2639,  ..., 1.5815, 1.5815, 2.1155],\n",
       "           [0.7833, 1.2639, 2.0636,  ..., 0.2580, 1.2696, 1.2696],\n",
       "           [0.7833, 1.1019, 1.4775,  ..., 1.6225, 1.6225, 0.2061]]]],\n",
       "        grad_fn=<MaxPool2DWithIndicesBackward0>),)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# features.keys()\n",
    "output_features['layer1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1000])\n"
     ]
    }
   ],
   "source": [
    "output = a(input)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.hooks.RemovableHandle at 0x7f08f3175f90>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_layer_dict['fc'].register_forward_pre_hook(process_intput_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512])\n",
      "1\n",
      "(tensor([[0.8521, 0.8843, 0.8571, 0.8756, 0.8817, 0.6911, 0.8150, 0.7686, 0.8114,\n",
      "         0.8035, 0.8053, 0.8745, 0.8230, 0.8477, 0.7836, 0.7642, 0.8472, 0.7740,\n",
      "         0.7787, 0.8380, 0.8850, 0.8542, 0.8351, 0.8305, 0.7290, 0.7273, 0.7453,\n",
      "         0.7277, 0.8082, 0.8099, 0.8460, 0.8099, 0.8420, 0.8395, 0.8212, 0.8286,\n",
      "         0.7991, 0.7459, 0.7840, 0.8562, 0.8209, 0.8916, 0.7601, 0.8400, 0.7486,\n",
      "         0.8434, 0.7859, 0.8006, 0.7762, 0.9161, 0.9102, 0.8754, 0.8900, 0.8903,\n",
      "         0.7101, 0.7210, 0.8212, 0.8002, 0.7749, 0.8284, 0.7585, 0.8117, 0.7458,\n",
      "         0.7942, 0.8259, 0.8315, 0.8267, 0.8092, 0.8949, 0.8666, 0.9146, 0.8007,\n",
      "         0.8776, 0.8205, 0.8850, 0.7944, 0.7410, 0.8022, 0.7202, 0.8261, 0.7206,\n",
      "         0.8087, 0.7488, 0.9439, 0.8753, 0.8024, 0.7947, 0.8331, 0.8633, 0.8933,\n",
      "         0.8710, 0.8753, 0.7856, 0.8437, 0.8937, 0.8769, 0.8670, 0.8295, 0.7832,\n",
      "         0.7729, 0.8595, 0.8228, 0.8323, 0.9276, 0.9092, 0.8107, 0.8392, 0.8235,\n",
      "         0.7727, 0.8329, 0.8453, 0.8176, 0.7830, 0.8138, 0.8461, 0.8060, 0.7890,\n",
      "         0.9205, 0.8182, 0.7860, 0.7332, 0.8974, 0.8043, 0.7605, 0.7924, 0.8713,\n",
      "         0.8338, 0.8203, 0.8565, 0.8789, 0.8746, 0.8922, 0.8124, 0.9034, 0.7631,\n",
      "         0.8580, 0.9073, 0.7209, 0.8181, 0.8352, 0.8901, 0.7839, 0.7794, 0.7819,\n",
      "         0.8444, 0.8130, 0.7938, 0.8516, 0.8088, 0.7396, 0.8060, 0.8237, 0.9284,\n",
      "         0.7557, 0.8038, 0.8334, 0.7481, 0.7716, 0.7526, 0.8229, 0.7609, 0.9011,\n",
      "         0.7984, 0.8530, 0.8656, 0.8421, 0.7885, 0.8663, 0.9177, 0.8665, 0.8467,\n",
      "         0.7935, 0.7286, 0.7732, 0.8628, 0.9239, 0.8069, 0.7836, 0.8506, 0.7706,\n",
      "         0.8124, 0.8073, 0.9021, 0.8293, 0.8154, 0.7722, 0.7732, 0.8461, 0.7959,\n",
      "         0.8134, 0.8178, 0.8821, 0.8671, 0.8041, 0.8351, 0.9001, 0.8321, 0.8316,\n",
      "         0.7755, 0.7814, 0.8048, 0.8517, 0.8710, 0.7789, 0.7986, 0.8078, 0.8747,\n",
      "         0.7934, 0.8655, 0.9448, 0.9252, 0.8714, 0.7592, 0.7414, 0.8556, 0.8642,\n",
      "         0.8772, 0.8318, 0.7810, 0.7218, 0.7847, 0.7842, 0.8583, 0.8511, 0.7265,\n",
      "         0.8279, 0.8319, 0.7645, 0.7209, 0.8176, 0.7571, 0.8901, 0.8478, 0.8445,\n",
      "         0.7937, 0.8775, 0.9076, 0.9192, 0.7423, 0.9387, 0.8738, 0.7552, 0.7739,\n",
      "         0.6992, 0.9375, 0.7682, 0.8688, 0.8122, 0.9179, 0.8469, 0.7899, 0.9064,\n",
      "         0.7803, 0.8733, 0.8629, 0.9368, 0.8936, 0.8546, 0.8093, 0.8194, 0.9045,\n",
      "         0.7981, 0.8782, 0.9021, 0.8578, 0.7791, 0.8944, 0.8848, 0.7875, 0.7271,\n",
      "         0.8128, 0.7927, 0.8134, 0.8719, 0.8309, 0.8083, 0.7022, 0.8342, 0.7180,\n",
      "         0.8710, 0.8791, 0.7409, 0.8682, 0.8721, 0.8500, 0.8467, 0.7712, 0.8103,\n",
      "         0.8120, 0.8642, 0.8180, 0.8138, 0.7752, 0.8563, 0.8249, 0.7827, 0.8014,\n",
      "         0.9156, 0.8221, 0.8287, 0.9369, 0.8141, 0.9090, 0.8747, 0.7913, 0.7147,\n",
      "         0.7944, 0.9773, 0.7544, 0.8258, 0.7748, 0.8808, 0.8007, 0.9009, 0.8812,\n",
      "         0.8093, 0.8664, 0.8711, 0.8036, 0.9053, 0.8792, 0.8323, 0.7705, 0.7984,\n",
      "         0.8658, 0.7644, 0.7671, 0.8132, 0.7858, 0.8607, 0.9076, 0.8183, 0.8471,\n",
      "         0.8339, 0.8744, 0.7889, 0.8489, 0.8039, 0.7586, 0.7507, 0.7971, 0.7959,\n",
      "         0.7249, 0.8226, 0.8565, 0.7896, 0.8722, 0.9016, 0.7775, 0.7613, 0.8805,\n",
      "         0.8091, 0.7756, 0.8111, 0.8501, 0.8440, 0.9232, 0.7611, 0.8281, 0.8138,\n",
      "         0.8148, 0.8406, 0.8355, 0.8974, 0.8208, 0.7986, 0.7866, 0.8024, 0.8716,\n",
      "         0.8330, 0.7913, 0.9448, 0.8094, 0.8023, 0.8078, 0.7885, 0.7477, 0.7879,\n",
      "         0.8018, 0.8075, 0.8778, 0.8236, 0.7680, 0.9269, 0.8437, 0.7931, 0.8230,\n",
      "         0.8096, 0.7090, 0.8638, 0.8014, 0.7961, 0.8010, 0.7901, 0.7623, 0.9112,\n",
      "         0.7886, 0.8600, 0.8476, 0.8787, 0.8937, 0.8205, 0.7448, 0.8832, 0.8967,\n",
      "         0.7773, 0.7976, 0.8510, 0.8762, 0.8146, 0.7248, 0.8230, 0.8334, 0.8120,\n",
      "         0.8422, 0.7940, 0.7269, 0.7828, 0.9483, 0.8706, 0.9149, 0.8753, 0.7860,\n",
      "         0.7920, 0.7862, 0.8768, 0.7958, 0.8165, 0.7547, 0.7810, 0.8415, 0.8001,\n",
      "         0.8350, 0.7309, 0.8063, 0.7917, 0.7641, 0.7791, 0.6948, 0.8860, 0.7888,\n",
      "         0.7588, 0.8065, 0.8434, 0.8100, 0.7974, 0.8397, 0.8497, 0.8885, 0.7884,\n",
      "         0.7856, 0.8676, 0.8087, 0.9073, 0.8227, 0.8386, 0.8599, 0.8468, 0.8330,\n",
      "         0.8357, 0.8233, 0.8599, 0.7611, 0.8592, 0.9192, 0.8703, 0.8030, 0.8348,\n",
      "         0.7795, 0.8124, 0.7718, 0.9003, 0.7667, 0.7074, 0.7705, 0.7565, 0.9124,\n",
      "         0.7943, 0.7388, 0.7612, 0.8262, 0.8786, 0.8401, 0.8910, 0.8744, 0.8814,\n",
      "         0.9403, 0.7473, 0.7966, 0.8249, 0.8024, 0.7595, 0.7777, 0.9049, 0.8584,\n",
      "         0.8287, 0.8067, 0.8739, 0.8289, 0.8861, 0.8534, 0.8055, 0.9691, 0.8335,\n",
      "         0.8790, 0.9092, 0.8358, 0.8785, 0.7573, 0.8455, 0.8139, 0.8817]],\n",
      "       grad_fn=<ReshapeAliasBackward0>),)\n",
      "tensor([[-0.4102,  0.1892, -0.9911, -1.2879,  2.2679, -0.3048,  1.2347,  0.1838,\n",
      "          1.1189, -1.3296, -0.1687,  1.0213,  1.0838, -0.1892, -0.3753,  0.6737,\n",
      "         -0.2405, -0.0877, -1.6118, -0.4689,  0.6170,  0.3645, -0.5893, -0.8050,\n",
      "          1.3740, -1.2741, -1.1339,  1.7083,  0.3161, -1.1441,  0.5137,  0.3928,\n",
      "          0.0726, -2.0443,  0.4523,  0.2330,  0.4829,  0.1456,  1.0063, -0.2328,\n",
      "          1.7611,  1.1871, -1.2505,  0.4335, -2.1211, -0.3776, -0.8015, -0.5276,\n",
      "          1.8031,  0.6868, -0.3356,  1.4608, -2.0806,  1.4636,  0.0344, -1.1739,\n",
      "          0.3241, -0.0578,  1.6591,  0.2522, -1.1661, -1.6550, -0.2837, -0.6995,\n",
      "         -2.0669,  0.6414, -1.0538, -1.1130,  0.1854,  0.0766, -0.7906, -0.9169,\n",
      "         -0.3436,  0.8871,  0.2179, -1.4328, -0.1542, -1.1207, -0.2463, -1.4205,\n",
      "         -1.9494, -0.5009, -1.0895, -0.6285, -0.5917,  2.6024, -0.7385, -0.2460,\n",
      "         -0.2672,  1.4479, -1.2940, -0.5610, -1.8863,  0.8219,  1.8604,  1.3581,\n",
      "          0.6953,  0.2657,  1.1375, -0.9512, -0.2757, -0.1245, -0.6643, -0.4318,\n",
      "         -0.0063,  0.4427,  1.8223, -0.3553, -2.3187,  1.8572, -0.8868,  0.6631,\n",
      "          0.3915, -1.3451, -0.6719, -0.0272, -0.4296, -0.6763,  1.6225, -0.1266,\n",
      "          0.2198, -1.6800, -0.6060,  1.4174,  1.7909,  1.2580,  0.5010, -0.1489,\n",
      "         -1.0984,  2.0665,  0.8651,  0.1184, -0.1498, -0.1708, -1.0543, -0.1982,\n",
      "         -0.3232,  1.3871, -2.6585,  0.6002, -0.9217,  0.6042,  0.3946,  0.8137,\n",
      "          0.8396,  0.1443, -0.2661, -1.9827,  0.4783,  0.4380,  0.2532, -0.9955,\n",
      "          1.1389, -0.1238,  1.1796,  2.0562,  0.0869, -0.2693, -1.6732,  2.1455,\n",
      "          1.8565,  0.7445,  1.7668, -0.7139,  0.4706,  0.0945, -0.4900,  0.4054,\n",
      "          0.3538,  0.2938, -0.8167,  0.2275,  0.7958,  0.0238,  0.7584,  1.2111,\n",
      "          1.1039,  0.5937,  2.9118, -0.6707,  0.7859, -0.4427,  0.6845,  0.4788,\n",
      "          0.7918, -1.1499, -0.1886, -0.1890, -0.6168,  0.7804,  1.3238,  0.2050,\n",
      "          1.3367, -2.2551,  0.4833, -1.8026,  1.3802,  0.5060, -0.1592, -1.4214,\n",
      "         -0.3130, -1.0844, -0.6552, -0.3197,  0.1209,  0.5092, -0.0374, -3.5802,\n",
      "         -0.8163,  0.1129,  0.2141,  1.0719,  2.2018, -1.5436, -0.6191,  0.5524,\n",
      "          0.6123,  2.1412,  0.8360, -0.8934,  0.2184,  0.2549, -0.1743,  1.4125,\n",
      "          1.9101,  0.3521, -0.2603,  1.5353,  0.3993,  0.5655, -0.7857,  0.6029,\n",
      "         -0.1216,  1.4945, -0.8467,  1.2352, -1.3051,  0.8167, -1.3081,  1.8894,\n",
      "         -0.1564,  1.1043, -1.1795,  0.0148,  1.3797, -0.1098, -0.3952, -2.5933,\n",
      "          0.3678,  1.7800,  1.2844, -0.3929,  0.2860,  0.0068,  0.9964, -0.5429,\n",
      "         -0.1808, -0.6490,  0.5828,  0.9021,  1.2319, -1.5371,  1.0136, -0.5151,\n",
      "         -0.7559, -0.7489, -1.5267, -1.0599,  0.5315, -1.3004,  0.0534,  0.7279,\n",
      "         -0.8422, -0.0343, -1.7255, -1.4484,  0.2001,  2.0992, -0.7200,  1.5669,\n",
      "          0.3701, -0.9973,  0.4962,  0.7862,  0.3264, -1.1247,  0.6303, -0.5686,\n",
      "          0.4775,  0.2134, -0.9464,  1.2656, -0.0253, -0.3426, -0.1185, -1.5977,\n",
      "          1.2669,  0.5837,  0.1246,  2.2984, -0.1748, -0.9294,  1.1724,  0.8338,\n",
      "          0.3735, -0.0864, -0.4755,  2.1938,  0.3391,  0.3913, -0.4195,  0.3683,\n",
      "          1.3061, -0.2264,  0.5579, -0.8381,  0.8261,  0.1669,  1.1224,  0.7948,\n",
      "         -0.4095,  0.8893, -0.3898,  0.7735, -0.0285,  0.5527, -0.5874, -1.0134,\n",
      "          2.1563,  0.8033,  0.9642, -0.2882, -1.4414,  0.3684, -0.1421,  0.7664,\n",
      "         -0.5493,  0.2621,  1.8027,  0.1207, -0.8440, -0.9229, -0.1416,  0.6537,\n",
      "         -0.4305,  0.7595, -0.1010,  0.0317, -1.3116, -1.5386, -1.3025,  1.6489,\n",
      "         -1.1805, -0.1095, -0.1602, -1.9105,  0.3345,  0.0236, -0.2182,  0.5462,\n",
      "          0.5103,  1.1903,  0.9794, -1.5501,  0.3666,  1.2434, -0.6652, -0.7846,\n",
      "         -1.8318, -1.0333, -2.3186,  0.8278, -0.0987, -0.3535,  0.5065,  0.4595,\n",
      "          2.0301,  0.7026, -0.6821,  1.8794, -1.0264,  0.5513, -1.0764, -0.3022,\n",
      "         -0.9392, -2.0181, -0.9082, -0.8433, -0.4172, -0.1322,  1.0828, -0.4843,\n",
      "         -0.3114,  0.7825, -0.7223, -0.0321,  0.6194,  2.3550, -0.0148, -0.5764,\n",
      "         -0.0303, -0.3832,  1.3027, -1.0282, -0.3594, -1.4970,  0.3407,  0.0044,\n",
      "          1.2881, -0.0561,  0.4477, -0.7979, -0.2190,  1.4617,  0.4619,  0.8022,\n",
      "         -1.6490, -0.6635, -0.0793, -0.9548,  1.6657, -0.0050, -0.3861, -0.1872,\n",
      "         -0.4112,  0.5315,  0.8057, -1.6877, -0.1078,  0.0956,  1.7954,  0.0560,\n",
      "         -0.3125, -1.3767, -0.0770, -0.0920, -0.2864,  0.6059,  0.9466, -1.8409,\n",
      "          1.0398, -0.2897,  0.8237,  0.6731,  0.6793, -1.0571, -1.2014,  0.9034,\n",
      "          1.4273,  0.8200, -1.3915,  0.1757,  1.0335,  0.8974,  0.9464, -1.2430,\n",
      "         -0.0472, -0.0523,  0.9795,  1.4826,  0.7318,  0.4194, -0.9082,  0.5449,\n",
      "          0.2996, -0.6716,  0.0870, -0.0138,  0.5131, -1.5406, -0.3361, -0.9784,\n",
      "          0.5914, -0.7567,  0.7995, -0.4053, -0.7787,  0.1404,  0.4595, -0.7505,\n",
      "         -1.3282, -0.0609,  1.9295, -1.3205, -1.5144, -0.5028,  0.2316, -0.2787,\n",
      "          0.2860, -0.7370,  0.3392,  0.6040,  0.8159, -1.2056,  1.1984,  1.1052,\n",
      "          0.3294, -1.3819,  1.2820,  0.3051,  1.0276, -0.4917, -0.1656,  2.4692,\n",
      "          1.7618, -0.2407,  1.5353, -0.6074, -1.5951,  0.1021,  1.2337, -0.1373,\n",
      "         -0.0800, -0.7224, -0.0882,  1.8118, -2.9316,  0.7284, -0.0754, -0.5518,\n",
      "          0.4242, -0.2774,  1.6774, -0.5549, -0.3141,  0.6568,  0.8512, -1.2163,\n",
      "          0.8054, -1.5025, -0.0812,  0.8766, -1.0244,  0.0369, -0.5782,  1.2090,\n",
      "          0.1542,  0.1284,  0.0896, -2.0031,  0.2582, -0.9530, -0.0509, -0.4197,\n",
      "          0.0952,  1.2807, -0.0103, -0.2491,  1.8781, -0.7572,  0.2434, -0.4702,\n",
      "          0.6735,  1.0487, -0.3222, -0.8243,  0.5392,  2.0255,  1.4450,  0.2084,\n",
      "          1.2208,  0.5708,  0.5358,  1.0066, -0.4774,  0.9092, -0.4908,  1.3999,\n",
      "         -1.1409, -1.1193, -1.4266, -0.8998,  1.0208, -0.5942, -1.3884,  0.7649,\n",
      "          2.0273, -0.0559, -0.2158, -0.6125,  1.3521,  1.0142,  0.9197, -0.5825,\n",
      "          0.8956, -0.3918,  1.1574,  0.6602,  0.8713, -0.1672, -0.7020, -1.2291,\n",
      "         -0.4700,  1.2226, -0.8873,  0.2773,  0.0877,  0.9081,  0.8969,  1.0041,\n",
      "         -0.3279,  0.9846, -0.8421, -0.4386,  1.8026,  1.3626, -0.6631, -0.4126,\n",
      "         -0.9697, -1.2285,  0.0941, -0.2320, -0.1844,  0.5098, -1.4865,  0.9801,\n",
      "         -1.1913, -1.3822,  0.1388,  0.4197,  0.8226,  0.7682, -0.1507,  0.6121,\n",
      "         -0.2706,  1.6756, -0.4432,  1.3166,  0.0674, -0.0898,  1.2659, -0.7125,\n",
      "          0.5165,  1.3420, -0.2873,  0.4441,  0.7323, -0.6657,  0.6601, -0.7159,\n",
      "          0.6850, -1.6449,  1.3874,  0.0229, -1.0147,  2.1939, -1.6277, -0.9842,\n",
      "          0.3435, -1.0346,  0.9677, -0.0994, -0.4896, -0.0355, -1.2261, -1.4999,\n",
      "          0.7072,  1.2846, -1.3663,  0.7805,  0.1484,  0.4766, -0.9676,  1.0143,\n",
      "         -1.2287, -0.2248, -0.7337, -0.5725,  0.2522, -2.1520,  0.4767,  0.8189,\n",
      "          2.2724, -1.2391,  0.0878,  1.2516, -0.6317, -0.2531, -0.3178, -0.7447,\n",
      "          1.3067, -0.6358, -0.9103, -1.9958, -0.0915,  1.0598, -0.6252, -0.0694,\n",
      "         -0.0734,  1.6955, -0.6087,  0.2889, -0.0793, -0.6368, -0.3649,  0.9647,\n",
      "         -0.3509, -0.5547, -0.2097, -0.7127, -0.0717, -0.7789, -0.0453,  0.4958,\n",
      "         -1.1251,  1.2119, -1.2358, -1.1526,  0.0330, -0.8638,  0.6675,  0.6677,\n",
      "         -0.5839,  1.2367,  2.6279,  0.7930,  2.0782, -0.0100,  1.6222,  0.0080,\n",
      "          0.3754, -0.3848, -0.2531,  1.5160, -0.6375,  0.5688, -0.1722,  2.4227,\n",
      "          0.8996,  1.2263, -1.1791, -0.6370,  1.2540, -0.6317, -1.1058, -1.2017,\n",
      "         -0.9323,  0.6124, -1.4342,  0.4245,  0.1463, -2.0511,  0.3239,  0.3638,\n",
      "          0.7883, -0.0253, -0.0530,  0.1049, -0.8116,  0.3864, -0.2524,  0.9686,\n",
      "         -0.9544, -0.1699, -0.5230, -2.6407,  0.1025, -1.2983, -0.8997,  0.5467,\n",
      "          0.3641,  0.8358,  0.9523, -1.4804, -1.0237,  0.6871, -1.0470,  0.7338,\n",
      "          1.2517,  1.1052, -1.3629, -1.8169,  0.3554,  0.0530,  0.3553, -0.0225,\n",
      "         -0.8726,  0.8612, -2.5425, -0.7023,  1.5286,  2.5729, -0.0166, -0.5674,\n",
      "         -1.1161,  0.7679, -2.3761, -0.3078, -0.8724,  0.4342, -1.2957,  0.1076,\n",
      "         -1.4245, -0.2187,  0.2879, -0.8208,  1.0227, -0.8979, -1.1358,  0.1281,\n",
      "          1.2541,  1.1458,  1.8974, -0.1502,  1.4384,  0.9894, -0.4055, -1.5137,\n",
      "          1.6724,  0.5932,  0.6342, -0.4665, -1.3559, -0.0199, -0.0888, -0.6699,\n",
      "         -2.3921, -1.0933, -0.9334,  0.5294, -1.1126,  0.2267,  1.5811, -0.0287,\n",
      "         -1.2786,  1.1103,  0.1909, -0.3571, -0.0912, -1.1504,  0.8779,  1.3112,\n",
      "          0.3581, -1.0474, -1.8532, -0.4505, -1.4553, -0.0143,  1.0844, -0.7190,\n",
      "         -0.2350, -0.4283, -1.8466, -0.0199, -0.2391, -1.1625, -1.4255,  1.1461,\n",
      "         -0.1026, -0.6079,  1.0222, -1.1114, -0.5244,  0.2445, -1.1349,  0.1174,\n",
      "          0.2531,  1.7764,  0.2441,  0.5711,  0.9178,  0.0689, -1.2594,  0.4025,\n",
      "         -0.6482, -0.2456, -0.0389,  0.3039,  1.6204,  1.1702,  0.7346,  0.4317,\n",
      "         -0.0716, -0.4797, -0.9439, -0.7187,  0.1780, -0.9133,  0.0889,  0.1299,\n",
      "         -0.3077,  0.9717,  1.0301,  0.5767,  0.4830,  0.4928, -0.9597, -0.7423,\n",
      "          0.3743,  0.9873,  0.2351, -1.0977, -0.4252, -1.3371, -0.0908, -0.8722,\n",
      "         -1.2962,  1.3510, -1.0333, -0.3710, -0.4881,  0.4680, -0.5974, -1.4830,\n",
      "          1.5034,  1.1573, -1.0161,  2.1153,  0.6000,  0.2920,  1.8887, -1.5930,\n",
      "         -2.2816, -1.5226, -0.4186,  1.1591, -0.5366, -0.6058,  2.3232,  0.1478,\n",
      "         -0.6004, -0.2120, -0.8848, -0.0936, -1.0504, -1.5713, -0.0895, -0.5271,\n",
      "          0.3216,  0.9871, -0.6465, -0.3300, -3.8550, -0.5805,  1.3032, -1.3558,\n",
      "          0.2498, -0.4552,  0.4226,  0.4602, -1.5245, -0.8058,  1.6946,  1.2386,\n",
      "         -0.8612, -0.1468, -0.9779,  0.8212, -0.3896, -0.2896, -1.2956,  0.6387,\n",
      "         -0.7257, -1.2590, -0.1129, -0.3330,  0.7949, -1.4961,  1.2990,  0.7630,\n",
      "          1.1952,  2.2159, -0.0953,  0.7936, -0.0645, -0.6857, -0.0052,  1.4841,\n",
      "         -1.2612,  1.5794, -0.6315, -0.8172, -0.4140, -0.3967,  1.1929,  0.3953,\n",
      "         -0.1579, -0.4615, -0.0236,  0.9323,  0.1073, -0.5751, -0.3332,  0.0383,\n",
      "         -1.8391,  1.5512,  0.1321,  0.9558,  0.3887,  0.6178, -0.8835, -0.5758,\n",
      "          0.5879, -0.9036,  0.9668, -1.7434,  1.0907, -1.3430, -0.3440,  0.3020]],\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(a(input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print({name: output.shape for name, output in features.items()})\n",
    "# print(features['fc'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(a)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a1f418ccde77a2e74e891fecf9609049497d17ad595ac488b9eac76325cbe8c8"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 ('IL')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
